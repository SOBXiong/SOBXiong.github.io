{"meta":{"title":"SOBXiong的博客","subtitle":"","description":"一只编程菜鸡，对Android、Java后端、大数据和Vue雨露均沾","author":"SOBXiong","url":"https://sobxiong.github.io","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-06-23T14:47:17.665Z","updated":"2020-06-23T14:47:17.656Z","comments":true,"path":"404.html","permalink":"https://sobxiong.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-06-23T14:45:30.095Z","updated":"2020-06-23T14:45:30.085Z","comments":true,"path":"about/index.html","permalink":"https://sobxiong.github.io/about/index.html","excerpt":"","text":"一只编程菜鸡，对Android、Java后端、大数据和Vue雨露均沾"},{"title":"所有分类","date":"2020-06-23T14:46:03.448Z","updated":"2020-06-23T14:46:03.438Z","comments":true,"path":"categories/index.html","permalink":"https://sobxiong.github.io/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-06-23T14:46:49.268Z","updated":"2020-06-23T14:46:49.258Z","comments":true,"path":"tags/index.html","permalink":"https://sobxiong.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JavaScript基础","slug":"FrontEnd/Basic/JavaScript基础","date":"2021-02-18T03:43:21.000Z","updated":"2021-03-01T14:00:14.178Z","comments":true,"path":"2021/02/18/FrontEnd/Basic/JavaScript基础/","link":"","permalink":"https://sobxiong.github.io/2021/02/18/FrontEnd/Basic/JavaScript%E5%9F%BA%E7%A1%80/","excerpt":"内容 介绍 基本语法 对象 DOM 事件","text":"内容 介绍 基本语法 对象 DOM 事件 介绍 ECMAScript：ECMAScript是一个标准，而这个标准需要由各个厂商去实现，其中Chrome浏览器的JavaScript的实现方式为v8 JavaScript组成：ECMAScript、DOM、BOM JavaScript特点： 解释型语言(无需被解释为机器码再执行,直接执行;运行较慢,但使用了JIT技术得以改善) 动态语言(相比静态语言性能较差) 基于原型的面向对象 类似C、Java的语法结构 基本语法 编写位置：学习的JS都是客户端的JS(浏览器中运行)，因此要在网页中编写。JS代码需要编写到&lt;script&gt;标签中(一般写到&lt;head&gt;中;type————默认为text/javascript,可写不写;src————引入外部js文件时的文件路径) 注释：同Java，单行注释为//，多行为/**/ 变量： 使用var关键字进行申明 数据类型 五种基本数据类型(不可变,保存在栈中)： 字符串型(String) 用于表示一个字符序列(字符串)；需用’或”括起来；也有转义字符(\\打头) 将其他值转为字符串的三种方式：toString()、String()、拼串 数值型(Number) 表示整数和浮点数；表示的数字大小是有限的，越界会返回±Infinity NaN(Not a Number)是一个特殊的值，对数值进行计算时没有结果则返回NaN 将非数值转为数值的三个函数：Number()、parseInt()、parseFloat()，前者用于转换任意类型，后者只适用于字符串 布尔型(Boolean) 只能取true和false两种；其他数据类型可通过Boolean()函数转换 转换规则如下： 数据类型 true false String 非空字符串 “”(空串) Number 非0值 0或NaN Object 任意对象 null Undefined / undefined null型(Null) 只有一个值null；null表示一个空对象，使用typeof检查null会返回一个Object undefined值实际上是由null值衍生出的，比较undefined和null相等时会返回true undefined型(Undefined) 只有一个值，即特殊的undefined；在使用var声明变量但未对其初始化时，该变量值即为undefined typeof对没有初始化和没有声明的变量都返回undefined Object类型(除上五种外的其他) typeof：类似于C，可用来检查一个变量的数据类型 instanceof：任意对象使用typeof都返回Object；获取对象的具体类型可使用instanceof运算符————变量 instanceof 类型 运算符 相等 / 不相等：==(null和undefined返回true) / != 全等 / 不全等：===(==在判断两个值时会进行自动的类型转换,===不会) / !== “55”==55(true)；”55”===55(false) 对象 Object对象 介绍：是JavaScript中的引用数据类型；是一种复合值；可看作属性的无序集合，每个属性都是名值对；除创建自有属性，还可从名为原型的对象那继承属性；除字符串、数字、true、false、null和undefined外的所有值都是对象 创建对象的两种方式： 12345678var person = new Object();person.name = \"SOBXiong\";person.age = 24;var person = &#123; name:\"SOBXiong\", age:24&#125; 属性： 属性的访问 .访问：对象.属性名 []访问：对象[‘属性名’] 修改属性值：对象.属性名 = 属性组 删除属性：delete 对象.属性名 constructor：每个对象中都有一个constructor属性，它引用了当前对象的构造函数 引用数据类型(栈保存对象地址;堆保存对象)： 引用类型的值是保存在内存中的对象 当变量是对象时，实际上变量中保存的并不是对象本身，而是对象的引用 当变量向另一个变量复制引用类型的值时，会将对象的引用复制到变量中而不是创建一个新的对象。此时两个变量指向的是同一个对象，改变其中一个变量会影响另一个 基本包装类型：基本数据类型不能调用方法，JS提供了三个特殊的引用类型(typeof返回均为object)： Boolean： 12// 最好不要使用var bObj = new Boolean(true); Number 12// 使用数值时建议使用基本而非包装类var nObj = new Number(20); String：var sObj = new String(&quot;Hello world&quot;); Math对象： 介绍：JS为保存数学公式和信息提供了一个公共位置；比直接编写的计算功能要快 常用方法： Math.max()：最大值 Math.min()：最小值 Math.ceil()：向上舍 Math.floor()：向下舍 Math.round()：四舍五入 Math.random()：随机数 Array(数组)： 介绍：一种对象；一种表达有顺序关系的值的集合的数据结构；JS的数组可保存任意类型的数据 创建方式： 123456// 使用构造器var array = new Array(len);var array = new Array(123, \"hello\", true);// 使用[]var array = [];var array = [2, 3, 4]; Date(时间)： 介绍：采取时间戳形式表示时间(从1970年1月1日0分0秒开始经过的毫秒数) 创建方式： 12345// 当前默认时间var date = new Date();var date = new Date(miliseconds);// 格式为月/日/年 时:分:秒的字符串构造函数var date = new Date(02/18/2021 10:10:10); Function(函数)： 介绍：一种对象；函数也存储在堆中；参数传递都是按值传递；函数可作为参数传递；函数作为参数时后加()表示将函数执行的结果作为参数，否则将函数本身作为参数 声明方式： 12345var sumFunc1 = function(a, b) &#123;return a + b&#125;;// 存在函数声明提升,该方式在函数声明前就可调用函数,上种方式则不行function sumFunc2(a, b)&#123; return a + b;&#125; 执行环境(类似作用域)： 执行环境定义了变量或函数有权访问的其他数据，决定了它们各自的行为 每个执行环境都有一个与之关联的变量对象，环境中定义的所有变量和函数都保存在这个对象中 全局执行环境是最外围的一个执行环境。在浏览器中，全局执行环境被认为是window对象，因此所有全局变量和函数都是作为window对象的属性和方法创建 某个执行环境中的所有代码执行完毕后，该环境被销毁，保存在其中的所有变量和函数定义也随之销毁 在内部环境可以读取外部环境的变量，反之则不行 内部属性(特殊对象)： arguments：一个数组，用于保存函数的参数；同时该对象还有callee表示当前函数 this： this引用的是一个对象。对于最外层代码与函数内部的情况，其引用目标是不同的 即使在函数内部，根据函数调用方式的不同，引用对象也会有所不同。this引用会根据代码的上下文语境自动改变其引用对象 在最外层代码中，this引用的是全局对象 在函数内，this根据函数调用方式的不同而有所不同，具体如下表所示： 函数调用方式 this引用的对象 构造函数 所生成的对象 调用对象的方法 当前对象 apply或call调用 参数指定的对象 其他方式 全局对象(window) 构造函数： 介绍： 用于生成对象的函数，例如new Object() 通过new关键字调用；new中this引用了被生成的对象 任何函数都可通过new来调用，函数都可是构造函数 声明方式： 1234function Test(x, y) &#123; this.x = x; this.y = y;&#125; 函数对象的方法： call()：函数对象.call(this对象, 参数数组) apply()：函数对象.apply(this对象, 参数1, 参数2…) 每个函数都有两个方法call()和apply()，其可指定一个函数的运行环境对象————this 闭包(closure)：当前作用域总是能够访问外部作用域中的变量。由于函数是JS中唯一拥有自身作用域的结构，闭包的创建依赖于函数。可将闭包的特征理解为————相关的局部变量在函数调用结束之后将会继续存在 原型：JS是一个基于原型的面向对象语言 原型介绍：在构造函数中存在着一个名为原型(prototype)的对象，该对象中保存着一些属性。凡是通过该构造函数创建的对象都可以访问存在于原型中的属性 原型属性举例：toString()————实际上对象中并没有定义这个函数，但却可以调用。因为该函数存在于Object对应的原型中 原型获取： 构造函数.prototype 原型就是一个对象，和其他对象没有任何区别，可通过构造函数来获取原型对象。prototype属性只存在于函数对象中，其他对象是没有prototype属性的 Object.getPrototypeOf(对象) 对象._proto 对象.constructor.prototype 和其他对象一样，可添加、修改、删除原型中的属性，也可修改原型对象的引用每个对象都有原型，原型对象也有原型。特殊的是，Object的原型对象没有原型可获取Object的原型对象，也可对它的属性进行操作，但不能修改Object原型对象的引用 原型链：对象、对象的原型、原型的原型…当从一个对象中获取属性时，首先从当前对象中查找，如果未找到则顺着向上查找原型对象，直到找到Object对象的原型位置，找到则返回，找不到则返回undefined DOM 介绍：DOM(Document Object Model)为文档对象模型；JavaScript可通过DOM对HTML文档进行操作 文档：整个HTML网页文档 对象：网页中的每一个部分都转换为一个对象 模型：表示对象之间的关系 节点(Node)：节点是构成网页的最基本的组成部分(构成HTML文档最基本的单元)，网页中的每一个部分都可称为一个节点————比如HTML标签、属性、文本、注释、整个文档等。节点具有不同的类型、属性和方法 常用节点分类： 文档节点：整个HTML文档 文档节点document代表的是整个HTML文档，网页中所有节点都是它的子节点document对象作为window对象的属性存在，不用获取即可直接使用通过该对象可以在整个文档内查找节点对象，并可通过该对象创建各种节点对象 元素节点：标签 HTML中的各种标签都是元素节点，这也是最常用的一个节点浏览器会将页面中所有的标签都转换为一个元素节点，可通过document的方法来获取元素节点，比如document.getElementById() 属性节点：元素的属性 属性节点表示的是标签中的属性；属性节点并非元素节点的子节点，而是元素节点的一部分可通过元素节点来获取指定的属性节点，比如元素节点.getAttributeNode(&quot;属性名&quot;)。一般不使用属性节点 文本节点：标签中的文本内容 文本节点表示的是HTML标签以外的文本内容，任意非HTML的文本都是文本节点它包括字面解释的纯文本内容；文本节点一般是作为元素节点的子节点存在的获取文本节点时，一般先要获取元素节点再通过元素节点获取文本节点，比如元素节点.firstChild 节点属性： nodeName nodeType nodeValue 文档节点 #document 9 null 元素节点 标签名 1 null 属性节点 属性名 2 属性值 文本节点 #text 3 文本内容 相应API： 获取元素节点(通过document对象调用)： getElementById()：通过id属性获取一个元素节点对象 getElementsByTagName()： 通过标签名获取一组元素节点对象 getElementsByName()：通过name属性获取一组元素节点对象 获取元素节点的子节点(通过具体元素节点调用)： getElementsByTagName()：返回当前节点的指定标签名的后代节点 childNodes(属性)：所有子节点 firstChild(属性)：第一个子节点 lastChild(属性)：最后一个子节点 获取父节点和兄弟节点(通过具体节点调用)： parentNode：父节点 previousSibling：前一个兄弟节点 nextSibling：后一个兄弟节点 元素节点的属性： 获取：element.xxx 设置：element.xxx = xxx 节点的修改： 创建节点：document.createElement(标签名) 删除节点：父节点.removeChild(子节点) 替换节点：父节点.replaceChild(新节点, 旧节点) 插入节点： 12父节点.appendChild(子节点)父节点.insertBefore(新节点, 旧节点) 其他属性： nodeValue：文本节点可通过该属性获取和设置文本节点的内容 innerHTML：元素节点可通过该属性获取和设置标签内部的HTML代码 事件 介绍：事件是文档或浏览器窗口中发生的一些特定的交互瞬间。JavaScript与HTML之间的交互是通过事件实现的。通过为指定事件绑定回调函数的形式来处理事件，当指定事件触发以后回调函数就会被调用，如此页面就可以完成和用户的交互 事件处理程序： 通过HTML元素指定事件属性绑定：&lt;button onclick=&quot;alert(&#39;hello&#39;);alert(&#39;world&#39;)&quot;&gt;按钮&lt;/button&gt; 示例代码会使点击按钮后，onclick属性中的JavaScript代码将会执行 除了直接将代码编写到onclick属性中，也可事先在外部定义函数 如果在函数最后添加return false，会取消元素默认行为 通过DOM对象指定属性绑定(推荐) 1234var btn = document.getElementById(\"btn\");btn.onClick = function()&#123; alert(\"Hello~~~\");&#125;; 这种方法可将HTML代码和JavaScript设置在不同的地方，方便维护 设置事件监听器：元素对象.addEventListener() 前两种方式都可以绑定事件处理程序，但是它们都只能绑定一个程序，而不能为一个事件绑定多个程序 此时可使用addEventListener()来处理，该函数需要两个参数：事件字符串和响应函数————btn.addEventListener(&#39;click&#39; , function() { alert(&quot;hello&quot;); }); 可使用removeEventListener()和detachEvent()移除事件 事件处理中的this：事件处理程序内的this所引用的对象即是设定了该事件处理程序的元素 事件对象：","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"https://sobxiong.github.io/tags/FrontEnd/"}]},{"title":"Spring源码分析","slug":"SpringSeries/Spring/Spring源码分析","date":"2021-02-16T03:25:14.000Z","updated":"2021-03-04T03:50:09.817Z","comments":true,"path":"2021/02/16/SpringSeries/Spring/Spring源码分析/","link":"","permalink":"https://sobxiong.github.io/2021/02/16/SpringSeries/Spring/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"内容 总体流程 资源加载 解析XML 解析Bean 加载Bean","text":"内容 总体流程 资源加载 解析XML 解析Bean 加载Bean 总体流程 说明：本文环境Spring版本5.3.1 分析入口： 123456@Testpublic void testGetBean() &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"test1.xml\"); TestBean testBean = context.getBean(TestBean.class); System.out.println(\"testBean = \" + testBean);&#125; ClassPathXmlApplicationContext构造函数： 1234567891011// ClassPathXmlApplicationContext.javapublic ClassPathXmlApplicationContext(String configLocation) throws BeansException &#123; this(new String[] &#123;configLocation&#125;, true, null);&#125;public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125;&#125; 首先调用setConfigLocations(String[])方法设置配置路径接着调用refresh()方法实现扩展功能，其中包括最重要的加载bean容器过程 setConfigLocations()方法： 1234567891011121314151617181920212223242526272829// AbstractRefreshableConfigApplicationContext.java// 设置应用程序上下文的配置路径public void setConfigLocations(@Nullable String... locations) &#123; if (locations != null) &#123; Assert.noNullElements(locations, \"Config locations must not be null\"); this.configLocations = new String[locations.length]; for (int i = 0; i &lt; locations.length; i++) &#123; this.configLocations[i] = resolvePath(locations[i]).trim(); &#125; &#125; else &#123; this.configLocations = null; &#125;&#125;// AbstractRefreshableConfigApplicationContext.java// 解析给定的路径,用相应的环境属性值替换占位符($&#123;&#125;)protected String resolvePath(String path) &#123; return getEnvironment().resolveRequiredPlaceholders(path);&#125;// AbstractApplicationContext.java// 创建应用环境信息,包括SystemProperties以及SystemEnvironment信息@Overridepublic ConfigurableEnvironment getEnvironment() &#123; if (this.environment == null) &#123; this.environment = createEnvironment(); &#125; return this.environment;&#125; setConfigLocations(String[])方法用于解析给定的路径数组，如果路径中包含占位符(${})，那么会尝试利用系统配置信息和系统环境信息进行解析可能的系统配置信息和系统环境信息如下： refresh()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 加载或刷新配置的持久表示(可来自基于Java配置、XML文件、属性文件、关系数据库模式或其他格式) * 由于这是一个启动方法,如果失败它应该销毁已经创建的单例以避免挂起资源 * 换句话说,在调用这个方法之后,要么全部实例化,要么根本不实例化 * 如果无法初始化BeanFactory,抛出BeansException * 如果已初始化且不支持多次刷新,抛出IllegalStateException */// AbstractApplicationContext.javapublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(\"spring.context.refresh\"); // 准备刷新的上下文环境 prepareRefresh(); // 初始化BeanFactory,进行XML文件读取 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 对BeanFactory进行各种功能填充 prepareBeanFactory(beanFactory); try &#123; // 子类覆盖方法 postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(\"spring.context.beans.post-process\"); // 激活各种BeanFactory处理器 invokeBeanFactoryPostProcessors(beanFactory); // 注册拦截Bean创建的处理器(BeanPostProcessor) registerBeanPostProcessors(beanFactory); beanPostProcess.end(); // 为上下文初始化Message源,用于国际化处理 initMessageSource(); // 初始化应用消息广播器 initApplicationEventMulticaster(); // \b刷新结束的回调函数,交由子类实现 onRefresh(); // 在注册的Bean中查找Listener类型的bean实例并注册到消息广播器中 registerListeners(); // 初始化剩下所有的非惰性单例Bean finishBeanFactoryInitialization(beanFactory); // 完成刷新过程,通知生命周期处理器lifecycleProcessor刷新过程,发出ContextRefreshEvent通知 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // 销毁bean实例 destroyBeans(); // 取消刷新 cancelRefresh(ex); throw ex; &#125; finally &#123; resetCommonCaches(); contextRefresh.end(); &#125; &#125;&#125; refresh()方法包含了几乎ApplicationContext中提供的全部功能 prepareRefresh()方法： 12345678910111213141516171819202122232425262728// AbstractApplicationContext.java// 准备刷新的上下文环境protected void prepareRefresh() &#123; // 记录启动时间 this.startupDate = System.currentTimeMillis(); // 设置context状态 this.closed.set(false); this.active.set(true); if (logger.isDebugEnabled()) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Refreshing \" + this); &#125; else &#123; logger.debug(\"Refreshing \" + getDisplayName()); &#125; &#125; // 初始化上下文环境中任何占位符属性来源 // 留给子类覆盖 initPropertySources(); // 校验需要的配置属性是否已存在于Enviroment中 getEnvironment().validateRequiredProperties(); if (this.earlyApplicationListeners == null) &#123; this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();&#125; prepareRefresh()方法主要有两个较大作用的方法： initPropertySources()方法：用户可根据需要重写该方法进行个性化属性处理(如环境变量中必须设置某个值才能运行)，这给予用户了最大扩展Spring能力 validateRequiredProperties()方法：对属性进行验证 obtainFreshBeanFactory()方法： 123456789101112131415161718192021222324252627282930313233// AbstractApplicationContext.java// 通知子类刷新内部BeanFactory并返回protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // 初始化BeanFactory,进行XML文件读取,将BeanFactory赋值给属性 refreshBeanFactory(); return getBeanFactory();&#125;// AbstractRefreshableApplicationContext.java// 执行上下文底层BeanFactory的实际刷新：关闭以前可能有的BeanFactory,初始化新的BeanFactory@Overrideprotected final void refreshBeanFactory() throws BeansException &#123; // 如果存在以前的BeanFactory if (hasBeanFactory()) &#123; // 销毁Bean实例 destroyBeans(); // 关闭以前的BeanFactory closeBeanFactory(); &#125; try &#123; // 创建DefaultListableBeanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); // 设置序列化id(反序列化用) beanFactory.setSerializationId(getId()); // 定制化BeanFactory,设置相关属性(是否允许覆盖名称、是否允许循环依赖) customizeBeanFactory(beanFactory); // 初始化DocumentReader,进行XML文件读取并解析 loadBeanDefinitions(beanFactory); this.beanFactory = beanFactory; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); &#125;&#125; ApplicationContext是对BeanFactory功能上的扩展，不但包含BeanFactory的全部功能更在其基础上添加了大量扩展。ApplicationContext通过组合BeanFactory的方式进行复用obtainFreshBeanFactory()方法将核心实现委托给refreshBeanFactory()方法 createBeanFactory()方法： 1234567891011121314151617181920212223242526272829// AbstractRefreshableApplicationContext.java// 为上下文创建内部BeanFactoryprotected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory());&#125;// DefaultListableBeanFactory.javapublic DefaultListableBeanFactory(@Nullable BeanFactory parentBeanFactory) &#123; super(parentBeanFactory);&#125;// AbstractAutowireCapableBeanFactorypublic AbstractAutowireCapableBeanFactory(@Nullable BeanFactory parentBeanFactory) &#123; this(); setParentBeanFactory(parentBeanFactory);&#125;// AbstractAutowireCapableBeanFactorypublic AbstractAutowireCapableBeanFactory() &#123; super(); ignoreDependencyInterface(BeanNameAware.class); ignoreDependencyInterface(BeanFactoryAware.class); ignoreDependencyInterface(BeanClassLoaderAware.class); if (IN_NATIVE_IMAGE) &#123; this.instantiationStrategy = new SimpleInstantiationStrategy(); &#125; else &#123; this.instantiationStrategy = new CglibSubclassingInstantiationStrategy(); &#125;&#125; createBeanFactory()方法最终构造了DefaultListableBeanFactory并传入可能有的父容器。在构造器链中，AbstractAutowireCapableBeanFactory的无参构造器中做了一些设置：忽略给定接口的自动装配功能(BeanNameAware.class、BeanFactoryAware.class以及BeanClassLoaderAware.class)、设置Bean实例化策略(instantiationStrategy) customizeBeanFactory()方法： 1234567891011// AbstractRefreshableApplicationContext.javaprotected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; // 是否允许覆盖同名称的不同定义的对象,默认null if (this.allowBeanDefinitionOverriding != null) &#123; beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // 是否允许bean之间存在循环依赖,默认null if (this.allowCircularReferences != null) &#123; beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125;&#125; loadBeanDefinitions()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// AbstractXmlApplicationContext.java// 通过XmlBeanDefinitionReader加载BeanDefinition@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // 为给定的BeanFactory创建XmlBeanDefinitionReader XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // 设置beanDefinitionReader的环境变量 beanDefinitionReader.setEnvironment(this.getEnvironment()); // 设置beanDefinitionReader的资源加载器 beanDefinitionReader.setResourceLoader(this); // 设置beanDefinitionReader的实体解析器 beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 初始化BeanDefinitionReader,允许子类覆盖 initBeanDefinitionReader(beanDefinitionReader); // 真正执行加载BeanDefinition loadBeanDefinitions(beanDefinitionReader);&#125;// XmlBeanDefinitionReader.javapublic XmlBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; super(registry);&#125;// AbstractBeanDefinitionReader.javaprotected AbstractBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); this.registry = registry; if (this.registry instanceof ResourceLoader) &#123; this.resourceLoader = (ResourceLoader) this.registry; &#125; else &#123; this.resourceLoader = new PathMatchingResourcePatternResolver(); &#125; if (this.registry instanceof EnvironmentCapable) &#123; this.environment = ((EnvironmentCapable) this.registry).getEnvironment(); &#125; else &#123; this.environment = new StandardEnvironment(); &#125;&#125;// AbstractXmlApplicationContext.javaprotected void initBeanDefinitionReader(XmlBeanDefinitionReader reader) &#123; // 设置XML解析的验证方式,默认为true reader.setValidating(this.validating);&#125;// AbstractXmlApplicationContext.javaprotected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; // 通过资源加载BeanDefinition reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; // 通过配置文件路径加载BeanDefinition reader.loadBeanDefinitions(configLocations); &#125;&#125; loadBeanDefinitions()方法创建了XmlBeanDefinitionReader，并对其进行了一系列的设置，接下来将委托该对象进行XML的解析与BeanDefinition的加载工作，这是IOC的核心 prepareBeanFactory()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// AbstractApplicationContext.java// 配置BeanFactory的上下文特性,如类加载器和后处理器protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // 设置类加载器classLoader beanFactory.setBeanClassLoader(getClassLoader()); if (!shouldIgnoreSpel) &#123; // 设置BeanFactory的表达式语言处理器(SpEL) beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); &#125; // 为BeanFactory设置默认属性编辑器(对bean属性等设置管理的工具) beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 添加ApplicationContextAwareProcessor beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 设置几个忽略自动装配的接口 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); beanFactory.ignoreDependencyInterface(ApplicationStartup.class); // 设置几个自动装配的特殊规则(可自动装配但在BeanFactory中没有定义为Bean) beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 注册早期后处理器ApplicationListenerDetector检查ApplicationListener类型的内部Bean beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // 增加对AspectJ的支持 if (!IN_NATIVE_IMAGE &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // 为类型匹配设置临时类加载器 beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // 注册默认的系统环境Bean if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125; if (!beanFactory.containsLocalBean(APPLICATION_STARTUP_BEAN_NAME)) &#123; beanFactory.registerSingleton(APPLICATION_STARTUP_BEAN_NAME, getApplicationStartup()); &#125;&#125; prepareBeanFactory()方法主要填充了BeanFactory的功能(具体参见注释)其中Spring表达式语言全称为Spring Expression Language(SpEL)，能在运行时构建复杂表达式、存取对象图属性、对象方法调用等。SpEL使用#{}作为定界符，大括号中的字符都将被认为是SpELPropertyEditor属性编辑器用于将XML中的String转为特定类的对象，可以通过继承PropertyEditorSupport类并注册实现该功能xxxAwareProcessor后置处理器用于将实现xxxAware的bean初始化时设置相应的资源xxxAwareProcessor注册后，间接调用的xxxAware类已经不是普通的bean了，因此无需在依赖注入时考虑 postProcessBeanFactory()方法： 123456789/** * 在标准初始化后修改ApplicationContext内部的BeanFactory * 将加载所有BeanDefinition,但尚未实例化任何Bean * 这允许在特定ApplicationContext实现中注册特定的BeanPostProcessor等 * * 目前空实现,交由子类实现 */// AbstractApplicationContext.javaprotected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123;&#125; invokeBeanFactoryPostProcessors()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142/** * 实例化并调用所有已注册的BeanFactoryPostProcessor的Bean实例,按照给定的显式顺序(如果给定) * 必须在单例Bean实例化之前调用 */// AbstractApplicationContext.javaprotected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; // 委托PostProcessorRegistrationDelegate调用BeanFactoryPostProcessor PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // 检测LoadTimeWeaver并准备将来的方法织入 if (!IN_NATIVE_IMAGE &amp;&amp; beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125;// 调用BeanFactoryPostProcessor// PostProcessorRegistrationDelegate.javapublic static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // 如果有,先调用BeanDefinitionRegistry Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); // 如果beanFactory是BeanDefinitionRegistry类型 if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); // 遍历硬编码注册的后处理器 for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; // 对于BeanDefinitionRegistryPostProcessor类型,在BeanFactoryPostProcessor基础上还有自定义的方法,需要先调用 registryProcessor.postProcessBeanDefinitionRegistry(registry); // 记录BeanDefinitionRegistry registryProcessors.add(registryProcessor); &#125; else &#123; // 记录常规BeanFactoryPostProcessor regularPostProcessors.add(postProcessor); &#125; &#125; /** * 不要在这里初始化Factory Bean：需要将所有常规Bean保持为初始化状态,以便BeanFactoryPostProcessor应用于它们 * 分离实现PriorityOrdered、Ordered接口和其他的BeanDefinitionRegistryPostProcessor */ List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // 首先调用实现了PriorityOrdered接口的BeanDefinitionRegistryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry, beanFactory.getApplicationStartup()); currentRegistryProcessors.clear(); // 接着调用实现了Ordered接口的BeanDefinitionRegistryPostProcessor postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry, beanFactory.getApplicationStartup()); currentRegistryProcessors.clear(); // 最终调用所有其他BeanDefinitionRegistryPostProcessor,直到不再出现其他BeanDefinitionRegistryPostProcessor boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry, beanFactory.getApplicationStartup()); currentRegistryProcessors.clear(); &#125; // 现在调用到目前为止处理的所有处理器的postProcessBeanFactory回调 invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // 调用在context实例中注册的工厂处理器 invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // 跳过,已在上面第一阶段处理过 &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size()); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size()); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // 清除缓存的MergedBeanDefinition,因为后处理器可能已修改了原始的元数据,例如替换值中的占位符... beanFactory.clearMetadataCache();&#125;// 调用给定的BeanDefinitionRegistryPostProcessor类型的Bean实例// PostProcessorRegistrationDelegate.javaprivate static void invokeBeanDefinitionRegistryPostProcessors(Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry, ApplicationStartup applicationStartup) &#123; for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; StartupStep postProcessBeanDefRegistry = applicationStartup.start(\"spring.context.beandef-registry.post-process\").tag(\"postProcessor\", postProcessor::toString); postProcessor.postProcessBeanDefinitionRegistry(registry); postProcessBeanDefRegistry.end(); &#125;&#125;// 调用给定的BeanFactoryPostProcessor类型的Bean实例// PostProcessorRegistrationDelegate.javaprivate static void invokeBeanFactoryPostProcessors(Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123; for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123; StartupStep postProcessBeanFactory = beanFactory.getApplicationStartup().start(\"spring.context.bean-factory.post-process\").tag(\"postProcessor\", postProcessor::toString); postProcessor.postProcessBeanFactory(beanFactory); postProcessBeanFactory.end(); &#125;&#125; 对于BeanFactoryPostProcessor的处理分两种情况处理，一种是对BeanDefinitionRegistryPostProcessor类的特殊处理，另一种是普通的BeanFactoryPostProcessor的处理。对于每种情况都需要考虑硬编码以及配置注入的后处理器：硬编码注入一般通过AbstractApplicationContext的addBeanFactoryPostProcessor()方法添加接着每种情况都进行排序(除了没实现PriorityOrdered以及Ordered接口)，接着统一调用postProcessBeanDefinitionRegistry()或postProcessBeanFactory()方法 registerBeanPostProcessors()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 实例化并注册所有BeanPostProcessor的Bean实例,按照给定的显式顺序(如果给定) * 必须在任何应用程序Bean实例化之前调用 */// AbstractApplicationContext.javaprotected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125;// PostProcessorRegistrationDelegate.javapublic static void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 获取通过配置文件注入的BeanPostProcessor名称 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // 统计BeanPostProcessor数目：硬编码 + BeanPostProcessorChecker + 配置文件 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; // 注册BeanPostProcessorChecker,当BeanPostProcessor实例化期间创建bean时(即当一个bean没有资格被所有BeanPostProcessor处理时),它会记录一条信息 beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // 分离实现PriorityOrdered、Ordered接口和其他的BeanPostProcessor List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // 首先注册实现了PriorityOrdered接口的BeanPostProcessor sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // 接着注册实现了Ordered接口的BeanPostProcessor List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size()); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // 接着注册所有其他BeanPostProcessor List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size()); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // 最后再注册所有的内部BeanPostProcessor(MergedBeanDefinitionPostProcessor类型) // 并非重复注册,addBeanPostProcesor中会先移除已存在的BeanPostProcessor sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // 添加用于检测内部Bean实例为ApplicationListener的后处理器ApplicationListenerDetector,将其移动到处理器链的末端(用于获取代理等) beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125;// PostProcessorRegistrationDelegate.javaprivate static void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanPostProcessor&gt; postProcessors) &#123; if (beanFactory instanceof AbstractBeanFactory) &#123; // 批量添加比CopyOnWriteArrayList更有效率 ((AbstractBeanFactory) beanFactory).addBeanPostProcessors(postProcessors); &#125; else &#123; for (BeanPostProcessor postProcessor : postProcessors) &#123; beanFactory.addBeanPostProcessor(postProcessor); &#125; &#125;&#125;// AbstractBeanFactory.java@Overridepublic void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; Assert.notNull(beanPostProcessor, \"BeanPostProcessor must not be null\"); // 移除旧的BeanPostProcessor this.beanPostProcessors.remove(beanPostProcessor); // 添加新的BeanPostProcessor到list尾部 this.beanPostProcessors.add(beanPostProcessor);&#125; 对BeanPostProcessor和BeanFactoryPostProcessor处理极为相似，相同的是都根据PriorityOrdered、Ordered接口和其他BeanPostProcessor进行分别注册不同的是BeanPostProcessor不是立刻使用而是注册，因此只需将所有配置注入的BeanPostProcessor加入到BeanFactory的属性中在注册Bean时通过先remove()再add()确保了BeanPostProcessor的唯一性 initMessageSource()方法： 12345678910111213141516171819202122232425262728293031// AbstractApplicationContext.javapublic static final String MESSAGE_SOURCE_BEAN_NAME = \"messageSource\";/** * 初始化MessageSource * 如果当前context没有定义,使用父容器定义的 */protected void initMessageSource() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123; this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // 设置父MessageSource if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123; HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) &#123; hms.setParentMessageSource(getInternalParentMessageSource()); &#125; &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Using MessageSource [\" + this.messageSource + \"]\"); &#125; &#125; else &#123; // 使用空MessageSource以接收getMessage()调用 DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); if (logger.isTraceEnabled()) &#123; logger.trace(\"No '\" + MESSAGE_SOURCE_BEAN_NAME + \"' bean, using [\" + this.messageSource + \"]\"); &#125; &#125;&#125; MessageSource主要用于国际化(i18n)，Spring通过封装JDK的java.util包中几个支持本地化的格式操作工具类NumberFormat、DateFormat、MessageFormat来支持国际化资源操作 initApplicationEventMulticaster()方法： 12345678910111213141516171819202122/** * 初始化ApplicationEventMulticaster * 如果context未定义,则使用SimpleApplicationEventMulticaster */// AbstractApplicationContext.javaprotected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isTraceEnabled()) &#123; logger.trace(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\"); &#125; &#125; else &#123; SimpleApplicationEventMulticaster simpleApplicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); simpleApplicationEventMulticaster.setApplicationStartup(getApplicationStartup()); this.applicationEventMulticaster = simpleApplicationEventMulticaster; beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isTraceEnabled()) &#123; logger.trace(\"No '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"' bean, using \" + \"[\" + this.applicationEventMulticaster.getClass().getSimpleName() + \"]\"); &#125; &#125;&#125; ApplicationEventMulticaster使用观察者模式，存放监听器并在合适的时候调用监听器(回调) onRefresh()方法： 123456/** * 模板方法,可重写该方法(交由子类)以添加特定context的刷新工作 * 在初始化特殊Bean时调用,在单例Bean实例化之前 */// AbstractApplicationContext.javaprotected void onRefresh() throws BeansException &#123;&#125; registerListeners()方法： 123456789101112131415161718192021222324/** * 将实现ApplicationListener接口的Bean添加为监听器 * 不会影响那些被添加但无需成为Bean的其他监听器 */// AbstractApplicationContext.javaprotected void registerListeners() &#123; // 先注册硬编码方法注册的监听器 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // 不要在这里初始化Factory Bean：需要将所有常规bean保持为未初始化状态以便让后处理器应用于它们 String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // 发布早期applicationEvent Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (!CollectionUtils.isEmpty(earlyEventsToProcess)) &#123; for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; finishBeanFactoryInitialization()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// 完成此context的BeanFactory的初始化,初始化剩余所有的单例Bean// AbstractApplicationContext.javaprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 为此context初始化转换服务 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService(beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // 如果之前没有注册Bean后处理器(比如PropertyPlaceholderConfigurer) // 那么注册一个默认的EmbeddedValueResolver(嵌入值解析器)：此时主要用于annotation(注解)属性值的解析 if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // 尽早初始化LoadTimeWeaverAware以便尽早注册它们的转换器 String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // 停止使用临时类加载器进行类型匹配 beanFactory.setTempClassLoader(null); // 运行缓存所有BeanDefinition元数据,预期没有进一步的修改 beanFactory.freezeConfiguration(); // 实例化所有剩余的单例Bean(不是lazy init(惰性加载)) beanFactory.preInstantiateSingletons();&#125;/** * 确保实例化所有非惰性单例Bean,同时考虑到FactoryBeans * 如果需要,通过在工厂设置结束时调用 * 如果无法创建一个单例Bean,则抛出BeansException * 注意：这可能使工厂中的一些Bean实例已经初始化 * 在这种情况下,调用destorySingletons()进行完全清理 */// DefaultListableBeanFactory.java@Overridepublic void preInstantiateSingletons() throws BeansException &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Pre-instantiating singletons in \" + this); &#125; // 迭代副本以允许init方法注册新的BeanDefinition // 尽管这不是常规Factory引导的一部分,但它在其他方面工作正常 List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 触发所有非单例Bean的初始化 for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // 触发所有适用Bean的初始化后的回调函数 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; StartupStep smartInitialize = this.getApplicationStartup().start(\"spring.beans.smart-initialize\").tag(\"beanName\", beanName); SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; smartInitialize.end(); &#125; &#125;&#125; finishBeanFactoryInitialization()方法主要完成BeanFactory的初始化工作，包括ConversionService的设置、配置冻结以及非延迟单例Bean的初始化工作ConversionService为自定义类型的转换器，大部分是将String转换为指定类型的对象freezeConfiguration()方法用于配置冻结，说明注册的BeanDefinition将不被修改或进一步的处理preInstantiateSingletons()方法用于实例化所有单例Bean，这也是ApplicationContext实现的默认行为 finishRefresh()方法： 1234567891011121314151617// 刷新context的刷新工作,调用LifecycleProcessor的onRefresh()方法并发布ContextRefreshedEvent// AbstractApplicationContext.java@SuppressWarnings(\"deprecation\")protected void finishRefresh() &#123; // 清除上下文级别的资源缓存(例如源于扫描的ASM元数据) clearResourceCaches(); // 为context初始化LifecycleProcessor initLifecycleProcessor(); // 首先调用LifecycleProcessor的onRefresh()方法 getLifecycleProcessor().onRefresh(); // 发布ContextRefreshedEvent事件 publishEvent(new ContextRefreshedEvent(this)); // 如果处于活动状态,参与LiveBeansView MBean(用于监控,SpringBoot的actuator模块用到) if (!IN_NATIVE_IMAGE) &#123; LiveBeansView.registerApplicationContext(this); &#125;&#125; Spring提供了Lifecycle接口，其中包含start()和stop()方法，实现此接口保证在Spring生命周期开始和结束时分别调用这两个方法，通常用于配置后台程序(如对MQ进行轮训) ApplicationContext介绍： BeanFactory：Spring管理Bean的顶层接口，ApplicationContext的IOC容器功能通过复用BeanFactoryResourceLoader：Spring加载资源的顶层接口，同样通过复用ApplicationEventPublisher：封装事件发布功能MessageSource：解析Message的策略接口，用于国际化EnvironmentCapable：用于获取Environment 常用的ClassPathXmlApplicationContext： 资源加载 背景：JavaSE中有一个标准类java.net.URL，表示统一资源定位器(Uniform Resource Locator)，但其实现存在局限性，没有定义相对于Classpath或ServletContext等资源的解析方式。因此Spring抽象了Resource用于统一资源，抽象了ResourceLoader用于统一资源加载 Resource接口(统一资源抽象)： 123456789101112131415161718192021222324252627282930// Resource.javapublic interface Resource extends InputStreamSource &#123; boolean exists(); default boolean isReadable() &#123; return exists(); &#125; default boolean isOpen() &#123; return false; &#125; default boolean isFile() &#123; return false; &#125; URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; default ReadableByteChannel readableChannel() throws IOException &#123; return Channels.newChannel(getInputStream()); &#125; long contentLength() throws IOException; long lastModified() throws IOException; Resource createRelative(String relativePath) throws IOException; @Nullable String getFilename(); String getDescription();&#125;// InputStreamSource.javapublic interface InputStreamSource &#123; InputStream getInputStream() throws IOException;&#125; InputStreamSource接口封装任何能返回InputStream的类(如File、Classpath下的资源和Byte Array等)，它只定义了一个方法————getInputStream()Resource接口抽象了所有Spring内部使用到的底层资源：File、URL、Classpath等，针对不同来源的资源文件，存在多种Resource实现： FileSystemResource：对java.io.File类型资源的封装，支持文件和URL的形式，实现WritableResource接口；从Spring5开始，FileSystemResource使用NIO2的API进行读/写交互 ByteArrayResource：对字节数组类型资源的封装。如果通过InputStream形式访问该类型的资源，该实现会根据字节数组的数据构造一个对应的ByteArrayInputStream UrlResource：对java.net.URL类型资源的封装。内部委派URL进行具体操作 ClassPathResource：获取Classpath类型资源的实现。使用给定的ClassLoader或者给定的Class来加载资源 InputStreamResource：获取InputStream类型资源的实现 ResourceLoader接口(统一资源加载器抽象)： 12345678// ResourceLoader.javapublic interface ResourceLoader &#123; // \"classpath:\" String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX; Resource getResource(String location); @Nullable ClassLoader getClassLoader();&#125; Spring将资源的定义和加载区分开，ResourceLoader资源加载器用于根据给定的资源文件地址返回对应的Resource loadBeanDefinitions()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * 用给定的XmlBeanDefinitionReader加载BeanDefinition * BeanFactory的生命周期是由refreshBeanFactory()方法处理的；因此该方法只应该是加载和/或注册BeanDefinition * 在Bean注册错误的情况下抛出BeansException * 在找不到所需的XML文档的情况下抛出IOException */// AbstractXmlApplicationContext.javaprotected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; // 通过资源加载BeanDefinition reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; // 通过配置文件路径加载BeanDefinition reader.loadBeanDefinitions(configLocations); &#125;&#125;// AbstractBeanDefinitionReader.javapublic int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, \"Location array must not be null\"); int count = 0; for (String location : locations) &#123; count += loadBeanDefinitions(location); &#125; return count;&#125;// AbstractBeanDefinitionReader.javapublic int loadBeanDefinitions(String location) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(location, null);&#125;/** * 从指定的资源位置加载BeanDefinition * 如果该BeanDefinitionReader的ResourceLoader是ResourcePatternResolver,那么路径可以是一个路径模式 * actualResources是一个集合,用于填充加载过程中解析的实际资源对象;可以为null,表示调用者对这些资源对象不感兴趣 * 返回找到的BeanDefinition数量 * 在加载或解析XML错误情况下抛出BeanDefinitionStoreException */// AbstractBeanDefinitionReader.javapublic int loadBeanDefinitions(String location, @Nullable Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException(\"Cannot load bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // 资源模式匹配可用 try &#123; Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int count = loadBeanDefinitions(resources); if (actualResources != null) &#123; Collections.addAll(actualResources, resources); &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Loaded \" + count + \" bean definitions from location pattern [\" + location + \"]\"); &#125; return count; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); &#125; &#125; else &#123; // 只能按绝对URL加载单个资源 Resource resource = resourceLoader.getResource(location); int count = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Loaded \" + count + \" bean definitions from location [\" + location + \"]\"); &#125; return count; &#125;&#125;// AbstractBeanDefinitionReader.javapublic int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, \"Resource array must not be null\"); int count = 0; for (Resource resource : resources) &#123; count += loadBeanDefinitions(resource); &#125; return count;&#125;// XmlBeanDefinitionReader.java@Overridepublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource));&#125;// XmlBeanDefinitionReader.javaprivate final ThreadLocal&lt;Set&lt;EncodedResource&gt;&gt; resourcesCurrentlyBeingLoaded = new NamedThreadLocal&lt;Set&lt;EncodedResource&gt;&gt;(\"XML bean definition resources currently being loaded\")&#123; @Override protected Set&lt;EncodedResource&gt; initialValue() &#123; return new HashSet&lt;&gt;(4); &#125; &#125;;/** * 从指定的XML文件加载BeanDefinition * 参数encodedResource是XML文件的资源描述符,允许指定用于解析文件的编码 * 返回找到的BeanDefinition数量 * 在加载或解析XML错误情况下抛出BeanDefinitionStoreException */public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isTraceEnabled()) &#123; logger.trace(\"Loading XML bean definitions from \" + encodedResource); &#125; // 获取当前线程保存的正在加载的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); // 如果有重复,就说明存在循环加载问题,抛出异常 if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException(\"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; // 获取输入流 try (InputStream inputStream = encodedResource.getResource().getInputStream()) &#123; // 封装成SAX的标准输入流 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 真正执行加载BeanDefinition return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"IOException parsing XML document from \" + encodedResource.getResource(), ex); &#125; finally &#123; // 清理当前线程保存的正在加载的资源 currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; 在总体流程中分析到loadBeanDefinitions()方法，顺着该方法，方法内部调用了一系列的重载方法比较重要的有两个地方：一个是类AbstractBeanDefinitionReader内loadBeanDefinitions(String, Set&lt;Resource&gt;)方法，该方法首先获取了ResourceLoader，接着用该对象的getResource()方法加载资源，最后通过调用重载的loadBeanDefinitions(Resource[])方法；首先来看看获取的ResourceLoader对象以及getResource()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// AbstractXmlApplicationContext.javaprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // ... XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); beanDefinitionReader.setResourceLoader(this); // ...&#125;// AbstractApplicationContext.javaprivate ResourcePatternResolver resourcePatternResolver;public AbstractApplicationContext() &#123; this.resourcePatternResolver = getResourcePatternResolver();&#125;/** * 返回用于将路径模式解析为资源实例的ResourcePatternResolver * 默认是支持Ant风格路径模式的PathMatchingResourcePatternResolver */protected ResourcePatternResolver getResourcePatternResolver() &#123; return new PathMatchingResourcePatternResolver(this);&#125;public Resource[] getResources(String locationPattern) throws IOException &#123; return this.resourcePatternResolver.getResources(locationPattern);&#125;// PathMatchingResourcePatternResolver.javaprivate final ResourceLoader resourceLoader;private PathMatcher pathMatcher = new AntPathMatcher();public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) &#123; Assert.notNull(resourceLoader, \"ResourceLoader must not be null\"); this.resourceLoader = resourceLoader;&#125;/** * 将给定的路径默认解析为资源对象 * 应尽可能避免重叠资源条目指向统一物理资源。结果应该具有set语义 */public Resource[] getResources(String locationPattern) throws IOException &#123; Assert.notNull(locationPattern, \"Location pattern must not be null\"); // String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\"; // 如果以\"classpath*:\"开头 if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) &#123; // 类路径资源(可能有同名的多个资源) // 如果路径是表示一种模式(含有'*'、'?'、\"&#123;&#125;\"等通配符) if (getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) &#123; // 单个类路径资源路径模式 // 解析通配符的路径获取资源 return findPathMatchingResources(locationPattern); &#125; else &#123; // 具有给定名称的所有类路径资源 // 返回classpath路径下和所有jar包中的所有相匹配资源 return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); &#125; &#125; else &#123; // 不以\"classpath*:\"开头 // 通常在这里只查找前缀后面的模式 int prefixEnd = (locationPattern.startsWith(\"war:\") ? locationPattern.indexOf(\"*/\") + 1 : locationPattern.indexOf(':') + 1); if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) &#123; // 单个文件模式 return findPathMatchingResources(locationPattern); &#125; else &#123; // 具有给定名称的单个资源 return new Resource[] &#123;getResourceLoader().getResource(locationPattern)&#125;; &#125; &#125;&#125; 首先使用的ResourceLoader资源加载器其实是传入的applicationContext，它在loadBeanDefinitions()方法中被设置其次ApplicationContext接口继承了ResourceLoader，因此可以被当成是ResourceLoader。而且AbstractApplicationContext继承自DefaultResourceLoader。在AbstractApplicationContext类构造器中，显式地初始化了PathMatchingResourcePatternResolver类的对象作为其委托的ResourceLoader实例并传入了自身。PathMatchingResourcePatternResolver相当于持有了DefaultResourceLoader(ApplicationContext)以及AntPatchMatcher，并将加载资源和路径模式匹配的工作委托给这两个属性接着看获取资源getResources()方法，根据是否以”classpath*:”和是否是路径模式共给出三种获取资源的方式，具体不再展开 另一处doLoadBeanDefinitions()方法是最重要的，这是核心逻辑部分，用于执行加载BeanDefinition的操作，在后面的XML解析部分说明 ResourceLoader解析Resource过程简单介绍： findAllClassPathResources()方法： 123456789101112131415161718192021222324252627282930313233343536373839// location：类路径中的绝对路径// PathMatchingResourcePatternResolver.javaprotected Resource[] findAllClassPathResources(String location) throws IOException &#123; String path = location; if (path.startsWith(\"/\")) &#123; path = path.substring(1); &#125; // 委托给doFindAllClassPathResources()方法执行 Set&lt;Resource&gt; result = doFindAllClassPathResources(path); if (logger.isTraceEnabled()) &#123; logger.trace(\"Resolved classpath location [\" + location + \"] to resources \" + result); &#125; return result.toArray(new Resource[0]);&#125;/** * 通过类加载器找到具有给定路径的所有类路径资源 * path：不带前导'/'的类路径中的绝对路径 * 返回一组匹配的资源实例 */// PathMatchingResourcePatternResolver.javaprotected Set&lt;Resource&gt; doFindAllClassPathResources(String path) throws IOException &#123; Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); ClassLoader cl = getClassLoader(); // 根据ClassLoader加载路径下的所有资源 Enumeration&lt;URL&gt; resourceUrls = (cl != null ? cl.getResources(path) : ClassLoader.getSystemResources(path)); while (resourceUrls.hasMoreElements()) &#123; URL url = resourceUrls.nextElement(); // 将URL转为URLResource result.add(convertClassLoaderURL(url)); &#125; // 如果是\"\"(空路径) if (!StringUtils.hasLength(path)) &#123; // 上述结果可能不完整,即仅包含文件系统引用 // 同时需要加载类路径下的每个jar文件 addAllClassLoaderJarRoots(cl, result); &#125; return result;&#125; findPathMatchingResources()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 通过Ant风格的PathMatcher查找与给定路径模式匹配的所有资源 * 支持jar、zip和文件系统中的资源 */// PathMatchingResourcePatternResolver.javaprotected Resource[] findPathMatchingResources(String locationPattern) throws IOException &#123; // 确定根路径 String rootDirPath = determineRootDir(locationPattern); // 确定子路径 String subPattern = locationPattern.substring(rootDirPath.length()); // 获取根路径下的资源 Resource[] rootDirResources = getResources(rootDirPath); Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); // 遍历根路径下的资源 for (Resource rootDirResource : rootDirResources) &#123; // rootDirResource = resolveRootDirResource(rootDirResource); URL rootDirUrl = rootDirResource.getURL(); // bundle资源类型 if (equinoxResolveMethod != null &amp;&amp; rootDirUrl.getProtocol().startsWith(\"bundle\")) &#123; URL resolvedUrl = (URL) ReflectionUtils.invokeMethod(equinoxResolveMethod, null, rootDirUrl); if (resolvedUrl != null) &#123; rootDirUrl = resolvedUrl; &#125; rootDirResource = new UrlResource(rootDirUrl); &#125; // vfs资源类型 if (rootDirUrl.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) &#123; result.addAll(VfsResourceMatchingDelegate.findMatchingResources(rootDirUrl, subPattern, getPathMatcher())); &#125; else if (ResourceUtils.isJarURL(rootDirUrl) || isJarResource(rootDirResource)) &#123; // jar资源类型 result.addAll(doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPattern)); &#125; else &#123; // 其他资源类型 result.addAll(doFindPathMatchingFileResources(rootDirResource, subPattern)); &#125; &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Resolved location pattern [\" + locationPattern + \"] to resources \" + result); &#125; return result.toArray(new Resource[0]);&#125; getResource()方法： 1234567891011121314151617181920212223242526272829303132// DefaultResourceLoader.javapublic Resource getResource(String location) &#123; Assert.notNull(location, \"Location must not be null\"); // 通过ProtocolResolver加载资源 /** * ProtocolResolver是用户自定义协议资源解决策略,作为DefaultResourceLoader的SPI(Service Provider Interface) * 它允许用户自定义资源加载协议,而不需要继承ResourceLoader的子类 */ for (ProtocolResolver protocolResolver : getProtocolResolvers()) &#123; Resource resource = protocolResolver.resolve(location, this); if (resource != null) &#123; return resource; &#125; &#125; // 如果以'/'开头,返回ClassPathContextResource类型的资源 if (location.startsWith(\"/\")) &#123; return getResourceByPath(location); &#125; else if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; // 再者,如果以\"classpath:\"开头,返回ClassPathResource类型的资源 return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); &#125; else &#123; try &#123; // 尝试将路径解析为URL URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); &#125; catch (MalformedURLException ex) &#123; // 不是URL,当作资源路径解析 // 返回ClassPathContextResource类型的资源 return getResourceByPath(location); &#125; &#125;&#125; 解析XML 背景：传统Spring程序均通过XML定义bean实例；因此Spring使用SAX(Simple API for XML)方式解析XML。该方式是sun公司内置于Java的，比传统的DOM解析方式快 doLoadBeanDefinitions()方法： 1234567891011121314151617181920212223242526272829303132333435363738/** * 从指定的XML文件实际加载BeanDefinition * 返回找到的BeanDefinition数量 * 在加载或解析XML错误情况下抛出BeanDefinitionStoreException */// XmlBeanDefinitionReader.javaprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 解析XML文档获取XML Document实例 Document doc = doLoadDocument(inputSource, resource); // 根据Document实例注册BeanDefinition int count = registerBeanDefinitions(doc, resource); if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + count + \" bean definitions from \" + resource); &#125; return count; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125;&#125;// XmlBeanDefinitionReader.javaprivate DocumentLoader documentLoader = new DefaultDocumentLoader();private ErrorHandler errorHandler = new SimpleSaxErrorHandler(logger);private boolean namespaceAware = false;protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware());&#125; doLoadBeanDefinitions()方法中主要做了两件事其一是解析XML获取Document实例，另一是注册BeanDefinition在这部分中先说明解析步骤：获取Document实例过程又将解析任务委托给DocumentLoader对象处理，在解析XML中传入了许多参数： inputSource：加载XML的Document的资源，封装InputStream而来 entityResolver：用于解析任何实体的解析器，默认是ResourceEntityResolver，在初始化XmlBeanDefinitionReader时设置 123456// AbstractXmlApplicationContext.java@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));&#125; errorHandler：用于报告Document加载期间错误的错误处理器 validationMode：XML的验证模式 namespaceAware：是否要提供对XML名称空间的支持 接着顺序分析\bgetValidationModeForResource()方法以及loadDocument()方法，其中前者用于获取XML的验证模式，后者用于加载Document \bgetValidationModeForResource()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * 确定指定资源的验证模式 * 如果未显式设置验证模式,则验证模式将通过detectValidationMode()方法检测 * 如果想完全控制验证模式,则重写此方法(即使设置了VALIDATION_AUTO) */// XmlBeanDefinitionReader.java// 禁用验证模式public static final int VALIDATION_NONE = XmlValidationModeDetector.VALIDATION_NONE;// 自动获取验证模式public static final int VALIDATION_AUTO = XmlValidationModeDetector.VALIDATION_AUTO;// DTD验证模式public static final int VALIDATION_DTD = XmlValidationModeDetector.VALIDATION_DTD;// XSD验证模式public static final int VALIDATION_XSD = XmlValidationModeDetector.VALIDATION_XSD;// 默认为自动模式private int validationMode = VALIDATION_AUTO;protected int getValidationModeForResource(Resource resource) &#123; // 获取指定的验证模式 int validationModeToUse = getValidationMode(); if (validationModeToUse != VALIDATION_AUTO) &#123; return validationModeToUse; &#125; // 检测XML的验证模式 int detectedMode = detectValidationMode(resource); if (detectedMode != VALIDATION_AUTO) &#123; return detectedMode; &#125; // 以XSD验证模式兜底 return VALIDATION_XSD;&#125;/** * 检测所提供资源标识的XML的验证模式 * 如果文件具有DOCTYPE定义则使用DTD验证,否则假定使用XSD验证 * 如果要自定义自动验证模式的处理策略,重写此方法 */// XmlBeanDefinitionReader.java// XML验证检测器private final XmlValidationModeDetector validationModeDetector = new XmlValidationModeDetector();protected int detectValidationMode(Resource resource) &#123; // 如果资源不可读 if (resource.isOpen()) &#123; throw new BeanDefinitionStoreException(\"Passed-in Resource [\" + resource + \"] contains an open stream: \" + \"cannot determine validation mode automatically. Either pass in a Resource \" + \"that is able to create fresh streams, or explicitly specify the validationMode \" + \"on your XmlBeanDefinitionReader instance.\"); &#125; InputStream inputStream; try &#123; inputStream = resource.getInputStream(); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"Unable to determine validation mode for [\" + resource + \"]: cannot open InputStream. \" + \"Did you attempt to load directly from a SAX InputSource without specifying the \" + \"validationMode on your XmlBeanDefinitionReader instance?\", ex); &#125; try &#123; // 获取相应验证模式 return this.validationModeDetector.detectValidationMode(inputStream); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"Unable to determine validation mode for [\" + resource + \"]: an error occurred whilst reading from the InputStream.\", ex); &#125;&#125;// XmlValidationModeDetector.javaprivate static final String DOCTYPE = \"DOCTYPE\";private boolean hasDoctype(String content) &#123; return content.contains(DOCTYPE);&#125;public int detectValidationMode(InputStream inputStream) throws IOException &#123; // 为了寻找DOCTYPE而快速查看文件 try (BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream))) &#123; boolean isDtdValidated = false; String content; // 逐行读取XML文件内容 while ((content = reader.readLine()) != null) &#123; content = consumeCommentTokens(content); // 跳过注释和空行 if (this.inComment || !StringUtils.hasText(content)) &#123; continue; &#125; // 判断是否包含\"DOCTYPE\",如包含则是DTD模式 if (hasDoctype(content)) &#123; isDtdValidated = true; break; &#125; // 走到正文,跳出 if (hasOpeningTag(content)) &#123; break; &#125; &#125; return (isDtdValidated ? VALIDATION_DTD : VALIDATION_XSD); &#125; catch (CharConversionException ex) &#123; // 被一些字符编码阻塞 // 把决定权交给调用者 return VALIDATION_AUTO; &#125;&#125; 加载Document首先要获取XML文件的验证模式(验证模式保证了XML文件的正确性)，DTD(Document Type Definition————文档类型定义)和XSD(XML Schemas Definition)是两个用于XML文件的验证机制XSD是为了替代DTD而出现的，基于XML，没有专门的语法(DTD不基于XML)，比DTD更优秀getValidationModeForResource()函数首先获取指定的验证模式，默认为自动模式。然后将检测验证模式的职责交由XmlValidationModeDetector类处理————逐行读取XML中的文本，根据是包含”DOCTYPE”判断是否为DTD模式 loadDocument()方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 使用标准的JAXP(Java API for XML Processing)配置的XML解析器根据提供的InputStream加载Document// DefaultDocumentLoader.java@Overridepublic Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception &#123; DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isTraceEnabled()) &#123; logger.trace(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\"); &#125; DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); return builder.parse(inputSource);&#125;// 创建DocumentBuilderFactory实例// DefaultDocumentLoader.javaprotected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware) throws ParserConfigurationException &#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(namespaceAware); if (validationMode != XmlValidationModeDetector.VALIDATION_NONE) &#123; factory.setValidating(true); if (validationMode == XmlValidationModeDetector.VALIDATION_XSD) &#123; // 如果为XSD验证模式,强制使用命名空间支持 factory.setNamespaceAware(true); try &#123; factory.setAttribute(SCHEMA_LANGUAGE_ATTRIBUTE, XSD_SCHEMA_LANGUAGE); &#125; catch (IllegalArgumentException ex) &#123; ParserConfigurationException pcex = new ParserConfigurationException(\"Unable to validate using XSD: Your JAXP provider [\" + factory + \"] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? \" + \"Upgrade to Apache Xerces (or Java 1.5) for full XSD support.\"); pcex.initCause(ex); throw pcex; &#125; &#125; &#125; return factory;&#125;// 生成DocumentBuilder用于解析XML文档// DefaultDocumentLoader.javaprotected DocumentBuilder createDocumentBuilder(DocumentBuilderFactory factory, @Nullable EntityResolver entityResolver, @Nullable ErrorHandler errorHandler) throws ParserConfigurationException &#123; DocumentBuilder docBuilder = factory.newDocumentBuilder(); if (entityResolver != null) &#123; docBuilder.setEntityResolver(entityResolver); &#125; if (errorHandler != null) &#123; docBuilder.setErrorHandler(errorHandler); &#125; return docBuilder;&#125; DocumentLoader是Spring用于包装SAX解析XML的类loadDocument()方法内部主要通过填充参数的方式创建了DocumentBuilderFactory和DocumentBuilder对象，而后者真正用于解析XML文档。这两个类都是JDK底层SAX部分代码，与Spring无关，Spring委托SAX处理XML解析工作，具体不再展开最后介绍一下EntityResolver，该类也是SAX规定的类，定义寻找解析文件的逻辑 ResourceEntityResolver介绍(EntityResolver实现)： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// EntityResolver.java// 用于定义寻找解析文件的逻辑public interface EntityResolver &#123; public abstract InputSource resolveEntity (String publicId, String systemId) throws SAXException, IOException;&#125;// ResourceEntityResolver.javapublic ResourceEntityResolver(ResourceLoader resourceLoader) &#123; super(resourceLoader.getClassLoader()); this.resourceLoader = resourceLoader;&#125;public InputSource resolveEntity(@Nullable String publicId, @Nullable String systemId) throws SAXException, IOException &#123; // 调用父类DelegatingEntityResolver进行解析 InputSource source = super.resolveEntity(publicId, systemId); // 解析失败,使用ResourceLoader解析 if (source == null &amp;&amp; systemId != null) &#123; // 获取Resource资源地址 String resourcePath = null; try &#123; String decodedSystemId = URLDecoder.decode(systemId, \"UTF-8\"); String givenUrl = new URL(decodedSystemId).toString(); // 获取解析文件资源的相对路径(相对于系统根路径) String systemRootUrl = new File(\"\").toURI().toURL().toString(); // 如果在系统根目录,尝试相对于资源库 if (givenUrl.startsWith(systemRootUrl)) &#123; resourcePath = givenUrl.substring(systemRootUrl.length()); &#125; &#125; catch (Exception ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Could not resolve XML entity [\" + systemId + \"] against system root URL\", ex); &#125; // 不是URL(或不是可处理的URL),尝试相对于资源库 resourcePath = systemId; &#125; if (resourcePath != null) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Trying to locate XML entity [\" + systemId + \"] as resource [\" + resourcePath + \"]\"); &#125; // 获取Resource资源 Resource resource = this.resourceLoader.getResource(resourcePath); source = new InputSource(resource.getInputStream()); // 设置publicId和systemId source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isDebugEnabled()) &#123; logger.debug(\"Found XML entity [\" + systemId + \"]: \" + resource); &#125; &#125; else if (systemId.endsWith(DTD_SUFFIX) || systemId.endsWith(XSD_SUFFIX)) &#123; // 网络请求验证文件 String url = systemId; if (url.startsWith(\"http:\")) &#123; url = \"https:\" + url.substring(5); &#125; try &#123; source = new InputSource(new URL(url).openStream()); source.setPublicId(publicId); source.setSystemId(systemId); &#125; catch (IOException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Could not resolve XML entity [\" + systemId + \"] through URL [\" + url + \"]\", ex); &#125; // 返回到解析器的默认行为 source = null; &#125; &#125; &#125; return source;&#125;// DelegatingEntityResolver.javapublic DelegatingEntityResolver(@Nullable ClassLoader classLoader) &#123; this.dtdResolver = new BeansDtdResolver(); this.schemaResolver = new PluggableSchemaResolver(classLoader);&#125;public InputSource resolveEntity(@Nullable String publicId, @Nullable String systemId) throws SAXException, IOException &#123; if (systemId != null) &#123; if (systemId.endsWith(DTD_SUFFIX)) &#123; // 调用BeansDtdResolver解析 return this.dtdResolver.resolveEntity(publicId, systemId); &#125; else if (systemId.endsWith(XSD_SUFFIX)) &#123; // 调用PluggableSchemaResolver解析 return this.schemaResolver.resolveEntity(publicId, systemId); &#125; &#125; // 返回到解析器的默认行为 return null;&#125; EntityResolver主要用于获取解析文件，有了解析文件就可以验证XML编写是否符合规则当前默认采用ResourceEntityResolver获取解析文件(由于构造时传入context————ResourceLoader的子接口)，首先调用父类的resolveEntity()方法进行解析父类DelegatingEntityResolver则分别根据验证文件类型分别交由BeansDtdResolver(DTD)和PluggableSchemaResolver(XSD)类来获取解析文件如果是XSD类型，PluggableSchemaResolver会先获取一个映射表，映射表是通过META-INF/spring.schemas从Spring依赖包(spring-beans)获取的，该配置文件中写明了映射表内容；BeansDtdResolver也先通过文件查找如果以上都解析不出，则通过网络访问 解析Bean 背景：目前为止，XML已经被SAX解析为Document文档了，接下来可以进行真正的Bean解析注册过程了 再探源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Actually load bean definitions from the specified XML file. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */// XmlBeanDefinitionReader.javaprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); int count = registerBeanDefinitions(doc, resource); if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + count + \" bean definitions from \" + resource); &#125; return count; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125;&#125;/** * Register the bean definitions contained in the given DOM document. * Called by &#123;@code loadBeanDefinitions&#125;. * &lt;p&gt;Creates a new instance of the parser class and invokes * &#123;@code registerBeanDefinitions&#125; on it. * @param doc the DOM document * @param resource the resource descriptor (for context information) * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of parsing errors */// XmlBeanDefinitionReader.javapublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // 创建BeanDefinitionDocumentReader对象 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // 获取已注册的BeanDefinition数量 int countBefore = getRegistry().getBeanDefinitionCount(); // 创建XmlReaderContext对象以及注册BeanDefinition documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); // 计算新注册的BeanDefinition数目 return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 接着看源码流程，这下来到了XmlBeanDefinitionReader类中的doLoadBeanDefinitions(InputSource, Resource)函数，该函数继续调用了本类的registerBeanDefinitions(Document, Resource)函数该函数总共做了以下几件事： 创建BeanDefinitionDocumentReader对象(定义读取Document并注册BeanDefinition的功能)；该BeanDefinitionDocumentReader实际上是DefaultBeanDefinitionDocumentReader类的对象 12345678910// XmlBeanDefinitionReader.javaprivate Class&lt;? extends BeanDefinitionDocumentReader&gt; documentReaderClass = DefaultBeanDefinitionDocumentReader.class;/** * Create the &#123;@link BeanDefinitionDocumentReader&#125; to use for actually * reading bean definitions from an XML document. * &lt;p&gt;The default implementation instantiates the specified \"documentReaderClass\". */protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() &#123; return BeanUtils.instantiateClass(this.documentReaderClass);&#125; 获取已注册的BeanDefinition数量；这里的Registry()对象是DefaultListableBeanFactory类的对象，在总体流程中介绍过(在AbstractXmlApplicationContext类的loadBeanDefinitions(DefaultListableBeanFactory)函数中XmlBeanDefinitionReader类的对象构造时传入了beanFactory) 创建XmlReaderContext对象；#TODO 123456789101112131415161718192021// XmlBeanDefinitionReader.javaprivate ProblemReporter problemReporter = new FailFastProblemReporter();private ReaderEventListener eventListener = new EmptyReaderEventListener();private SourceExtractor sourceExtractor = new NullSourceExtractor();private NamespaceHandlerResolver namespaceHandlerResolver;/** * Lazily create a default NamespaceHandlerResolver, if not set before. * @see #createDefaultNamespaceHandlerResolver() */public NamespaceHandlerResolver getNamespaceHandlerResolver() &#123; if (this.namespaceHandlerResolver == null) &#123; this.namespaceHandlerResolver = createDefaultNamespaceHandlerResolver(); &#125; return this.namespaceHandlerResolver;&#125;/** * Create the &#123;@link XmlReaderContext&#125; to pass over to the document reader. */public XmlReaderContext createReaderContext(Resource resource) &#123; return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver());&#125; 最关键调用BeanDefinitionDocumentReader类的registerBeanDefinitions(Document, XmlReaderContext)函数注册BeanDefinition 返回计算出的新注册的BeanDefinition数目 registerBeanDefinitions(Document, XmlReaderContext)函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * This implementation parses bean definitions according to the \"spring-beans\" XSD * (or DTD, historically). * &lt;p&gt;Opens a DOM Document; then initializes the default settings * specified at the &#123;@code &lt;beans/&gt;&#125; level; then parses the contained bean definitions. */// DefaultBeanDefinitionDocumentReader.java@Overridepublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; // 获取XML的Document的Root元素,执行注册BeanDefinition doRegisterBeanDefinitions(doc.getDocumentElement());&#125;/** * Register each bean definition within the given root &#123;@code &lt;beans/&gt;&#125; element. */// DefaultBeanDefinitionDocumentReader.java@SuppressWarnings(\"deprecation\") // for Environment.acceptsProfiles(String...)protected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. // 记录老的BeanDefinitionParserDelegate对象 BeanDefinitionParserDelegate parent = this.delegate; // 创建新的BeanDefinitionParserDelegate对象,并设置给delegate属性 this.delegate = createDelegate(getReaderContext(), root, parent); // 检查是否是默认命名空间： // &lt;beans/&gt;根标签的命名空间是否为空,或者是http://www.springframework.org/schema/beans if (this.delegate.isDefaultNamespace(root)) &#123; // 获取profile属性并处理 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; // 使用分隔符切分得到可能的多个profile String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); // We cannot use Profiles.of(...) since profile expressions are not supported // in XML config. See SPR-12458 for details. // 如果profile都无效,则不进行注册 if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; // 解析前处理,模板设计模式,当前空实现 preProcessXml(root); // 解析XML成BeanDefinition parseBeanDefinitions(root, this.delegate); // 解析后处理,模板设计模式,当前空实现 postProcessXml(root); // 设置回老的BeanDefinitionParserDelegate对象 this.delegate = parent;&#125; registerBeanDefinitions(Document, XmlReaderContext)函数获取了XML的Document的Root元素并传入doRegisterBeanDefinitions(Element)函数该函数进行了一系列操作： 创建BeanDefinitionParserDelegate类的对象，并设置给delegate属性。该类很重要，主要负责解析BeanDefinition 12345678// DefaultBeanDefinitionDocumentReader.javaprotected BeanDefinitionParserDelegate createDelegate(XmlReaderContext readerContext, &gt;Element root, @Nullable BeanDefinitionParserDelegate parentDelegate) &#123; // 创建DefaultBeanDefinitionDocumentReader对象 BeanDefinitionParserDelegate delegate = new BeanDefinitionParserDelegate(readerContext); // 初始化默认 delegate.initDefaults(root, parentDelegate); return delegate;&#125; 接着调用BeanDefinitionParserDelegate类的isDefaultNamespace(Element)函数判断是否为默认的命名空间；接着判断是否在&lt;beans/&gt;标签查看是否配置了profile属性，如果有则切分得到可能多个的profile配置，接着判断如果当前所有的profile都无效，则退出注册 调用parseBeanDefinitions(Element, BeanDefinitionParserDelegate)函数进行解析逻辑；而preProcessXml(Element)和postProcessXml(Element)函数主要是解析前后的回调函数，目前都是空实现，交由子类实现，是模板设计模式的体现，留足可扩展性 parseBeanDefinitions(Element, BeanDefinitionParserDelegate)函数： 123456789101112131415161718192021222324252627/** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */// DefaultBeanDefinitionDocumentReader.javaprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 如果根节点使用默认命名空间 if (delegate.isDefaultNamespace(root)) &#123; // 遍历子节点 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; // 如果该节点使用默认命名空间,执行默认解析 if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; // 如果该节点不使用默认命名空间,执行自定义解析 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; // 如果根节点不使用默认命名空间,执行自定义解析 delegate.parseCustomElement(root); &#125;&#125; parseBeanDefinitions(Element, BeanDefinitionParserDelegate)函数总结起来就是对使用默认命名空间的节点调用parseDefaultElement(Element, BeanDefinitionParserDelegate)函数执行默认解析逻辑，对不使用默认命名空间的节点调用parseCustomElement(Element)函数执行自定义解析逻辑Spring的XML有两种配置文件声明方式，一种是配置文件式：&lt;bean id=&quot;testService&quot; class=&quot;com.xiong.service.TestService&quot;/&gt;\b，这对应默认命名空间方式；另一种是自定义注解方式：&lt;tx:annotation-driven&gt;，这对应非默认命名空间方式 parseDefaultElement(Element, BeanDefinitionParserDelegate)函数： 12345678910111213141516171819// DefaultBeanDefinitionDocumentReader.javapublic static final String BEAN_ELEMENT = BeanDefinitionParserDelegate.BEAN_ELEMENT; // \"bean\"public static final String NESTED_BEANS_ELEMENT = \"beans\";public static final String ALIAS_ELEMENT = \"alias\";public static final String ALIAS_ATTRIBUTE = \"alias\";public static final String IMPORT_ELEMENT = \"import\";private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; // import if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; // alias processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; // bean processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // beans // recurse doRegisterBeanDefinitions(ele); &#125;&#125; parseDefaultElement(Element, BeanDefinitionParserDelegate)函数功能一目了然，别分时对四种不同标签————import、alias、bean以及beans进行解析，接着按照顺序来分析 解析import标签： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * Parse an \"import\" element and load the bean definitions * from the given resource into the bean factory. */// DefaultBeanDefinitionDocumentReader.javaprotected void importBeanDefinitionResource(Element ele) &#123; // 获取resource的属性值 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); // 为空值,直接返回 if (!StringUtils.hasText(location)) &#123; getReaderContext().error(\"Resource location must not be empty\", ele); return; &#125; // Resolve system properties: e.g. \"$&#123;user.dir&#125;\" // 解析系统属性(占位符) location = getReaderContext().getEnvironment().resolveRequiredPlaceholders(location); // 实际Resource集合————从import的地址解析而来 Set&lt;Resource&gt; actualResources = new LinkedHashSet&lt;&gt;(4); // Discover whether the location is an absolute or relative URI // 判断location是相对路径还是绝对路径 boolean absoluteLocation = false; try &#123; absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &#125; catch (URISyntaxException ex) &#123; // cannot convert to an URI, considering the location relative // unless it is the well-known Spring prefix \"classpath*:\" &#125; // Absolute or relative? if (absoluteLocation) &#123; try &#123; // 将添加的配置文件的Resource通过location解析,并把结果放入actualResources集合中 // 并加载其中的BeanDefinitions int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources); if (logger.isTraceEnabled()) &#123; logger.trace(\"Imported \" + importCount + \" bean definitions from URL location [\" + location + \"]\"); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to import bean definitions from URL location [\" + location + \"]\", ele, ex); &#125; &#125; else &#123; // No URL -&gt; considering resource location as relative to the current file. try &#123; int importCount; // 创建相对路径的Resource Resource relativeResource = getReaderContext().getResource().createRelative(location); if (relativeResource.exists()) &#123; // 加载relativeResource中的BeanDefinition importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource); // 将relativeResource加入actualResources集合 actualResources.add(relativeResource); &#125; else &#123; // 获取根路径 String baseLocation = getReaderContext().getResource().getURL().toString(); // 根据根路径和location构造相对路径并加载BeanDefinition importCount = getReaderContext().getReader().loadBeanDefinitions(StringUtils.applyRelativePath(baseLocation, location), actualResources); &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Imported \" + importCount + \" bean definitions from relative location [\" + location + \"]\"); &#125; &#125; catch (IOException ex) &#123; getReaderContext().error(\"Failed to resolve current resource location\", ele, ex); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to import bean definitions from relative location [\" + location + \"]\", ele, ex); &#125; &#125; Resource[] actResArray = actualResources.toArray(new Resource[0]); // 解析成功后,进行监听器激活处理 getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));&#125; 解析import标签过程较为清晰，总分为以下几个步骤： 获取source属性的值————表示资源的路径 解析资源路径汇总的系统属性(占位符) 判断资源路径是绝对路径还是相对路径 以”classpath*:”或者”classpath:”开头为绝对路径 能够通过location构建出URL类对象为绝对路径 根据location构造URI类对象并调用isAbsolute()函数返回true为绝对路径 如果是绝对路径，递归调用Bean的解析过程进行另一次解析；在int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources);语句上调用了AbstractBeanDefinitionReader类的loadBeanDefinitions(String, Set&lt;Resource&gt;)函数(参考资源加载分析部分) 如果是相对路径，计算出绝对路径得到Resource再进行解析。如果Resource存在，则调用XmlBeanDefinitionReader类的loadBeanDefinitions(Resource)函数(参考总体过程分析部分)进行BeanDefinition的加载；否则，构造一个绝对的location并于绝对路径一样在进行另一次解析 通知监听器完成解析 解析alias标签： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * Process the given alias element, registering the alias with the registry. */// DefaultBeanDefinitionDocumentReader.javaprotected void processAliasRegistration(Element ele) &#123; // 解析name和alias属性 String name = ele.getAttribute(NAME_ATTRIBUTE); String alias = ele.getAttribute(ALIAS_ATTRIBUTE); boolean valid = true; // 校验 if (!StringUtils.hasText(name)) &#123; getReaderContext().error(\"Name must not be empty\", ele); valid = false; &#125; if (!StringUtils.hasText(alias)) &#123; getReaderContext().error(\"Alias must not be empty\", ele); valid = false; &#125; if (valid) &#123; try &#123; // 真正注册别名 getReaderContext().getRegistry().registerAlias(name, alias); &#125; catch (Exception ex) &#123; getReaderContext().error(\"Failed to register alias '\" + alias + \"' for bean with name '\" + name + \"'\", ele, ex); &#125; getReaderContext().fireAliasRegistered(name, alias, extractSource(ele)); &#125;&#125;// SimpleAliasRegistry.java/** Map from alias to canonical name. */private final Map&lt;String, String&gt; aliasMap = new ConcurrentHashMap&lt;&gt;(16);public void registerAlias(String name, String alias) &#123; // 校验name和alias Assert.hasText(name, \"'name' must not be empty\"); Assert.hasText(alias, \"'alias' must not be empty\"); // 锁对象 synchronized (this.aliasMap) &#123; if (alias.equals(name)) &#123; this.aliasMap.remove(alias); if (logger.isDebugEnabled()) &#123; logger.debug(\"Alias definition '\" + alias + \"' ignored since it points to same name\"); &#125; &#125; else &#123; // 获取alias已注册的beanName String registeredName = this.aliasMap.get(alias); // 已存在 if (registeredName != null) &#123; // 相同,无需重复注册 if (registeredName.equals(name)) &#123; // An existing alias - no need to re-register return; &#125; // 是否允许覆盖 if (!allowAliasOverriding()) &#123; throw new IllegalStateException(\"Cannot define alias '\" + alias + \"' for name '\" + name + \"': It is already registered for name '\" + registeredName + \"'.\"); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Overriding alias '\" + alias + \"' definition for registered name '\" + registeredName + \"' with new target name '\" + name + \"'\"); &#125; &#125; // 检验是否存在循环指向 checkForAliasCircle(name, alias); // 注册alias,实际就是放入hash表 this.aliasMap.put(alias, name); if (logger.isTraceEnabled()) &#123; logger.trace(\"Alias definition '\" + alias + \"' registered for name '\" + name + \"'\"); &#125; &#125; &#125;&#125; 解析alias标签首先调用DefaultBeanDefinitionDocumentReader类的processAliasRegistration(Element)函数，在其中首先解析name和alias属性并对这两个属性进行非空校验。接着如果通过校验则真正调用BeanDefinitionRegistry类的对象注册bean的别名当前的BeanDefinitionRegistry类的对象其实就是DefaultListableBeanFactory对象，因为它实现了BeanDefinitionRegistry接口，该对象是在总体过程介绍中loadBeanDefinitions(DefaultListableBeanFactory)函数中创建XmlBeanDefinitionReader对象传入的真正实现操作的是SimpleAliasRegistry类(DefaultListableBeanFactory继承该类)————首先进行校验，接着判断当前是否已经注册过alias和对应的beanName，如果有，或进行覆盖(允许覆盖情况下)或无操作(同一个)；否则先校验是否存循环指向，如果不存在则将&lt;alias, beanName&gt;键值对放入hash表中 解析beans标签：beans标签相当于又是一个XML文件，因此调用doRegisterBeanDefinitions(Element)函数进行迭代解析 解析bean标签(最复杂和最重要)： 1234567891011121314151617181920212223242526272829303132/** * Process the given bean element, parsing the bean definition * and registering it with the registry. */// DefaultBeanDefinitionDocumentReader.javaprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 解析bean元素,如果成功返回BeanDefinitionHolder(为持有name和alias的BeanDefinition对象) // 否则返回null BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; // 进行自定义标签解析 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. // 进行beanDefinition注册 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. // 发出响应事件,通知相关监听器————已完成该bean标签解析 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125;// BeanDefinitionHolder.classpublic class BeanDefinitionHolder implements BeanMetadataElement &#123; private final BeanDefinition beanDefinition; private final String beanName; @Nullable private final String[] aliases;&#125; processBeanDefinition(Element, BeanDefinitionParserDelegate)函数过程共分以下几步： 将解析过程委托给BeanDefinitionParserDelegate类的parseBeanDefinitionElement(Element)函数，如果解析失败返回null(错误由ProblemReporter处理)；如果解析成功则返回BeanDefinitionHolder实例(持有name和alias的BeanDefinition) 若bdHolder实例不为空，调用BeanDefinitionParserDelegate类的decorateBeanDefinitionIfRequired(Element, BeanDefinitionHolder)函数进行自定义标签处理 解析完成调用，调用BeanDefinitionReaderUtils类的registerBeanDefinition(Element, BeanDefinitionHolder)函数进行BeanDefinition的注册 发出响应通知相关监听器————完成该Bean标签解析 parseBeanDefinitionElement(Element)函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Parses the supplied &#123;@code &lt;bean&gt;&#125; element. May return &#123;@code null&#125; * if there were errors during parse. Errors are reported to the ProblemReporter */// BeanDefinitionParserDelegate.java@Nullablepublic BeanDefinitionHolder parseBeanDefinitionElement(Element ele) &#123; return parseBeanDefinitionElement(ele, null);&#125;// BeanDefinitionParserDelegate.java@Nullablepublic BeanDefinitionHolder parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) &#123; // 解析id和name属性 String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); // 别名集合 List&lt;String&gt; aliases = new ArrayList&lt;&gt;(); // 切分name属性 if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; // beanName优先使用id String beanName = id; // 其次使用alias别名的第一个 if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isTraceEnabled()) &#123; logger.trace(\"No XML 'id' specified - using '\" + beanName + \"' as bean name and \" + aliases + \" as aliases\"); &#125; &#125; // 检查beanName的唯一性 if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; // 解析其他属性,封装成AbstractBeanDefinition对象 AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) &#123; // 如果没有beanName,使用beanName生成规则生成唯一的beanName if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName(beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Neither XML 'id' nor 'name' specified - \" + \"using generated bean name [\" + beanName + \"]\"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); // 创建BeanDefinitionHolder对象 return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; return null;&#125; parseBeanDefinitionElement(Element)最终调用了重载函数，并在其中完成以下工作： 提取元素中的id以及name属性，根据id和name设置beanName和alias，检查beanName的唯一性 123456789101112131415161718192021222324252627282930// BeanDefinitionParserDelegate.java/** * Stores all used bean names so we can enforce uniqueness on a per * beans-element basis. Duplicate bean ids/names may not exist within the * same level of beans element nesting, but may be duplicated across levels. */// 已使用beanName集合(包括alias)private final Set&lt;String&gt; usedNames = new HashSet&lt;&gt;();/** * Validate that the specified bean name and aliases have not been used already * within the current level of beans element nesting. */protected void checkNameUniqueness(String beanName, List&lt;String&gt; aliases, Element beanElement) &#123; String foundName = null; // 找beanName匹配 if (StringUtils.hasText(beanName) &amp;&amp; this.usedNames.contains(beanName)) &#123; foundName = beanName; &#125; // 找alias匹配 if (foundName == null) &#123; foundName = CollectionUtils.findFirstMatch(this.usedNames, aliases); &#125; // 如果匹配上,使用problemReporter提示错误 if (foundName != null) &#123; error(\"Bean name '\" + foundName + \"' is already used in this &lt;beans&gt; element\", beanElement); &#125; // 将beanName和alias都加入beanName集合 this.usedNames.add(beanName); this.usedNames.addAll(aliases);&#125; 通过parseBeanDefinitionElement(Element, String, BeanDefinition)函数解析其他所有属性，并统一封装成AbstractBeanDefinition实例 如果beanName为空，根据默认规则生成唯一beanName 将所有信息封装成BeanDefinitionHolder parseBeanDefinitionElement(Element, String, BeanDefinition)函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Parse the bean definition itself, without regard to name or aliases. May return * &#123;@code null&#125; if problems occurred during the parsing of the bean definition. */// BeanDefinitionParserDelegate.java@Nullablepublic AbstractBeanDefinition parseBeanDefinitionElement(Element ele, String beanName, @Nullable BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); // 解析class属性 String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; // 解析parent属性 String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; try &#123; // 创建用于封装属性的AbstractBeanDefinition实例 AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 解析默认bean的各种属性 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); // 提取description bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); // 解析&lt;meta/&gt;标签 parseMetaElements(ele, bd); // 解析lookup-method属性：&lt;lookup-method/&gt; parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析replaced-method属性：&lt;replaced-method/&gt; parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析构造函数参数&lt;constructor-arg/&gt; parseConstructorArgElements(ele, bd); // 解析property子元素&lt;property/&gt; parsePropertyElements(ele, bd); // 解析qualifier子元素&lt;qualifier/&gt; parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error(\"Bean class [\" + className + \"] not found\", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err); &#125; catch (Throwable ex) &#123; error(\"Unexpected failure during bean definition parsing\", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null;&#125; parseBeanDefinitionElement(Element, String, BeanDefinition)函数中完成所有bean标签属性的解析工作，解析完成后可以得到一个基本可用的BeanDefinition createBeanDefinition(String, String)函数： 12345678910111213141516171819202122232425262728293031323334353637383940/** * Create a bean definition for the given class name and parent name. * @param className the name of the bean class * @param parentName the name of the bean's parent bean * @return the newly created bean definition * @throws ClassNotFoundException if bean class resolution was attempted but failed */// BeanDefinitionParserDelegate.javaprotected AbstractBeanDefinition createBeanDefinition(@Nullable String className, @Nullable String parentName) throws ClassNotFoundException &#123; return BeanDefinitionReaderUtils.createBeanDefinition(parentName, className, this.readerContext.getBeanClassLoader());&#125;/** * Create a new GenericBeanDefinition for the given parent name and class name, * eagerly loading the bean class if a ClassLoader has been specified. * @param parentName the name of the parent bean, if any * @param className the name of the bean class, if any * @param classLoader the ClassLoader to use for loading bean classes * (can be &#123;@code null&#125; to just register bean classes by name) * @return the bean definition * @throws ClassNotFoundException if the bean class could not be loaded */// BeanDefinitionReaderUtils.javapublic static AbstractBeanDefinition createBeanDefinition(@Nullable String parentName, @Nullable String className, @Nullable ClassLoader classLoader) throws ClassNotFoundException &#123; // 创建GenericBeanDefinition对象 GenericBeanDefinition bd = new GenericBeanDefinition(); // 设置parentName bd.setParentName(parentName); if (className != null) &#123; // 如果存在classLoader类加载器 if (classLoader != null) &#123; // 设置beanClass bd.setBeanClass(ClassUtils.forName(className, classLoader)); &#125; else &#123; // 设置beanClassName bd.setBeanClassName(className); &#125; &#125; return bd;&#125; createBeanDefinition(String, String)函数将创建AbstractBeanDefinition工作委托给BeanDefinitionReaderUtils，而在真正创建过程中创建的是GenericBeanDefinition实例，并设置了parentName、className以及beanClass属性 BeanDefinition介绍： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// BeanDefinition.javapublic interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; // \"singleton\" String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; // \"prototype\" int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; void setParentName(@Nullable String parentName); @Nullable String getParentName(); void setBeanClassName(@Nullable String beanClassName); @Nullable String getBeanClassName(); void setScope(@Nullable String scope); @Nullable String getScope(); void setLazyInit(boolean lazyInit); boolean isLazyInit(); void setDependsOn(@Nullable String... dependsOn); @Nullable String[] getDependsOn(); void setAutowireCandidate(boolean autowireCandidate); boolean isAutowireCandidate(); void setPrimary(boolean primary); boolean isPrimary(); void setFactoryBeanName(@Nullable String factoryBeanName); @Nullable String getFactoryBeanName(); void setFactoryMethodName(@Nullable String factoryMethodName); @Nullable String getFactoryMethodName(); ConstructorArgumentValues getConstructorArgumentValues(); default boolean hasConstructorArgumentValues() &#123; return !getConstructorArgumentValues().isEmpty(); &#125; MutablePropertyValues getPropertyValues(); default boolean hasPropertyValues() &#123; return !getPropertyValues().isEmpty(); &#125; void setInitMethodName(@Nullable String initMethodName); @Nullable String getInitMethodName(); void setDestroyMethodName(@Nullable String destroyMethodName); @Nullable String getDestroyMethodName(); void setRole(int role); int getRole(); void setDescription(@Nullable String description); @Nullable String getDescription(); ResolvableType getResolvableType(); boolean isSingleton(); boolean isPrototype(); boolean isAbstract(); @Nullable String getResourceDescription(); @Nullable BeanDefinition getOriginatingBeanDefinition();&#125; BeanDefinition是一个接口，描述了Bean实例的定义，包括属性值、构造方法值等更多信息基本上，和&lt;bean/&gt;标签中能定义的属性都能一一对应除此之外，BeanDefinition继承了AttributeAccessor以及BeanMetadataElement两个接口 123456789101112131415161718// AttributeAccessor.javapublic interface AttributeAccessor &#123; void setAttribute(String name, @Nullable Object value); @Nullable Object getAttribute(String name); @Nullable Object removeAttribute(String name); boolean hasAttribute(String name); String[] attributeNames();&#125;// BeanMetadataElement.javapublic interface BeanMetadataElement &#123; @Nullable default Object getSource() &#123; return null; &#125;&#125; 其中AttributeAccessor接口用于定义于其他对象的(元数据)进行连接和访问的约定————属性的获取与修改BeanMetadataElement中的getSource()函数则用于获取Bean元素对象持有的配置元素 BeanDefinition的继承图：BeanDefinition三个常用的实现类是ChildBeanDefinition、RootBeanDefinition以及GenericBeanDefinition。这三个类都继承自AbstractBeanDefinition抽象类，如果存在父子关系，那么父bean用RootBeanDefinition，子bean用ChildBeanDefinition表示；没有父子关系的bean也用RootBeanDefinition表示。GenericBeanDefinition是Spring2.5引入的bean文件配置定义属性类，是一站式服务类 parseBeanDefinitionAttributes(Element, String, BeanDefinition, AbstractBeanDefinition)函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * Apply the attributes of the given bean element to the given bean * definition. * @param ele bean declaration element * @param beanName bean name * @param containingBean containing bean definition * @return a bean definition initialized according to the bean element attributes */public AbstractBeanDefinition parseBeanDefinitionAttributes(Element ele, String beanName, @Nullable BeanDefinition containingBean, AbstractBeanDefinition bd) &#123; if (ele.hasAttribute(SINGLETON_ATTRIBUTE)) &#123; error(\"Old 1.x 'singleton' attribute in use - upgrade to 'scope' declaration\", ele); &#125; else if (ele.hasAttribute(SCOPE_ATTRIBUTE)) &#123; bd.setScope(ele.getAttribute(SCOPE_ATTRIBUTE)); &#125; else if (containingBean != null) &#123; // Take default from containing bean in case of an inner bean definition. bd.setScope(containingBean.getScope()); &#125; if (ele.hasAttribute(ABSTRACT_ATTRIBUTE)) &#123; bd.setAbstract(TRUE_VALUE.equals(ele.getAttribute(ABSTRACT_ATTRIBUTE))); &#125; String lazyInit = ele.getAttribute(LAZY_INIT_ATTRIBUTE); if (isDefaultValue(lazyInit)) &#123; lazyInit = this.defaults.getLazyInit(); &#125; bd.setLazyInit(TRUE_VALUE.equals(lazyInit)); String autowire = ele.getAttribute(AUTOWIRE_ATTRIBUTE); bd.setAutowireMode(getAutowireMode(autowire)); if (ele.hasAttribute(DEPENDS_ON_ATTRIBUTE)) &#123; String dependsOn = ele.getAttribute(DEPENDS_ON_ATTRIBUTE); bd.setDependsOn(StringUtils.tokenizeToStringArray(dependsOn, MULTI_VALUE_ATTRIBUTE_DELIMITERS)); &#125; String autowireCandidate = ele.getAttribute(AUTOWIRE_CANDIDATE_ATTRIBUTE); if (isDefaultValue(autowireCandidate)) &#123; String candidatePattern = this.defaults.getAutowireCandidates(); if (candidatePattern != null) &#123; String[] patterns = StringUtils.commaDelimitedListToStringArray(candidatePattern); bd.setAutowireCandidate(PatternMatchUtils.simpleMatch(patterns, beanName)); &#125; &#125; else &#123; bd.setAutowireCandidate(TRUE_VALUE.equals(autowireCandidate)); &#125; if (ele.hasAttribute(PRIMARY_ATTRIBUTE)) &#123; bd.setPrimary(TRUE_VALUE.equals(ele.getAttribute(PRIMARY_ATTRIBUTE))); &#125; if (ele.hasAttribute(INIT_METHOD_ATTRIBUTE)) &#123; String initMethodName = ele.getAttribute(INIT_METHOD_ATTRIBUTE); bd.setInitMethodName(initMethodName); &#125; else if (this.defaults.getInitMethod() != null) &#123; bd.setInitMethodName(this.defaults.getInitMethod()); bd.setEnforceInitMethod(false); &#125; if (ele.hasAttribute(DESTROY_METHOD_ATTRIBUTE)) &#123; String destroyMethodName = ele.getAttribute(DESTROY_METHOD_ATTRIBUTE); bd.setDestroyMethodName(destroyMethodName); &#125; else if (this.defaults.getDestroyMethod() != null) &#123; bd.setDestroyMethodName(this.defaults.getDestroyMethod()); bd.setEnforceDestroyMethod(false); &#125; if (ele.hasAttribute(FACTORY_METHOD_ATTRIBUTE)) &#123; bd.setFactoryMethodName(ele.getAttribute(FACTORY_METHOD_ATTRIBUTE)); &#125; if (ele.hasAttribute(FACTORY_BEAN_ATTRIBUTE)) &#123; bd.setFactoryBeanName(ele.getAttribute(FACTORY_BEAN_ATTRIBUTE)); &#125; return bd;&#125; #TODO","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://sobxiong.github.io/tags/Spring/"}]},{"title":"MyBatis","slug":"SpringSeries/MyBatis","date":"2021-01-23T10:55:07.000Z","updated":"2021-01-24T03:41:19.092Z","comments":true,"path":"2021/01/23/SpringSeries/MyBatis/","link":"","permalink":"https://sobxiong.github.io/2021/01/23/SpringSeries/MyBatis/","excerpt":"内容 MyBatis入门","text":"内容 MyBatis入门 MyBatis入门 中文链接：https://mybatis.org/mybatis-3/zh/index.html","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://sobxiong.github.io/tags/Spring/"}]},{"title":"MySQL源码分析","slug":"Middleware/MySQL/MySQL源码分析","date":"2021-01-08T08:44:06.000Z","updated":"2021-01-17T12:53:17.831Z","comments":true,"path":"2021/01/08/Middleware/MySQL/MySQL源码分析/","link":"","permalink":"https://sobxiong.github.io/2021/01/08/Middleware/MySQL/MySQL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"内容 环境搭建 查询分析 事务 故障恢复","text":"内容 环境搭建 查询分析 事务 故障恢复 环境搭建查询分析 源码启动首先从sql/main.cc的main()方法开始 1234int main(int argc, char **argv)&#123; return mysqld_main(argc, argv);&#125; 紧接着调用了sql/mysqld.cc的mysqld_main()方法，最主要调用了sql/conn_handler/connection_acceptor.h中connection_event_loop()方法的mysqld_socket_acceptor-&gt;connection_event_loop();语句进行端口监听，等待client客户端的连接 connection_event_loop()方法主要逻辑如下： 1234567891011// Connection acceptor loop to accept connections from clients. 连接接收器循环接收来自客户端的连接void connection_event_loop()&#123; Connection_handler_manager *mgr= Connection_handler_manager::get_instance(); while (!abort_loop) &#123; Channel_info *channel_info= m_listener-&gt;listen_for_connection_event(); if (channel_info != NULL) mgr-&gt;process_new_connection(channel_info); &#125;&#125; 在监听到客户端的连接后，调用sql/conn_handler/connection_handler_manager.cc中process_new_connection()方法的mgr-&gt;process_new_connection(channel_info);语句添加新的客户端连接并设置信息 process_new_connection()方法主要逻辑如下： 1234567891011121314void Connection_handler_manager::process_new_connection(Channel_info* channel_info)&#123; if (abort_loop || !check_and_incr_conn_count()) &#123; channel_info-&gt;send_error_and_close_channel(ER_CON_COUNT_ERROR, 0, true); delete channel_info; return; &#125; if (m_connection_handler-&gt;add_connection(channel_info)) &#123; inc_aborted_connects(); delete channel_info; &#125;&#125; 在处理新的连接方法中，主要调用了connection_handler_manager.cc中process_new_connection()方法的m_connection_handler-&gt;add_connection(channel_info)语句新增连接 add_connection()方法主要逻辑如下： 123456789101112131415161718192021222324252627bool Per_thread_connection_handler::add_connection(Channel_info* channel_info)&#123; int error= 0; my_thread_handle id; // ... /* There are no idle threads avaliable to take up the new connection. Create a new thread to handle the connection 没有空闲线程可以占用新连接 创建一个新线程来处理连接 */ channel_info-&gt;set_prior_thr_create_utime(); error= mysql_thread_create(key_thread_one_connection, &amp;id, &amp;connection_attrib, handle_connection, (void*) channel_info);handle_error: if (error) &#123; connection_errors_internal++; if (!create_thd_err_log_throttle.log()) sql_print_error(\"Can't create thread to handle new connection(errno= %d)\", error); channel_info-&gt;send_error_and_close_channel(ER_CANT_CREATE_THREAD, error, true); Connection_handler_manager::dec_connection_count(); &#125; Global_THD_manager::get_instance()-&gt;inc_thread_created();&#125; 在sql/conn_handler/connection_handler_per_thread.cc的add_connection()方法中主要通过mysql_thread_create();语句创建了线程监听连接的事件。在传入的参数中包含一个函数\bhandle_connection，该函数主要处理接收的事件操作 handle_connection()方法主要逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/**Thread handler for a connection 一个连接的线程处理器@param arg Connection object (Channel_info)This function (normally) does the following:- Initialize thread 初始化线程- Initialize THD to be used with this thread 初始化THD信息- Authenticate user 鉴权用户- Execute all queries sent on the connection 处理所有连接发送的请求- Take connection down 断开连接- End thread / Handle next connection using thread from thread cache 结束线程 / 从线程缓存中使用线程处理下一个连接*/extern \"C\" void *handle_connection(void *arg)&#123; // init ... for (;;) &#123; THD *thd= init_new_thd(channel_info); if (thd == NULL) &#123; connection_errors_internal++; handler_manager-&gt;inc_aborted_connects(); Connection_handler_manager::dec_connection_count(); break; // We are out of resources, no sense in continuing. &#125; if (pthread_reused) /**/ if (thd_prepare_connection(thd)) handler_manager-&gt;inc_aborted_connects(); else &#123; while (thd_connection_alive(thd)) &#123; if (do_command(thd)) break; &#125; end_connection(thd); &#125; close_connection(thd, 0, false, false); // ... &#125; my_thread_end(); my_thread_exit(0); return NULL;&#125; 在sql/conn_handler/connection_handler_per_thread.cc的handle_connection()方法中通过无限的for循环接收连接发送的事件，最主要通过do_command()方法进行事件的回调处理 do_command()方法主要逻辑如下： 12345678910111213141516171819/**Read one command from connection and execute it (query or simple command).从连接中读取一条命令并执行This function is called in loop from thread function. 这个方法被线程方法循环调用For profiling to work, it must never be called recursively.@retval 0 success 成功@retval 1 request of thread shutdown (see dispatch_command() description) 线程关闭*/bool do_command(THD *thd)&#123; bool return_value; // ... return_value= dispatch_command(thd, &amp;com_data, command); // ... return return_value;&#125; 在sql/sql_parse.cc中的do_command()方法读取客户端传递的命令并进行分发，最主要调用了dispatch_command()方法进行命令的分发调用 dispatch_command()方法主要逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/**Perform one connection-level (COM_XXXX) command. 执行一条连接级别的命令(以COM_为前缀)@param thd connection handle 连接句柄@param command type of command to perform 执行的命令类型@com_data com_data union to store the generated command \b保存的命令信息@retval 0 ok 成功@retval 1 request of thread shutdown, i. e. if command is COM_QUIT/COM_SHUTDOWN 线程关闭,比如命令是quit或shutdown*/bool dispatch_command(THD *thd, const COM_DATA *com_data, enum enum_server_command command)&#123; switch (command) &#123; case COM_INIT_DB: case COM_STMT_EXECUTE: case COM_STMT_FETCH: case COM_STMT_SEND_LONG_DATA: case COM_STMT_PREPARE: case COM_STMT_CLOSE: case COM_STMT_RESET: case COM_QUERY: &#123; // 从网络数据包中读取Query并存入thd-&gt;query // 如果发生致命错误,返回true if (alloc_query(thd, com_data-&gt;com_query.query, com_data-&gt;com_query.length)) break; // 记录原始SQL if (opt_general_log_raw) query_logger.general_log_write(thd, command, thd-&gt;query().str, thd-&gt;query().length); // ... // 解析SQL语句 mysql_parse(thd, &amp;parser_state); // ... &#125; &#125; // ... // 从网络返回结果 thd-&gt;send_statement_status(); thd-&gt;rpl_thd_ctx.session_gtids_ctx().notify_after_response_packet(thd); query_cache.end_of_result(thd); // ...&#125; 在sql/sql_parse.cc中的dispatch_command()方法根据具体的方法类型分别进行处理，在查询操作中首先调用alloc_query()方法从packet数据包中读取query信息并封装到线程数据结构中；接着最主要调用了mysql_parse()方法进行sql语句的解析和执行；在解析完毕后，调用thd-&gt;send_statement_status();语句从网络返回结果，查询调用完成 mysql_parse()方法主要逻辑如下： 123456789101112131415161718192021222324252627282930313233// Parse a query 解析一个查询语句void mysql_parse(THD *thd, Parser_state *parser_state)&#123; // ... mysql_reset_thd_for_next_command(thd); // ... // 如果不存在查询缓存 if (query_cache.send_result_to_client(thd, thd-&gt;query()) &lt;= 0) &#123; bool err= thd-&gt;get_stmt_da()-&gt;is_error(); if (!err) &#123; // SQL语句词法语法解析 err= parse_sql(thd, parser_state, NULL); // ... &#125; if (!err) &#123; // ... if (!thd-&gt;is_error()) &#123; // ... if (unlikely(thd-&gt;security_context()-&gt;password_expired() &amp;&amp;!lex-&gt;is_set_password_sql &amp;&amp; lex-&gt;sql_command != SQLCOM_SET_OPTION &amp;&amp; lex-&gt;sql_command != SQLCOM_ALTER_USER)) &#123; my_error(ER_MUST_CHANGE_PASSWORD, MYF(0)); error= 1; &#125; // 查询语句具体执行 else error= mysql_execute_command(thd, true); &#125; &#125; &#125;&#125; 在sql/sql_parse.cc中的mysql_parse()方法通过query_cache.send_result_to_client(thd, thd-&gt;query()) &lt;= 0语句首先判断当前查询是否已经有缓存结果，如果没有，则首先调用parse_sql()方法进行词法语法的解析工作，随后通过mysql_execute_command()方法进行sql语句的执行 parse_sql()方法的主要逻辑如下： 1234567891011121314151617181920212223242526/**This is a wrapper of MYSQLparse(). All the code should call parse_sql()instead of MYSQLparse(). 这是MYSQLparse()方法的包装器,所有的代码应该调用parse_sql()方法而不是MYSQLparse()方法As a by product of parsing, the parser can also generate a query digest. 作为解析的副产品,解析器还可以生成查询摘要.@param thd Thread context. 线程上下文@param parser_state Parser state. 解析器状态@param creation_ctx Object creation context. 对象创建上下文@return Error status.@retval FALSE on success.@retval TRUE on parsing error.*/bool parse_sql(THD *thd, Parser_state *parser_state, Object_creation_ctx *creation_ctx)&#123; // ... // 调用bison进行词法分析 bool mysql_parse_status= MYSQLparse(thd) != 0; // ...&#125;// from sql_yacc.ccextern int MYSQLparse(class THD *thd); mysql_execute_command()方法的主要逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/**Execute command saved in thd and lex-&gt;sql_command. 执行存储在线程句柄和lex中的sql语句@param thd Thread handle 线程句柄@retval FALSE OK@retval TRUE Error*/int mysql_execute_command(THD *thd, bool first_level)&#123; // ... // 获取解析后的sql语法树 LEX *const lex= thd-&gt;lex; // ... // 根据解析后的sql语法树的类型,决定下一步具体执行 switch (lex-&gt;sql_command) &#123; case SQLCOM_SHOW_STATUS: case SQLCOM_SHOW_DATABASES: case SQLCOM_SHOW_TABLES: case SQLCOM_SHOW_TRIGGERS: case SQLCOM_SHOW_TABLE_STATUS: case SQLCOM_SHOW_PLUGINS: case SQLCOM_SHOW_FIELDS: case SQLCOM_SHOW_KEYS: case SQLCOM_SHOW_VARIABLES: case SQLCOM_SHOW_CHARSETS: case SQLCOM_SHOW_COLLATIONS: case SQLCOM_SHOW_STORAGE_ENGINES: case SQLCOM_SHOW_PROFILE: case SQLCOM_SELECT: &#123; DBUG_EXECUTE_IF(\"use_attachable_trx\", thd-&gt;begin_attachable_ro_transaction();); thd-&gt;clear_current_query_costs(); res= select_precheck(thd, lex, all_tables, first_table); // 具体执行select if (!res) res= execute_sqlcom_select(thd, all_tables); // 保存当前查询花费 thd-&gt;save_current_query_costs(); DBUG_EXECUTE_IF(\"use_attachable_trx\", thd-&gt;end_attachable_transaction();); break; &#125; case SQLCOM_PREPARE: &#123; mysql_sql_stmt_prepare(thd); break; &#125; case SQLCOM_EXECUTE: &#123; mysql_sql_stmt_execute(thd); break; &#125; case SQLCOM_CREATE_TABLE: case SQLCOM_UNLOCK_TABLES: // ... &#125; // ...&#125; 在sql/sql_parse.cc中的parse_sql()方法最主要调用了MYSQLparse()方法(具体实现复杂)调用bison(类似yacc)进行词法分析。简单地说，主要通过调用yychar = yylex(&amp;yylval, &amp;yylloc, YYTHD)获取到SQL语句中的一个个token，然后根据事先的规则进行处理在sql/sql_parse.cc中的mysql_execute_command()方法中首先通过LEX *const lex= thd-&gt;lex;语句得到解析后的sql语法树，再根据sql语法树的类型决定下一步操作。在当前为SELECT操作，具体首先通过select_precheck()方法进行查询前的检查，如果通过检查，那么最主要调用res= execute_sqlcom_select(thd, all_tables);语句具体执行SELECT操作 execute_sqlcom_select()方法具体逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243static bool execute_sqlcom_select(THD *thd, TABLE_LIST *all_tables)&#123; // ... // 获取解析后的sql语法树 LEX *lex= thd-&gt;lex; // 打开查询或statement所需all_tables中的所有表 if (!(res= open_tables_for_query(thd, all_tables, 0))) &#123; MYSQL_SELECT_START(const_cast&lt;char*&gt;(thd-&gt;query().str)); // 判断是否是EXPLAIN语句 if (lex-&gt;is_explain()) &#123; /* We always use Query_result_send for EXPLAIN, even if it's an EXPLAIN for SELECT ... INTO OUTFILE: a user application should be able to prepend EXPLAIN to any query and receive output for it, even if the query itself redirects the output. */ Query_result *const result= new Query_result_send; if (!result) return true; /* purecov: inspected */ res= handle_query(thd, lex, result, 0, 0); &#125; else &#123; Query_result *result= lex-&gt;result; if (!result &amp;&amp; !(result= new Query_result_send())) return true; /* purecov: inspected */ Query_result *save_result= result; Query_result *analyse_result= NULL; if (lex-&gt;proc_analyse) &#123; if ((result = analyse_result= new Query_result_analyse(result, lex-&gt;proc_analyse)) == NULL) return true; &#125; // 具体处理sql语句 res= handle_query(thd, lex, result, 0, 0); delete analyse_result; if (save_result != lex-&gt;result) delete save_result; &#125; MYSQL_SELECT_DONE((int) res, (ulong) thd-&gt;current_found_rows); &#125;&#125; 在sql/sql_parse.cc中的execute_sqlcom_select()方法中首先调用LEX *lex= thd-&gt;lex;获取解析后的sql语法树；接着调用res= open_tables_for_query(thd, all_tables, 0)语句打开查询或者statement所需的表(包括锁的判断、获取等准备操作)；最后主要调用handle_query()方法进行最终sql语句的处理 handle_query()方法主要逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/**Handle a data manipulation query, from preparation through cleanup 从准备到清理处理数据操作查询@param thd thread handler 线程句柄@param lex query to be processed 解析后的sql语法树@param result sink of result of query execution. may be protocol object (for passing result to a client), insert object, update object, delete object, etc. 查询执行结果的接收器 可能是协议对象(用于将结果传递给客户端),也可能是插入对象、更新对象、删除对象等@param added_options additional options for detailed control over execution 执行详细控制的附加选项@param removed_options options that are not applicable for this command 不适用于此命令的选项@returns false if success, true if error@details Processing a query goes through 5 phases (parsing is already done) 处理一个查询需要经历5个阶段(解析已经完成) - Preparation 准备 - Locking of tables 表的锁定 - Optimization 优化 - Execution or explain 执行或解释 - Cleanup 清理 The queries handled by this function are: 此函数处理的查询有 SELECT INSERT ... SELECT REPLACE ... SELECT UPDATE (multi-table) DELETE (multi-table) The function processes simple query expressions without UNION and without multi-level ORDER BY/LIMIT separately. 这个函数处理简单的表达式查询,而不使用并集或分别进行多级排序 Such queries are executed with a more direct code path. 这样的查询使用更直接的代码路径执行*/bool handle_query(THD *thd, LEX *lex, Query_result *result, ulonglong added_options, ulonglong removed_options)&#123; // ... SELECT_LEX_UNIT *const unit= lex-&gt;unit; SELECT_LEX *const select= unit-&gt;first_select(); // ... const bool single_query= unit-&gt;is_simple(); // ... // 步骤1: Preparation if (single_query) &#123; unit-&gt;set_limit(unit-&gt;global_parameters()); select-&gt;context.resolve_in_select_list= true; select-&gt;set_query_result(result); select-&gt;make_active_options(added_options, removed_options); select-&gt;fields_list= select-&gt;item_list; if (select-&gt;prepare(thd)) goto err; unit-&gt;set_prepared(); &#125; else &#123; if (unit-&gt;prepare(thd, result, SELECT_NO_UNLOCK | added_options, removed_options)) goto err; &#125; /* Locking of tables is done after preparation but before optimization. This allows to do better partition pruning and avoid locking unused partitions. As a consequence, in such a case, prepare stage can rely only on metadata about tables used and not data from them. 表的锁定在准备之后但在优化之前完成 这允许更好地进行分区修剪并避免锁定未使用的分区。因此,在这种情况下,准备阶段只能依靠关于所用表的元数据,而不是来自表的数据 */ // 步骤2:Locking of tables if (lock_tables(thd, lex-&gt;query_tables, lex-&gt;table_count, 0)) goto err; /* Register query result in cache. Tables must be locked before storing the query in the query cache. Transactional engines must be signalled that the statement has started, by calling external_lock(). 在缓存中注册查询结果 必须先锁定表,然后才能将查询存储在查询缓存中 必须通知事务引擎statement已启动,通过调用external_lock()方法 */ query_cache.store_query(thd, lex-&gt;query_tables); // 步骤3: Optimization if (single_query) &#123; if (select-&gt;optimize(thd)) goto err; unit-&gt;set_optimized(); &#125; else &#123; if (unit-&gt;optimize(thd)) goto err; &#125; // 步骤4: Execution or explain if (lex-&gt;is_explain()) &#123; if (explain_query(thd, unit)) goto err; /* purecov: inspected */ &#125; else &#123; if (single_query) &#123; select-&gt;join-&gt;exec(); unit-&gt;set_executed(); if (thd-&gt;is_error()) goto err; &#125; else &#123; if (unit-&gt;execute(thd)) goto err; &#125; &#125; // ... // 步骤5: Cleanup res= unit-&gt;cleanup(false); // ...&#125; 在sql/sql_select.cc中的handle_query()方法依次经过五个步骤：Preparation、Locking of tables、Optimization、Execution or explain和Cleanup 事务 事务部分知识： MySQL采用XA-2PC(two phrase commit————两阶段提交)进行事务的提交 第一阶段(prepare)：TM(事务管理器————Transaction Manager)向RM(资源管理器————Resource Manager)发出prepare指令，RM进行操作，然后返回成功与否的信息给TM第二阶段(commit or rollback)：如果TM收到所有RM的成功消息，则TM向RM发出提交指令；否则发出回滚指令 MySQL通过两阶段提交很好地解决了binlog和redo log的一致性问题 第一阶段：InnoDB prepare，持有prepare_commit_mutex，并且write/sync redo log；将回滚段设置为Prepared状态，binlog不作任何操作第二阶段：包含两步 write/sync binlog； InnoDB commit(写入commit标记后释放prepare_commit_mutex) 以binlog的写入与否作为事务提交成功与否的标志：innodb commit标志并不是事务成功与否的标志，因为事务崩溃恢复过程如下： 崩溃恢复时，扫描最后一个binlog文件，提取其中的xid InnoDB维持了状态为prepare的事务链表，将这些事务的xid和binlog中记录的xid做比较，如果在binlog中存在，则提交，否则回滚事务 通过这种方式，InnoDB和binlog中的事务状态保持一致 MySQL5.7中binlog的组提交： 从XA(XA协议,采用两阶段提交方式管理分布式事务)恢复的逻辑可得————只要保证InnoDB prepare的redo日志在写binlog前完成write/sync即可，具体步骤如下： InnoDB Prepare，记录当前的LSN(日志序列号————log sequence number)到thd中 进入Group Commit的flush stage Leader搜集队列，同时算出队列中最大的LSN 将InnoDB的redo log write/fsync到指定的LSN 写binlog并进行随后的工作(sync binlog, InnoDB commit, etc) 将redo log的write/sync延迟到了binlog group commit的flush stage之后，sync binlog之前。通过延迟写redo log的方式，显式地为redo log做了一次组写入(redo log group write)，并减少了(redo log)log_sys-&gt;mutex的竞争 以commit命令为例分析事务执行流程，与查询命令一致，最终走到sql/sql_parse.cc中的mysql_execute_command()方法 mysql_execute_command()方法具体逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364int mysql_execute_command(THD *thd, bool first_level)&#123; // ... switch (lex-&gt;sql_command) &#123; // ... case SQLCOM_COMMIT: &#123; DBUG_ASSERT(thd-&gt;lock == NULL || thd-&gt;locked_tables_mode == LTM_LOCK_TABLES); bool tx_chain= (lex-&gt;tx_chain == TVL_YES || (thd-&gt;variables.completion_type == 1 &amp;&amp; lex-&gt;tx_chain != TVL_NO)); bool tx_release= (lex-&gt;tx_release == TVL_YES || (thd-&gt;variables.completion_type == 2 &amp;&amp; lex-&gt;tx_release != TVL_NO)); if (trans_commit(thd)) goto error; thd-&gt;mdl_context.release_transactional_locks(); /* Begin transaction with the same isolation level. */ if (tx_chain) &#123; if (trans_begin(thd)) goto error; &#125; else &#123; /* Reset the isolation level and access mode if no chaining transaction.*/ trans_reset_one_shot_chistics(thd); &#125; /* Disconnect the current client connection. */ if (tx_release) thd-&gt;killed= THD::KILL_CONNECTION; my_ok(thd); break; &#125; // ... &#125; // ... if (!thd-&gt;in_sub_stmt &amp;&amp; thd-&gt;transaction_rollback_request) &#123; /* We are not in sub-statement and transaction rollback was requested by one of storage engines (e.g. due to deadlock). Rollback transaction in all storage engines including binary log. 不在子statement中并且事务回滚是由某个存储引擎请求的(例如: 由于死锁) 回滚所有存储引擎中的事务,包括binlog */ trans_rollback_implicit(thd); thd-&gt;mdl_context.release_transactional_locks(); &#125; else if (stmt_causes_implicit_commit(thd, CF_IMPLICIT_COMMIT_END)) &#123; /* No transaction control allowed in sub-statements. 子statement不允许事务控制 */ DBUG_ASSERT(!thd-&gt;in_sub_stmt); /* If commit fails, we should be able to reset the OK status. 如果提交失败,应该设置OK状态 */ thd-&gt;get_stmt_da()-&gt;set_overwrite_status(true); /* Commit the normal transaction if one is active. 如果处于活动状态,提交正常事务 */ trans_commit_implicit(thd); thd-&gt;get_stmt_da()-&gt;set_overwrite_status(false); thd-&gt;mdl_context.release_transactional_locks(); &#125; // ...&#125; 在mysql_execute_command()方法中关于commit命令的case语句标识为SQLCOM_COMMIT，在其中最主要调用了trans_commit()方法同时，在switch-case匹配代码块后，可能会触发事务的隐式提交trans_commit_implicit();或回滚trans_rollback_implicit操作，其中前者最终触发tc_log-&gt;commit();语句；后者最终触发ha_rollback_trans;语句，具体参照后面内容 trans_commit()方法具体逻辑如下： 123456789101112131415161718/**Commit the current transaction, making its changes permanent.提交当前事务,使其更改永久化@param thd Current thread 当前线程@retval FALSE Success@retval TRUE Failure*/bool trans_commit(THD *thd)&#123; // ... if (trans_check_state(thd)) DBUG_RETURN(TRUE); // ... res= ha_commit_trans(thd, TRUE); // ...&#125; 在sql/transaction.cc中的trans_commit()方法进行事务的提交操作，其中最主要调用了ha_commit_trans()方法 ha_commit_trans()方法具体逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/**@param[in] ignore_global_read_lock Allow commit to complete even if a global read lock is active. This can be used to allow changes to internal tables (e.g. slave status tables). 允许提交完成,即是全局读锁定处于活动状态 这可能用于允许更改内部表(例如从库状态表)@retval 0 ok@retval 1 transaction was rolled back 事务回滚@retval 2 error during commit, data may be inconsistent 提交时出错,数据可能不一致*/int ha_commit_trans(THD *thd, bool all, bool ignore_global_read_lock)&#123; // ... if (ha_info) &#123; // ... if (rw_trans &amp;&amp; !ignore_global_read_lock) &#123; /* Acquire a metadata lock which will ensure that COMMIT is blocked by an active FLUSH TABLES WITH READ LOCK (and vice versa: COMMIT in progress blocks FTWRL). 获取一个元数据锁,这将保证提交被一个FTWRL(MySQL全局锁————整个库处于只读状态)阻止(反之亦然: 正在提交阻塞了FTWRL) We allow the owner of FTWRL to COMMIT; we assume that it knows what it does. 允许FTWRL的所有者提交; 并假设他知道它的作用 */ if (thd-&gt;mdl_context.acquire_lock(&amp;mdl_request, thd-&gt;variables.lock_wait_timeout)) &#123; ha_rollback_trans(thd, all); DBUG_RETURN(1); &#125; &#125; if (rw_trans &amp;&amp; (stmt_has_updated_trans_table(ha_info) || trans_has_noop_dml(ha_info)) &amp;&amp; check_readonly(thd, true)) &#123; ha_rollback_trans(thd, all); error= 1; goto end; &#125; if (!trn_ctx-&gt;no_2pc(trx_scope) &amp;&amp; (trn_ctx-&gt;rw_ha_count(trx_scope) &gt; 1)) error= tc_log-&gt;prepare(thd, all); &#125; if (error || (error= tc_log-&gt;commit(thd, all))) &#123; ha_rollback_trans(thd, all); error= 1; goto end; &#125; // ...&#125; 在sql/handler.cc中的ha_commit_trans()方法具体进行事务操作，首先经过一系列判断，如果条件不满足则调用ha_rollback_trans()方法进行回滚，否则先调用tc_log-&gt;prepare(thd, all);进行prepare操作；接着调用tc_log-&gt;commit(thd, all);进行commit操作；如果其中有错误，则调用a_rollback_trans()方法进行回滚 tc_log对象为MYSQL_BIN_LOG tc_log-&gt;prepare()方法具体逻辑如下： 12345678910111213/*Prepare the transaction in the transaction coordinator.在事务处理协调器中准备事务This function will prepare the transaction in the storage engines(by calling @c ha_prepare_low) what will write a prepare recordto the log buffers.此方法将在存储引擎中准备事务(通过调用ha_prepare_low()方法),这将写入准备记录到日志缓存区@retval 0 success@retval 1 error*/int MYSQL_BIN_LOG::prepare(THD *thd, bool all) tc_log-&gt;commit()方法具体逻辑如下： 1234567891011121314151617181920212223242526272829303132333435363738/**Commit the transaction in the transaction coordinator.在事务协调器中提交事务This function will commit the sessions transaction in the binary logand in the storage engines (by calling @c ha_commit_low). If thetransaction was successfully logged (or not successfully unlogged)but the commit in the engines did not succed, there is a risk ofinconsistency between the engines and the binary log.此方法将在binlog和存储引擎(通过调用ha_commit_low()方法)中提交会话事务如果事务已成功记录(或未成功取消记录),但在引擎中的提交没有成功,这会存在一个binlog和存储引擎不一致的风险For binary log group commit, the commit is separated into threeparts:对于binlog组提交,提交分为三个部分:1. First part consists of filling the necessary caches and finalizing them (if they need to be finalized). After this, nothing is added to any of the caches. 第一部分包括填充必要的缓存和并清除他们(如果需要清除) 此后,不会向任何缓存添加任何内容2. Second part execute an ordered flush and commit. This will be done using the group commit functionality in ordered_commit. 第二部分执行有序的flush和commit 这将使用有序提交中的组提交功能完成3. Third part checks any errors resulting from the ordered commit and handles them appropriately. 第三部分检查由有序提交导致的任何错误并妥善处理@retval RESULT_SUCCESS success@retval RESULT_ABORTED error, transaction was neither logged nor committed 中止 错误,事务不会被记录或提交@retval RESULT_INCONSISTENT error, transaction was logged but not committed 不一致 错误,事务会被记录但不会被提交*/TC_LOG::enum_result MYSQL_BIN_LOG::commit(THD *thd, bool all) ha_rollback_trans()方法具体逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int ha_rollback_trans(THD *thd, bool all)&#123; // ... if (tc_log) error= tc_log-&gt;rollback(thd, all); // ...&#125;/**Write a rollback record of the transaction to the binary log.将事务的回滚记录写入binlogFor binary log group commit, the rollback is separated into threeparts:对于binlog组提交,回滚分为三个部分:1. First part consists of filling the necessary caches and finalizing them (if they need to be finalized). After a cache is finalized, nothing can be added to the cache. 第一部分包括填充必要的缓存和并清除他们(如果需要清除) 在缓存被清除后,不能向缓存中添加任何内容2. Second part execute an ordered flush and commit. This will be done using the group commit functionality in @c ordered_commit. 第二部分执行有序的flush和commit,这将使用组提交完成(在ordered_commit()方法中) Since we roll back the transaction early, we call @c ordered_commit with the @c skip_commit flag set. The @c ha_commit_low call inside @c ordered_commit will then not be called. 因为提前回滚事务,所以需要调用ordered_commit()方法并设置skip_commit标识 ha_commit_low()方法内部的ordered_commit()方法将不会被调用3. Third part checks any errors resulting from the flush and handles them appropriately. 第三部分检查检查由flush导致的任何错误,并对其进行适当的处理@see MYSQL_BIN_LOG::ordered_commit@see ha_commit_low@see ha_rollback_low@param thd Session to commit 要提交的会话@param all This is @c true if this is a real transaction rollback, and @false otherwise. true：一个真正的事务回滚 false：其他情况@return Error code, or zero if there were no error.*/int MYSQL_BIN_LOG::rollback(THD *thd, bool all) 故障恢复 故障恢复部分知识 crash recovery过程中，binlog需保证： 所有已提交事务的binlog已存在 所有未提交事务的binlog不存在 MySQL使用两阶段提交解决binlog和InnoDB redo log的一致性问题：将普通事务当做内部XA事务处理，为每个事务分配一个XID，binlog作为事务的协调者 阶段1：InnoDB redo log写盘，InnoDB事务进入prepare状态 阶段2：binlog写盘，InooDB事务进入commit状态 每个事务binlog的末尾，会记录一个XID event，标志着事务是否提交成功。也就是说recovery过程中，binlog最后一个XID event之后的内容都应该被purge(清除)。InnoDB日志可能也需要回滚或者提交 sql/mysqld.cc中的mysqld_main()方法启动mysqld服务端，在其中进行恢复工作 mysqld_main()方法的主要逻辑如下： 123456int mysqld_main(int argc, char **argv)&#123; // ... if (init_server_components()) unireg_abort(MYSQLD_ABORT_EXIT); // ...&#125; 在mysqld_main()方法中，启动恢复工作的方法为init_server_components()，目的为初始化服务端组件 init_server_components()方法的主要逻辑如下： 123456789101112131415161718192021222324252627static int init_server_components()&#123; // ... if (opt_bin_log) &#123; // ... /* Skip opening the index file if we start with --help. This is necessary to avoid creating the file in an otherwise empty datadir, which will cause a succeeding 'mysqld --initialize' to fail. */ if (!opt_help &amp;&amp; mysql_bin_log.open_index_file(opt_binlog_index_name, ln, TRUE)) unireg_abort(MYSQLD_ABORT_EXIT); // ... &#125; // ... if (total_ha_2pc &gt; 1 || (1 == total_ha_2pc &amp;&amp; opt_bin_log)) &#123; if (opt_bin_log) tc_log= &amp;mysql_bin_log; else tc_log= &amp;tc_log_mmap; &#125; if (tc_log-&gt;open(opt_bin_log ? opt_bin_logname : opt_tc_log_file)) &#123; sql_print_error(\"Can't init tc log\"); unireg_abort(MYSQLD_ABORT_EXIT); &#125; // ...&#125; 在sql/mysqld.cc中的init_server_components()方法中，首先根据参数设置事务协调者(tc,Transaction Coordinator)即代码中的tc_log对象，在MySQL启动时默认初始化为mysql_bin_log对象。之后最主要调用了tc_log-&gt;open()也即binlog的open()方法 在事务提交时会依次执行tc_log-&gt;prepare();tc_log-&gt;commit();————即执行binlog的prepare()和commit()方法 \bMYSQL_BIN_LOG::open()方法主要逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101int open(const char *opt_name) &#123; return open_binlog(opt_name); &#125;int MYSQL_BIN_LOG::open_binlog(const char *opt_name)&#123; // ... // 确保index文件初始化成功 if (!my_b_inited(&amp;index_file)) &#123; /* There was a failure to open the index file, can't open the binlog */ cleanup(); return 1; &#125; // ... // 找到index中第一个binlog if ((error= find_log_pos(&amp;log_info, NullS, true/*need_lock_index=true*/))) &#123; if (error != LOG_INFO_EOF) sql_print_error(\"find_log_pos() failed (error: %d)\", error); else error= 0; goto err; &#125; // ... &#123; // ... // 找到index中最后一个binlog do&#123; strmake(log_name, log_info.log_file_name, sizeof(log_name)-1); &#125; while (!(error= find_next_log(&amp;log_info, true/*need_lock_index=true*/))); // ... /* 打开最后一个binlog;校验文件头的Magic Number————\\xfe\\x62\\x69\\x6e 如果Magic Number校验失败,报错退出,无法完成recovery 如果确定最后一个binlog没有内容,可删除binlog文件再重试 */ if ((file= open_binlog_file(&amp;log, log_name, &amp;errmsg)) &lt; 0) &#123; sql_print_error(\"%s\", errmsg); goto err; &#125; // ... /* If the binary log was not properly closed it means that the server may have crashed. In that case, we need to call MYSQL_BIN_LOG::recover to: 如果binlog没有正常关闭,mysql服务端可能crash 此时我们需要调用MYSQL_BIN_LOG::recover,为了: a) collect logged XIDs; 找出已记录的XIDs b) complete the 2PC of the pending XIDs; 完成待处理的XIDs的两阶段提交(InnoDB commit) c) collect the last valid position. 找到最后一个合法位点 Therefore, we do need to iterate over the binary log, even if total_ha_2pc == 1, to find the last valid group of events written. Later we will take this value and truncate the log if need be. 因此我们需要遍历binlog文件,找出最后写入的一个合法event集合 稍后截断无效的binlog,如果有必要的话 */ if ((ev= Log_event::read_log_event(&amp;log, 0, &amp;fdle, opt_master_verify_checksum)) &amp;&amp; ev-&gt;get_type_code() == binary_log::FORMAT_DESCRIPTION_EVENT &amp;&amp; (ev-&gt;common_header-&gt;flags &amp; LOG_EVENT_BINLOG_IN_USE_F || DBUG_EVALUATE_IF(\"eval_force_bin_log_recovery\", true, false))) &#123; sql_print_information(\"Recovering after a crash using %s\", opt_name); // 初始化合法点位 valid_pos= my_b_tell(&amp;log); // 执行recover恢复过程,并计算出合法点位 error= recover(&amp;log, (Format_description_log_event *)ev, &amp;valid_pos); &#125; else error=0; // ... /* Trim the crashed binlog file to last valid transaction or event (non-transaction) base on valid_pos. */ // 将崩溃的binlog文件修剪到最后一个有效的事务或基于有效位置的event(非事务) if (valid_pos &gt; 0) &#123; if ((file= mysql_file_open(key_file_binlog, log_name, O_RDWR | O_BINARY, MYF(MY_WME))) &lt; 0) &#123; // ... return -1; &#125; /* Change binlog file size to valid_pos */ // 将binlog文件大小更改为有效位置 if (valid_pos &lt; binlog_size) &#123; // 将valid_pos后面的binlog截断 if (my_chsize(file, valid_pos, 0, MYF(MY_WME))) &#123; // ... mysql_file_close(file, MYF(MY_WME)); return -1; &#125; else /**/ &#125; /* Clear LOG_EVENT_BINLOG_IN_USE_F */ my_off_t offset= BIN_LOG_HEADER_SIZE + FLAGS_OFFSET; uchar flags= 0; if (mysql_file_pwrite(file, &amp;flags, 1, offset, MYF(0)) != 1) &#123; // ... mysql_file_close(file, MYF(MY_WME)); return -1; &#125; mysql_file_close(file, MYF(MY_WME)); &#125; // ... &#125;&#125; 在sql/binlog.h中的open()方法直接调用了sql/binlog.cc中的MYSQL_BIN_LOG::open_binlog()方法，其中最主要调用了recover()方法进行恢复操作 recover()方法主要逻辑如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/**MYSQLD server recovers from last crashed binlog.MySQL服务端从上次崩溃的binlog中恢复@param log IO_CACHE of the crashed binlog. 崩溃binlog的IO缓存@param fdle Format_description_log_event of the crashed binlog. 崩溃binlog的格式化描述@param valid_pos The position of the last valid transaction or event(non-transaction) of the crashed binlog. 最后一个有效的事务或崩溃binlog的event(非事务)的位置@retval 0 ok@retval 1 error*/int MYSQL_BIN_LOG::recover(IO_CACHE *log, Format_description_log_event *fdle, my_off_t *valid_pos)&#123; // ... // 初始化XID hash,用于记录binlog中的xid if (!fdle-&gt;is_valid() || my_hash_init(&amp;xids, &amp;my_charset_bin, memory_page_size / 3, 0, sizeof(my_xid), 0, 0, 0, key_memory_binlog_recover_exec)) goto err1; // ... // 依次读取binlog while ((ev= Log_event::read_log_event(log, 0, fdle, TRUE)) &amp;&amp; ev-&gt;is_valid()) &#123; if (ev-&gt;get_type_code() == binary_log::QUERY_EVENT &amp;&amp; !strcmp(((Query_log_event*)ev)-&gt;query, \"BEGIN\")) in_transaction= TRUE; /* begin表示事务开始 */ if (ev-&gt;get_type_code() == binary_log::QUERY_EVENT &amp;&amp; !strcmp(((Query_log_event*)ev)-&gt;query, \"COMMIT\")) /* commit表示事务结束 */ &#123; DBUG_ASSERT(in_transaction == TRUE); in_transaction= FALSE; &#125; else if (ev-&gt;get_type_code() == binary_log::XID_EVENT) &#123; // xid event表示事务结束 DBUG_ASSERT(in_transaction == TRUE); in_transaction= FALSE; Xid_log_event *xev=(Xid_log_event *)ev; uchar *x= (uchar *) memdup_root(&amp;mem_root, (uchar*) &amp;xev-&gt;xid, sizeof(xev-&gt;xid)); // 记录xid if (!x || my_hash_insert(&amp;xids, x)) goto err2; &#125; /* Recorded valid position for the crashed binlog file which did not contain incorrect events. The following positions increase the variable valid_pos: 为崩溃的binlog文件记录的有效位置,其中不包含不正确的事件 以下位置增加有效位置变量： 1 - ... &lt;---&gt; HERE IS VALID &lt;---&gt; GTID BEGIN ... COMMIT ... 2 - ... &lt;---&gt; HERE IS VALID &lt;---&gt; GTID DDL/UTILITY ... In other words, the following positions do not increase the variable valid_pos: 换句话说,以下位置不会增加有效位置变量 1 - GTID &lt;---&gt; HERE IS VALID &lt;---&gt; ... 2 - GTID BEGIN &lt;---&gt; HERE IS VALID &lt;---&gt; ... */ /* 如果不在事务中,且不是gtid event,则更新valid_pos 如果在事务中,且最后一段event不是一个完整事务,pos不合法 */ if (!log-&gt;error &amp;&amp; !in_transaction &amp;&amp; !is_gtid_event(ev)) *valid_pos= my_b_tell(log); delete ev; &#125; /* Call ha_recover if and only if there is a registered engine that does 2PC, otherwise in DBUG builds calling ha_recover directly will result in an assert. (Production builds would be safe since ha_recover returns right away if total_ha_2pc &lt;= opt_log_bin.) 当且仅当注册的引擎执行两阶段提交调用ha_recover()方法 */ if (total_ha_2pc &gt; 1 &amp;&amp; ha_recover(&amp;xids)) goto err2; // ...&#125; 在sql/binlog.cc中的recover()方法主要逻辑为————遍历最后一个binlog的所有event，每次事务结尾(或者非事务event结尾)更新valid_pos(gtid event不更新)。并在一个hash中记录所有xid，用于引擎层恢复 在tc_log-&gt;open();语句执行恢复操作前，会调用MYSQL_BIN_LOG对象的open_index_file()方法 为了保证binlog index的crash safe，MySQL引入了一个临时文件————crash_safe_index_file新的binlog_file_name写入binlog_index_file，流程如下： 创建临时文件crash_safe_index_file 拷贝binlog_index_file中的内容到crash_safe_index_file 新的binlog_file_name写入crash_safe_index_file 删除binlog_index_file 重命名crash_safe_index_file到binlog_index_file这个流程保证了在任何时候崩溃时，binlog_index_file和crash_safe_index_file至少有一个可用这样恢复时只需判断这两个文件是否可用，如果binlog_index_file可用则无需特殊处理，如果binlog_index_file不可用则重命名crash_safe_index_file到binlog_index_filebinlog index的恢复过程主要在MYSQL_BIN_LOG::open_index_file()方法中 open_index_file()方法主要逻辑如下： 12345678910111213141516171819202122232425262728bool MYSQL_BIN_LOG::open_index_file(const char *index_file_name_arg, const char *log_name, bool need_lock_index)&#123; // 拼接index_file_name fn_format(index_file_name, index_file_name_arg, mysql_data_home, \".index\", opt); // 拼接crash_safe_index_file_name if (set_crash_safe_index_file_name(index_file_name_arg)) &#123; sql_print_error(\"MYSQL_BIN_LOG::set_crash_safe_index_file_name failed.\"); error= true; goto end; &#125; /* We need move crash_safe_index_file to index_file if the index_file does not exist and crash_safe_index_file exists when mysqld server restarts. 检查index_file_name和crash_safe_index_file_name是否存在 如果index_file_name不存在,crash_safe_index_file_name存在 那么将crash_safe_index_file_name重命名为index_file_name */ if (my_access(index_file_name, F_OK) &amp;&amp; !my_access(crash_safe_index_file_name, F_OK) &amp;&amp; my_rename(crash_safe_index_file_name, index_file_name, MYF(MY_WME))) &#123; sql_print_error(\"MYSQL_BIN_LOG::open_index_file failed to \" \"move crash_safe_index_file to index file.\"); error= true; goto end; &#125; // ...&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"https://sobxiong.github.io/tags/Middleware/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sobxiong.github.io/tags/MySQL/"}]},{"title":"前端基础","slug":"FrontEnd/Basic/H5+CSS3","date":"2021-01-01T13:58:38.000Z","updated":"2021-02-17T11:07:07.556Z","comments":true,"path":"2021/01/01/FrontEnd/Basic/H5+CSS3/","link":"","permalink":"https://sobxiong.github.io/2021/01/01/FrontEnd/Basic/H5+CSS3/","excerpt":"内容 HTML介绍 CSS介绍","text":"内容 HTML介绍 CSS介绍 HTML介绍 注释 介绍：会被浏览器忽视，不会直接显示；注释不能嵌套 语法：&lt;!-- --&gt; 文档声明(doctype) 介绍：用来告知浏览器当前网页的版本 HTML5的文档声明：&lt;!doctype html&gt;或&lt;!Doctype HTML&gt; HTML网页的基本构成 &lt;!doctype html&gt;：文档声明，声明当前网页的版本 &lt;html&gt;：html的根标签(元素)，网页中所有内容都要写在根标签中 &lt;head&gt;：网页头部，head中的内容不会直接出现，主要用来帮助浏览器或搜索引擎来解析网页 &lt;meta&gt;：设置网页的元数据，可用来设置字符集避免乱码问题 &lt;title&gt;：title中的内容会显示在浏览器的标题栏，搜索引擎主要根据title中的内容来判断网页的主要内容 &lt;body&gt;：body是html的子元素，表示网页的主体，网页中所有的可见内容都应该写在body中 实体： 介绍：在网页中编写的多个空格默认情况会自动被浏览器解析为一个空格。在HTML中有些时候不能直接书写一些特殊符号————比如多个连续的空格、字母两侧的大于和小于。如果需要在网页中书写这些特殊的符号，则需要使用html中的实体(转义字符) 实体的语法：&amp;实体的名字; 示例： &amp;nbsp; 空格(&nbsp;) &amp;gt; 大于号(&gt;) &amp;lt; 小于号(&lt;) &amp;copy; 版权符号(&copy;) ... meta标签 介绍：meta主要用于设置网页中的一些元数据(不是给用户使用,而是给浏览器和搜索引擎使用) 主要属性： charset：指定网页的字符集 &lt;meta charset=&quot;UTF-8&quot;&gt; name：指定数据的名称；content：指定数据的内容 &lt;meta name=&quot;keywords&quot; content=&quot;SOBXiong&quot;&gt; &lt;meta name=&quot;description&quot; content=&quot;SOBXiong&quot;&gt; keywords：表示网站的关键词，可同时指定多个(使用’,’隔开) description：用于指定网站的描述，网站的描述会显示在搜索引擎的搜索结果中 title：标签的内容会作为搜索结果的超链接上的文字显示 http-equiv以及content可用于重定向到其他页面： &lt;meta http-equiv=&quot;refresh&quot; content=&quot;3;url=https://www.baidu.com&quot;&gt; 默认3秒后重定向到百度 语义化标签 介绍：在网页中HTML专门用来负责网页的结构，因此在使用html标签时应关注标签的语义，而不是样式 浏览器在解析网页时，会自动对网页中不符合规范的内容进行修正。比如： 标签写在了根元素的外部 p元素中嵌套了块元素 根元素中出现了除head和body以外的子元素 ... 标签总体分类： 块元素(Block Element)：在页面中独占一行的元素 在网页中一般通过块元素来对页面进行布局 行内元素(Inline Element)：在页面中不会独占一行的元素 行内元素主要用来包裹文字 一般情况下会在块元素中放行内元素，而不会在行内元素中放块元素 块元素中基本上什么都能放 p元素中不能放任何的块元素 标签具体分类： 标题标签： 介绍：分为h1～h6(一共有六级标题)，h1～h6重要性依次递减，h1最重要，h6最不重要。h1在网页中的重要性仅次于title标签。一般情况下一个页面中只会有一个h1，且标题标签一般只会使用到h1～h3，h4～h6很少用。块元素 hgroup：为标题分组，可将一组相关的标题同时放入hgroup p标签：页面中的一个段落；块元素 em标签：表示语音语调的一个加重；行内元素 strong标签：表示强调，属于重要内容；行内元素 blockquote标签：表示一个长引用；块元素 q标签：短引用；行内元素 br标签：页面中的换行；行内元素 布局标签(结构化语义标签) header：网页的头部 main：网页的主体部分(一个页面中只会有一个main) footer：网页的底部 nav：网页中的导航 aside：和主体相关的其他内容(侧边栏) article：一个独立的文章 section：一个独立的区块，以上标签都不能表示时可使用section div：无语义，用来表示一个区块；目前div是主要的布局元素 span：行内元素，无语义，一般用于在网页中选中文字 列表： 介绍：列表之间可以相互嵌套，共有三种列表 分类： 无序列表：使用&lt;ol&gt;标签创建，用&lt;li&gt;表示列表项 有序列表：使用&lt;ul&gt;标签创建，用&lt;li&gt;表示列表项 定义列表：使用&lt;dl&gt;标签创建，用&lt;dt&gt;表示定义的内容，使用&lt;dd&gt;表示对内容的解释说明 超链接： 介绍：超链接可使从一个页面跳转到其他页面，或者是当前页面的其他的位置。超链接是也是一个行内元素，在a标签中可以嵌套除它自身外的任何元素 标签：&lt;a&gt; 属性： href：用于指定跳转的目标路径(一个外部网站或内部页面) 使用’#’作为占位符，会跳转到页面顶部可设置为’javascript:;’作为占位符，点击无效果如需跳转到指定位置，可设置为’#x’(目标元素的id值) target：用来指定超链接打开的位置 _self：默认值，在当前页面中打开超链接_blank：在一个新的页面中打开超链接 图片标签： 介绍：用于向当前页面中引入一个外部图片，是一个自结束标签，属于替换元素(块和行内元素之间,具有两种元素的特点) 标签：&lt;img&gt; 属性： src：指定外部图片的路径(路径规则和超链接一样) alt：图片的描述，该描述默认情况下不会显示，有些浏览器图片无法加载时会显示。搜索引擎会根据alt中的内容来识别图片，如果不写alt属性则图片不会被搜索引擎收录 width、height：图片的高度和宽度(单位为px,像素)。如果只修改其中一个，另一个默认会等比例缩放。一般在pc端不建议修改图片的大小，需要多大的图片就裁多大；但在移动端经常需要对图片进行缩放(大图缩小) 图片格式(效果一样用小的,不一样用好的)： jpeg(jpg)： 支持的颜色比较丰富，不支持透明效果和动图 一般用来显示照片 gif： 支持的颜色比较少，支持简单透明效果和动图 颜色单一的图片，动图 png： 支持的颜色丰富，支持复杂透明但不支持动图 颜色丰富，复杂透明(专为网页而生) webp： 谷歌新推出的专门用来表示网页中的图片的一种格式 具备其他图片格式的所有优点，而且文件还特别小 缺点：兼容性不好 base64编码：将图片使用base64编码，可将图片转换为字符。通过字符的形式来引入图片，一般都是一些需要和网页一起加载的图片才会使用base64 内联框架： 介绍：用于向当前页面中引入其他页面 属性： src：指定要引入的网页路径 frameborder：指定内联框架的边框 音视频标签： audio标签： 介绍：用来向页面中引入一个外部的音频文件；引入时默认情况下不允许用户自己控制播放停止 属性： src：指定文件路径 controls：是否允许用户控制播放 autoplay：音频文件是否自动播放(如果设置了则打开页面时会自动播放,但目前大部分浏览器都不支持) loop：音乐是否循环播放 video标签：用来向页面中引入一个视频，属性和audio基本一致 CSS介绍 网页组成：","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"https://sobxiong.github.io/tags/FrontEnd/"}]},{"title":"杂项","slug":"BasicSkill/Others","date":"2020-12-31T08:27:37.000Z","updated":"2021-01-17T12:25:24.894Z","comments":true,"path":"2020/12/31/BasicSkill/Others/","link":"","permalink":"https://sobxiong.github.io/2020/12/31/BasicSkill/Others/","excerpt":"内容 Idea常用快捷键","text":"内容 Idea常用快捷键 Idea常用快捷键 查找相关： Command + O：查询任意存在Class，并跳转到源码 Command + F12：查看当前类的方法 Option + H：查看当前类的继承结构 跳转相关： Option + Command + 左：上次查看地方 Option + Command + 右：下次查看地方 Command + 上：查看当前类所在包所有文件 Command + 下：maven定位当前类的包 Command + Fn + 左：查看当前文件的顶部 Command + Fn + 右：查看当前文件的底部 Command + L：通过行号快速跳转到某行","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"}]},{"title":"SpringBoot基础","slug":"SpringSeries/SpringBoot/SpringBoot基础","date":"2020-12-24T11:26:44.000Z","updated":"2021-01-08T03:08:32.415Z","comments":true,"path":"2020/12/24/SpringSeries/SpringBoot/SpringBoot基础/","link":"","permalink":"https://sobxiong.github.io/2020/12/24/SpringSeries/SpringBoot/SpringBoot%E5%9F%BA%E7%A1%80/","excerpt":"内容 SpringBoot概述 SpringBoot入门 自动配置原理介绍 Web场景 杂项","text":"内容 SpringBoot概述 SpringBoot入门 自动配置原理介绍 Web场景 杂项 SpringBoot概述 SpringBoot是什么：整合Spring技术栈的一站式框架，简化Spring技术栈的快速开发脚手架 Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”————能快速创建出生产级别的Spring应用 SpringBoot优点： 快速创建独立Spring应用 内嵌web服务器(Tomcat、Jetty、Undertow) 自动starter依赖，简化构建配置 自动配置Spring以及第三方功能 提供生产级别的监控、健康检查及外部化配置 无代码生成、无需编写XML SpringBoot资料： 官方资料： https://spring.io/projects/spring-boot#learn https://docs.spring.io/spring-boot/docs/current/reference/html/ Github(介绍版本差别和新特性)：https://github.com/spring-projects/spring-boot 中文资料：https://www.docs4dev.com/ SpringBoot入门 HelloWorld(根据官网手册) 创建maven项目 导入依赖 123456789101112131415161718192021222324&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 加入SpringBoot maven打包工具 --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 编写yml配置文件 创建主程序(@SpringBootApplication、SpringApplication.run(xxxApplication.class)) SpringApplication.run()方法有返回值，返回值为IOC容器对象 依赖管理： 父项目定义依赖： 我们的SpringBoot项目依赖spring-boot-starter-parentspring-boot-starter-parent依赖spring-boot-dependenciesspring-boot-dependencies管理了大部分依赖关系和版本 starter场景启动器(只要引入starter，该场景的所有依赖和基本配置都自动引入了)： spring-boot-starter-*表示官方编写的场景启动器SpringBoot支持的所有官方场景：https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-starter*-spring-boot-starter表示第三方提供的场景启动器所以场景启动器最底层都依赖了spring-boot-starter 依赖版本号 引入依赖默认都不需要写版本号(都经过SpringBoot的版本仲裁)引入非版本仲裁的依赖需要指定版本号修改默认版本号的方式 12345678&lt;!-- 查看spring-boot-dependencies中规定的当前依赖的版本所用的property属性名 在当前maven配置中重写 maven默认以子项目的版本号为主--&gt;&lt;properties&gt; &lt;xxx.version&gt;xxx&lt;/xxx.version&gt;&lt;/properties&gt; 自动配置 自动配置Tomcat(引入starter-web)：内嵌tomcat服务器 自动配置SpringMVC(引入starter-web) dispatcherServlet中央处理器 characterEncodingFilter解决字符编码问题 jackson解决json转换 viewResolver解决资源映射问题 multipartResolver解决上传文件问题 … 自动配置扫描包组件： 主程序Application所在包及子包中的组件都会被默认扫描 修改扫描路径：@SpringBootApplication(scanBasePackages = “xxx”) @SpringBootApplication注解的作用： 12345678910@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;&#125;// @SpringBootApplication注解属于合成注解，相当于使用了以下三个注解：// @SpringBootConfiguration// @EnableAutoConfiguration// @ComponentScan \b自动配置项属性 默认配置最终都会映射到某个类上(如MultipartProperties) 配置文件的值最终会绑定到一个配置属性类上，该类对象会保存在容器中 按需加载自动配置项 引入某场景，对应场景的自动配置才会开启 SpringBoot所有的自动配置功能都在spring-boot-autoconfigure包中 组件添加 @Configuration： 起到配置类的作用，相当于Spring中xml配置文件的作用 配置类本身也是组件，可以在容器中拿到 配置类中可使用@Bean注解给容器注册组件，默认也是单实例的 属性proxyBeanMethods描述代理bean的方法： Full模式(proxyBeanMethods = true)：保证每个@Bean方法被调用返回的组件都是从容器中找————单实例(组件依赖的情况必须使用Full模式,true也是默认值) Lite模式(proxyBeanMethods = false)：每个@Bean方法被调用返回的组件都是新创建的 @Bean、@Component、@Controller、@Service、@Repository @Bean注册的组件名默认为方法名 @ComponentScan @Import：根据类型在容器中创建组件，默认组件名是全类名 @Conditional： 条件装配(满足Conditional指定的条件才进行组件注册) SpringBoot按需自动加载配置项大量用到条件装配 @ImportResource：导入指定路径的原生Spring xml配置文件(适合老项目迁移) 配置绑定 介绍：读取application.properties或applicaiton.yml的内容并封装到JavaBean中；其中对应的JavaBean必须是在容器中的组件 实现方式： @Component + @ConfigurationProperties(同一个类上)：@Component保证将该配置Bean注册进容器，@ConfigurationProperties开启配置绑定功能 @EnableConfigurationProperties + @ConfigurationProperties(不同类上)：@EnableConfigurationProperties可指定注册进容器的@ConfigurationProperties标注的配置Bean(一般用于第三方配置) IDE启用properties或yml配置文件的提示： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 自动配置原理介绍 引导加载自动配置类 @SpringBootConfiguration：代表当前是一个配置类 12@Configurationpublic @interface SpringBootConfiguration &#123;&#125; @ComponentScan：指定包扫描组件路径 @EnableAutoConfiguration： @EnableAutoConfiguration是一个合成注解 123@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123;&#125; @AutoConfigurationPackage通过@Import注解导入另一个类AutoConfigurationPackages.Registrar 12@Import(AutoConfigurationPackages.Registrar.class)public @interface AutoConfigurationPackage &#123;&#125; Registrar通过调用register()方法进行批量注册(导入一系列组件) Registrar源码： 1234567891011static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImports(metadata).getPackageNames().toArray(new String[0])); &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.singleton(new PackageImports(metadata)); &#125;&#125; AnonotationMetadata就是指标注了@AutoConfigurationPackages的类的注解元信息，又由于@EnableAutoConfiguration是一个合成注解，因此相当于@AutoConfigurationPackages标注在MainApplicaiton上 其中new PackageImports(metadata).getPackageNames().toArray(new String[0])就是获取当前MainApplication的所在的包名；因此register()方法就是把当前MainApplication所在的包下的所有组件都注册进容器 @EnableAutoConfiguration通过@Import导入AutoConfigurationImportSelector类 AutoConfigurationImportSelector部分源码： 12345678910111213141516171819202122232425262728public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware,ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; // ... protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations; &#125; // ...&#125; 最主要的就是通过getAutoConfigurationEntry(annotationMetadata)方法得到自动配置的组件。该方法通过getCandidateConfigurations()获取所有候选的配置configurations，接下来反复操作configurations，比如removeDuplicates()方法去重、removeAll()排除部分...最终封装并返回 方法调用链如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; ClassLoader classLoaderToUse = classLoader; if (classLoaderToUse == null) &#123; classLoaderToUse = SpringFactoriesLoader.class.getClassLoader(); &#125; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoaderToUse).getOrDefault(factoryTypeName, Collections.emptyList());&#125;private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(ClassLoader classLoader) &#123; Map&lt;String, List&lt;String&gt;&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; result = new HashMap&lt;&gt;(); try &#123; Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); String[] factoryImplementationNames = StringUtils.commaDelimitedListToStringArray((String) entry.getValue()); for (String factoryImplementationName : factoryImplementationNames) &#123; result.computeIfAbsent(factoryTypeName, key -&gt; new ArrayList&lt;&gt;()) .add(factoryImplementationName.trim()); &#125; &#125; &#125; // Replace all lists with unmodifiable lists containing unique elements result.replaceAll((factoryType, implementations) -&gt; implementations.stream().distinct() .collect(Collectors.collectingAndThen(Collectors.toList(), Collections::unmodifiableList))); cache.put(classLoader, result); &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); &#125; return result;&#125; loadSpringFactories()方法最终是通过 Enumeration&lt;URL&gt; urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); 加载文件的。其中FACTORIES_RESOURCE_LOCATION值为”META-INF/spring.factories”，因此会默认扫描当前系统中所有META-INF/spring.factories位置的文件 spring.factories中Auto Configure部分写死了SpringBoot一启动就要向容器中加载的所有配置类 按需开启自动配置项 介绍：上面介绍了启动时会默认全部加载所有场景的自动配置；按照条件装配规则，最终按需配置加载 例子1：Aop场景(AopAutoConfiguration自动配置类)： AopAutoConfiguration源码： 123456789101112131415161718192021222324252627282930313233343536@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(prefix = \"spring.aop\", name = \"auto\", havingValue = \"true\", matchIfMissing = true)public class AopAutoConfiguration &#123; @Configuration(proxyBeanMethods = false) @ConditionalOnClass(Advice.class) static class AspectJAutoProxyingConfiguration &#123; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false) static class JdkDynamicAutoProxyConfiguration &#123;&#125; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) static class CglibAutoProxyConfiguration &#123;&#125; &#125; @Configuration(proxyBeanMethods = false) @ConditionalOnMissingClass(\"org.aspectj.weaver.Advice\") @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) static class ClassProxyingConfiguration &#123; ClassProxyingConfiguration(BeanFactory beanFactory) &#123; if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; &#125; &#125;&#125; 只有主类上的条件装配满足，才需要看子类和方法的条件装配 @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;auto&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)表示如果在配置文件中声明了spring.aop.name为true时当前aop的自动配置生效，但因为matchIfMissing属性，所以没声明也认为是true，也自动生效 AspectJAutoProxyingConfiguration使用@ConditionalOnClass(Advice.class)标注只有在导入了Advice.class(aspectj的包)之后才会生效 由于Advice.class没被导入，此时ClassProxyingConfiguration生效。因为它使用@ConditionalOnMissingClass(&quot;org.aspectj.weaver.Advice&quot;)标注，表示没有导入Adivce.class时生效，此时开启了简单的AOP功能 例子2：Web场景(DispatcherServletAutoConfiguration自动配置类) DispatcherServletAutoConfiguration源码： 123456789101112131415161718192021222324252627282930313233343536@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(DispatcherServlet.class)@AutoConfigureAfter(ServletWebServerFactoryAutoConfiguration.class)public class DispatcherServletAutoConfiguration &#123; // ... @Configuration(proxyBeanMethods = false) @Conditional(DefaultDispatcherServletCondition.class) @ConditionalOnClass(ServletRegistration.class) @EnableConfigurationProperties(WebMvcProperties.class) protected static class DispatcherServletConfiguration &#123; @Bean(name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME) public DispatcherServlet dispatcherServlet(WebMvcProperties webMvcProperties) &#123; DispatcherServlet dispatcherServlet = new DispatcherServlet(); dispatcherServlet.setDispatchOptionsRequest(webMvcProperties.isDispatchOptionsRequest()); dispatcherServlet.setDispatchTraceRequest(webMvcProperties.isDispatchTraceRequest()); dispatcherServlet.setThrowExceptionIfNoHandlerFound(webMvcProperties.isThrowExceptionIfNoHandlerFound()); dispatcherServlet.setPublishEvents(webMvcProperties.isPublishRequestHandledEvents()); dispatcherServlet.setEnableLoggingRequestDetails(webMvcProperties.isLogRequestDetails()); return dispatcherServlet; &#125; @Bean @ConditionalOnBean(MultipartResolver.class) @ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) public MultipartResolver multipartResolver(MultipartResolver resolver) &#123; // Detect if the user has created a MultipartResolver but named it incorrectly return resolver; &#125; &#125; // ...&#125; @ConditionalOnWebApplication注解判断当前是否是一个web应用，而且是一个传统的原生servlet web应用(区别于响应式WebFlux)@ConditionalOnClass注解判断当前是否导入了DispatcherServlet类(Spring-webmvc包下)@AutoConfigureOrder指定最先的加载顺序@AutoConfigureAfter指定在web服务器配置加载之后加载子类DispatcherServletConfiguration启用了WebMvcProperties配置，并在dispatcherServlet()方法中返回一个封装好各种参数的dispatcherServlet，且beanName默认为dispatcherServlet————public static final String DEFAULT_DISPATCHER_SERVLET_BEAN_NAME = &quot;dispatcherServlet&quot;;还配置了一个MultipartResolver文件上传解析器(优先使用用户自定义的)：@ConditionalOnMissingBean表示如果用户自定义的解析器名称不合乎规范，那么就将它原样返回(方法参数会默认从容器中找) 总结： SpringBoot先加载所有的自动配置类xxxAutoConfiguration 每个自动配置类按照条件装配，默认会绑定一个xxxProperties配置类，xxxProperties配置类又和和配置文件application.properties/application.yml进行了绑定 生效的配置类会给容器装配很多组件；只要容器中有对应的组件，就相当于启用了对应的功能 定制化配置(默认以用户配置为主) 修改配置文件中的对应属性值 使用@Bean替换底层组件 最佳实践 引入场景依赖：https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-starter 查看自动配置了哪些 引入场景后，一般对应的自动配置都生效 在配置文件中声明debug=true开启打印自动配置报告并查看自动配置情况 按需修改 参照文档修改配置： 官网资料：https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-application-properties.html#common-application-properties 查看并分析xxxProperties中的属性 自定义加入或替换组件：@Bean、@Component... 自定义器：xxxCustomizer ... Web场景 SpringMVC自动配置概览 内容协商视图解析器ContentNegotiatingViewResolver和BeanName视图解析器BeanNameViewResolver 静态资源映射(包括webjars) 自动注册Converter, GenericConverter, Formatter 支持HttpMessageConverters 自动注册MessageCodesResolver(国际化) 静态index.html支持 自定义Favicon 自动使用ConfigurableWebBindingInitializer(DataBinder负责将请求数据绑定到JavaBean上) 定制化SpringMVC功能：通过在配置类中导入WebMvcConfigurer的Bean，并在创建时重写一系列方法 静态资源访问相关 静态资源访问：参考地址：https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-static-content 静态资源目录： 只要静态资源放在类路径(classpath)下————/static、/public、/resources、/META-INF/resources，就可以通过使用当前项目跟路径/静态资源名来访问 原理：默认静态资源映射为/**，请求进来先去找Controller能不能处理，不能处理的所有请求全都交给静态资源处理器(默认从上面的路径下找)，再找不到则响应404页面 改变默认静态资源路径示例如下： 123spring: resources: static-locations: [classpath:/res/] 静态资源访问前缀： 默认情况无前缀，静态资源访问路径 = 项目名/static-path-pattern/资源名，示例如下： 123spring: mvc: static-path-pattern: /res/** 欢迎页支持： 默认路径为静态资源路径下的index.html，配置静态资源的访问前缀会导致欢迎页失效 可以使用controller处理/index请求 自定义Favicon：\bfavicon.ico放在静态资源目录下即可；同样地，配置静态资源的访问前缀会导致欢迎页失效(浏览器默认请求/favicon获取) 静态资源配置原理分析： 导入web场景后，SpringMVC的自动配置类WebMvcAutoConfiguration生效 WebMvcAutoConfiguration源码： 12345678910111213141516171819202122232425262728293031323334353637@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; @Configuration(proxyBeanMethods = false) @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties(&#123; WebMvcProperties.class, org.springframework.boot.autoconfigure.web.ResourceProperties.class, WebProperties.class &#125;) @Order(0) public static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer &#123; public WebMvcAutoConfigurationAdapter( org.springframework.boot.autoconfigure.web.ResourceProperties resourceProperties, WebProperties webProperties, WebMvcProperties mvcProperties, ListableBeanFactory beanFactory, ObjectProvider&lt;HttpMessageConverters&gt; messageConvertersProvider, ObjectProvider&lt;ResourceHandlerRegistrationCustomizer&gt; resourceHandlerRegistrationCustomizerProvider, ObjectProvider&lt;DispatcherServletPath&gt; dispatcherServletPath, ObjectProvider&lt;ServletRegistrationBean&lt;?&gt;&gt; servletRegistrations) &#123; this.resourceProperties = resourceProperties hasBeenCustomized() ? resourceProperties : webProperties.getResources(); this.mvcProperties = mvcProperties; this.beanFactory = beanFactory; this.messageConvertersProvider = messageConvertersProvider; this.resourceHandlerRegistrationCustomizer = resourceHandlerRegistrationCustomizerProvider.getIfAvailable(); this.dispatcherServletPath = dispatcherServletPath; this.servletRegistrations = servletRegistrations; this.mvcProperties.checkConfiguration(); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; /**/ &#125; @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) &#123; /**/ &#125; &#125;&#125; 在WebMvcAutoConfigurationAdapter\b\b\b中启用了WebMvcProperties(绑定spring.mvc)和ResourceProperties配置类(绑定spring.resources)在WebMvcAutoConfigurationAdapter构造器中的参数都从容器中获取： 其中properties是绑定的配置类对象 ListableBeanFactory是spring的beanFactory(容器) ObjectProvider&lt;HttpMessageConverters&gt;：所有的HttpMessageConveter ObjectProvider&lt;ResourceHandlerRegistrationCustomize&gt;：资源处理器的自定义器 静态资源映射原理分析：相关源码： 12345678910111213141516171819202122@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug(\"Default resource handling disabled\"); return; &#125; Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); if (!registry.hasMappingForPattern(\"/webjars/**\")) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\") .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl) .setUseLastModified(this.resourceProperties.getCache().isUseLastModified())); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl) .setUseLastModified(this.resourceProperties.getCache().isUseLastModified())); &#125;&#125; !this.resourceProperties.isAddMappings()如果resourceProperties的addMappings属性为false(对应properties配置文件中的spring.web.resources.add-mappings)，那么直接跳过，这表明禁用静态资源映射接下来的两行 12Duration cachePeriod = this.resourceProperties.getCache().getPeriod();CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); 表明可通过resourceProperties配置类配置静态资源的缓存规则(对应properties配置文件的spring.web.resources.cache) 接着指定webjars的映射和缓存规则 123456if (!registry.hasMappingForPattern(\"/webjars/**\")) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\") .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl) .setUseLastModified(this.resourceProperties.getCache().isUseLastModified()));&#125; 最后设置静态资源的加载规则 1234567String staticPathPattern = this.mvcProperties.getStaticPathPattern();if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl) .setUseLastModified(this.resourceProperties.getCache().isUseLastModified()));&#125; staticPathPattern默认值为/**，静态资源和webjars的映射和缓存规则几乎相同，除了映射地址不同。其中静态资源地址的默认值源码如下： 123456789public static class Resources &#123; private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; \"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" &#125;; private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS; // ...&#125; 欢迎页处理规则分析：相关源码： 1234567891011121314151617181920@Beanpublic WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) &#123; WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider)); welcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations()); return welcomePageHandlerMapping;&#125;WelcomePageHandlerMapping(TemplateAvailabilityProviders templateAvailabilityProviders, ApplicationContext applicationContext, Optional&lt;Resource&gt; welcomePage, String staticPathPattern) &#123; if (welcomePage.isPresent() &amp;&amp; \"/**\".equals(staticPathPattern)) &#123; logger.info(\"Adding welcome page: \" + welcomePage.get()); setRootViewName(\"forward:index.html\"); &#125; else if (welcomeTemplateExists(templateAvailabilityProviders, applicationContext)) &#123; logger.info(\"Adding welcome page template: index\"); setRootViewName(\"index\"); &#125;&#125; 在WelcomePageHandlerMapping构造函数中welcomePage.isPresent() &amp;&amp; &quot;/**&quot;.equals(staticPathPattern)表明如果欢迎页存在并且静态资源路径前缀是/**才会转发到index.html，否则就调用controller响应index请求。这就解释了为什么配置静态资源前缀会使欢迎页失效 请求参数处理 请求映射 rest介绍与原理： Rest介绍： Controller方法使用@xxxMapping注释 Rest风格使用：GET————获取、POST————保存、DELETE————删除、PUT————修改 表单的核心Filter：HiddenHttpMethodFilter 用法：表单method设置为post，隐藏域_method=xxx SpringBoot手动开启：spring.mvc.hiddenmethod.filter.enable=true(开启页面表单的Rest功能) 客户端默认支持Rest(表单只支持GET、POST) Rest简要原理(表单提交)： 表单提交会带上_method=PUT/DELETE 请求时被HiddenHttpMethodFilter拦截处理 源码分析： WebMvcAutoConfiguration源码： 123456@Bean@ConditionalOnMissingBean(HiddenHttpMethodFilter.class)@ConditionalOnProperty(prefix = \"spring.mvc.hiddenmethod.filter\", name = \"enabled\", matchIfMissing = false)public OrderedHiddenHttpMethodFilter hiddenHttpMethodFilter() &#123; return new OrderedHiddenHttpMethodFilter();&#125; matchIfMissing = false，如果不手动开启就不使用隐藏表单提交Rest请求 HiddenHttpMethodFilter源码： 1234567891011121314151617181920212223public class HiddenHttpMethodFilter extends OncePerRequestFilter &#123; public static final String DEFAULT_METHOD_PARAM = \"_method\"; private String methodParam = DEFAULT_METHOD_PARAM; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; HttpServletRequest requestToUse = request; if (\"POST\".equals(request.getMethod()) &amp;&amp; request.getAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE) == null) &#123; String paramValue = request.getParameter(this.methodParam); if (StringUtils.hasLength(paramValue)) &#123; String method = paramValue.toUpperCase(Locale.ENGLISH); if (ALLOWED_METHODS.contains(method)) &#123; requestToUse = new HttpMethodRequestWrapper(request, method); &#125; &#125; &#125; filterChain.doFilter(requestToUse, response); &#125;&#125; &quot;POST&quot;.equals(request.getMethod()请求必须为POST请求request.getParameter(this.methodParam)又有methodParam默认为”_method”，因此默认获取_method请求参数(PUT/DELETE)paramValue.toUpperCase(Locale.ENGLISH)表明_method大小写均可ALLOWED_METHODS.contains(method)验证请求方式是否支持(PUT、DELETE、PATCH)最后通过wrapper包装原生的request(重写了getMethod()方法)，最终交由过滤器链运行 请求映射原理 SpringMVC中的Servlet继承结构： 请求过程分析： 请求经过HttpServlet的doGet(doPost等等同)方法： 子类FrameworkServlet重写doGet(doPost等等同)方法统一调用processRequest()方法 1234@Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125; processRequest()最终调用doService()处理逻辑 1234567891011121314151617181920212223protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // ... try &#123; doService(request, response); &#125; catch (ServletException | IOException ex) &#123; failureCause = ex; throw ex; &#125; catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException(\"Request processing failed\", ex); &#125; finally &#123; resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) &#123; requestAttributes.requestCompleted(); &#125; logResult(request, response, failureCause, asyncManager); publishRequestHandledEvent(request, response, startTime, failureCause); &#125;&#125; 子类DispatcherServlet重写抽象方法doService()，最终调用doDispatch()方法进行转发 12345678910111213141516171819202122// FrameworkServlet.classprotected abstract void doService(HttpServletRequest request, HttpServletResponse response) throws Exception;// DispatcherServlet.class@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // ... try &#123; doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; if (requestPath != null) &#123; ServletRequestPathUtils.clearParsedRequestPath(request); &#125; &#125;&#125; doDispatch()方法解析 12345678910111213141516171819202122232425262728293031323334353637383940414243protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // ... &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; // ...&#125;protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; if (this.handlerMappings != null) &#123; for (HandlerMapping mapping : this.handlerMappings) &#123; HandlerExecutionChain handler = mapping.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; return null;&#125; processedRequest = checkMultipart(request)检查是否进行文件上传请求 mappedHandler = getHandler(processedRequest)决定当前请求的处理方法 @RequestMappingHandlerMapping：保存了所有@RequestMapping和handler的映射规则 getHandler\b()获取处理方法解析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// AbstractHandlerMapping.classpublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; Object handler = getHandlerInternal(request); if (handler == null) &#123; handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; // Bean name or resolved handler? if (handler instanceof String) &#123; String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); &#125; HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); // ... return executionChain;&#125;protected abstract Object getHandlerInternal(HttpServletRequest request) throws Exception;// RequestMappingInfoHandlerMapping.classprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; request.removeAttribute(PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE); try &#123; return super.getHandlerInternal(request); &#125; finally &#123; ProducesRequestCondition.clearMediaTypesAttribute(request); &#125;&#125;// AbstractHandlerMethodMapping.classprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; String lookupPath = initLookupPath(request); this.mappingRegistry.acquireReadLock(); try &#123; HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); &#125; finally &#123; this.mappingRegistry.releaseReadLock(); &#125;&#125;protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;&gt;(); List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByDirectPath(lookupPath); if (directPathMatches != null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; if (matches.isEmpty()) &#123; addMatchingMappings(this.mappingRegistry.getRegistrations().keySet(), matches, request); &#125; if (!matches.isEmpty()) &#123; Match bestMatch = matches.get(0); if (matches.size() &gt; 1) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); matches.sort(comparator); bestMatch = matches.get(0); if (logger.isTraceEnabled()) &#123; logger.trace(matches.size() + \" matching mappings: \" + matches); &#125; if (CorsUtils.isPreFlightRequest(request)) &#123; return PREFLIGHT_AMBIGUOUS_MATCH; &#125; Match secondBestMatch = matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); String uri = request.getRequestURI(); throw new IllegalStateException( \"Ambiguous handler methods mapped for '\" + uri + \"': &#123;\" + m1 + \", \" + m2 + \"&#125;\"); &#125; &#125; request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.handlerMethod); handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.handlerMethod; &#125; else &#123; return handleNoMatch(this.mappingRegistry.getRegistrations().keySet(), lookupPath, request); &#125;&#125; DispatcherServlet的getHandler()调用AbstractHandlerMapping的getHandler()方法 getHandler()方法调用getHandlerInternal()抽象方法，实际调用了RequestMappingInfoHandlerMapping的getHandlerInternal()方法 getHandlerInternal()方法实际调用了父类AbstractHandlerMethodMapping的getHandlerInternal()方法 最后getHandlerInternal()方法调用了lookupHandlerMethod()方法决定选择处理请求的处理器方法 自动的添加映射器源码分析 WebMvcAutoConfiguration源码： 12345678910111213141516171819202122@Bean@Primary@Overridepublic RequestMappingHandlerMapping requestMappingHandlerMapping( @Qualifier(\"mvcContentNegotiationManager\") ContentNegotiationManager contentNegotiationManager, @Qualifier(\"mvcConversionService\") FormattingConversionService conversionService, @Qualifier(\"mvcResourceUrlProvider\") ResourceUrlProvider resourceUrlProvider) &#123; // Must be @Primary for MvcUriComponentsBuilder to work return super.requestMappingHandlerMapping(contentNegotiationManager, conversionService, resourceUrlProvider);&#125;@Beanpublic WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) &#123; WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider)); welcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations()); return welcomePageHandlerMapping;&#125; SpringBoot默认添加RequestMappingHandlerMapping用于映射Controller编写的@RequestMapping修饰的方法；默认添加WelcomePageHandlerMapping映射欢迎页 总结 自动配置欢迎页的WelcomePageHandlerMapping，访问’/‘能访问到index.html 自动配置了默认的RequestMappingHandlerMapping 请求进来后挨个尝试所有的HandlerMapping看是否有请求信息(如果有就找到这个请求对应的handler,没有就继续遍历) 若需要一些自定义的映射处理，也可给容器中放HandlerMapping(自定义 HandlerMapping) 请求参数 相关类： 注解：@PathVariable、@RequestHeader、@ModelAttribute、@RequestParam、@MatrixVariable、@CookieValue、@RequestBody Servlet API：WebRequest、ServletRequest、MultipartRequest、HttpSession等(具体见ServletRequestMethodArgumentResolver类的supportsParameter()方法) 复杂参数：Map、Model(map、model里面的数据会被放在request的请求域中————相当于request.setAttribute())、RedirectAttributes(重定向携带数据)、ServletResponse(response) 无论是Map还是Model类型，底层都会使用mavContainer.getModel();方法返回BindingAwareModelMap(即是Model也是Map) 参数处理： 介绍： HandlerMapping中找到能够处理请求的Handler(Controller中的处理方法) 为当前Handler找一个适配器HandlerAdapter————RequestMappingHandlerAdapter RequestMappingHandlerAdapter支持标注@RequestMapping的方法 HandlerFunctionAdapter支持函数式变成的方法 使用参数解析器argumentResolver解析目标方法的每一个参数的值 SpringMVC目标方法能支持多少种参数类型取决于参数解析器 supportsParameter()方法表示当前解析器是否支持解析这种参数 resolveArgument()方法表示具体解析的逻辑 执行目标方法 源码分析： DispatcherServlet的doDispatch()方法： 1234567891011121314151617181920212223242526272829303132333435363738protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // ... try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // ... // Determine handler for the current request. mappedHandler = getHandler(processedRequest); // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // ... // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // ... &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; // ... &#125;&#125; 首先通过mappedHandler = getHandler(processedRequest);找到能够响应当前请求的处理器方法然后通过HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());找到处理当前请求的handler适配器最后通过mv = ha.handle(processedRequest, response, mappedHandler.getHandler());执行处理器方法并返回modelAndView handle()方法执行流程分析： 1234567891011121314151617181920212223242526272829// AbstractHandlerMethodAdapter.classpublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125;// RequestMappingHandlerAdapter.classprotected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; // ... // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &#125; // ... return mav;&#125; DispatcherServlet中的doDispatcher方法调用mv = ha.handle(processedRequest, response, mappedHandler.getHandler());执行目标方法之后handle方法调用的是AbstractHandlerMethodAdapter的handle方法，其实质上又调用了子类RequestMappingHandlerAdapter的handleInternal方法，最终调用了RequestMappingHandlerAdapter的invokeHandlerMethod方法 invokeHandlerMethod()方法执行流程分析： 1234567891011121314151617181920212223242526272829303132333435363738// RequestMappingHandlerAdapter.classprotected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; // ... ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; // ... invocableMethod.invokeAndHandle(webRequest, mavContainer); // ... return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125;// ServletInvocableHandlerMethod.classpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); // ...&#125;// InvocableHandlerMethod.classpublic Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace(\"Arguments: \" + Arrays.toString(args)); &#125; return doInvoke(args);&#125; invokeHandlerMethod首先设置参数解析器和返回值解析器，最终调用类ServletInvocableHandlerMethod的invocableMethod.invokeAndHandle(webRequest, mavContainer);解析参数、执行目标方法并获得返回值invokeAndHandle通过调用父类InvocableHandlerMethod的invokeForRequest执行目标方法，invokeForRequest先调用getMethodArgumentValues获取方法参数值，最终调用doInvoke方法执行目标处理器方法的逻辑(反射执行) getMethodArgumentValues方法流程分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// InvocableHandlerMethod.classprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); if (ObjectUtils.isEmpty(parameters)) &#123; return EMPTY_ARGS; &#125; Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) &#123; MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); args[i] = findProvidedArgument(parameter, providedArgs); if (args[i] != null) &#123; continue; &#125; if (!this.resolvers.supportsParameter(parameter)) &#123; throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\")); &#125; try &#123; args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); &#125; catch (Exception ex) &#123; // Leave stack trace for later, exception may actually be resolved and handled... if (logger.isDebugEnabled()) &#123; String exMsg = ex.getMessage(); if (exMsg != null &amp;&amp; !exMsg.contains(parameter.getExecutable().toGenericString())) &#123; logger.debug(formatArgumentError(parameter, exMsg)); &#125; &#125; throw ex; &#125; &#125; return args;&#125;// HandlerMethodArgumentResolverComposite.classpublic boolean supportsParameter(MethodParameter parameter) &#123; return getArgumentResolver(parameter) != null;&#125;private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123; HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter); if (result == null) &#123; for (HandlerMethodArgumentResolver resolver : this.argumentResolvers) &#123; if (resolver.supportsParameter(parameter)) &#123; result = resolver; this.argumentResolverCache.put(parameter, result); break; &#125; &#125; &#125; return result;&#125;public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); if (resolver == null) &#123; throw new IllegalArgumentException(\"Unsupported parameter type [\" + parameter.getParameterType().getName() + \"]. supportsParameter should be called first.\"); &#125; return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125; MethodParameter[] parameters = getMethodParameters();首先获取方法的参数声明this.resolvers.supportsParameter(parameter)使用参数解析器列表判断当前是否能解析参数————supportsParameter()方法最终调用类HandlerMethodArgumentResolverComposite的getArgumentResolver()方法判断是否支持(通过遍历所有的参数解析器)，判断支持后进行缓存args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);使用上一步确定的参数解析器对参数进行解析(最终使用具体的解析器解析————大部分通过原生ServletAPI获取相应的参数) 自定义参数(POJO封装过程)分析： 表单提交： 支持的请求参数解析器分析流程： 1234567891011121314151617181920212223// ModelAttributeMethodProcessor.classpublic boolean supportsParameter(MethodParameter parameter) &#123; return (parameter.hasParameterAnnotation(ModelAttribute.class) || (this.annotationNotRequired &amp;&amp; !BeanUtils.isSimpleProperty(parameter.getParameterType())));&#125;// BeanUtils.classpublic static boolean isSimpleProperty(Class&lt;?&gt; type) &#123; Assert.notNull(type, \"'type' must not be null\"); return isSimpleValueType(type) || (type.isArray() &amp;&amp; isSimpleValueType(type.getComponentType()));&#125;public static boolean isSimpleValueType(Class&lt;?&gt; type) &#123; return (Void.class != type &amp;&amp; void.class != type &amp;&amp; (ClassUtils.isPrimitiveOrWrapper(type) || Enum.class.isAssignableFrom(type) || CharSequence.class.isAssignableFrom(type) || Number.class.isAssignableFrom(type) || Date.class.isAssignableFrom(type) || Temporal.class.isAssignableFrom(type) || URI.class == type || URL.class == type || Locale.class == type || Class.class == type));&#125; 紧接着上述的分析，通过InvocableHandlerMethod类的getMethodArgumentValues()方法中的!this.resolvers.supportsParameter(parameter)开始判断首先调用HandlerMethodArgumentResolverComposite类的getArgumentResolver()方法找到能够处理的请求参数解析器最终找到的能够支持的请求参数解析器为ServletModelAttributeMethodProcessor类(ModelAttributeMethodProcessor的子类)首先ModelAttribute注解没有，前者为false；其次annotationNotRequired属性默认初始化为true；然后isSimpleProperty方法返回是否为简单属性————规定的class类本身或其数组(此处是自定义的数据类,因此不满足),后者条件为true，当前解析器满足。跳出循环并放入缓存 调用请求参数解析器解析流程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// HandlerMethodArgumentResolverComposite.classpublic Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); if (resolver == null) &#123; throw new IllegalArgumentException(\"Unsupported parameter type [\" + parameter.getParameterType().getName() + \"]. supportsParameter should be called first.\"); &#125; return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125;// ModelAttributeMethodProcessor.classpublic final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; // ... if (mavContainer.containsAttribute(name)) &#123; attribute = mavContainer.getModel().get(name); &#125; else &#123; // Create attribute instance try &#123; attribute = createAttribute(name, parameter, binderFactory, webRequest); &#125; catch (BindException ex) &#123; if (isBindExceptionRequired(parameter)) &#123; // No BindingResult parameter -&gt; fail with BindException throw ex; &#125; // Otherwise, expose null/empty value and associated BindingResult if (parameter.getParameterType() == Optional.class) &#123; attribute = Optional.empty(); &#125; else &#123; attribute = ex.getTarget(); &#125; bindingResult = ex.getBindingResult(); &#125; &#125; if (bindingResult == null) &#123; // Bean property binding and validation; // skipped in case of binding failure on construction. WebDataBinder binder = binderFactory.createBinder(webRequest, attribute, name); if (binder.getTarget() != null) &#123; if (!mavContainer.isBindingDisabled(name)) &#123; bindRequestParameters(binder, webRequest); &#125; validateIfApplicable(binder, parameter); if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123; throw new BindException(binder.getBindingResult()); &#125; &#125; // Value type adaptation, also covering java.util.Optional if (!parameter.getParameterType().isInstance(attribute)) &#123; attribute = binder.convertIfNecessary(binder.getTarget(), parameter.getParameterType(), parameter); &#125; bindingResult = binder.getBindingResult(); &#125; // ... return attribute;&#125; 通过InvocableHandlerMethod类的getMethodArgumentValues()方法中的args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);开始解析首先getArgumentResolver就是调用之前的流程，因为已经缓存，所以直接可以找到。最主要是语句return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);调用ModelAttributeMethodProcessor类的resolveArgument()方法在resolveArgument()方法中： attribute = createAttribute(name, parameter, binderFactory, webRequest);得到通过反射创建的JavaBean(属性全为默认值————null、0、false) WebDataBinder binder = binderFactory.createBinder(webRequest, attribute, name);创建web数据绑定器，该类能够将请求参数值绑定到指定的JavaBean中 bindRequestParameters(binder, webRequest);真正通过web数据绑定器绑定参数值 根据validate条件(数据校验条件,@Valid注解校验)，进行数据校验并返回校验结果，可在处理器方法中通过BindingResult参数获取 最终返回绑定好的参数值 绑定器绑定参数流程分析： 12345678910111213141516171819202122232425262728293031323334353637// ServletModelAttributeMethodProcessor.classprotected void bindRequestParameters(WebDataBinder binder, NativeWebRequest request) &#123; ServletRequest servletRequest = request.getNativeRequest(ServletRequest.class); Assert.state(servletRequest != null, \"No ServletRequest\"); ServletRequestDataBinder servletBinder = (ServletRequestDataBinder) binder; servletBinder.bind(servletRequest);&#125;// ServletRequestDataBinder.classpublic void bind(ServletRequest request) &#123; MutablePropertyValues mpvs = new ServletRequestParameterPropertyValues(request); MultipartRequest multipartRequest = WebUtils.getNativeRequest(request, MultipartRequest.class); if (multipartRequest != null) &#123; bindMultipart(multipartRequest.getMultiFileMap(), mpvs); &#125; else if (StringUtils.startsWithIgnoreCase(request.getContentType(), \"multipart/\")) &#123; HttpServletRequest httpServletRequest = WebUtils.getNativeRequest(request, HttpServletRequest.class); if (httpServletRequest != null) &#123; StandardServletPartUtils.bindParts(httpServletRequest, mpvs, isBindEmptyMultipartFiles()); &#125; &#125; addBindValues(mpvs, request); doBind(mpvs);&#125;// ExtendedServletRequestDataBinder.classprotected void addBindValues(MutablePropertyValues mpvs, ServletRequest request) &#123; String attr = HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE; @SuppressWarnings(\"unchecked\") Map&lt;String, String&gt; uriVars = (Map&lt;String, String&gt;) request.getAttribute(attr); if (uriVars != null) &#123; uriVars.forEach((name, value) -&gt; &#123; if (mpvs.contains(name)) // ... else mpvs.addPropertyValue(name, value); &#125;); &#125;&#125; 通过ServletModelAttributeMethodProcessor类的bindRequestParameters()方法进行绑定首先通过ServletRequest servletRequest = request.getNativeRequest(ServletRequest.class);获取原始的ServletRequest请求对象(参数都在其上)主要调用了servletBinder.bind(servletRequest);实际绑定参数值ServletRequestDataBinder的bind()方法中，首先通过MutablePropertyValues mpvs = new ServletRequestParameterPropertyValues(request);得到所有的kv参数值mpvs，然后通过addBindValues(mpvs, request);方法把uri中的参数值也添加到mpvs中，最终通过doBind(mpvs)最终进行绑定 doBind()方法执行流程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125// WebDataBinder.classprotected void doBind(MutablePropertyValues mpvs) &#123; checkFieldDefaults(mpvs); checkFieldMarkers(mpvs); adaptEmptyArrayIndices(mpvs); super.doBind(mpvs);&#125;// DataBinder.classprotected void doBind(MutablePropertyValues mpvs) &#123; checkAllowedFields(mpvs); checkRequiredFields(mpvs); applyPropertyValues(mpvs);&#125;protected void applyPropertyValues(MutablePropertyValues mpvs) &#123; try &#123; // Bind request parameters onto target object. getPropertyAccessor().setPropertyValues(mpvs, isIgnoreUnknownFields(), isIgnoreInvalidFields()); &#125; catch (PropertyBatchUpdateException ex) &#123; // Use bind error processor to create FieldErrors. for (PropertyAccessException pae : ex.getPropertyAccessExceptions()) &#123; getBindingErrorProcessor().processPropertyAccessException(pae, getInternalBindingResult()); &#125; &#125;&#125;// AbstractPropertyAccessor.classpublic void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown, boolean ignoreInvalid) throws BeansException &#123; List&lt;PropertyValue&gt; propertyValues = (pvs instanceof MutablePropertyValues ? ((MutablePropertyValues) pvs).getPropertyValueList() : Arrays.asList(pvs.getPropertyValues())); try &#123; for (PropertyValue pv : propertyValues) &#123; // setPropertyValue may throw any BeansException, which won't be caught // here, if there is a critical failure such as no matching field. // We can attempt to deal only with less serious exceptions. try &#123; setPropertyValue(pv); &#125; catch (NotWritablePropertyException ex) &#123; if (!ignoreUnknown) &#123; throw ex; &#125; // Otherwise, just ignore it and continue... &#125; // ... Other catch &#125; &#125; finally &#123; // ... &#125; // ...&#125;public void setPropertyValue(PropertyValue pv) throws BeansException &#123; setPropertyValue(pv.getName(), pv.getValue());&#125;// AbstractNestablePropertyAccessor.classpublic void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException &#123; // ... nestedPa.setPropertyValue(tokens, new PropertyValue(propertyName, value));&#125;protected void setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv) throws BeansException &#123; if (tokens.keys != null) processKeyedProperty(tokens, pv); else processLocalProperty(tokens, pv);&#125;private void processLocalProperty(PropertyTokenHolder tokens, PropertyValue pv) &#123; // ... Object oldValue = null; try &#123; Object originalValue = pv.getValue(); Object valueToApply = originalValue; if (!Boolean.FALSE.equals(pv.conversionNecessary)) &#123; if (pv.isConverted()) &#123; valueToApply = pv.getConvertedValue(); &#125; else &#123; // ... valueToApply = convertForProperty( tokens.canonicalName, oldValue, originalValue, ph.toTypeDescriptor()); &#125; pv.getOriginalPropertyValue().conversionNecessary = (valueToApply != originalValue); &#125; ph.setValue(valueToApply); &#125; catch (TypeMismatchException ex) &#123; throw ex; &#125; // ... Other catch&#125;protected Object convertForProperty(String propertyName, @Nullable Object oldValue, @Nullable Object newValue, TypeDescriptor td) throws TypeMismatchException &#123; return convertIfNecessary(propertyName, oldValue, newValue, td.getType(), td);&#125;private Object convertIfNecessary(@Nullable String propertyName, @Nullable Object oldValue, @Nullable Object newValue, @Nullable Class&lt;?&gt; requiredType, @Nullable TypeDescriptor td) throws TypeMismatchException &#123; try &#123; return this.typeConverterDelegate.convertIfNecessary(propertyName, oldValue, newValue, requiredType, td); &#125; catch (ConverterNotFoundException | IllegalStateException ex) &#123; // ... &#125; // ... Other catch&#125;// TypeConverterDelegate.classpublic &lt;T&gt; T convertIfNecessary(@Nullable String propertyName, @Nullable Object oldValue, @Nullable Object newValue, @Nullable Class&lt;T&gt; requiredType, @Nullable TypeDescriptor typeDescriptor) throws IllegalArgumentException &#123; // ... if (editor == null &amp;&amp; conversionService != null &amp;&amp; newValue != null &amp;&amp; typeDescriptor != null) &#123; TypeDescriptor sourceTypeDesc = TypeDescriptor.forObject(newValue); if (conversionService.canConvert(sourceTypeDesc, typeDescriptor)) &#123; try &#123; return (T) conversionService.convert(newValue, sourceTypeDesc, typeDescriptor); &#125; catch (ConversionFailedException ex) &#123; // fallback to default conversion logic below conversionAttemptEx = ex; &#125; &#125; &#125; // ...&#125; 首先ServletRequestDataBinder类的doBind()方法调用父类WebDataBinder的doBind()方法，在父类的doBind()方法中继续调用父类DataBinder的doBind()方法，最终调用了applyPropertyValues()方法DataBinder的applyPropertyValues()方法调用了AbstractPropertyAccessor类的setPropertyValues()方法，并循环mpvs(请求参数的键值对)并通过setPropertyValue()方法设置属性值AbstractPropertyAccessor类的setPropertyValue()方法在内部调用了其子类AbstractNestablePropertyAccessor类的setPropertyValue()方法，在其中又调用了setPropertyValue()方法，最终调用了processLocalProperty()方法在processLocalProperty()方法中最主要调用了valueToApply = convertForProperty(tokens.canonicalName, oldValue, originalValue, ph.toTypeDescriptor());，在其中\b\b又调用了convertIfNecessary()方法，最终在convertIfNecessary()方法中调用了TypeConverterDelegate类的convertIfNecessary()方法，在该方法中调用ConversionService类的canConvert()方法判断是否能转换参数，如果能就通过convert()方法进行转换，至此请求参数交由ConversionService进行处理 在请求中一般由GenericConversionService类进行解析，详细流程分析如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106// GenericConversionService.classpublic boolean canConvert(@Nullable TypeDescriptor sourceType, TypeDescriptor targetType) &#123; Assert.notNull(targetType, \"Target type to convert to cannot be null\"); if (sourceType == null) &#123; return true; &#125; GenericConverter converter = getConverter(sourceType, targetType); return (converter != null);&#125;protected GenericConverter getConverter(TypeDescriptor sourceType, TypeDescriptor targetType) &#123; ConverterCacheKey key = new ConverterCacheKey(sourceType, targetType); GenericConverter converter = this.converterCache.get(key); if (converter != null) &#123; return (converter != NO_MATCH ? converter : null); &#125; converter = this.converters.find(sourceType, targetType); if (converter == null) &#123; converter = getDefaultConverter(sourceType, targetType); &#125; if (converter != null) &#123; this.converterCache.put(key, converter); return converter; &#125; this.converterCache.put(key, NO_MATCH); return null;&#125;// Converters.classpublic GenericConverter find(TypeDescriptor sourceType, TypeDescriptor targetType) &#123; // Search the full type hierarchy List&lt;Class&lt;?&gt;&gt; sourceCandidates = getClassHierarchy(sourceType.getType()); List&lt;Class&lt;?&gt;&gt; targetCandidates = getClassHierarchy(targetType.getType()); for (Class&lt;?&gt; sourceCandidate : sourceCandidates) &#123; for (Class&lt;?&gt; targetCandidate : targetCandidates) &#123; ConvertiblePair convertiblePair = new ConvertiblePair(sourceCandidate, targetCandidate); GenericConverter converter = getRegisteredConverter(sourceType, targetType, convertiblePair); if (converter != null) &#123; return converter; &#125; &#125; &#125; return null;&#125;public Object convert(@Nullable Object source, @Nullable TypeDescriptor sourceType, TypeDescriptor targetType) &#123; // ... GenericConverter converter = getConverter(sourceType, targetType); if (converter != null) &#123; Object result = ConversionUtils.invokeConverter(converter, source, sourceType, targetType); return handleResult(sourceType, targetType, result); &#125; return handleConverterNotFound(source, sourceType, targetType);&#125;// ConversionUtils.classpublic static Object invokeConverter(GenericConverter converter, @Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType) &#123; try &#123; return converter.convert(source, sourceType, targetType); &#125; catch (ConversionFailedException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new ConversionFailedException(sourceType, targetType, source, ex); &#125;&#125;// GenericConversionService.classpublic Object convert(@Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType) &#123; if (source == null) &#123; return convertNullSource(sourceType, targetType); &#125; return this.converterFactory.getConverter(targetType.getObjectType()).convert(source);&#125;// StringToNumberConverterFactory.classpublic &lt;T extends Number&gt; Converter&lt;String, T&gt; getConverter(Class&lt;T&gt; targetType) &#123; return new StringToNumber&lt;&gt;(targetType);&#125;// StringToNumber.classpublic T convert(String source) &#123; if (source.isEmpty()) &#123; return null; &#125; return NumberUtils.parseNumber(source, this.targetType);&#125;// NumberUtils.classpublic static &lt;T extends Number&gt; T parseNumber(String text, Class&lt;T&gt; targetClass) &#123; String trimmed = StringUtils.trimAllWhitespace(text); if (Byte.class == targetClass) &#123; return (T) (isHexNumber(trimmed) ? Byte.decode(trimmed) : Byte.valueOf(trimmed)); &#125; else if (Short.class == targetClass) &#123; return (T) (isHexNumber(trimmed) ? Short.decode(trimmed) : Short.valueOf(trimmed)); &#125; else if (Integer.class == targetClass) &#123; return (T) (isHexNumber(trimmed) ? Integer.decode(trimmed) : Integer.valueOf(trimmed)); &#125; else if (Long.class == targetClass) &#123; return (T) (isHexNumber(trimmed) ? Long.decode(trimmed) : Long.valueOf(trimmed)); &#125; // ...&#125; 首先调用GenericConversionService的canConvert()方法，在其中调用getConverter()方法获取满足条件的converter对象在getConverter()方法中首先去缓存中找如果没有则通过Converters类的find()方法进行寻找在find()方法中会通过类继承规则过滤一部分类，并通过双重循环得到能够转换源类型到目的类型的converter再进行缓存。默认存在的converter如下图所示：找到符合的converter后再依次退出函数调用栈，最终调用GenericConversionService类的convert()方法进行转换，首先得到之前缓存的converter，然后使用ConversionUtils类的invokeConverter()方法进行转换在invokeConverter()方法中又调用了GenericConversionService类的重载convert()方法，最终调用了具体的converter工厂的构造方法和具体converter的convert()方法。以String转Number为例：使用StringToNumberConverterFactory类的getConverter()方法新建内部的转换bean————StringToNumber，再使用StringToNumber类的convert()方法实现将String转为Number 数据响应与内容协商 数据响应 响应Json 依赖：jackson 12345spring-boot-starter-web|- spring-boot-starter-json |- jackson-datatype-jdk8 |- jackson-datatype-jsr310 |- jackson-module-parameter-names 使用：需要在处理器方法上标注@ResponseBody或在处理器类上标注@RestController 源码分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// DispatcherServlet.classprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // ... mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // ...&#125;// AbstractHandlerMethodAdapter.classpublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125;// RequestMappingHandlerAdapter.classprotected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; // ... mav = invokeHandlerMethod(request, response, handlerMethod); // ...&#125;protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; try &#123; if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; // ... invocableMethod.invokeAndHandle(webRequest, mavContainer); // ... return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125;// ServletInvocableHandlerMethod.classpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); // ... try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; throw ex; &#125;&#125; 首先是流程的回顾，跟请求参数解析的过程一样，都是通过DispatcherServlet的doDispatch()方法进行响应，接着方法调用链依次为AbstractHandlerMethodAdapter类的handle()方法、RequestMappingHandlerAdapter类的handleInternal()方法以及invokeHandlerMethod()方法在invokeHandlerMethod()方法中，首先准备了argumentResolvers请求参数解析器以及returnValueHandlers返回值处理器，SpringBoot默认装配的返回值处理器如下：返回值处理器接口方法如下：其中supportsReturnType()方法返回是否支持特定的返回值类型，handleReturnValue()方法进行具体的处理逻辑装配好处理器后就调用ServletInvocableHandlerMethod类的invokeAndHandle()方法在invokeAndHandle()方法中invokeForRequest()首先将请求参数解析后，再通过反射调用编写的处理器方法，最后通过this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest);进行返回值的处理 handleReturnValue()方法处理流程分析： 1234567891011121314151617181920212223242526272829303132333435// HandlerMethodReturnValueHandlerComposite.classpublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType); if (handler == null) &#123; throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName()); &#125; handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125;private HandlerMethodReturnValueHandler selectHandler(@Nullable Object value, MethodParameter returnType) &#123; boolean isAsyncValue = isAsyncReturnValue(value, returnType); for (HandlerMethodReturnValueHandler handler : this.returnValueHandlers) &#123; if (isAsyncValue &amp;&amp; !(handler instanceof AsyncHandlerMethodReturnValueHandler)) &#123; continue; &#125; if (handler.supportsReturnType(returnType)) &#123; return handler; &#125; &#125; return null;&#125;// RequestResponseBodyMethodProcessor.classpublic boolean supportsReturnType(MethodParameter returnType) &#123; return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) || returnType.hasMethodAnnotation(ResponseBody.class));&#125;public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123; mavContainer.setRequestHandled(true); ServletServerHttpRequest inputMessage = createInputMessage(webRequest); ServletServerHttpResponse outputMessage = createOutputMessage(webRequest); // Try even with null return value. ResponseBodyAdvice could get involved. writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);&#125; 在handleReturnValue()方法中首先调用selectHandler()方法查找能处理当前返回值类型的处理器。在查找处理器方法中，根据处理器是否支持返回值类型进行匹配，最终返回相应的处理器，这里以能处理标注@ResponseBody注解的处理器方法为例(RequestResponseBodyMethodProcessor)：由于标注了@ResponseBody注解，因此supportsReturnType()方法返回true，该类能处理然后调用处理器的handleReturnValue()处理返回值，主要是调用writeWithMessageConverters()方法进行处理 writeWithMessageConverters()方法的处理流程解析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// AbstractMessageConverterMethodProcessor.classprotected &lt;T&gt; void writeWithMessageConverters(@Nullable T value, MethodParameter returnType, ServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123; // ... if (value instanceof CharSequence) &#123; body = value.toString(); valueType = String.class; targetType = String.class; &#125; else &#123; body = value; valueType = getReturnValueType(body, returnType); targetType = GenericTypeResolver.resolveType(getGenericType(returnType), returnType.getContainingClass()); &#125; if (isResourceType(value, returnType)) &#123; // ... &#125; MediaType selectedMediaType = null; MediaType contentType = outputMessage.getHeaders().getContentType(); boolean isContentTypePreset = contentType != null &amp;&amp; contentType.isConcrete(); if (isContentTypePreset) &#123; // ... &#125; else &#123; HttpServletRequest request = inputMessage.getServletRequest(); List&lt;MediaType&gt; acceptableTypes = getAcceptableMediaTypes(request); List&lt;MediaType&gt; producibleTypes = getProducibleMediaTypes(request, valueType, targetType); // ... List&lt;MediaType&gt; mediaTypesToUse = new ArrayList&lt;&gt;(); for (MediaType requestedType : acceptableTypes) &#123; for (MediaType producibleType : producibleTypes) &#123; if (requestedType.isCompatibleWith(producibleType)) &#123; mediaTypesToUse.add(getMostSpecificMediaType(requestedType, producibleType)); &#125; &#125; &#125; // ... MediaType.sortBySpecificityAndQuality(mediaTypesToUse); for (MediaType mediaType : mediaTypesToUse) &#123; if (mediaType.isConcrete()) &#123; selectedMediaType = mediaType; break; &#125; else if (mediaType.isPresentIn(ALL_APPLICATION_MEDIA_TYPES)) &#123; selectedMediaType = MediaType.APPLICATION_OCTET_STREAM; break; &#125; &#125; // ... &#125; if (selectedMediaType != null) &#123; selectedMediaType = selectedMediaType.removeQualityValue(); for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) &#123; GenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ? (GenericHttpMessageConverter&lt;?&gt;) converter : null); if (genericConverter != null ? ((GenericHttpMessageConverter) converter).canWrite(targetType, valueType, selectedMediaType) : converter.canWrite(valueType, selectedMediaType)) &#123; body = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType, (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(),inputMessage, outputMessage); if (body != null) &#123; Object theBody = body; // ... if (genericConverter != null) &#123; genericConverter.write(body, targetType, selectedMediaType, outputMessage); &#125; else &#123; ((HttpMessageConverter) converter).write(body, selectedMediaType, outputMessage); &#125; &#125; else &#123; // ... &#125; return; &#125; &#125; &#125; // ...&#125; 在writeWithMessageConverters()方法中，首先获取返回值的数据和类型，然后判断是否是资源类型，如果是，进行一系列操作；否则，从requestHeaders请求头中获取contentType媒体类型，这就涉及到内容协商浏览器默认会以请求头方式告诉服务器它能接受的内容类型，示例如下：其中q=0.9表示为权重由于当前为首次请求，不存在contentType所以走else块————使用原生ServletRequest通过List&lt;MediaType&gt; acceptableTypes = getAcceptableMediaTypes(request);获取浏览器可接收的媒体类型，接着通过List&lt;MediaType&gt; producibleTypes = getProducibleMediaTypes(request, valueType, targetType);获取服务器可响应的媒体类型。示例如下：随后通过两个双层循环进行匹配，最终得到两边都可用的媒体类型，示例如下：然后通过MediaType.sortBySpecificityAndQuality(mediaTypesToUse);进行权重的排序，最终通过遍历messageConverters消息转换器得到能处理当前返回值数据的消息转换器 消息转换流程分析如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// AbstractMessageConverterMethodProcessor.class中截取的writeWithMessageConverters()方法for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) &#123; GenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ? (GenericHttpMessageConverter&lt;?&gt;) converter : null); if (genericConverter != null ? ((GenericHttpMessageConverter) converter).canWrite(targetType, valueType, selectedMediaType) : converter.canWrite(valueType, selectedMediaType)) &#123; body = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType, (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(),inputMessage, outputMessage); if (body != null) &#123; Object theBody = body; // ... if (genericConverter != null) &#123; genericConverter.write(body, targetType, selectedMediaType, outputMessage); &#125; else &#123; ((HttpMessageConverter) converter).write(body, selectedMediaType, outputMessage); &#125; &#125; &#125;&#125;// AbstractGenericHttpMessageConverter.classpublic boolean canWrite(@Nullable Type type, Class&lt;?&gt; clazz, @Nullable MediaType mediaType) &#123; return canWrite(clazz, mediaType);&#125;// AbstractJackson2HttpMessageConverter.classpublic boolean canWrite(Class&lt;?&gt; clazz, @Nullable MediaType mediaType) &#123; if (!canWrite(mediaType)) &#123; return false; &#125; // ... AtomicReference&lt;Throwable&gt; causeRef = new AtomicReference&lt;&gt;(); if (this.objectMapper.canSerialize(clazz, causeRef)) &#123; return true; &#125; logWarningIfNecessary(clazz, causeRef.get()); return false;&#125;// AbstractHttpMessageConverter.classprotected boolean canWrite(@Nullable MediaType mediaType) &#123; if (mediaType == null || MediaType.ALL.equalsTypeAndSubtype(mediaType)) &#123; return true; &#125; for (MediaType supportedMediaType : getSupportedMediaTypes()) &#123; if (supportedMediaType.isCompatibleWith(mediaType)) &#123; return true; &#125; &#125; return false;&#125;// AbstractGenericHttpMessageConverter.classpublic final void write(final T t, @Nullable final Type type, @Nullable MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; final HttpHeaders headers = outputMessage.getHeaders(); addDefaultHeaders(headers, t, contentType); if (outputMessage instanceof StreamingHttpOutputMessage) &#123; // ... &#125; else &#123; writeInternal(t, type, outputMessage); outputMessage.getBody().flush(); &#125;&#125;// AbstractJackson2HttpMessageConverter.classprotected void writeInternal(Object object, @Nullable Type type, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; MediaType contentType = outputMessage.getHeaders().getContentType(); JsonEncoding encoding = getJsonEncoding(contentType); OutputStream outputStream = StreamUtils.nonClosing(outputMessage.getBody()); try (JsonGenerator generator = this.objectMapper.getFactory().createGenerator(outputStream, encoding)) &#123; writePrefix(generator, object); // ... objectWriter.writeValue(generator, value); writeSuffix(generator, object); generator.flush(); &#125; // catchs ...&#125; HttpMessageConverter消息转换器接口介绍如下：canRead()和canWrite()方法分别表示是否支持把某个类型以指定媒体类型读入或写出；而read()和write()分别表示具体的读入和写出逻辑；getSupportedMediaTypes()方法则返回支持的媒体类型其中SpringBoot Web环境下默认装载以下消息转换器：接下来以MappingJackson2HttpMessageConverter为例首先调用遍历消息转换器，查看是否支持写出，对于例子来说，依次调用了AbstractGenericHttpMessageConverter类的canWrite()方法、AbstractJackson2HttpMessageConverter类的canWrite()方法以及AbstractHttpMessageConverter类的canWrite()方法在AbstractHttpMessageConverter的canWrite()方法中，由于mediaType为协商后的json格式而且getSupportedMediaTypes()方法返回json格式，因此返回true，最终调用栈返回AbstractJackson2HttpMessageConverter类的canWrite()方法，最终使用jackson的objectMapper查看是否支持序列化(返回true)最终调用AbstractGenericHttpMessageConverter类的write()方法写出数据，首先为响应设置响应头(在本例中为contentType=json)。再查看是否为流响应，发现不是，最终调用AbstractJackson2HttpMessageConverter类的writeInternal()方法进行实际的写操作在writeInternal()方法中基本都是jackson的操作，将返回数据附加在response的流上并返回。结果如下图所示： 杂项 yaml 简介：YAML是”YAML Ain’t Markup Language”(YAML不是一种标记语言)的递归缩写。在开发这种语言时，YAML的意思其实是————“Yet Another Markup Language”(仍是一种标记语言)。为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名 基本语法： key: value(kv之间有空格) 大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格 缩进的空格数不重要，只要相同层级的元素左对齐即可 ‘#’表示注释 字符串无需加引号；如果加，’’/“”表示字符串内容会/不会被转义 数据类型： 字面量(单个的、不可再分的值,如date、boolean、string、number、null)：k: v 对象(键值对集合,如map、hash、set、object)： 12345k: &#123;k1: v1, k2: v2, k3: v3&#125;k: k1: v1 k2: v2 k3: v3 数组(一组按次序排列的值,如array、list、queue)： 12345k: [v1, v2, v3]k: - v1 - v2 - v3","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://sobxiong.github.io/tags/SpringMVC/"}]},{"title":"Redis基础","slug":"Middleware/Redis/Redis基础","date":"2020-12-12T14:45:59.000Z","updated":"2020-12-19T11:24:02.492Z","comments":true,"path":"2020/12/12/Middleware/Redis/Redis基础/","link":"","permalink":"https://sobxiong.github.io/2020/12/12/Middleware/Redis/Redis%E5%9F%BA%E7%A1%80/","excerpt":"内容 Redis介绍 Redis持久化 Redis事务 Redis消息发布订阅 Redis主从复制 Redis常用配置","text":"内容 Redis介绍 Redis持久化 Redis事务 Redis消息发布订阅 Redis主从复制 Redis常用配置 Redis介绍 NoSQL简介：NoSQL(Not Only SQL)泛指non-relational(非关系型数据库)。NoSQL数据库是为了解决大规模数据集合多重数据种类带来的挑战，特别是超大规模数据的存储。NoSQL数据库的一个显著特点就是去掉了关系数据库的关系型特性，数据之间一旦没有关系，使得扩展性、读写性能都大大提高 Redis简介：Redis(Remote Dictionary Server：远程字典服务器)是一个用C语言编写的、开源的、基于内存运行并支持持久化的、高性能的NoSQL数据库。也是当前热门的NoSQL数据库之一 Redis特性： 支持数据持久化：Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启时可以再次加载进行使用 支持多种数据结构：Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储 支持数据备份：Redis支持数据的备份(即master-slave模式的数据备份) Redis安装(6.0.9版本)：https://blog.csdn.net/qq_26030541/article/details/109448545 Redis应用： 为热点数据加速查询(主要场景)：热点商品、热点新闻、热点资讯、推广类等高访问量信息等 任务队列，如秒杀、抢购、购票排队等 即时信息查询：各类排行榜、各类网站访问统计、公交到站信息、在线人数信息(聊天室、网站)、设备信号等 时效性信息控制：验证码控制、投票控制等 分布式数据共享：分布式集群架构中的session分离等 消息队列 分布式锁 Redis客户端(Redis-cli)命令简介： 连接redis(本机可省去-h参数)：redis-cli -p 6379 -h 127.0.0.1 退出客户端：exit、quit 查看redis服务器统计信息：info [section] 以一种易于解释且易于阅读的格式返回关于Redis服务器的各种信息和统计数值。section用来指定统计信息的部分，值为server、clients、memory等。不加section则返回全部统计信息 切换库命令：select [index] index默认从0~15，redis默认有16个库 查看当前数据库中key的数目：dbsize 查看当前数据库中有哪些key：keys * 清空当前库：flushdb 清空所有库：flushall 获取redis的配置信息：config get [parameter/*] 获取运行中Redis服务器的配置参数，获取全部配置可以使用*。参数信息来自redis.conf文件的内容 认证：auth &#39;password&#39; Redis的数据结构： string(字符串类型)：字符串类型是Redis中最基本的数据结构，它能存储任何类型的数据，包括二进制数据、序列化后的数据、JSON化的对象甚至是一张图片。最大512M list(列表类型)：Redis列表是简单的字符串列表，按照插入顺序排序，元素可以重复。可以添加一个元素到列表的头部(左边)或者尾部(右边)，底层为链表结构 set(集合类型)：Redis的set是string类型的无序无重复集合 hash(哈希类型)：Redis的hash是一个string类型的field和value的映射表，hash特别适合用于存储对象 zset(sorted set,有序集合类型)：Redis有序集合zset和集合set一样也是string类型元素的集合，且不允许重复的成员。不同的是zset的每个元素都会关联一个分数(分数可以重复)，redis通过分数来为集合中的成员进行从小到大的排序 Redis常用的操作命令：http://redisdoc.com/ Redis持久化 介绍：redis是内存数据库，它把数据存储在内存中。在加快读取速度的同时也对数据安全性产生了新的问题————当redis所在服务器宕机后，数据库里的所有数据将会全部丢失。为了解决这个问题，redis提供了持久化功能————RDB和AOF(Append Only File) RDB： 介绍：RDB(Redis DataBase)是Redis的默认持久化方案。在指定的时间间隔内执行指定次数的写操作，则会将内存中的数据写入到磁盘中(即在指定目录下生成一个dump.rdb文件,每次同步)。Redis重启时会通过加载dump.rdb文件来恢复数据。适合大规模的数据恢复，但它的数据一致性和完整性较差 原理：Redis会复制一个与当前进程一样的进程。新进程的所有数据(变量、环境变量、程序计数器等)数值都和原进程一致，但是一个全新的进程，并作为原进程的子进程来进行持久化整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能如果需要进行大规模的数据恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加高效。RDB的缺点是最后一次持久化后的数据可能丢失 保存文件介绍：RDB保存的文件是默认为dump.rdb，位置位于Redis的启动目录。Redis每次同步数据到磁盘都会生成一个dump.rdb文件，新的dump.rdb会覆盖旧的dump.rdb文件 手动保存rdb快照：save命令可用于执行一个同步保存操作————将当前Redis实例的所有数据快照(snapshot)以RDB文件的形式保存到硬盘。由于save指令会阻塞所有客户端，因此保存数据库的任务通常由BGSAVE命令异步地执行，而save作为保存数据的最后手段来使用(当负责保存数据的后台子进程不幸出现问题时使用) AOF： 介绍：AOF(Append Only File)，Redis默认不开启。它的出现是为了弥补RDB的不足(数据的不一致性)，它采用日志的形式来记录每个写操作并追加到文件中。Redis重启后会根据日志文件的内容将写指令从前往后执行一次以完成数据的恢复工作 原理：Redis以日志的形式来记录每个写操作，将执行过的所有写指令记录下来(读操作不记录)，只许追加文件(不可以改写文件)，redis启动之初会读取该文件重新构建数据(根据日志文件的内容将写指令从前往后执行一次以完成数据的恢复工作) 保存文件介绍：AOF默认保存的文件是appendonly.aof文件，位置位于Redis的启动目录。如果开启了AOF，Redis每次记录写操作都会往appendonly.aof文件追加新的日志内容 重写机制：AOF采用文件追加方式，那么文件会越来越大。为避免出现该情况，新增了重写机制————当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(先写临时文件最后再rename)————遍历新进程内存中的数据，每条记录有一条Set语句。重写aof文件的操作并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。也可在配置文件中进行配置 总结：Redis需要手动开启AOF持久化方式，AOF的数据完整性比RDB高，但记录内容多了会影响数据恢复的效率关于Redis持久化的使用：若只打算用Redis做缓存可以关闭持久化。若打算使用Redis的持久化，建议RDB和AOF都开启AOF与RDB模式可同时启用，并不冲突。如果AOF是可用的，那Redis启动时将自动加载AOF，这个文件能够提供更好的持久性保障。同时启用时，RDB作为AOF出问题的后备方案 Redis事务 介绍：Redis的事务允许在一次单独的步骤中执行一组命令，并且能够保证将一个事务中的所有命令序列化，然后按顺序执行；在一个Redis事务中，要么执行其中的所有命令，要么什么都不执行。即Redis的事务要能够保证序列化和原子性 事务的常用命令： mutli： 功能：用于标记事务块的开始————Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令原子化地执行这个命令序列 返回值：开启成功返回OK exec： 功能：在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态 如果在把命令压入队列的过程中报错，则整个队列中的命令都不会执行，执行结果报错如果在压入队列的过程中正常且在执行队列中某一个命令报错，则只会影响该条命令的执行结果，其它命令正常运行当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令；一旦执行了exec命令，之前加的所有watch监控全部取消 返回值：一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值 当使用WATCH命令时，如果事务执行中止，那么EXEC命令就会返回一个Null值 discard 功能：清除所有先前在一个事务中放入队列的命令，并且结束事务 如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控 返回值：清除成功返回OK watch 语法：watch key1 [key2、key3、…] 功能：当某个事务需要按条件执行时，可使用该命令将给定的键设置为受监控的。如果被监控的key值在本事务外被修改时，则本事务所有指令都不会被执行。Watch命令相当于关系型数据库中的乐观锁 返回值：监控成功返回OK unwatch 功能：清除所有先前为一个事务监控的键 如果在watch命令之后调用了EXEC或DISCARD命令，那么就无须手动调用UNWATCH命令 返回值：清除成功返回OK 总结： 单独的隔离操作：事务中的所有命令都会序列化、顺序地执行。事务在执行过程中不会被其它客户端发来的命令请求打断(除非使用watch命令监控某些键) 不保证事务的原子性：redis同一个事务中如果一条命令执行失败，其后的命令仍然可能会被执行，redis的事务没有回滚。Redis已经在系统内部进行功能简化，如此可确保更快的运行速度，因为Redis不需要事务回滚的能力 Redis消息发布订阅 介绍：Redis发布订阅(pub/sub)是一种消息通信模式————发送者(pub)发送消息，订阅者(sub)接收消息。Redis客户端可以订阅任意数量的频道 示意图： 订阅相关的常用命令： subscribe： 语法：subscribe channel [channel…] 功能：订阅一个或多个频道的消息 返回值：订阅的消息 publish： 语法：publish channel message 功能：将信息发送到指定的频道 返回值：数字————接收到消息订阅者的数量 psubsribe 语法：psubscribe pattern [pattern] 功能：订阅一个或多个符合给定模式的频道，模式可以’*‘作为通配符。例如：news.*匹配所有以news.开头的频道 返回值：订阅的信息 Redis主从复制 介绍：主机数据更新后根据配置和策略，自动同步到从机的master/slave机制。Master以写为主，Slave以读为主 一主二从： 原理： 配从(库)不配主(库) 配从(库)：slaveof masterIP masterPort 主写从读、读写分离 主断从待命、从断重新连 搭建： 将redis.conf拷贝三份，修改其中的port、pid日志文件和rdb文件名(启动三个redis-server进程) 分别使用命令启动redis三个服务：./redis-server redis6381.conf &amp; 查看主从信息：info replication 设置主从关系：slaveof 127.0.0.1 6379 另一种方式是修改从库的配置文件，在最后加入slaveof masterIp masterPort；如果主redis设置了密码，从库配置还需设置masteruath masterPassword 特点： 全量/增量复制：全量指主redis之前累计的数据在从库上线时会同步过来，增量是主redis新添加的数据 主写从读、读写分离：从机执行写操作报错 主机宕机：主机shutdown后，从机保持不变原地待命 主机宕机后恢复：执行写命令，从机会收到 从机宕机：主机连接数减少 从机宕机后恢复：宕机的从机与主机无关，无法获取增量数据，其他从机不受影响 通过配置文件方式配置会重新与主机建立关系 复制原理： 全量复制：slave启动成功连接到master后会发送一个sync命令，master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令。在后台进程执行完毕之后，master将传送整个数据文件到slave以完成一次完全同步。slave服务在接收到数据库文件数据后将其存盘并加载到内存中只要是重新连接master，一次完全同步(全量复制)将被自动执行 增量复制：master将新的所有收集到的修改命令依次传给slave，完成同步 哨兵模式： 介绍：从机上位的自动版。Redis提供了哨兵的命令————哨兵命令是一个独立的进程，通过发送命令来监控主从服务器的运行状态，如果检测到master故障了则根据投票数自动将某个slave替换为master。然后通过消息订阅模式通知其它slave，让它们切换主机。然而一个哨兵进程对Redis服务器进行监控可能会出现问题，因此可使用多哨兵进行监控 Redis常用配置 网络相关： bind：绑定IP地址，其它机器可以通过此IP访问Redis，默认绑定127.0.0.1，也可以修改为本机的IP地址 port：配置Redis占用的端口，默认是6379 tcp-keepalive：TCP连接保活策略，可以通过tcp-keepalive配置项来进行设置，单位为秒，假如设置为60秒，则server端会每60秒向连接空闲的客户端发起一次ACK请求以检查客户端是否已经挂掉，对于无响应的客户端则会关闭其连接。如果设置为0，则不会进行保活检测 常规配置： loglevel：日志级别，开发阶段可以设置成debug，生产阶段通常设置为notice或者warning logfile：指定日志文件名，如果不指定，Redis只进行标准输出。要保证日志文件所在的目录必须存在，文件可以不存在。还要在redis启动时指定所使用的配置文件，否则配置不起作用 databases：配置Redis数据库的个数，默认是16个 安全配置：requirepass：配置Redis的访问密码。默认不配置密码，即访问不需要密码验证。此配置项需要在protected-mode=yes时起作用。使用密码登录客户端：redis-cli -h ip -p 6379 -a pwd RDB配置： save &lt;seconds&gt; &lt;changes&gt;：配置复合的快照触发的条件，即Redis在seconds秒内key改变changes次，Redis把快照内的数据保存到磁盘中一次 默认的策略是： 1分钟内改变了1万次 或者5分钟内改变了10次 或者15分钟内改变了1次 如果要禁用Redis的持久化功能，则需要把所有的save配置都注释掉 stop-writes-on-bgsave-error：当bgsave快照操作出错时停止写数据到磁盘，这样能保证内存数据和磁盘数据的一致性。但如果不在乎这种一致性，要在bgsave快照操作出错时继续写操作，可以配置为no rdbcompression：设置存储在磁盘中的快照是否进行压缩————设置为yes时，Redis会采用LZF算法进行压缩；如果不想消耗CPU进行压缩的话，可设置为no来关闭此功能 rdbchecksum：在存储快照以后，还可使用CRC64算法来进行数据校验，但这样会消耗一定的性能。如果系统比较在意性能的提升，可设置为no来关闭此功能 dbfilename：Redis持久化数据生成的文件名，默认是dump.rdb，也可以自己配置 dir：Redis持久化数据生成文件保存的目录，默认是./(即redis的启动目录)，也可以自己配置 AOF配置： appendonly：配置是否开启AOF(yes/no)。默认是no appendfilename：AOF保存文件名 appendfsync：AOF异步持久化策略 always：同步持久化，每次发生数据变化会立刻写入到磁盘中。性能较差但数据完整性比较好(慢但安全) everysec：出厂默认推荐，每秒异步记录一次(默认值) no：不即时同步，由操作系统决定何时同步 no-appendfsync-on-rewrite：重写时是否可以运用appendsync(默认no)，可以保证数据的安全性 auto-aof-rewrite-percentage：设置重写的基准百分比 auto-aof-rewrite-min-size：设置重写的基准值","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"https://sobxiong.github.io/tags/Middleware/"},{"name":"Redis","slug":"Redis","permalink":"https://sobxiong.github.io/tags/Redis/"}]},{"title":"刷题记录","slug":"BasicSkill/Algorithm/ProblemRecord","date":"2020-12-11T13:04:18.000Z","updated":"2021-03-04T14:58:12.749Z","comments":true,"path":"2020/12/11/BasicSkill/Algorithm/ProblemRecord/","link":"","permalink":"https://sobxiong.github.io/2020/12/11/BasicSkill/Algorithm/ProblemRecord/","excerpt":"内容 10正则表达式匹配 218天际线问题 220存在重复元素III 239滑动窗口最大值 241为运算表达式设计优先级 264丑数II 279完全平方数 282给表达式添加运算符 316去除重复字母 321拼接最大数 338比特位计数 354俄罗斯套娃信封问题 395至少有K个重复字符的最长子串 514自由之路 621任务调度器 659分割数组为连续子序列 803打砖块 947移除最多的同行或同列石头 959由斜杠划分区域 995K连续位的最小翻转次数 1178猜字谜 1438绝对差不超过限制的最长连续子数组 1489找到最小生成树里的关键边和伪关键边 1631最小体力消耗路径 1776车队II 剑指Offer36二叉搜索树与双向链表 剑指Offer37序列化二叉树 剑指Offer39数组中出现次数超过一半的数字 剑指Offer48最长不含重复字符的子字符串 剑指Offer51数组中的逆序对 剑指Offer56数组中数字出现的次数I 剑指Offer56数组中数字出现的次数II","text":"内容 10正则表达式匹配 218天际线问题 220存在重复元素III 239滑动窗口最大值 241为运算表达式设计优先级 264丑数II 279完全平方数 282给表达式添加运算符 316去除重复字母 321拼接最大数 338比特位计数 354俄罗斯套娃信封问题 395至少有K个重复字符的最长子串 514自由之路 621任务调度器 659分割数组为连续子序列 803打砖块 947移除最多的同行或同列石头 959由斜杠划分区域 995K连续位的最小翻转次数 1178猜字谜 1438绝对差不超过限制的最长连续子数组 1489找到最小生成树里的关键边和伪关键边 1631最小体力消耗路径 1776车队II 剑指Offer36二叉搜索树与双向链表 剑指Offer37序列化二叉树 剑指Offer39数组中出现次数超过一半的数字 剑指Offer48最长不含重复字符的子字符串 剑指Offer51数组中的逆序对 剑指Offer56数组中数字出现的次数I 剑指Offer56数组中数字出现的次数II 10正则表达式匹配 问题描述： 解法：动态规划 首先找出动态转移方程，设dp[i][j]表示串s的前i个字符和串p的前j个字符能否匹配那么很容易想到p[j - 1]除了’‘的情况dp[i][j] = dp[i - 1][j - 1] &amp;&amp; (s[i - 1] == p[j - 1] || p[j - 1] == ‘.’) ———— 都是字母和’.’匹配任意一个字符的情况如果是’‘，情况有些复杂，但只有两种情况： 匹配s末尾的一个字符，将该字符扔掉，而该组合还可以继续进行匹配：dp[i][j] = dp[i - 1][j] &amp;&amp; matches(s[i - 1], p[j - 2]) ———— 还有”.*”的组合 不匹配字符，将该组合扔掉，不再进行匹配：dp[i][j] = dp[i][j - 2] 实现代码： 12345678910111213141516171819202122232425bool isMatch(string s, string p) &#123; int len_s = s.size(), len_p = p.size(); vector&lt;vector&lt;bool&gt;&gt; dp(len_s + 1, vector&lt;bool&gt;(len_p + 1)); dp[0][0] = true; auto matches = [&amp;](int i, int j) &#123; if (i == 0) return false; if (p[j - 1] == '.') return true; return s[i - 1] == p[j - 1]; &#125;; for (int i = 0; i &lt;= len_s; ++i) &#123; for (int j = 1; j &lt;= len_p; ++j) &#123; if (p[j - 1] == '*') &#123; // 匹配0个 dp[i][j] = dp[i][j] || dp[i][j - 2]; // 匹配一个或多个 if (matches(i, j - 1)) &#123; dp[i][j] = dp[i][j] || dp[i - 1][j]; &#125; &#125; else &#123; if (matches(i, j)) dp[i][j] = dp[i - 1][j - 1]; &#125; &#125; &#125; return dp[len_s][len_p];&#125; 218天际线问题 问题描述： 解法1：分治法(归并的思想)每次将问题划分成更小的子问题，当问题分解到单个建筑时进行解决。如果单个建筑的输入信息为[x1, x2, h]，那么返回[[x1, h], [x2, 0]]。分解完后，进入归并Merge阶段。归并的关键是从轮廓看去只能看到不同的高度，归并模拟过程如下： 假如有以下划分好的结果：skyline1 = {(1, 11), (3, 13), (9, 0), (12, 7), (16, 0)}skyline2 = {(14, 3), (19, 18), (22, 3), (23, 13), (29, 0)}假设i、j分别表示skyline1、skyline2的当前遍历下标，h1、h2分别代表skyline1、skyline2当前的高度首先比较(1, 11)和(14, 3)，由于1 &lt; 14，选取(1, 11)，h1置为当前大小11，hmax = max(h1, h2) = 11，ans结果集加入(1, 11)，i++之后比较(3, 13)和(14, 3)，h1置为当前大小13，hmax = max(h1, h2) = 13，同理ans结果集加入(3, 13)，i++…直到(16, 0)，此时比较(16, 0)和(14, 3)，14 &lt; 3，选取(14, 3)，h2 = 3。而此时h1 = 7，h2 = 3，hmax = max(h1, h2) = 7，因此结果集加入(14, 7)，由于之前的结果集存在(12, 7)，所以(14, 7)不应该加入结果集，j++比较(16, 0)和(19, 18)，此时16 &lt; 19，选取(16, 0)，h1 = 0。此时h1 = 0，h2 = 3，hmax = max(h1, h2) = 3。因此ans结果集加入(16, 3)，至此skyline1全部遍历完，只需将skyline2的剩余部分加入结果集 代码实现如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859vector&lt;vector&lt;int&gt;&gt; divideAndConquer(vector&lt;vector&lt;int&gt;&gt; &amp;buildings, int left, int right) &#123; vector&lt;vector&lt;int&gt;&gt; ans; // 如果left、right一致,相当于只处理单个建筑 if (left == right) &#123; ans.push_back(&#123;buildings[left][0], buildings[left][2]&#125;); ans.push_back(&#123;buildings[left][1], 0&#125;); &#125; else &#123; // 找到中间下标 int mid = (left + right) &gt;&gt; 1; // 递归分治 vector&lt;vector&lt;int&gt;&gt; leftAns = divideAndConquer(buildings, left, mid), rightAns = divideAndConquer(buildings, mid + 1, right); // 定义下标和各自的高度变量 // 每次都需要更新高度信息 int i = 0, j = 0, h1 = 0, h2 = 0; while (i &lt; leftAns.size() &amp;&amp; j &lt; rightAns.size()) &#123; // 记录结果 vector&lt;int&gt; cur(2, 0); // 如果起始相同,做了简化 if (leftAns[i][0] == rightAns[j][0]) &#123; h1 = leftAns[i][1], h2 = rightAns[j][1]; cur[0] = leftAns[i][0], cur[1] = max(h1, h2); i++, j++; &#125; else if (leftAns[i][0] &lt; rightAns[j][0]) &#123; // 起始不同,取起始小的作为当前结果开头,取当前的最大高度为当前结果高度 h1 = leftAns[i][1]; cur[0] = leftAns[i][0], cur[1] = max(h1, h2); i++; &#125; else &#123; // 起始不同,取起始小的作为当前结果开头,取当前的最大高度为当前结果高度 h2 = rightAns[j][1]; cur[0] = rightAns[j][0], cur[1] = max(h1, h2); j++; &#125; // 如果当前结果集为空或当前结果与上次高度不同,加入结果集 if (ans.empty() || ans.back()[1] != cur[1]) &#123; ans.push_back(cur); &#125; &#125; // 依次加入剩余的结果 if (i &lt; leftAns.size()) &#123; for (int k = i; k &lt; leftAns.size(); ++k) ans.push_back(leftAns[k]); &#125; else if (j &lt; rightAns.size()) &#123; for (int k = j; k &lt; rightAns.size(); ++k) ans.push_back(rightAns[k]); &#125; &#125; return ans;&#125;vector&lt;vector&lt;int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt; &amp;buildings) &#123; int size = buildings.size(); if (size == 1) &#123; vector&lt;vector&lt;int&gt;&gt; ans; ans.push_back(&#123;buildings[0][0], buildings[0][2]&#125;); ans.push_back(&#123;buildings[0][1], 0&#125;); return ans; &#125; return divideAndConquer(buildings, 0, size - 1);&#125; 解法2：使用从左向右的扫描，如果遇到左端点，将高度入堆，如果遇到右端点，将高度从堆中删除。还需使用last记录上一个转折点的信息，以示例1为例： 端点排序如下(小技巧：使用正负区别左右端点)：[2, -10], [3, -15], [5, -12], [7, 15], [9, 10], [12, 12], [15, -10], [19, -8], [20, 10], [24, 8]设堆为q(用于存储当前能看到的最大高度,先加入0,用于启动)，结果集为ans，last[0]和last[1]分别保存上一个转折点的下标和高度依次扫描，有： q中加入10{0, 10}，从q中取出最大高度为10 != last[1] = 0，last更新(last={2, 10})，ans中加入[2, 10]，此时and为{[2, 10]} q中加入15{0, 10, 15}，从q中取出最大高度为15 != last[1] = 10，last更新(last={3, 15})，ans中加入[3, 15]，此时and为{[2, 10], [3, 15]} q中加入12{0, 10, 12, 15}，从q中取出最大高度为15 = last[1] = 15，last无需更新，此时前面建筑高度挡住了后面建筑的高度且前面建筑未遇到右端点，ans不改动 \b\bq中减少15{0, 10, 12}，从q中取出最大高度为12 != last[1] = 15，last更新(last={7, 12})，ans中加入[7, 12]，此时and为{[2, 10], [3, 15], [7, 12]} q中减少10{0, 12}，从q中取出最大高度为12 = last[1] = 12，last无需更新，ans不改动 q\b中减少12{0}，从q中取出最大高度为0 != last[1] = 12，last更新(last={12, 0})，ans中加入[12, 0]，此时and为{[2, 10], [3, 15], [7, 12], [12, 0]} q中加入10{0, 10}，从q中取出最大高度为10 != last[1] = 0，last更新(last={15, 10})，ans中加入[15, 10]，此时and为{[2, 10], [3, 15], [7, 12], [12, 0], [15, 10]} q中加入8{0, 8, 10}，从q中取出最大高度为10 = last[1] = 10，last无需更新，ans不改动 q中减少10{0, 8}，从q中取出最大高度为8 != last[1] = 10，last更新(last={20, 8})，ans中加入[20, 8]，此时and为{[2, 10], [3, 15], [7, 12], [12, 0], [15, 10], [20, 8]} q中\b\b\b\b减少\b8{0}，从q中中取出最大高度为0 != last[1] = 8，last更新(last={24, 0})，ans中加入[24, 0]，此时and为{[2, 10], [3, 15], [7, 12], [12, 0], [15, 10], [20, 8], [24, 0]} 代码实现如下： 123456789101112131415161718192021vector&lt;vector&lt;int&gt;&gt; getSkyline(vector&lt;vector&lt;int&gt;&gt; &amp;buildings) &#123; multiset&lt;pair&lt;int, int&gt;&gt; all; vector&lt;vector&lt;int&gt;&gt; ans; for (const vector&lt;int&gt; &amp;building : buildings) &#123; all.insert(&#123;building[0], -building[2]&#125;); all.insert(&#123;building[1], building[2]&#125;); &#125; multiset&lt;int&gt; height&#123;0&#125;; vector&lt;int&gt; last(2, 0); for (const auto &amp;data : all) &#123; if (data.second &lt; 0) height.insert(-data.second); else height.erase(height.find(data.second)); int maxHeight = *height.rbegin(); if (last[1] != maxHeight) &#123; last[0] = data.first; last[1] = maxHeight; ans.emplace_back(last); &#125; &#125; return ans;&#125; 220存在重复元素III 题目描述： 解法1：搜索树 该题暴力解法会超时，考虑一个长度为k的滑动窗口，每次只需要在插入元素前查看是否在当前滑动窗口中是否存在大于等于nums[i] - t并且小于等于nums[i] + t的元素即可，如果存在则返回true否则，插入元素，并维持滑动窗口的大小在c++中set以及multiset都有一个upper_bound()函数用于找到首个大于某值的数，因此可以使用该方式来加快查找速度 1234567891011121314bool containsNearbyAlmostDuplicate(vector&lt;int&gt; &amp;nums, int k, int t) &#123; int len = nums.size(); if (len == 0 || k &lt;= 0 || t &lt; 0) return false; multiset&lt;long&gt; set; for (int i = 0; i &lt; len; ++i) &#123; auto iter = set.upper_bound((long)nums[i] - t - 1); if (iter != set.end() &amp;&amp; *iter &lt;= (long)nums[i] + t) &#123; return true; &#125; set.insert(nums[i]); if (set.size() == k + 1) set.erase(set.find(nums[i - k])); &#125; return false;&#125; 解法2：桶 借鉴桶排序的思想，可以把元素根据t+1分割(此时最大相差t)如果同在一个桶内，就相当于满足条件如果不再同一个桶内，那就需要找前一个桶和后一个桶，检验是否绝对值相差t比如t为3，由于除的特性，-1 / 3 = 0，但是应该划分到-1，因此需要特殊求值，类似于getId函数当桶里的所有元素总数等于k+1，那么就需要把最前添加的元素从桶中删除 123456789101112131415161718192021long getId(long num, long w) &#123; return num &lt; 0 ? (num + 1) / w - 1 : num / w;&#125;bool containsNearbyAlmostDuplicate(vector&lt;int&gt; &amp;nums, int k, int t) &#123; int len = nums.size(); if (len == 0 || k &lt;= 0 || t &lt; 0) return false; long w = (long)t + 1; unordered_map&lt;long, long&gt; map; for (int i = 0; i &lt; len; ++i) &#123; int curId = getId(nums[i], w); if (map.count(curId)) return true; auto iter = map.find(curId - 1); if (iter != map.end() &amp;&amp; nums[i] - iter-&gt;second &lt;= t) return true; iter = map.find(curId + 1); if (iter != map.end() &amp;&amp; iter-&gt;second - nums[i] &lt;= t) return true; map.emplace(curId, nums[i]); if (map.size() == k + 1) map.erase(map.find(getId(nums[i - k], w))); &#125; return false;&#125; 239滑动窗口最大值 题目描述： 解法1：优先队列 很容易就想到使用大顶堆来实现，但每次都需要删除滑出的数，加入新的数，但大顶堆不支持随机删除，只支持删除顶部元素。因此转而想到使用multiset(多重set)完成，但由于需要较多的删除、添加操作，会导致较低的效率有一种更简单的做法，保留使用堆(priority_queue)的方式，但是延迟删除————即如果当前滑出的数如果是最大数才删除，因为如果滑出的数过小，就是一个耗时的操作，没有必要 123456789101112131415161718vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt; &amp;nums, int k) &#123; int len = nums.size(); if (k == 1) return nums; if (k == len) return &#123;*max_element(nums.begin(), nums.end())&#125;; priority_queue&lt;pair&lt;int, int&gt;&gt; window; vector&lt;int&gt; ans; for (int i = 0; i &lt; k; ++i) &#123; window.emplace(nums[i], i); &#125; ans.reserve(len - k + 1); ans.push_back(window.top().first); for (int i = k; i &lt; len; ++i) &#123; window.emplace(nums[i], i); while (window.top().second &lt;= i - k) window.pop(); ans.push_back(window.top().first); &#125; return ans;&#125; 解法2：单调队列 优先队列方式其实也多增加了无用的数据，因为如果后面的数比前面的数大，其实一个区间内的最大只是由后面的数决定的因此可以采用单调队列的方式，由于可能会有重复值的原因，因此采取记录下标值的方式。总体规律是单调队列中index小的值大，每次如果数值小于等于队尾的值，可以添加到队尾————因为可能会把前面的都熬死；如果大于队尾的值，那么就可以消灭任何小于等于其的数值————因为它寿命大而且可以替代区间内的最大值 1234567891011121314151617181920212223242526vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt; &amp;nums, int k) &#123; int len = nums.size(); if (k == 1) return nums; if (k == len) return &#123;*max_element(nums.begin(), nums.end())&#125;; deque&lt;int&gt; dQueue; for (int i = 0; i &lt; k; ++i) &#123; if (dQueue.empty() || nums[dQueue.back()] &gt; nums[i]) dQueue.push_back(i); else &#123; while (!dQueue.empty() &amp;&amp; nums[dQueue.back()] &lt;= nums[i]) dQueue.pop_back(); dQueue.push_back(i); &#125; &#125; vector&lt;int&gt; ans; ans.reserve(len - k + 1); ans.push_back(nums[dQueue.front()]); for (int i = k; i &lt; len; ++i) &#123; if (dQueue.front() &lt;= i - k) dQueue.pop_front(); if (dQueue.empty() || nums[dQueue.back()] &gt; nums[i]) dQueue.push_back(i); else &#123; while (!dQueue.empty() &amp;&amp; nums[dQueue.back()] &lt;= nums[i]) dQueue.pop_back(); dQueue.push_back(i); &#125; ans.push_back(nums[dQueue.front()]); &#125; return ans;&#125; 241为运算表达式设计优先级 题目描述： 解法1：递归 + 记忆化 每次都把字符串根据中间的运算符拆分成两半，再递归计算左右部分的数值，再在外部根据左右计算出的数值进行组合得到可能的结果例如：2*3-4*5依次拆分成2以及3-4*5、2*3以及4*5、2*3-4以及5以第一个拆分为例，首先2直接得出接着拆分3-4*5，有3以及4*5、3-4以及5最终3-4*5就有两种结果，-17以及-5最终与2结合，得到-34和-10 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647bool isOperator(const char &amp;c) &#123; return c == '+' || c == '-' || c == '*';&#125;int calculate(const int &amp;left, const int &amp;right, const char &amp;op) &#123; switch (op) &#123; case '-': return left - right; case '+': return left + right; case '*': return left * right; default: exit(-1); &#125;&#125;void divideAndConcur(const string &amp;input, unordered_map&lt;string, vector&lt;int&gt;&gt; &amp;memo) &#123; if (memo.find(input) != memo.end()) return; int len = input.size(); bool hasOp = false; for (int i = 0; i &lt; input.size(); ++i) &#123; if (isOperator(input[i])) &#123; hasOp = true; string left = input.substr(0, i), right = input.substr(i + 1, len - i - 1); divideAndConcur(left, memo); divideAndConcur(right, memo); auto iter = memo.find(input); if (iter == memo.end()) memo.emplace(input, vector&lt;int&gt;()); for (const int &amp;l : memo[left]) &#123; for (const int &amp;r : memo[right]) &#123; memo[input].push_back(calculate(l, r, input[i])); &#125; &#125; &#125; &#125; if (!hasOp) &#123; int data = atoi(input.c_str()); memo.insert(&#123;input, &#123;data&#125;&#125;); &#125;&#125;vector&lt;int&gt; diffWaysToCompute(string input) &#123; unordered_map&lt;string, vector&lt;int&gt;&gt; memo; divideAndConcur(input, memo); return memo[input];&#125; 解法2：动态规划 动态规划方式十分巧妙，首先把所有的数字和操作符都识别出来并存储例如：2*3-4*5那么数字为2、3、4、5，操作符为*、-、*接着定义dp[i][j]为从第i个到第j个数字所构成的结果按照定义，则初始状态dp[i][i] = nums[i]动态转移方程为dp[i][j] = dp[i][s] op[s] dp[s+1][j]方程表示dp[i][j]的结果为dp[i][s]集合中元素与dp[s+1][j]集合中元素通过操作符op[s]产生的结果集合 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061bool isOperator(const char &amp;c) &#123; return c == '+' || c == '-' || c == '*';&#125;int calculate(const int &amp;left, const int &amp;right, const char &amp;op) &#123; switch (op) &#123; case '-': return left - right; case '+': return left + right; case '*': return left * right; default: exit(-1); &#125;&#125;vector&lt;int&gt; diffWaysToCompute(string input) &#123; vector&lt;int&gt; nums; vector&lt;char&gt; ops; int lastOpIndex = -1; for (int i = 0; i &lt; input.size(); ++i) &#123; if (isOperator(input[i])) &#123; ops.push_back(input[i]); string num = input.substr(lastOpIndex + 1, i - lastOpIndex); nums.push_back(atoi(num.c_str())); lastOpIndex = i; &#125; &#125; // 最后一个数字的获取 string num = input.substr(lastOpIndex + 1, input.size() - lastOpIndex); nums.push_back(atoi(num.c_str())); // 没有操作符 if (lastOpIndex == -1) &#123; return nums; &#125; int size = nums.size(); vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(size, vector&lt;vector&lt;int&gt;&gt;(size)); // 设置dp[i][i] for (int i = 0; i &lt; size; ++i) &#123; dp[i][i].push_back(nums[i]); &#125; // 数字数目 for (int N = 2; N &lt;= size; ++N) &#123; // 起始下标 for (int i = 0; i &lt; size; ++i) &#123; // 结束下标 int j = i + N - 1; if (j &gt;= size) break; // 迭代的下标 for (int s = i; s &lt; j; ++s) &#123; for (const int &amp;lNum : dp[i][s]) &#123; for (const int &amp;rNum : dp[s + 1][j]) &#123; dp[i][j].push_back(calculate(lNum, rNum, ops[s])); &#125; &#125; &#125; &#125; &#125; return dp[0][size - 1];&#125; 264丑数II 题目描述： 解法：动态规划 实际上更容易想到的方法是使用堆排序，把每次得到的数进行排序后，再得到最后的结果，但这种方法有一个巨大的问题————乘数的差距越来越大，后面有很大的数据空隙，很难匹配上，需要求得更多的数来弥合，或者对更多数先求2的乘数还有一种更简单的方式————三指针法，记录当前指向因子分别为2、3和5的指针，之后每次求出这三个指针指向的丑数乘各自因子，取最小值，再更新等于最小值的指针为更大的丑数。这样每次不需要进行额外的计算，而且不用担心排序的问题 实现代码： 123456789101112131415int nthUglyNumber(int n) &#123; vector&lt;int&gt; uglyNum(n, 1); int index_2 = 0, index_3 = 0, index_5 = 0, index = 0; while (index &lt; n - 1) &#123; int num_2 = uglyNum[index_2] * 2; int num_3 = uglyNum[index_3] * 3; int num_5 = uglyNum[index_5] * 5; int min_num = min(num_2, min(num_3, num_5)); uglyNum[++index] = min_num; if (min_num == num_2) index_2++; if (min_num == num_3) index_3++; if (min_num == num_5) index_5++; &#125; return uglyNum[n - 1];&#125; 279完全平方数 题目描述： 解法：动态规划 如果采用贪心法，每次减去最大的平方数，会导致一部分的错误结果————如12=9+1+1+1，而答案为12=4+4+4；采用动态规划时，可以利用上一次的结果进行迭代求解dp[i] = min{dp[i-k] + 1} (k是平方数且i-k &gt;= 0) 实现代码： 12345678910int numSquares(int n) &#123; vector&lt;int&gt; dp(n + 1, INT_MAX); dp[0] = 0; for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 1; i - j * j &gt;= 0; ++j) &#123; dp[i] = min(dp[i], dp[i - j * j] + 1); &#125; &#125; return dp[n];&#125; 282给表达式添加运算符 题目描述： 解法：回溯法 \b由于没有直接的关联，只能使用回溯法遍历整个有效的搜索空间由于’*‘的优先级与’+’与’-‘的优先级不同，最主要是解决该问题比如235，2+3*5，当前的值(5,2+3)和上一次的操作数3恢复结果为(5-3+3*5=17)，因此需要保留当前的结果和上一次的操作数再考虑连乘的情况，5+2*3*5；计算第一个’*‘时，当前值(7)，上次操作数(2)，此时恢复为(7-2+2*3=11)；但在计算第二个’*‘时，当前值(11)，上次操作数(2)，此时的结果无法恢复，所以乘法需要单独计算上一次的操作数————将整个连乘的结果当前上一次的操作数，此时第二次的情况变为当前值(11)，上次操作数(6)，恢复结果(11-6+6*5=35)其次，由于如果每次传递string的值，复制的开销过大，因此可以使用引用传递，每次改变后在恢复回原样以加速(resize()恢复长度) 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748vector&lt;string&gt; ans;void backTrack(const string &amp;num, const int &amp;target, int curIndex, long curNum, long lastNum, string &amp;curStr) &#123; // 递归出口,遍历完所有数字字符 if (curIndex == num.size()) &#123; if (curNum == target) ans.push_back(curStr); return; &#125; // 遍历可能的截取数字 for (int i = curIndex; i &lt; num.size(); ++i) &#123; // 截取数字 string tempStr = num.substr(curIndex, i - curIndex + 1); long tempNum = stol(tempStr); // 获取当前串长,用于恢复 int len = curStr.size(); if (curIndex == 0) &#123; // 刚开始 curStr += tempStr; backTrack(num, target, i + 1, tempNum, tempNum, curStr); curStr.resize(len); &#125; else &#123; // 考虑符号 // + curStr += '+' + tempStr; backTrack(num, target, i + 1, curNum + tempNum, tempNum, curStr); curStr.resize(len); // - curStr += '-' + tempStr; // 将'-'转变为'+',形式统一 backTrack(num, target, i + 1, curNum - tempNum, -tempNum, curStr); curStr.resize(len); // * curStr += '*' + tempStr; // 如果是'*'需要将乘的结果作为更大的当前值(而不是当前值),这用于后面可能接着的'*' backTrack(num, target, i + 1, curNum - lastNum + lastNum * tempNum, lastNum * tempNum, curStr); curStr.resize(len); &#125; // 不允许以0开头的多位数 if (!tempNum) return; &#125;&#125;vector&lt;string&gt; addOperators(string num, int target) &#123; if (num.empty()) return &#123;&#125;; string curStr; backTrack(num, target, 0, 0, 0, curStr); return ans;&#125; 316去除重复字母 题目描述： 解法：贪心 + 单调栈 先统计字母最后出现的下标，这用于确定是否还会碰到接着利用贪心法，遍历字符，如果已有这个字符则跳过否则判断当前栈是否非空，如果非空再判断当前字符是否字典序小于栈顶如果小于栈顶，并且目前处于栈顶的字符后面还能遇到，那么就可以弹出栈顶最终将字符压栈，最终结果就是栈中的顺序可采用二进制移位技巧和利用string代替stack进行优化 1234567891011121314151617181920212223string removeDuplicateLetters(string s) &#123; vector&lt;int&gt; lastIndex(26, -1); int len = s.size(), bitmask = 0; string ans; for (int i = 0; i &lt; len; ++i) &#123; lastIndex[s[i] - 'a'] = i; &#125; for (int i = 0; i &lt; len; ++i) &#123; // 如果存在一样的字符,跳过 if (bitmask &amp; (1 &lt;&lt; (s[i] - 'a'))) continue; // 非空 栈顶字典序大 以后还能遇到栈顶字符 while (!ans.empty() &amp;&amp; ans.back() &gt; s[i] &amp;&amp; lastIndex[ans.back() - 'a'] &gt; i) &#123; // 删除字符标记 int mask = INT_MAX - (1 &lt;&lt; (ans.back() - 'a')); bitmask &amp;= mask; ans.pop_back(); &#125; ans.push_back(s[i]); // 添加字符标记 bitmask |= 1 &lt;&lt; (s[i] - 'a'); &#125; return ans;&#125; 321拼接最大数 题目描述： 解法：单调栈 由于结果由两个序列给出，因此将k个数分隔，一部分由m给出，另一部分由n给出这样就可以分别对m和n利用单调栈求出指定长度的最优解接着按照能使结果最优的方式合并得到的两个序列即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657vector&lt;int&gt; makeSubSequence(const vector&lt;int&gt; &amp;nums, int targetLen) &#123; // 特殊情况处理 if (!targetLen) return &#123;&#125;; if (targetLen == 1) return &#123; *max_element(nums.begin(), nums.end()) &#125;; if (targetLen == nums.size()) return nums; vector&lt;int&gt; ans; ans.reserve(targetLen); // 单调栈 for (int i = 0; i &lt; nums.size(); ++i) &#123; // 如果非空,并且遍历值大于最后值,并且删除后长度符合targetLen while (!ans.empty() &amp;&amp; ans.back() &lt; nums[i] &amp;&amp; ans.size() + nums.size() - i &gt; targetLen) ans.pop_back(); // 未满则添加 if (ans.size() &lt; targetLen) ans.push_back(nums[i]); &#125; return ans;&#125;int compare(vector&lt;int&gt; &amp;subsequence1, int index1, vector&lt;int&gt; &amp;subsequence2, int index2) &#123; int x = subsequence1.size(), y = subsequence2.size(); while (index1 &lt; x &amp;&amp; index2 &lt; y) &#123; int difference = subsequence1[index1] - subsequence2[index2]; if (difference != 0) return difference; index1++; index2++; &#125; // 如果都相同,返回长的 return (x - index1) - (y - index2);&#125;// 合并vector&lt;int&gt; merge(vector&lt;int&gt; &amp;subsequence1, vector&lt;int&gt; &amp;subsequence2) &#123; int x = subsequence1.size(), y = subsequence2.size(); if (!x) return subsequence2; if (!y) return subsequence1; int mergeLength = x + y; vector&lt;int&gt; merged(mergeLength); int index1 = 0, index2 = 0; for (int i = 0; i &lt; mergeLength; i++) &#123; if (compare(subsequence1, index1, subsequence2, index2) &gt; 0) merged[i] = subsequence1[index1++]; else merged[i] = subsequence2[index2++]; &#125; return merged;&#125;vector&lt;int&gt; maxNumber(vector&lt;int&gt; &amp;nums1, vector&lt;int&gt; &amp;nums2, int k) &#123; vector&lt;int&gt; ans; int len1 = nums1.size(), len2 = nums2.size(); for (int i = 0; i &lt;= k; ++i) &#123; // 不满足长度,跳过 if (len1 &lt; i || len2 &lt; k - i) continue; vector&lt;int&gt; l = makeSubSequence(nums1, i); vector&lt;int&gt; r = makeSubSequence(nums2, k - i); vector&lt;int&gt; merged = merge(l, r); if (compare(merged, 0, ans, 0) &gt; 0) ans = merged; &#125; return ans;&#125; 338比特位计数 题目描述： 解法：动态规划 考虑最高位的情况，如果一个数A有n个1的bit位，那么在A的bitSet最高位置1(第一个不是1的置)，那么B就有n+1个1的bit位dp[0] = 0dp[1] = 1(2^0)dp[2] = 1(2^1)dp[3] = dp[1] + 1 = 2dp[4] = 1(2^2)dp[5] = dp[1] + 1 = 2因此找到规律有，2^n数bit位为1的共有一位，而如果满足该条件，则A&amp;(A - 1)为0，每次记录最高位的值，用于找到差dp[i] = dp[i - highBitNum] + 1(dp[0] = 0) 123456789101112vector&lt;int&gt; countBits(int num) &#123; vector&lt;int&gt; bits(num + 1); int highBit = 0; for (int i = 1; i &lt;= num; i++) &#123; // 为2^n if ((i &amp; (i - 1)) == 0) &#123; highBit = i; &#125; bits[i] = bits[i - highBit] + 1; &#125; return bits;&#125; 354俄罗斯套娃信封问题 题目描述： 解法1：朴素动态规划 由于需要在二维数组上组成一个递增的序列(严格每维大于)，因此需要固定一维(先按第一维升序)如果固定了一个维，那么再看第二维，由于如果第二维降序，那么原题就转化成了求第二维数组的最长递增子序列(如果是升序,那么会因为第一维相同而导致不能确定)接着就可以列出动态转移方程：dp[0] = 1dp[i] = dp[j] + 1 (如果nums[i] &gt; nums[j],0 &lt;= j &lt; i)接着返回dp中的最大值即可 12345678910111213141516int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt; &amp;envelopes) &#123; int size = envelopes.size(); if (size &lt; 2) return size; sort(envelopes.begin(), envelopes.end(), [](const vector&lt;int&gt; &amp;v1, const vector&lt;int&gt; &amp;v2) &#123; if (v1[0] != v2[0]) return v1[0] &lt; v2[0]; return v1[1] &gt; v2[1]; &#125;); vector&lt;int&gt; dp(size); dp[0] = 1; for (int i = 1; i &lt; envelopes.size(); ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; if (envelopes[i][1] &gt; envelopes[j][1]) dp[i] = max(dp[i], dp[j] + 1); &#125; &#125; return *max_element(dp.begin(), dp.end());&#125; 解法2：二分法的动态规划 设dp表示序列前i个元素组成的最长严格递增子序列，假设dp长度为j，那么dp[j - 1]表示末尾元素的最小值进行遍历时，考虑当前元素num如果num大于dp的末尾元素，那么num可以接在dp之后形成更长的严格递增子序列否则找出dp中比num严格小的最大元素dp[j0]，则dp[j0] &lt; num &lt;= dp[j0 + 1]，那么dp[j0 + 1]可以替换为num————如果不在末尾，可以任意替换，因为不起决定作用；如果在末尾，那么可以减少末尾的值，可能导致后面的dp增长 123456789101112131415161718int maxEnvelopes(vector&lt;vector&lt;int&gt;&gt;&amp; envelopes) &#123; int n = envelopes.size(); if (n &lt; 2) return n; sort(envelopes.begin(), envelopes.end(), [](const vector&lt;int&gt; &amp;v1, const vector&lt;int&gt; &amp;v2) &#123; if (v1[0] != v2[0]) return v1[0] &lt; v2[0]; return v1[1] &gt; v2[1]; &#125;); vector&lt;int&gt; dp = &#123;envelopes[0][1]&#125;; for (int i = 1; i &lt; n; ++i) &#123; int num = envelopes[i][1]; if (num &gt; dp.back()) dp.push_back(num); else &#123; auto it = lower_bound(dp.begin(), dp.end(), num); *it = num; &#125; &#125; return dp.size();&#125; 395至少有K个重复字符的最长子串 题目描述： 解法1：分治 一个思想是找到数目小于K个的字符，然后通过该字符将原字符串进行分割分割后的子字符串再如此，符合条件的递归出口为字符串中每个字符的数目都大于K 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 递归函数int dfs(const string &amp;s, int left, int right, int k) &#123; // 如果字符串长度小于k,没有必要继续搜索 if (right - left + 1 &lt; k) return 0; // 统计每个字符的个数 vector&lt;int&gt; cNums(26, 0); for (int i = left; i &lt;= right; ++i) &#123; cNums[s[i] - 'a']++; &#125; // 查找第一个不符合个数的字符 char targetLessChar = 0; for (int i = 0; i &lt; 26; ++i) &#123; if (cNums[i] &amp;&amp; cNums[i] &lt; k) targetLessChar = i + 'a'; &#125; // 如果找不到,说明每个字母都大于等于K个,直接返回当前字符串长度 if (!targetLessChar) return right - left + 1; int ans = 0; while (left &lt; right) &#123; // 记录原始left int beforeLeft = left; // 查找不符合字符的出现位置 for (int i = left; i &lt;= right; ++i) &#123; if (s[i] == targetLessChar) &#123; // 递归 ans = max(dfs(s, left, i - 1, k), ans); // left移动 left = i + 1; break; &#125; &#125; // 如果原始left没有改动,说明这一段没有出现不符合字符,应该直接递归,并退出 if (left == beforeLeft) &#123; ans = max(dfs(s, left, right, k), ans); break; &#125; &#125; return ans;&#125;int longestSubstring(string s, int k) &#123; int len = s.size(); if (k == 1) return len; return dfs(s, 0, len - 1, k);&#125; 解法2：滑动窗口 可以列举最长子串的字符种类数目，最小为1，最大为26对于给定的字符种类数目，维护滑动窗口的左右边界l/r、滑动窗口内部每个字符出现的次数cNums，当前窗口内小于k数值的字符种类计数器less、窗口内的字符种类数目total每次窗口向右滑动一步，如果当前字符在cNums中为0，那么total自增————表明新出现一种字符，且less自增————表明又有一种字符数目小于k；如果当前字符在cNums中为k-1，那么less自减————表明少了一种数目小于k的字符接着，查看当前total是否大于指定的字符种类数目，如果大于，左边界向右移动，并与向右移动一样对数据做出改变最终如果less为0，说明当前符合，计算当前子符串长度 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647int longestSubstring(string s, int k) &#123; int len = s.size(); // 特殊处理 if (k == 1) return len; int ans = 0; // 罗列字符种类数目 for (int i = 1; i &lt;= 26; ++i) &#123; // 统计窗口内字符数目 vector&lt;int&gt; cNums(26, 0); // 总共种类、少于k的种类、左边界、有边界 int total = 0, less = 0, l = 0, r = 0; while (r &lt; len) &#123; int rIndex = s[r] - 'a'; // 如果新出现一种字符 if (!cNums[rIndex]) &#123; total++; less++; &#125; // 字符数目达到k if (cNums[rIndex] == k - 1) &#123; less--; &#125; cNums[rIndex]++; // 种类超过规定 while (total &gt; i) &#123; int lIndex = s[l] - 'a'; // 少一种字符 if (cNums[lIndex] == 1) &#123; less--; total--; &#125; // 一种字符数目少于k if (cNums[lIndex] == k) &#123; less++; &#125; cNums[lIndex]--; l++; &#125; // 符合条件,更新结果 if (!less) &#123; ans = max(ans, r - l + 1); &#125; r++; &#125; &#125; return ans;&#125; 514自由之路 题目描述： 解题思路： 每次转到指定位置后还需要按一次按钮，那么结果还需要加上key的长度 转动到指定位置有两种方向，单考虑转到指定位置的话(不考虑再按一次的触发)；假设curRingIndex表示当前转动前的位置下标，curKeyIndex表示转动到的指定位置的下标： l1 = abs(curRingIndex - curKeyIndex) l2 = ring.length() - l1 每次转动后curKeyIndex变为下一次curRingIndex，即从新指定位置开始转动 截止条件是curKeyIndex = key.length()，即当前所有key的字符都被转到12点方向过 解法1：动态规划方式记录每次从当前位置转动到顺序读取到的key字符的位置所花费的转动次数，最终返回到达最后key字符的转动次数的最小值 动态转移方程如下 1234567// 默认dp中元素为INT_MAX// 得到第一步的转动次数dp[0][i] = (ring[i] == key[0]) ? min(i, m - i);// 如果dp[i - 1][k]不为INT_MAX,即上一步(第i步)能转动到ring的第k个字符,且为到第k个字符的最小值// 当前为第i+1步,将要走到第j个字符// 最小距离为已知的最小值与当前走法的较小值dp[i][j] = min(dp[i][j], dp[i - 1][k] + min(abs(j - k), m - abs(j - k))); 最终代码如下 1234567891011121314151617181920212223242526272829int findRotateSteps(string ring, string key) &#123; int m = ring.size(), n = key.size(); vector&lt;int&gt; pos[26]; // 记录字符下标 for (int i = 0; i &lt; m; i++) &#123; pos[ring[i] - 'a'].push_back(i); &#125; vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(m, INT_MAX)); // 遍历首字符匹配的下标集合 for (const int &amp;index : pos[key[0] - 'a']) &#123; // 走第一步 dp[0][index] = min(index, m - index); &#125; for (int i = 1; i &lt; n; ++i) &#123; // 遍历下一步字符的下标集合 for (const int &amp;index : pos[key[i] - 'a']) &#123; for (int j = 0; j &lt; m; j++) &#123; // 如果第i步不可达j,跳过 if (dp[i - 1][j] == INT_MAX) continue; // 当前走第i+1步的最小步数 int steps = min(abs(index - j), m - abs(index - j)); // 记录走i+1步的最小步数 dp[i][index] = min(dp[i - 1][j] + steps, dp[i][index]); &#125; &#125; &#125; // 每次移动到指定位置还需要转动一次触发,因此要+n return *min_element(dp[n - 1].begin(), dp[n - 1].end()) + n;&#125; 解法2：动态规划方式，使用滚动数组的方式，节省空间 根据方式一，发现第i+1步只与第i步的位置有关，因此只需保留两个数组用于保存上一步的最小步数和当前步的最小步数即可 最终代码如下 12345678910111213141516171819202122232425262728293031int findRotateSteps(string ring, string key) &#123; int m = ring.size(), n = key.size(); vector&lt;int&gt; pos[26]; // 记录字符下标 for (int i = 0; i &lt; m; i++) &#123; pos[ring[i] - 'a'].push_back(i); &#125; vector&lt;int&gt; last(m), current(m, INT_MAX); // 遍历首字符匹配的下标集合 for (const int &amp;index : pos[key[0] - 'a']) &#123; // 走第一步 current[index] = min(index, m - index); &#125; for (int i = 1; i &lt; n; ++i) &#123; last = current; fill(current.begin(), current.end(), INT_MAX); // 遍历下一步字符的下标集合 for (const int &amp;index : pos[key[i] - 'a']) &#123; for (int j = 0; j &lt; m; j++) &#123; // 如果第i步不可达j,跳过 if (last[j] == INT_MAX) continue; // 当前走第i+1步的最小步数 int steps = min(abs(index - j), m - abs(index - j)); // 记录走i+1步的最小步数 current[index] = min(last[j] + steps, current[index]); &#125; &#125; &#125; // 每次移动到指定位置还需要转动一次触发,因此要+n return *min_element(current.begin(), current.end()) + n;&#125; 解法3：dfs + 记忆化方式 12345678910111213141516171819202122232425262728293031323334353637383940int findRotateSteps(string ring, string key) &#123; int m = ring.size(), n = key.size(); vector&lt;int&gt; pos[26]; // 记录字符下标 for (int i = 0; i &lt; m; i++) &#123; pos[ring[i] - 'a'].push_back(i); &#125; // 记录从ring的第i个字符转动到key的第j个字符的最小转动次数 vector&lt;vector&lt;int&gt;&gt; memo(m, vector&lt;int&gt;(n, -1)); /* curRingIndex：当前处于ring转盘的第几个字符 curKeyIndex：当前需匹配的key的第几个字符 memo：记录表 */ std::function&lt;int(int, int, vector&lt;vector&lt;int&gt;&gt; &amp;)&gt; dfs = [&amp;, m, pos, key](int curRingIndex, int curKeyIndex, vector&lt;vector&lt;int&gt;&gt; &amp;memo) -&gt; int &#123; // 递归出口 if (curKeyIndex == key.size()) &#123; return 0; &#125; // 如果已记录过,直接返回 if (memo[curRingIndex][curKeyIndex] != -1) &#123; return memo[curRingIndex][curKeyIndex]; &#125; // 记录此次转动的最小次数 int res = INT_MAX; // 遍历ring中当前key对应字符的位置 for (const int &amp;index : pos[key[curKeyIndex] - 'a']) &#123; int d1 = abs(curRingIndex - index); int d2 = m - d1; // 此次转动的最小次数 // 当前转动成功后,curRingIndex自动变为index,curKeyIndex移动到下一个 res = min(res, min(d1, d2) + dfs(index, curKeyIndex + 1, memo)); &#125; // 更新记录表 memo[curRingIndex][curKeyIndex] = res; return res; &#125;; // 每次移动到指定位置还需要转动一次触发,因此要+n return n + dfs(0, 0, memo);&#125; 621任务调度器 题目描述： 解法1：模拟 首先就容易想到的就是采用模拟的方式，首先应该每次优先考虑做次数多的工作(因为冷却的存在,替换着做比不替换更好)因此首先要统计每种工作的次数；接着每次要找到未在冷却期间的剩余次数最多的那个工作，此时时间自增1如果找不到未在冷却期间的工作，那么需要跳跃到最小的下一个可继续工作时间，因此需要记录每种工作下一次可以立马执行的时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445int leastInterval(vector&lt;char&gt; &amp;tasks, int n) &#123; int len = tasks.size(); // 两种特殊情况 if (len == 1) return 1; if (n == 0) return len; unordered_map&lt;char, int&gt; taskNums; // 记录次数 for (const char &amp;task : tasks) &#123; taskNums[task]++; &#125; int taskTypes = taskNums.size(); vector&lt;pair&lt;int, int&gt;&gt; taskInfo(taskTypes); int index = 0; // 初始化下一次可以执行的时间以及次数 for (const auto &amp;taskNum : taskNums) &#123; taskInfo[index].first = 1; taskInfo[index++].second = taskNum.second; &#125; int curTime = 1; while (len) &#123; // 标记 int minTime = INT_MAX, maxTaskNum = 0, targetIndex = 0; for (int i = 0; i &lt; taskTypes; ++i) &#123; // 记录还能继续执行的最小下一次执行时间 if (taskInfo[i].second) minTime = min(minTime, taskInfo[i].first); // 找到能够执行的且剩余次数最多的工作 if (taskInfo[i].first &lt;= curTime) &#123; if (maxTaskNum &lt; taskInfo[i].second) &#123; maxTaskNum = taskInfo[i].second; targetIndex = i; &#125; &#125; &#125; // 更新数据 if (maxTaskNum) &#123; taskInfo[targetIndex].second--; taskInfo[targetIndex].first = curTime + n + 1; curTime++; len--; &#125; else &#123; // 跳跃 curTime = minTime; &#125; &#125; return curTime - 1;&#125; 解法2：桶思想 考虑桶的思想，考虑数目最多的任务，他们之间至少需要设置冷却时间+1个时间(桶大小)，因此如果在任务较少的情况下，其实影响最大的部分在于数目最多的任务举例如下： A B C A B C A B / 此时结果为(最多任务数目 - 1) * 桶大小 + 最多任务数目种类 再考虑到任务多的情况下，举例如下： A B C D A B C E A B D / 如果任务数目较多，则可通过扩展桶大小实现。那么其实最多时间也就是任务的数目(taskNums)，而与任务性质与否无关因此结论是结果为两个例子结果取最大值 1234567891011121314151617int leastInterval(vector&lt;char&gt; &amp;tasks, int n) &#123; // 单个桶内的承载的数目 int bucketNum = n + 1, len = tasks.size(); vector&lt;int&gt; taskNums(26); // 统计同种任务数目 for (const char &amp;task : tasks) &#123; taskNums[task - 'A']++; &#125; sort(taskNums.begin(), taskNums.end(), greater&lt;int&gt;()); int maxCount = 0; // 统计数目最多的任务数 for (const int &amp;taskNum : taskNums) &#123; if (taskNum == taskNums[0]) maxCount++; else break; &#125; return max(len, maxCount + (taskNums[0] - 1) * bucketNum);&#125; 659分割数组为连续子序列 题目描述： 解法1：堆 由于有最小长度为3的限制，因此每次需要将数字增加到长度最短的那个子序列中考虑最小堆，堆中每个元素代表子序列长度，而与之关联的是一个子序列最后一个元素，因为原序列是递增的，如果连续只会比子序列的最后一个元素大，因此无需考虑更大的元素。因此只需要遍历一次原序列，并更新映射关系(可以连续/不可以连续情况)即可 1234567891011121314151617181920212223242526272829303132bool isPossible(vector&lt;int&gt; &amp;nums) &#123; // 建立&lt;子序列最后一个元素, 子序列大小堆&gt;的映射 unordered_map&lt;int, priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt;&gt; um; for (const int &amp;num : nums) &#123; // 如果没有找到映射 if (um.find(num) == um.end()) &#123; um[num] = &#123;&#125;; &#125; // 如果找到之前的元素,可以连续 if (um.find(num - 1) != um.end()) &#123; // 获取之前的长度 int preMinLen = um[num - 1].top(); // 删除之前的元素 um[num - 1].pop(); if (um[num - 1].empty()) &#123; um.erase(num - 1); &#125; // 更新当前长度 um[num].push(preMinLen + 1); &#125; else &#123; // 新增 um[num].push(1); &#125; &#125; for (const auto &amp;kv : um) &#123; // 检验子序列长度 if (kv.second.top() &lt; 3) &#123; return false; &#125; &#125; return true;&#125; 解法2：贪心法 将x加入已有的以x-1结尾的子序列更优，因为前者可以将已有子序列的长度增加1；而新建一个长度为1的子序列不满足题目要求分割的子序列长度不小于3，因此应尽量避免新建短的子序列而在解法1中，每次只做了一次操作，其实可以根据上面的思路，每次如果找到以x-1结尾的子序列则合并，否则尝试建立一个长度为3的子序列，如果不能做到，那么说明输入不满足 12345678910111213141516171819202122232425262728bool isPossible(vector&lt;int&gt; &amp;nums) &#123; // x出现次数map、x为结尾的子序列map数目 unordered_map&lt;int, int&gt; numOccur, numEnd; // 记录各元素出现次数 for (const int &amp;num : nums) &#123; numOccur[num]++; &#125; for (const int &amp;num : nums) &#123; // 如果元素用完,跳过 if (!numOccur[num]) continue; // 优先考虑能够合并 if (numOccur[num] &amp;&amp; numEnd[num - 1]) &#123; // 更新map numOccur[num]--; numEnd[num - 1]--; numEnd[num]++; &#125; else if (numOccur[num] &amp;&amp; numOccur[num + 1] &amp;&amp; numOccur[num + 2]) &#123; // 一次性建立3个元素的子序列 // 更新map numOccur[num]--; numOccur[num + 1]--; numOccur[num + 2]--; numEnd[num + 2]++; &#125; else &#123; return false; &#125; &#125; return true;&#125; 803打砖块 题目描述： 举例说明： 假设敲打前如上图所示，那么所有都不会掉落，因为都系在[0, 0]这个砖块上。如果此时打掉[1, 2]这个砖块，砖块[2, 2]和[3, 2]都与[0, 0]失去间接连接，因此会一起掉落很容易想到这是一道连通性的问题，但又因为只需要需求连通的个数，可以快速地想到使用并查集进行求解。但如果初始阶段进行一次并查集的初始化，再一个一个打掉砖块，那么每次读需要完全重新初始化并查集，打掉的那块并不会对起到任何提示作用。这里可以使用并查集的删除重整算法(没有较好的资料)，但另一种考虑是逆向思维，从最后一步开始倒推重建整个网格比如当前的示例图，右图只有3块稳定，加上[1, 2]砖块后变成左图，共有6块稳定。因此增加(反之这一步打掉砖块附带掉落了)6 - 3 - 1 = 2块 小技巧(trick)：由于当前为二维表格，可能并查集内容很稀疏，可采用map代替传统的定长数组，再者可通过转化二维为一维简化记录内容(t = i * m + j————m行n列) 实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273pair&lt;int, int&gt; find_root(int x, unordered_map&lt;int, pair&lt;int, int&gt;&gt; &amp;union_set) &#123; auto iter = union_set.find(x); if (iter == union_set.end()) &#123; union_set.insert(&#123;x, &#123;x, 1&#125;&#125;); return &#123;x, 1&#125;; &#125; if (x != iter-&gt;second.first) &#123; auto root = find_root(iter-&gt;second.first, union_set); iter-&gt;second.first = root.first; return root; &#125; return iter-&gt;second;&#125;void union_element(int x, int y, unordered_map&lt;int, pair&lt;int, int&gt;&gt; &amp;union_set) &#123; auto x_root = find_root(x, union_set), y_root = find_root(y, union_set); if (x_root.first == y_root.first) return; if (x_root.first == -1) &#123; union_set[y_root.first].first = x_root.first; union_set[x_root.first].second += y_root.second; &#125; else &#123; union_set[x_root.first].first = y_root.first; union_set[y_root.first].second += x_root.second; &#125;&#125;int direction[5] = &#123;0, -1, 0, 1, 0&#125;;vector&lt;int&gt; hitBricks(vector&lt;vector&lt;int&gt;&gt; &amp;grid, vector&lt;vector&lt;int&gt;&gt; &amp;hits) &#123; unordered_map&lt;int, pair&lt;int, int&gt;&gt; union_set; vector&lt;vector&lt;int&gt;&gt; new_grid = grid; union_set.insert(&#123;-1, &#123;-1, 0&#125;&#125;); int m = new_grid.size(), n = new_grid[0].size(), hit_size = hits.size(); vector&lt;int&gt; ans(hit_size); // 重置砖块 for (const vector&lt;int&gt; &amp;hit : hits) &#123; new_grid[hit[0]][hit[1]] = 0; &#125; // 初始化并查集 for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; int index = i * n + j; if (new_grid[i][j]) &#123; if (!i) union_element(index, -1, union_set); else &#123; if (new_grid[i - 1][j]) union_element(index, (i - 1) * n + j, union_set); if (j &amp;&amp; new_grid[i][j - 1]) union_element(index, i * n + j - 1, union_set); &#125; &#125; &#125; &#125; // 倒序添加砖块 int hang_num; for (int i = hit_size - 1; i &gt;= 0; i--) &#123; hang_num = union_set[-1].second; int x = hits[i][0], y = hits[i][1]; // 可能打下的原本没有的砖块,跳过 if (!grid[x][y]) continue; int index = x * n + y; if (!x) union_element(index, -1, union_set); for (int j = 0; j &lt; 4; ++j) &#123; int next_x = x + direction[j], next_y = y + direction[j + 1]; if (next_x &lt; 0 || next_x &gt;= m || next_y &lt; 0 || next_y &gt;= n) continue; if (new_grid[next_x][next_y]) &#123; union_element(index, next_x * n + next_y, union_set); &#125; &#125; new_grid[x][y] = 1; // 可能连不上,最小为0 ans[i] = max(union_set[-1].second - hang_num - 1, 0); &#125; return ans;&#125; 947移除最多的同行或同列石头 题目描述： 举例：说明：由于同行或同列是可以移除的，可以把同行同列的石头连起来，就形成了一个无向图。根据观察，可得到只要是一个无向连通图，那么可以移除到只剩一个石头，那么原题目就变成了求连通子图的个数。如果只需求连通子图的个数而无需求是怎样连通的，可以采用并查集————将连通的石头挂载到一个节点上 实现代码： 12345678910111213141516171819202122232425262728293031323334int find_root(int x, unordered_map&lt;int, int&gt; &amp;union_set, int &amp;connection_component) &#123; auto iter = union_set.find(x); // 没有找到当前节点,相当于初始化 if (iter == union_set.end()) &#123; // 连通子图+1 connection_component++; // 默认父节点为自身 union_set.emplace(x, x); return x; &#125; else &#123; if (iter-&gt;second == x) return x; else &#123; // 路径压缩,找到根节点 union_set[x] = find_root(iter-&gt;second, union_set, connection_component); return union_set[x]; &#125; &#125;&#125;void union_element(int x, int y, unordered_map&lt;int, int&gt; &amp;union_set, int &amp;connection_component) &#123; int xRoot = find_root(x, union_set, connection_component), yRoot = find_root(y, union_set, connection_component); if (xRoot == yRoot) return; union_set[xRoot] = yRoot; connection_component--;&#125;int removeStones(vector&lt;vector&lt;int&gt;&gt; &amp;stones) &#123; unordered_map&lt;int, int&gt; union_set; int connection_component = 0; for (const vector&lt;int&gt; &amp;stone : stones) &#123; union_element(stone[0] + 1001, stone[1], union_set, connection_component); &#125; return stones.size() - connection_component;&#125; 由于同行同列都算连通,因此可以把连通的行列都链接到一起,只需要挂载到单个x或y上即可。由于题目要求0 &lt;= xi,yi &lt;= 10000,因此x+10001即可与y完全隔开 959由斜杠划分区域 题目描述： 解法：并查集 这是一个连通性的问题，只需要求得不连通区域的个数即可，可以使用并查集来解决但使用’/‘和’&#39;分割区域中，单元格并不是最小的单位，而需要把单元格划分成个小的单位如此，每个单元格被划分成4个更小的块，原题就变成了求块的连通区域的个数其次，合并相邻单元格时，只需要考虑两个方向(向右和向下,这样顺序遍历时是全覆盖的)；然而并不是所有块都需要合并，只有块2需要与向下方向的其他块合并，块1需要和向右方向的其他块合并 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class UnionSet &#123;public: int setNum; vector&lt;int&gt; unionSet, weight; explicit UnionSet(int num) &#123; this-&gt;setNum = num; this-&gt;unionSet.resize(num), this-&gt;weight.resize(num); for (int i = 0; i &lt; num; ++i) &#123; this-&gt;unionSet[i] = i; this-&gt;weight[i] = 1; &#125; &#125; int findRoot(int x) &#123; return unionSet[x] == x ? x : unionSet[x] = findRoot(unionSet[x]); &#125; void unionElements(int x, int y) &#123; int xRoot = findRoot(x), yRoot = findRoot(y); if (xRoot == yRoot) return; // 按秩合并 if (weight[xRoot] &gt; weight[yRoot]) swap(xRoot, yRoot); unionSet[xRoot] = yRoot; weight[yRoot] += weight[xRoot]; this-&gt;setNum--; &#125;&#125;;int regionsBySlashes(vector&lt;string&gt; &amp;grid) &#123; int len = grid.size(); if (len == 1) return grid[0][0] == ' ' ? 1 : 2; int chunk_size = len * len &lt;&lt; 2; UnionSet unionSet(chunk_size); for (int i = 0; i &lt; len; ++i) &#123; for (int j = 0; j &lt; len; ++j) &#123; int index = (i * len + j) &lt;&lt; 2; // '/'的情况 if (grid[i][j] == '/') &#123; unionSet.unionElements(index, index + 3); unionSet.unionElements(index + 1, index + 2); &#125; else if (grid[i][j] == '\\\\') &#123; // '\\'的情况 unionSet.unionElements(index, index + 1); unionSet.unionElements(index + 2, index + 3); &#125; else &#123; // ' '的情况 unionSet.unionElements(index, index + 1); unionSet.unionElements(index + 1, index + 2); unionSet.unionElements(index + 2, index + 3); &#125; // 向下合并 if (i != len - 1) &#123; int nextIndex = ((i + 1) * len + j) &lt;&lt; 2; unionSet.unionElements(index + 2, nextIndex); &#125; // 向右合并 if (j != len - 1) &#123; int nextIndex = (i * len + j + 1) &lt;&lt; 2; unionSet.unionElements(index + 1, nextIndex + 3); &#125; &#125; &#125; return unionSet.setNum;&#125; 995K连续位的最小翻转次数 题目描述： 前提条件：对若干个K位翻转操作，改变先后顺序不影响最终翻转效果。因此可以通过自左向右执行翻转，由于翻转是唯一的，如果最终数组元素均为1即是最少的翻转次数。如果自左向右每次遇到一个0就把接下来的K位翻转，会导致超时，因此做了许多不必要的操作 解法1：差分数组 维护一个差分数组diff，其中diff[i]表示两个相邻元素A[i-1]和A[i]的翻转次数差通过累加差分数组可以得到当前位置需要翻转的次数，用revCnt表示遍历到A[i]时，若A[i] + revCnt为偶数，则实际值为0，翻转区间[i, i + K - 1]，可直接将revCnt增加1，diff[i + K]减少1若i + K &gt; n则无法执行翻转操作，返回-1 1234567891011121314151617int minKBitFlips(vector&lt;int&gt; &amp;A, int K) &#123; int n = A.size(); vector&lt;int&gt; diff(n + 1); int ans = 0, revCnt = 0; for (int i = 0; i &lt; n; ++i) &#123; revCnt += diff[i]; if ((A[i] + revCnt) % 2 == 0) &#123; if (i + K &gt; n) &#123; return -1; &#125; ++ans; ++revCnt; --diff[i + K]; &#125; &#125; return ans;&#125; 解法2：滑动窗口 位置i的状态与前面K-1个元素翻转的次数(奇偶)有关可使用队列模拟滑动窗口，此处滑动窗口含义是前面K-1个元素中以哪些位置起始的子区间进行了翻转从左至右滑动，若位置i需要翻转，则将该位置存储到队尾。遍历到新位置j(j &lt; i + K)时，队列中元素个数代表i被之前K-1个是元素翻转的次数 若size为偶，A[i] = 0，则需要翻转 若size为奇，A[i] = 1，则需要翻转因此queue.size() % 2 == A[i]时，元素需要翻转当i + K &gt; N时，说明元素剩余不足，返回-1 1234567891011121314151617181920int minKBitFlips(vector&lt;int&gt; &amp;A, int K) &#123; int ans = 0; if (K == 1) &#123; for (const int &amp;a : A) &#123; if (!a) ans++; &#125; &#125; else &#123; int size = A.size(); queue&lt;int&gt; q; for (int i = 0; i &lt; size; ++i) &#123; if (!q.empty() &amp;&amp; q.front() + K == i) q.pop(); if (q.size() % 2 == A[i]) &#123; if (i + K &gt; size) return -1; ans++; q.push(i); &#125; &#125; &#125; return ans;&#125; 1178猜字谜 题目描述： 解法1：hash表 + 移位 由于只需要求单词中的字母是否都在谜面中，因此不需要细致的统计，应该统计具有相同字母的单词个数并进行归类计算因此，首先需要将具有相同字母的单词个数统计出来，由于题目提示谜底为7位不同的字符，因此如果单词个数大于7可快速省略；而且由于都为小写字母，因此可以采用一个26位的bit位表示(int足以)接着，如果接着遍历单词的数组与谜面进行一一匹配还是效率太低，应该遍历谜面，从hash表中找出是否存在，再累加；因此，需要罗列出谜底要求的bitSet子集 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 计算bitSet中1的个数(低26位)int oneNumsInBits(int bitSet) &#123; int ans = 0; for (int i = 0; i &lt; 26; ++i) &#123; if (bitSet &amp; (1 &lt;&lt; i)) ans++; &#125; return ans;&#125;vector&lt;int&gt; findNumOfValidWords(vector&lt;string&gt; &amp;words, vector&lt;string&gt; &amp;puzzles) &#123; int bitSet; // 记录拥有相同字符单词个数 unordered_map&lt;int, int&gt; bitSetNums; for (const string &amp;word : words) &#123; bitSet = 0; for (const char &amp;c : word) &#123; bitSet |= 1 &lt;&lt; (c - 'a'); // 大于puzzle7个字符 if (oneNumsInBits(bitSet) &gt; 7) break; &#125; bitSetNums[bitSet]++; &#125; vector&lt;int&gt; ans; ans.reserve(puzzles.size()); for (const string &amp;puzzle : puzzles) &#123; int mask, curAns = 0; // 遍历可能余下6位可能的取值,罗列子集 for (int i = 0; i &lt; (1 &lt;&lt; 6); ++i) &#123; mask = 0; for (int j = 0; j &lt; 6; ++j) &#123; if (i &amp; (1 &lt;&lt; j)) &#123; mask |= 1 &lt;&lt; (puzzle[j + 1] - 'a'); &#125; &#125; // 加上第一位 mask |= 1 &lt;&lt; (puzzle[0] - 'a'); if (bitSetNums.find(mask) != bitSetNums.end()) &#123; curAns += bitSetNums[mask]; &#125; &#125; ans.push_back(curAns); &#125; return ans;&#125; 解法2：字典树#TODO 1438绝对差不超过限制的最长连续子数组 题目描述： 解法：滑动窗口 + 单调队列 滑动窗口 + multiset方式很容易想到，每次新插入数据rIndex，如果头尾相差在limit内则更新结果，否则删除lIndex这样多做了许多工作，因为很多中间值多余了，只需要抓住最大值和最小值因此可以采用两个单调队列，一个记录最小值(单调增)，一个记录最大值(单调减)，因为后续可能会浮出水面而后每次查找最大值和最小值只需要查看队头元素即可，如果队头元素之差在limit之外，那么就需要遍历lIndex把可能的最大值或最小值去除复原之差在limit之内 1234567891011121314151617181920212223int longestSubarray(vector&lt;int&gt; &amp;nums, int limit) &#123; int len = nums.size(); int l = 0, r = 0, ans = 0; // 单调递减 priority_queue&lt;int&gt; maxQueue; // 单调递增 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minQueue; while (r &lt; len) &#123; while (!maxQueue.empty() &amp;&amp; maxQueue.top() &lt; nums[r]) maxQueue.pop(); while (!minQueue.empty() &amp;&amp; minQueue.top() &gt; nums[r]) minQueue.pop(); maxQueue.push(nums[r]); minQueue.push(nums[r++]); if (maxQueue.top() - minQueue.top() &lt;= limit) &#123; ans = max(ans, r - l); &#125; else &#123; while (!maxQueue.empty() &amp;&amp; !minQueue.empty() &amp;&amp; maxQueue.top() - minQueue.top() &gt; limit) &#123; if (nums[l] == maxQueue.top()) maxQueue.pop(); if (nums[l++] == minQueue.top()) minQueue.pop(); &#125; &#125; &#125; return ans;&#125; 1489找到最小生成树里的关键边和伪关键边 题目描述： 解法：并查集 首先通过归并具有最小距离的最小生成树生成算法(Kruskal算法)，这样就能得到最小生成树的总权值，在归并过程中可使用并查集进行处理连通性问题接着遍历测试除去一条指定边后的情况：如果一条边是关键边，那么加上这条边后，不能连通(连通数目大于1)或者当前的总权值大于先前的最小权值(连通并且严格大于)最后遍历测试使用一条指定边后的情况：如果一条边是伪关键边，那么使用这条边后，能够连通(此处无需判断,如果不能连通就是关键边)而且与最小权值一样 实现代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 并查集class UnionSet &#123;public: // 连通数目 int setNum; vector&lt;int&gt; unionSet; explicit UnionSet(int num) &#123; this-&gt;setNum = num; unionSet.reserve(num); for (int i = 0; i &lt; num; ++i) &#123; unionSet.push_back(i); &#125; &#125; int findRoot(int x) &#123; return x == unionSet[x] ? x : unionSet[x] = findRoot(unionSet[x]); &#125; // 联合节点,返回是否需要联合 bool unionElement(int x, int y) &#123; int xRoot = findRoot(x), yRoot = findRoot(y); if (xRoot == yRoot) return false; unionSet[xRoot] = yRoot; setNum--; return true; &#125;&#125;;vector&lt;vector&lt;int&gt;&gt; findCriticalAndPseudoCriticalEdges(int n, vector&lt;vector&lt;int&gt;&gt; &amp;edges) &#123; int len = edges.size(); // 设置编号,用于最后的返回 for (int i = 0; i &lt; len; ++i) &#123; edges[i].push_back(i); &#125; // 根据距离从小到大排序 sort(edges.begin(), edges.end(), [](const vector&lt;int&gt; &amp;v1, const vector&lt;int&gt; &amp;v2) &#123; return v1[2] &lt; v2[2]; &#125;); int min_value = 0; UnionSet unionSet(n); // 依次加入并查集,得到最小权值 for (const auto &amp;edge : edges) &#123; if (unionSet.unionElement(edge[0], edge[1])) &#123; min_value += edge[2]; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; ans(2); for (int i = 0; i &lt; len; ++i) &#123; UnionSet temp(n); int temp_value = 0; // 关键边判断 for (int j = 0; j &lt; len; ++j) &#123; if (i == j) continue; const vector&lt;int&gt; &amp;edge = edges[j]; if (temp.unionElement(edge[0], edge[1])) &#123; temp_value += edge[2]; &#125; &#125; if (temp.setNum &gt; 1 || (temp.setNum == 1 &amp;&amp; min_value &lt; temp_value)) &#123; ans[0].push_back(edges[i][3]); continue; &#125; // 伪关键边判断 temp = UnionSet(n); temp.unionElement(edges[i][0], edges[i][1]); temp_value = edges[i][2]; for (int j = 0; j &lt; len; ++j) &#123; if (i == j) continue; const vector&lt;int&gt; &amp;edge = edges[j]; if (temp.unionElement(edge[0], edge[1])) &#123; temp_value += edge[2]; &#125; &#125; if (temp_value == min_value) ans[1].push_back(edges[i][3]); &#125; return ans;&#125; 1631最小体力消耗路径 题目描述： 解法：并查集 原题可以转换成一个连通性问题————如果从左上角到右上角首先通过构造格子间的过渡连接(from, to, cost)可以得到连接对，再通过对这些连接对的排序，把cost较大的移动到最后，那么每次必定从连接对中合并较小代价的连接。在每次连接后都判断当前操作是否能使左上角和右下角连通，而最后的一次成功的操作必定是cost最大的连接，因为是按升序排列的本题中cost为数值的高度差的绝对值，还可通过对行列进行映射到唯一的id(i * row + j)方便编码 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class UnionSet &#123;public: int cellNum; vector&lt;int&gt; unionSet, parent; UnionSet(int cellNum) : cellNum(cellNum) &#123; unionSet.resize(cellNum); parent.resize(cellNum); for (int i = 0; i &lt; cellNum; ++i) &#123; unionSet[i] = i; parent[i] = 1; &#125; &#125; int findRoot(int x) &#123; return x == unionSet[x] ? x : unionSet[x] = findRoot(unionSet[x]); &#125; bool isConnected(int x, int y) &#123; return findRoot(x) == findRoot(y); &#125; bool unionElements(int x, int y) &#123; int xRoot = findRoot(x), yRoot = findRoot(y); if (xRoot == yRoot) return false; // 按秩合并 if (parent[xRoot] &gt; parent[yRoot]) swap(xRoot, yRoot); unionSet[xRoot] = unionSet[yRoot]; return true; &#125;&#125;;int minimumEffortPath(vector&lt;vector&lt;int&gt;&gt; &amp;heights) &#123; int row = heights.size(), col = heights[0].size(); if (row == col &amp;&amp; row == 1) return 0; vector&lt;tuple&lt;int, int, int&gt;&gt; cellDis; for (int i = 0; i &lt; row; ++i) &#123; for (int j = 0; j &lt; col; ++j) &#123; // 加入下连接 if (i &lt; row - 1) cellDis.emplace_back(i * col + j, (i + 1) * col + j, abs(heights[i][j] - heights[i + 1][j])); // 加入右连接 if (j &lt; col - 1) cellDis.emplace_back(i * col + j, i * col + j + 1, abs(heights[i][j] - heights[i][j + 1])); &#125; &#125; sort(cellDis.begin(), cellDis.end(), [](const tuple&lt;int, int, int&gt; &amp;t1, const tuple&lt;int, int, int&gt; &amp;t2) &#123; return get&lt;2&gt;(t1) &lt; get&lt;2&gt;(t2); &#125;); int ans = 0, size = row * col; UnionSet unionSet(size); for (const auto &amp;c : cellDis) &#123; if (unionSet.unionElements(get&lt;0&gt;(c), get&lt;1&gt;(c))) &#123; ans = get&lt;2&gt;(c); if (unionSet.isConnected(0, size - 1)) break; &#125; &#125; return ans;&#125; 1776车队II 题目描述： 解法：单调栈 由于题目隐含一些条件：如果可以合并，左边的都将以右边的车的速度移动，因为如果左边的车能够追上右边的车，那么一定会同化成右边的车速；不管已经行动了多少，能追上的时间都是相对的距离 / 相对的时间可从右向左遍历并维护一个单调栈，单调栈的规律是序号递减，速度递增，这样才可以追上；而且合并之后不再计算与前车相遇时间，必须在前车合并前前车前追上首先入栈right元素(初值为len-1)，而后查看后面元素是否能够追上栈顶元素：如果已经合并那么需要计算在合并前是否能追上；否则查看速度是否大于栈顶元素(如果大于,一定能追上)；然后依次递减right值 1234567891011121314151617181920212223242526272829vector&lt;double&gt; getCollisionTimes(vector&lt;vector&lt;int&gt;&gt; &amp;cars) &#123; int len = cars.size(); if (len == 1) return &#123;-1.0&#125;; vector&lt;double&gt; ans(len); stack&lt;int&gt; s; for (int i = len - 1; i &gt;= 0; i--) &#123; while (!s.empty()) &#123; // 追不上栈顶 if (cars[s.top()][1] &gt;= cars[i][1]) s.pop(); else &#123; // 能追上栈顶 // 没有消失 if (ans[s.top()] &lt; 0) break; // 查看能否在合并前碰到,计算能跟上的距离 double relativeDis = ans[s.top()] * (cars[i][1] - cars[s.top()][1]); // 碰得到 if (relativeDis &gt; cars[s.top()][0] - cars[i][0]) break; // 碰不到 else s.pop(); &#125; &#125; if (s.empty()) ans[i] = -1; else &#123; double t = (cars[s.top()][0] - cars[i][0]) * 1.0 / (cars[i][1] - cars[s.top()][1]); ans[i] = t; &#125; s.push(i); &#125; return ans;&#125; 剑指Offer36二叉搜索树与双向链表 题目描述： 解法：递归 由于是二叉搜索树，因此中序遍历就是一个递增序列，又要求原地算法，因此使用递归的中序遍历由图示的例子，中序遍历后的序列为12345，如果每次得到之前遍历的节点pre，那么每次就能够设置两个指针(当前遍历节点cur)————pre-&gt;right = cur;cur-&gt;left = pre;，那么只需要一次遍历即可得到除首位链接好的双向链表又由于头节点head在遍历过程中pre一定为空，因此可以在递归算法中记录head值，还需要一个全局的pre指针不能使用Node*在函数中传递————在函数中传的是值，指针不能改变，只能改变指针指向的数据，可使用指针的指针或者全局变量 实现代码： 12345678910111213141516171819Node *pre = nullptr, *head = nullptr;void preOrderTraverse(Node *node) &#123; if (node-&gt;left) preOrderTraverse(node-&gt;left); if (pre) &#123; pre-&gt;right = node; node-&gt;left = pre; &#125; else head = node; pre = node; if (node-&gt;right) preOrderTraverse(node-&gt;right);&#125;Node *treeToDoublyList(Node *root) &#123; if (!root) return nullptr; preOrderTraverse(root); head-&gt;left = pre; pre-&gt;right = head; return head;&#125; 剑指Offer37序列化二叉树 题目描述： 解法：层次遍历 由于先序、中序、后序遍历中的任何一种都无法确定一颗二叉树，因此可以通过采用层次遍历的方式，根据隐形的个数条件确定唯一的二叉树首先是serialize()序列化方法，很容易通过队列得到结果，最后通过消除末尾多余的”null,”和’,’最后添加上结束符’]’最重要的是deserialize()反序列化方法，首先通过字符串切割的方式得到所有的数据并存放入集合，接着由于不是满二叉树的情况，因此不能直接通过父元素与子元素的映射得到(有空隙,如下图所示)。需要设置两个指针来确定具体的映射关系 实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455string serialize(TreeNode *root) &#123; if (!root) return \"[null]\"; string ans = \"[\"; queue&lt;TreeNode *&gt; q; q.push(root); while (!q.empty()) &#123; TreeNode *front = q.front(); q.pop(); if (front) &#123; ans.append(to_string(front-&gt;val)).push_back(','); q.push(front-&gt;left); q.push(front-&gt;right); &#125; else ans.append(\"null,\"); &#125; // 去除末尾的\"null,\" while (ans.size() &gt; 5 &amp;&amp; ans.substr(ans.size() - 5, 5) == \"null,\") &#123; ans.erase(ans.size() - 5, 5); &#125; // 去除末尾的',' ans.pop_back(); ans.push_back(']'); return ans;&#125;TreeNode *deserialize(string data) &#123; if (data == \"[null]\") return nullptr; vector&lt;TreeNode *&gt; ans; int start = 1; while (start &lt; data.size()) &#123; // 如果是\"null,\"或\"null]\" if (data[start] == 'n') &#123; ans.push_back(nullptr); start += 5; &#125; else &#123; // 找后一个','的位置 int end = data.find(\",\", start); // 遍历到最后 if (end == string::npos) end = data.size(); int value = stoi(data.substr(start, end - start)); ans.push_back(new TreeNode(value)); start = end + 1; &#125; &#125; // 父元素和子元素的指针,从0开始 int parent = 0, child = 1; while (child &lt; ans.size()) &#123; if (ans[parent]) &#123; ans[parent]-&gt;left = ans[child++]; // 右为null,且不计入的情况 if (child &lt; ans.size()) ans[parent]-&gt;right = ans[child++]; &#125; parent++; &#125; return ans[0];&#125; 剑指Offer39数组中出现次数超过一半的数字 题目描述： 解法：摩尔投票法 若记众数(超过一半的数)的票数为+1，非众数的票数为-1，则必有所有数字的票数和大于0摩尔投票法在众数存在情况下一定指示众数，否则需要验证 实现代码： 12345678int majorityElement(vector&lt;int&gt; &amp;nums) &#123; int majority = 0, count = 0; for (const int &amp;num : nums) &#123; if (!count) majority = num; count += (num == majority) ? 1 : -1; &#125; return majority;&#125; 剑指Offer48最长不含重复字符的子字符串 题目描述： 解法：滑动窗口 采用滑动窗口的方式，比如”dvdf”的例子，设置滑动窗口的当前边界left和right(初始全为0)以及一个存储字符最近遇到下标的集合(由于可见字符只有0～127共128个,因此可以设置为长度为128的向量,并赋初值-1)首先扫描当前right下标的字符’d’，由于’d’未扫描过，因此right++，记录’d’最近下标为0，ans更新为1接着扫描’v’，由于’v’未扫描过，因此right++，记录’v’最近下标为1，ans更新为2接着扫描’d’，由于’d’扫描过且最近下标为0，因此需要将left移动到最近下标+1处————即下标为1，此时left=1，right++，记录’d’最近下标为2，ans不更新再接着扫描’f’，由于’f’未扫描过，因此right++，记录’f’最近下标为3，ans更新为3最后right越界，返回ans 123456789101112131415int lengthOfLongestSubstring(string s) &#123; int len = s.size(); if (len &lt; 2) return len; vector&lt;int&gt; chars(128, -1); int left = 0, right = 0, ans = 0; while (right &lt; len) &#123; if (chars[s[right]] &gt;= left) &#123; left = chars[s[right]] + 1; &#125; chars[s[right]] = right; right++; ans = max(ans, right - left); &#125; return ans;&#125; 剑指Offer51数组中的逆序对 题目描述： 解法1：分治法(归并排序) 假设有两个已排序的序列等待归并计算逆序对个数，分别为L = {8, 12, 16, 22, 100}和R = {9, 26, 55, 64, 91}，使用两个指针lPtr、rPtr分别指向当前待L和R的头部首先8 &lt;= 9，不存在逆序，将8放入答案数组中，lPtr++…这样最终得到逆序对个数即为归并L和R的逆序对的个数加上L和R别分的逆序对个数，就可以把原问题拆分成规模较小的子问题 123456789101112131415161718192021222324252627282930313233343536373839404142int reversePairs(vector&lt;int&gt; &amp;nums, int left, int right, vector&lt;int&gt; &amp;temp) &#123; if (right == left) return 0; if (right - left == 1) &#123; if (nums[left] &gt; nums[right]) &#123; swap(nums[left], nums[right]); return 1; &#125; return 0; &#125; else &#123; int mid = (left + right) &gt;&gt; 1; int leftN = reversePairs(nums, left, mid, temp), rightN = reversePairs(nums, mid + 1, right, temp); // 如果前后总体已有序,提前退出,没有逆序对 if (nums[mid] &lt;= nums[mid + 1]) return leftN + rightN; int curN = 0, lPtr = left, rPtr = mid + 1, index = left; while (lPtr &lt;= mid &amp;&amp; rPtr &lt;= right) &#123; if (nums[lPtr] &lt;= nums[rPtr]) &#123; curN += rPtr - mid - 1; temp[index++] = nums[lPtr++]; &#125; else &#123; temp[index++] = nums[rPtr++]; &#125; &#125; while (lPtr &lt;= mid) &#123; curN += right - mid; temp[index++] = nums[lPtr++]; &#125; while (rPtr &lt;= right) &#123; temp[index++] = nums[rPtr++]; &#125; for (int i = left; i &lt;= right; ++i) &#123; nums[i] = temp[i]; &#125; return leftN + curN + rightN; &#125;&#125;int reversePairs(vector&lt;int&gt; &amp;nums) &#123; int size = nums.size(); if (size &lt; 2) return 0; vector&lt;int&gt; temp(size); return reversePairs(nums, 0, size - 1, temp);&#125; 解法2：树状数组#TODO 剑指Offer56数组中数字出现的次数I 问题描述： 解法：异或分组 由于异或运算有一种性质：A异或A为0，因此通过对所有数字进行异或，能得到两个单数S1、S2的异或结果res接着通过得到res的最高位div(其后全0)，由于最高位div只能由一个数提供(S1或S2)，因此可通过div与S1、S2的和，查看是否满足最高位为div，由此可将S1、S2分成两个数 123456789101112131415161718192021vector&lt;int&gt; singleNumbers(vector&lt;int&gt; &amp;nums) &#123; int res = 0; for (const int &amp;num : nums) &#123; res ^= num; &#125; // 取得最高的不同位 int div = 1; while ((div &amp; res) == 0) &#123; div &lt;&lt;= 1; &#125; // 通过是否满足最高位区分单数 int a = 0, b = 0; for (const int &amp;num : nums) &#123; if (div &amp; num) &#123; a ^= num; &#125; else &#123; b ^= num; &#125; &#125; return &#123;a, b&#125;;&#125; 剑指Offer56数组中数字出现的次数II 问题描述： 解决思路： 由于其他数字都出现了三次，如果采用map的话，效率太低考虑比特位集合，由于int可以转化为32个bit位，如果每个数都出现三次，那么各个位同样也出现了三次，那么只需要统计出各个位的数目，在取余就可以得到0或1，就可以复原出唯一的数 解法1：遍历统计 12345678910111213141516171819// 统计比特位void calculateBit(vector&lt;int&gt; &amp;bitSet, int num) &#123; for (int i = 0; i &lt; 32; ++i) &#123; if (num &amp; (1 &lt;&lt; i)) bitSet[i]++; &#125;&#125;int singleNumber(vector&lt;int&gt; &amp;nums) &#123; vector&lt;int&gt; bitSet(32, 0); // 遍历统计 for (const int &amp;num : nums) &#123; calculateBit(bitSet, num); &#125; int ans = 0; // 还原唯一数的比特位 for (int i = 0; i &lt; 32; ++i) &#123; if (bitSet[i] % 3) ans += 1 &lt;&lt; i; &#125; return ans;&#125; 解法2：状态转换图 由于次数由0变为1，再变为2，最终回到0，可以联想到状态转换(数字逻辑电路)由于0 -&gt; 1 -&gt; 2 -&gt; 0需要两个bit位才能承载，因此扩展为00 -&gt; 01 -&gt; 10 -&gt; 00有转换图 n two(before) one(before) two(after) one(after) 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 如果n输入位0，那么bit位无需变化；若为1，则需要相应的变化当two为0，n为0时，one = one；n为1时，one = ~one，因此此时one = one ^ n当two为1，n为0时，one = 0；n为1时，one = 0，因此此时one = 0综合得到one = (~two &amp; (one ^ n)) | 0即one = one ^ n &amp; ~two同理，当one为0，n为0时，two = two；n为1时，two = ~two，因此此时two = two ^ n当one为1，n为0时，two = 0；n为1时，two = 0，因此此时two = 0因此，one与two一样的表达式two = two ^ n &amp; (~one)由于每个位都具有独立性，因为int与一个bit一样同样遵循上述规律结果时one为1，因此最后的结果由00 -&gt; 01，而one就是最终的结果 12345678int singleNumber(vector&lt;int&gt; &amp;nums) &#123; int one = 0, two = 0; for (const int &amp;num : nums) &#123; one = one ^ num &amp; (~two); two = two ^ num &amp; (~one); &#125; return one;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"},{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://sobxiong.github.io/tags/LeetCode%E9%A2%98%E8%A7%A3/"}]},{"title":"MySQL基础","slug":"Middleware/MySQL/MySQL基础","date":"2020-12-08T12:14:49.000Z","updated":"2020-12-21T11:19:05.610Z","comments":true,"path":"2020/12/08/Middleware/MySQL/MySQL基础/","link":"","permalink":"https://sobxiong.github.io/2020/12/08/Middleware/MySQL/MySQL%E5%9F%BA%E7%A1%80/","excerpt":"内容 SQL语句 表约束和范式 多表查询和子查询 事务 存储引擎 其他","text":"内容 SQL语句 表约束和范式 多表查询和子查询 事务 存储引擎 其他 SQL语句 SQL概述 什么是SQL：SQL(Structured Query Language)是”结构化查询语言”，它是对关系型数据库的操作语言，可以应用到所有关系型数据库中。很多数据库还都有标准以外的一些语法，称之为”方言”。例如MySQL中的LIMIT语句就是MySQL独有的方言，其它数据库都不支持 SQL语法要求： SQL语句可单行或多行书写，以分号结尾 可用空格和缩进来增强语句的可读性 关键字不区别大小写，建议使用大写 SQL分类： DDL(Data Definition Language)：数据定义语言，用来定义数据库对象：库、表、列等 DML(Data Manipulation Language)：数据操作语言，用来定义数据库记录(数据) DCL(Data Control Language)：数据控制语言，用来定义访问权限和安全级别 DQL(Data Query Language)：数据查询语言，用来查询记录(数据) DDL介绍： 操作数据库： 创建数据库： 基础创建：CREATE DATABSE dbName 不存在则创建：CREATE DATABASE IF NOT EXISTS dbName 指定字符集：CREATE DATABSE dbName CHARACTER SET charsetName 查看数据库： 查看所有数据库：SHOW DATABASES 查看某个数据库的定义信息：SHOW CREATE DATABASE dbName 修改数据库(默认)字符集：ALTER DATABASE dbName (DEFAULT) CHARACTER SET charsetName 删除数据库：DROP DATABSE dbName 使用数据库： 查看正在使用的数据库：SELECT DATABASE() 使用/切换数据库：USE dbName 操作表结构： 创建表：CREATE TABLE tableName(field1 fieldType1, field2 fieldType2) MySQL表名是以文件的形式保存在磁盘上的，因此表名的字符可以使用任何文件允许的字符 查看某个数据库的所有表：SHOW TABLES 查看表结构：DESC tableName 查看建表语句：SHOW CREATE TABLE tableName 快速创建表结构相同的表：CREATE TABLE newTableName LIKE oldTableName 删除表 直接删除：DROP TABLE tableName 存在则删除：DROP TABLE IF EXISTS tableName 修改表结构： 添加列：ALTER TABLE tableName ADD fieldName fieldType 修改列：ALTER TABLE tableName MODIFY fieldName fieldType 修改列名(同时可修改字段类型)：ALTER TABLE tableName CHANGE oldFieldName newFieldName fieldType change和modify都可以修改表的定义，change后面需要写两次列名，change可以修改列名称但modify不能 删除列：ALTER TABLE tableName DROP fieldName 修改表名：RENAME TABLE oldTableName TO newTableName 修改表字符集：ALTER TABLE tableName CHARACTER SET charsetName 修改字段位置(ADD/CHANGE/MODIFY后)：[first | after columnName] CHANGE和修改字段位置关键字属于扩展 DML介绍： 插入记录： 插入全部字段：INSERT INTO tableName VALUES(v1, v2, v3, ...) 插入部分字段：INSERT INTO tableName(field1, field2, ...) VALUES(v1, v2, ...) 插入的数据应与字段的数据类型相同，且在范围内 在VALUES中列出的数据位置必须与被加入的列的排列位置相对应 字符和日期型数据应包含在单引号中。MySQL中也可以使用双引号做为分隔符 不指定列或使用NULL，表示插入空值 可以插入多条记录，之间用’,’隔开 蠕虫复制：将一张已存在表中数据复制到另一张表中 复制所有列：INSERT INTO tableName1 SELECT * FROM tableName2 复制部分列：INSERT INTO tableName1(field1, field2, ...) SELECT field1, field2, ... FROM tableName2 更新记录： 不带条件修改(修改所有行)：UPDATE tableName SET field1=v1, field2=v2, ... 带条件修改：UPDATE tableName SET field1=v1,field2=v2, ... WHERE ... 更新记录也可更新多张表的字段 删除记录： 不带条件删除(删除所有行)：DELETE FROM tableName 带条件删除：DELETE FROM tableName WHERE ... 删除记录也可删除多张表的字段 使用truncate删除：TRUNCATE TABLE tableName truncate相当于删除表的结构，再创建一张表；而delete仅删除数据 DCL介绍： 创建用户： 语法：CREATE USER &#39;username&#39; @&#39;hostname&#39; IDENTIFIED BY &#39;password&#39; 单引号’’不可少 说明： username：将创建的用户名 hostname：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost；如果想让该用户可以从任意远程主机登陆，可以使用通配符% password：该用户的登陆密码，可以为空，如果为空则该用户可以不需要密码登陆服务器 授予用户权限 语法：GRANT authority1, authority2, ... ON database.tableName TO &#39;username&#39;@&#39;hostname&#39; 单引号’’不可少 说明： GRANT … ON … TO：授权关键字 authority：授予用户的权限，如CREATE、ALTER、SELECT、INSERT和UPDATE等。如果要授予所有的权限可使用ALL database.tableName：该用户可以操作哪个数据库的哪些表。如果要授予该用户对所有数据库和表的相应操作权限则可用*表示，如*.* ‘username’@’hostname’：给哪个用户授权 撤销用户权限：REVOKE authority1, authority2, ... ON database.tableName FROM &#39;username&#39;@&#39;hostname&#39; 说明参见授予权限 查看权限：SHOW GRANTS FOR &#39;username&#39;@&#39;hostname&#39; usage是指连接(登陆)权限，建立一个用户就会自动授予其usage权限(默认授予) 删除用户：DROP USER &#39;username&#39;@&#39;hostname&#39; 修改管理员密码：mysqldadmin -u root -p password newPassword 需要在未登陆MySQL的情况下操作，新密码不需要加上引号；password是关键字，newPassword是新密码串 修改普通用户密码：SET PASSWORD FOR &#39;username&#39;@&#39;hostname&#39;=password(&#39;newPassword&#39;) 需要在登陆MySQL的情况下操作 DQL介绍： 总体语法： 1234567891011121314SELECT selection_list /*要查询的列名称*/FROM table_list /*要查询的表名称*/WHERE condition /*行条件*/GROUP BY grouping_columns /*对结果分组*/HAVING condition /*分组后的行条件*/ORDER BY sorting_columns /*对结果分组*/LIMIT offset_start, row_count /*结果限定*/ 简单查询： 查询所有列：SELECT * FROM tableName 查询指定列：SELECT field1, field2, ... FROM tableName 指定别名查询： 指定列别名：SELECT field1 AS newField1, field2 AS newField2, ... FROM tableName 指定列和表别名：SELECT field1 AS newField1, field2 AS newField2, ... FROM tableName AS newTableName 指定表别名主要用于多表查询，其中别名的AS可以省略；别名可用双引号””括起 清除指定列的重复值：SELECT DISTINCT field FROM tableName 查询结果参与运算(参与运算的必须是数值类型)： 条件查询： 语法：SELECT field FROM tableName WHERE condition 比较运算符： 运算符 说明 &gt;、&lt;、&lt;=、&gt;= =、&lt;&gt; / !=、&lt;=&gt; &lt;=&gt;为NULL安全的等于,其余不能用于NULL比较 BETWEEN 存在于指定范围 IN 存在于指定集合 IS [NOT] NULL LIKE 通配符匹配 REGEXP / RLIKE 正则表达式匹配 逻辑运算符： 运算符 说明 AND / &amp;&amp; 与,AND更通用；操作数任一为NULL返回NULL OR / || 或；一操作数为NULL另一操作为0(非零)时返回NULL(1),两操作数均为NULL时返回NULL NOT / ! 非,NOT NULL返回指为NULL XOR 异或；操作数任一为NULL返回NULL 位运算符：&amp;、|、^、~、&gt;&gt;、&lt;&lt; LIKE关键字：模糊查询 通配符 说明 % 匹配任意多个字符(包含0个字符) _ 匹配一个字符 ESCAPE 转义指定字符 SELECT username FROM user WHERE username LIKE &#39;%pbo/_%&#39; ESCAPE &#39;/&#39; 排序查询：SELECT field FROM tabelName WHERE field = value ORDER BY field1 [ASC|DESC], field2[ASC|DESC], ... 同时对多个字段进行排序时，如果第一个字段相同则按第二个字段排序，依此类推 聚合函数： 介绍：聚合函数查询是纵向查询，它对一列的值进行计算，然后返回一个结果值。聚合函数会忽略空值NULL 主要的聚合函数： 函数 作用 max(列) 求列的最大值 min(列) 求列的最小值 avg(列) 求列的平均值 count(列) 统计列的数据条数 sum(列) 求列数据的总和 语法：SELECT fcuntion(field) FROM tableName 对于NULL的记录不会统计，如果要统计需要借助IFNULL函数IFNULL(fieldName, defaultValue)：如果列不为空返回这列的值。如果为NULL则返回默认值修改后的SQL语句：SELECT function(IFNULL(fieldName, defaultValue)) FROM tableName 分组查询: 介绍：GROUP BY语句会将分组字段结果中相同内容作为一组，并且返回每组的第一条数据。因此单独分组没什么用处。分组的目的是为了统计，一般分组查询会跟聚合函数一起使用 语法：SELECT field1, field2, ... FROM tableName GROUP BY field [HAVING condition] HAVING和WHERE子句的区别： 语句 作用 WHERE子句 1. 对查询结果进行分组前，将不符合WHERE条件的行去掉，即在分组之前过滤数据，即先过滤再分组 2. WHERE子句后不可以使用聚合函数 HAVING子句 1. HAVING子句的作用是筛选满足条件的组，即在分组之后过滤数据，即先分组再过滤 2. HAVING子句后可以使用聚合函数 LIMIT语句： 介绍：限制查询记录的条数，用于语句的末尾 语法：LIMIT offset, length offset：起始行数，从0开始计数。省略默认就是0length：返回的行数 记录联合： 介绍：用于将结果合并显示 语法：select1 UNION | UNION ALL select2 ... UNION ALL是把结果集直接合并，UNION在UNION ALL结果的基础上进行了一此DISTINCT，去除了重复记录 表约束和范式 表约束 约束作用：可以一定程度保证数据的正确性、有效性和完整性 约束种类： 约束名 关键字 主键 PRIMARY KEY 唯一 UNIQUE 非空 NOT NULL 外键 FOREIGN KEY(主表中主键列,从表中外键列) 检查约束 CHECK(MySQL不支持) 主键： 特点： 非空，NOT NULL 唯一，UNIQUE 设置语句： 创建表时添加 在已有表中添加主键：ALTER TABLE tableName ADD PRIMARY KEY(fieldName) 删除主键：ALTER TABLE tableName DROP PRIMARY KEY 主键自增： 介绍：建表时使用AUTO_INCREMENT关键字可以指定主键自增，默认开始值为1，且主键必须是整型类型的一个字段 创建表时指定起始值： 12345CREATE TABLE tableName( field1 INT PRIMARY KEY AUTO_INCREMENT, field2 ..., ...)AUTO_INCREMENT=v; 修改主键起始值：ALTER TABLE tableName AUTO_INCREMENT=value DELETE和TRUNCATE对自增长的影响：前者删除记录后自增长无影响；后者删除后自增长从头开始 唯一约束： 特点：某列不能出现重复的值，NULL不存在重复问题 语法：field fieldType UNIQUE 非空约束： 特点：某列不能为NULL 语法：field fieldType NOT NULL 默认值：field fieldType DEFAULT value 外键约束： 语法： 新建表：[CONSTRAINT] [foreignKeyName] FOREIGN KEY(fieldName) REFERENCES tableName(fieldName) [ON UPDATE CASCADE|ON DELETE CASCADE] 已有表新增：ALTER TABLE table1 ADD [CONSTRAINT] [foreignKeyName] FOREIGN KEY(fieldName) REFERENCES table2(fieldName) [ON UPDATE CASCADE|ON DELETE CASCADE] 删除：ALTER TABLE tableName DROP FOREIGN KEY foreignKeyName 级联操作：在修改和删除主表的主键时，同时更新或删除副表的外键值(可同时设置级联更新和删除) 级联操作语法 描述 ON UPDATE CASCADE 级联更新,只能是创建表的时候创建级联关系。更新主表中的主键,从表中的外键列也自动同步更新 ON DELETE CASCADE 级联删除 范式 第一范式(1NF)：数据库表的每一列都是不可分割的原子数据项，不能是集合、数组等非原子数据项。即表中的某个列有多个值时，必须拆分为不同的列。简而言之，第一范式每一列不可再拆分，称为原子性 第二范式(2NF) 介绍：在满足第一范式的前提下，表中的每一个字段都完全依赖于主键所谓完全依赖是指不能存在仅依赖主键一部分的列。简而言之，第二范式就是在第一范式的基础上所有列完全依赖于主键列 特点： 一张表只描述一件事情 表中的每一列都完全依赖于主键 第三范式(3NF)：在满足第二范式的前提下，表中的每一列都直接依赖于主键，而不是通过其它的列来间接依赖于主键。简而言之，第三范式就是所有列不依赖于其它非主键列，也就是在满足2NF的基础上，任何非主列不得传递依赖于主键 多表查询和子查询 多表查询 内连接：用左边表的记录去匹配右边表的记录，如果符合条件的则显示 隐式内连接：看不到JOIN关键字，条件由WHERE指定 SELECT field FROM table1, table2 WHERE condition 显式内连接：使用INNER JOIN … ON格式，可以省略INNER SELECT field FROM table1 [INNER] JOIN table2 ON condition 外连接： 左外连接：用左表记录去匹配右表记录，如果符合条件的则显示原数据；否则显示NULL。可理解为在内连接基础上保证左表数据全部显示。使用LEFT OUTER JOIN … ON格式，可以省略OUTER SELECT field FROM table1 LEFT [OUTER] JOIN table2 ON condition 右外连接：用右表记录去匹配左表记录，如果符合条件的则显示原数据；否则显示NULL。可理解为在内连接基础上保证右表数据全部显示。使用RIGHT OUTER JOIN … ON格式，可以省略OUTER SELECT field FROM table1 RIGHT [OUTER] JOIN table2 ON condition 子查询 介绍： 一个查询的结果做为另一个查询的条件 有查询的嵌套，内部的查询称为子查询 子查询要使用括号 子查询的情况： 结果是一个数据(单行单列)：可以供父查询使用比较运算符 SELECT field FROM tableName WHERE field = (child selection) 结果是一个数组(多行单列)：可以供父查询使用IN运算符 SELECT field FROM tableName WHERE field IN (child selection) 结果是一张表(多行多列)：可作为查询的表或连接表，还需取表别名 SELECT field FROM (child seletion) aliasName WHERE conditionSELECT field FROM table1 [LEFT|RIGHT] JOIN (child selection) aliasName ON condition 事务 介绍：事务执行是一个整体，所有的SQL语句都必须执行成功。如果其中有1条SQL语句出现异常，则所有的SQL语句都要回滚，整个业务执行失败 MySQL执行事务的方式： 手动提交事务 执行语句： 开启事务：start transaction 提交事务：commit 回滚事务：rollback 使用过程： 执行成功：开始事务 -&gt; 执行多条SQL语句 -&gt; 成功完成,提交事务 执行失败：开启事务 -&gt; 执行多条SQL语句 -&gt; 出现异常,事务回滚 自动提交事务：MySQL默认每一条DML(增删改)语句都是一个单独的事务，每条语句都会自动开启一个事务，语句执行完毕自动提交事务 查看MySQL是否开启自动提交事务：SELECT @@autocommit @@表示全局变量，1表示开启，0表示关闭 取消自动提交事务：SET @@autocommit = 0 事务原理：事务开启之后，所有的操作都会临时保存到事务日志中。事务日志只有在收到commit命令才会同步到数据表中，其他任何情况都会清空事务日志(rollback,断开连接) 事务步骤： 客户端连接数据库服务器，创建连接时创建此用户临时日志文件 开启事务以后，所有的操作都会先写入到临时日志文件中 所有的查询操作从表中查询，但会经过日志文件加工后才返回 如果事务提交则将日志文件中的数据写到表中，否则清空日志文件 回滚点：在某些成功的操作完成之后，后续的操作有可能成功有可能失败，但是不管成功还是失败，前面操作都已经成功。可以在当前成功的位置设置一个回滚点，以供后续失败操作返回到该位置，而不是返回所有操作，这个点称之为回滚点 回滚点操作 语句 设置回滚点 savepoint name 回到回滚点 rollback to name 事务的隔离级别 事务四大特性：原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability) 事务的隔离级别： 问题 含义 脏读 一个事务读取到了另一个事务中尚未提交的数据 不可重复读 一个事务中两次读取的数据内容不一致 幻读 一个事务中两次读取的数据的数量不一致 数据库的隔离级别： 级别 名字 隔离级别 脏读 不可重读 幻读 说明 1 读未提交 read uncommitted 是 是 是 \\ 2 读已提交 read committed 否 是 是 Oracle和SQL Server默认的隔离级别 3 可重复读 repeatable read 否 否 是 MySQL默认的隔离级别 4 串行化 serializable 否 否 否 \\ 隔离级别越高，安全级越高，性能越差 MySQL事务隔离级别相关命令： 查询全局事务隔离级别：SELECT @@tx_isolation 设置隔离级别(需要退出后重新登录才生效)：SET GLOBAL TRANSACTION ISOLATION LEVEL 隔离级别字符串 存储引擎 介绍：插件式存储引擎是MySQL数据库最重要的特性之一，用户可以根据应用的需要选择如何存储和索引数据、是否使用事务等 支持的存储引擎(MySQL5.7)：InnoDB、MyISAM、MEMORY、CSV、BLACKHOLE、ARCHIVE、MERGE(MRG_MyISAM)、FEDERATED、EXAMPLE、NDB等。其中InnoDB和NDB提供事务安全表 指定存储引擎： 建表：创建新表时如果不指定存储引擎，那么就会使用默认存储引擎，MySQL 5.5之前默认为MyISAM，5.5之后默认为InnoDB。如果要修改默认的存储引擎，可在参数文件中设置default_storage_engine属性。可通过增加ENGINE关键字设置新建表的存储引擎：ENGINE=xxx 查看当前的默认存储引擎：SHOW VARIABLES LIKE &#39;default_storage_engine&#39; 查询当前数据库支持的存储引擎：SHOW engines \\G 其中Support不同值的含义分别为： Support值 含义 DEFAULT 支持并启用,并且作为默认引擎 YES 支持并启用 NO 不支持 DISABLED 支持,但数据库启动时被禁用 修改表：使用ALTER TABLE语句将一个已经存在的表修改存储引擎：ALTER TABLE t engine = xxx 修改表的存储引擎需要锁表并复制数据，对于线上环境的表进行这个操作非常危险 常用存储引擎介绍 特点对比： 特点 MyISAM Memory InnoDB Archive NDB B树索引 支持 支持 支持 / / 备份/时间点恢复 支持 支持 支持 支持 支持 支持集群 / / / / 支持 聚簇索引 / / 支持 / / 数据压缩 支持 / 支持 支持 / 数据缓存 / N/A 支持 / 支持 数据加密 支持 支持 支持 支持 支持 支持外键 / / 支持 / 支持 全文索引 支持 / 支持 / / 地理坐标数据类型 支持 / 支持 支持 支持 地理坐标索引 支持 / 支持 / / 哈希索引 / 支持 / / 支持 索引缓存 支持 N/A 支持 / 支持 锁粒度 表级 表级 行级 行级 行级 MVCC多版本控制 / / 支持 / / 支持复制 支持 有限支持 支持 支持 支持 存储限制 256TB RAM 64TB None 384EB T树索引 / / / / 支持 支持事务 / / 支持 / 支持 统计信息 支持 支持 支持 支持 支持 MyISAM 其他 mysqld是MySQL的主程序(服务器端)；mysql是MySQL的命令行工具(客户端) 查看MySQL内部设置的编码：SHOW VARIABLES LIKE &#39;character%&#39; 备份语句：mysqldump -u username -p password database &gt; filePath mysqldump在bin文件目录下是一个可执行文件，用于执行文件备份上述语句用于将数据库备份到本地文件(.sql) 还原语句： 12USE database;SOURCE filePath; 查看帮助(MySQL CLI中)： 显示所有可供查看的命令：? contents 显示具体信息：? xx 查询元数据信息：information_schema系统数据库，是一个虚拟数据库，物理上并不存在相关的目录和文件；存储的全部是视图 SCHEMA：提供当前MySQL实例中所有数据库的信息；show databaes的结果来源于该视图 TABLES：提供了关于数据库中表的信息(包括视图)，详细表述了某个表属于哪个SCHEMA、表类型、表引擎、创建时间等信息；show tables from schemaName的结果来源于该视图 COLUMNS：提供了表中的列信息，详细表述了某张表的所有列以及每个列的信息。show columns from schemaName.tableName的结果来源于该视图 STATISTIC：提供了关于表索引的信息。show index from schemaName.tableName的结果来源于该视图","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"https://sobxiong.github.io/tags/Middleware/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sobxiong.github.io/tags/MySQL/"}]},{"title":"SpringMVC基础","slug":"SpringSeries/SpringMVC/SpringMVC基础","date":"2020-12-08T11:23:44.000Z","updated":"2020-12-12T14:45:25.758Z","comments":true,"path":"2020/12/08/SpringSeries/SpringMVC/SpringMVC基础/","link":"","permalink":"https://sobxiong.github.io/2020/12/08/SpringSeries/SpringMVC/SpringMVC%E5%9F%BA%E7%A1%80/","excerpt":"内容 SpringMVC概述 常用注解介绍 RestFul介绍 其他细节介绍 SpringMVC核心技术","text":"内容 SpringMVC概述 常用注解介绍 RestFul介绍 其他细节介绍 SpringMVC核心技术 SpringMVC概述 什么是MVC： MVC是模型(Model)、视图(View)和控制器(Controller)的简写，是一种软件设计规范。使用将业务逻辑、数据、显示分离的方式来组织代码，降低了视图与业务逻辑间的双向耦合。MVC是一种架构模式，不同的MVC也存在差异。最典型的MVC就是JSP + servlet + javaBean MVC各自的解释： Model(模型)：数据模型，提供要展示的数据，包含数据和行为 View(视图)：负责进行模型的展示，一般指用户界面 Controller(控制器)：接收用户请求，委托给模型进行处理(状态改变)，处理完毕后把返回的模型数据返回给视图，由视图负责展示。控制器做了调度员的工作 MVC框架需要做的工作： 将url映射到java类或java类的方法 封装用户提交的数据 处理请求：调用相关的业务处理、封装响应数据 将响应的数据进行渲染(jsp/html等表示层数据) 简介：SpringMVC是Spring框架的一部分，是基于Java实现MVC的轻量级Web框架。围绕DispatcherServlet(调度Servlet)设计 优点： 轻量级，简单易学 简洁、灵活、高效，基于请求响应的MVC框架 与Spring兼容性好，无缝结合 约定优于配置 功能强大：RESTful、数据验证、格式化、本地化、主题等 SpringMVC的HelloWorld搭建： 新建maven web项目 引入servlet、SpringMVC依赖 1234567891011&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在web.xml中注册中央处理器 12345678910111213141516171819&lt;!-- 注册中央处理器 --&gt;&lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- 指定SpringMVC配置文件路径 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 装载顺序 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;!-- 处理器拦截映射 --&gt;&lt;!-- /会匹配所有请求,/*才会匹配.jsp --&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; &lt;load-on-startup&gt; 标记是否在Web服务器(Tomcat)启动时会创建这个Servlet实例，即是否在Web服务器启动时调用执行该Servlet的init()方法，而不是在真正访问时才创建。值必须是一个整数： 当值大于等于0时，表示容器在启动时就加载并初始化这个Servlet；数值越小，该Servlet的优先级就越高，被创建的也就越早 当值小于0或者没有指定时，则表示该Servlet在真正被使用时才会去创建 当值相同时，容器会自己选择创建顺序 &lt;url-pattern/&gt; &lt;init-param&gt;\b自定义SpringMVC配置文件地址 默认要从项目根下的WEB-INF目录下找名称为Servlet名称-servlet.xml的配置文件(即springmvc-servlet.xml)，而一般情况下配置文件是放在类路径下(即resources目录下)。因此在注册中央调度器时还需要为中央调度器设置查找SpringMVC配置文件的路径DispatcherServlet继承自FrameworkServlet，该类中有一个属性contextConfigLocation用于设置SpringMVC配置文件的路径及文件名 声明组件扫描器(Spring配置文件中) 定义目标页面(show.jsp) 创建处理器 12345678910111213@Controller@Slf4jpublic class MyController &#123; @RequestMapping(value = \"/test.do\") public ModelAndView doSome() &#123; log.info(\"Handle /test.do request ~~~\"); ModelAndView modelAndView = new ModelAndView(); modelAndView.addObject(\"msg\", \"testMsg\"); modelAndView.addObject(\"code\", 200); modelAndView.setViewName(\"/show.jsp\"); return modelAndView; &#125;&#125; 若有多个请求路径均可匹配该处理器方法的执行，则@RequestMapping的value属性可赋值一个数组ModelAndView类中的addObject()方法用于向Model中添加数据。Model的底层为HashMap。Model中的数据存储在request作用域中，SringMVC默认采用转发的方式跳转到视图。本次请求结束，模型中的数据会被销毁 修改视图解析器的注册 12345678&lt;!-- 注册视图解析器：帮助处理视图的路径和扩展名,生成视图对象 --&gt;&lt;!-- 注册内部资源视图解析器InternalResourceViewResolver --&gt;&lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!-- 前缀：表示视图所在的路径 --&gt; &lt;property name=\"prefix\" value=\"/jsp/\"/&gt; &lt;!-- 后缀：表示视图文件的扩展名 --&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt;&lt;/bean&gt; 为了避免对于请求资源路径与扩展名上的冗余，在视图解析器InternalResouceViewResolver中引入请求的前辍与后辍。此时ModelAndView中只需给出要跳转页面的文件名即可。对于具体的文件路径与扩展名，视图解析器会自动完成拼接 修改对应的处理器跳转地址和页面位置 中心控制器DispatcherServlet： 介绍：Spring的web框架围绕DispatcherServlet设计。DispatcherServlet的作用是将请求分发到不同的处理器。SpringMVC框架像许多其他MVC框架一样，以请求为驱动，围绕一个中心Servlet分派请求及提供其他功能。DispatcherServlet是一个实际的Servlet(它继承自HttpServlet基类) SpringMVC的原理：当发起请求时被前置的控制器拦截到请求，根据请求参数生成代理请求，找到请求对应的实际控制器，控制器处理请求，创建数据模型，访问数据库，将模型响应给中心控制器，控制器使用模型与视图渲染视图结果，将结果返回给中心控制器，再将结果返回给请求者 SpringMVC执行逻辑： DispatcherServlet表示前置控制器，是整个SpringMVC的控制中心。用户发出请求，DispatcherServlet接收请求并拦截请求 假设请求的url为：http://localhost:8080/SpringMVC/hellourl可以拆分成三部分： http://localhost:8080：服务器域名 SpringMVC部署在服务器上的web站点 hello表示控制器 如上url表示为：请求位于服务器localhost:8080上的SpringMVC站点的hello控制器 HandlerMapping为处理器映射。DispatcherServlet调用HandlerMapping，HandlerMapping根据请求url查找Handler HandlerExecution表示具体的Handler，其主要作用是根据url查找控制器。示例url被查找控制器为hello HandlerExecution将解析后的信息传递给DispatcherServlet，如解析控制器映射等 HandlerAdapter表示处理器适配器，其按照特定的规则去执行Handler Handler让具体的Controller执行 Controller将具体的执行信息返回给HandlerAdapter，如ModelAndView HandlerAdapter将视图逻辑名或模型传递给DispatcherServlet DispatcherServlet调用视图解析器(ViewResolver)来解析HandlerAdapter传递的逻辑视图名 视图解析器将解析的逻辑视图名传给DispatcherServlet DispatcherServlet根据视图解析器解析的视图结果，调用具体的视图 最终视图呈现给用户 常用注解介绍 @Controller：声明控制器，需要使用包扫描注册进Spring容器 @RequestMapping：定义请求规则 value属性：定义处理器对于请求的映射规则。可以注解在方法上，也可以注解在类上。常以’/‘开始，用于定义所匹配请求的URI 注解于类上：配合@Controller进行使用，表示类中所有响应请求方法以该地址作为父路径 注解于方法上：表示相对于父路径的请求地址 method属性：用于约束请求的类型，可以收窄请求范围。指定请求谓词的类型如GET、POST、HEAD、OPTIONS、PUT、PATCH、DELETE和TRACE等。支持指定多个method produces属性：设置输出结果类型，可用于设置响应体格式和字符集 例如：application/json;charset=utf-8；text/plain;charset=utf-8 @GetMapping、PostMapping、PutMapping、DeleteMapping、PatchMapping：组合注解，指定了请求方法的便于使用的@RequestMapping版本 @ResponseBody：用于将处理器的方法返回值转换为json @RestController：相当于@Controller + @ResponseBody，相当于控制器当中每个处理器方法都使用@ResponseBody注解 @RequestParam：校正请求参数名 所谓校正请求参数名，是指若请求URL所携带的参数名称与处理方法中指定的参数名不相同时，则需在处理方法参数前添加注解@RequestParam指定请求URL所携带参数的名称。该注解是对处理器方法参数进行修饰的，value属性指定请求参数的名称 @PathVariable：使方法参数的值对应绑定到一个URI模版变量上 路径变量的好处： 使路径变得更加简洁 获得参数更加方便，框架会自动进行类型转换 通过路径变量的类型可以约束访问参数，如果类型不一样，则访问不到对应的请求方法 RestFul介绍 概念：Restful就是一个资源定位及资源操作的风格。不是标准也不是协议，只是一种风格。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制 优点：可以通过不同的请求方式来实现不同的效果。请求地址一样，但是功能可以不同 http://127.0.0.1/item/1 查询,GEThttp://127.0.0.1/item 新增,POSThttp://127.0.0.1/item 更新,PUThttp://127.0.0.1/item/1 删除,DELETE 其他细节介绍 处理器方式参数：处理器方法可以包含以下四类参数，这些参数会在系统调用时由系统自动赋值，可在方法内直接使用 HttpServletRequest HttpServletResponse HttpSession 请求中所携带的请求参数 请求参数中文乱码： 问题介绍：对于接收的请求参数，若含有中文，则会出现中文乱码问题。Spring对于请求参数中的中文乱码问题，给出了专门的字符集过滤器：org.springframework.web.filter包下的CharacterEncodingFilter类 解决方式：在web.xml中注册字符集过滤器即可解决Spring请求参数的中文乱码问题。不过最好将该过滤器注册在其它过滤器之前，因为过滤器的执行是按照注册顺序进行的 1234567891011121314151617181920212223&lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 指定字符集 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 强制request使用字符集encoding --&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 强制response使用字符集encoding --&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 处理器方式的返回值 处理器方法常用返回值有四种类型： ModelAndView String void 自定义类型对象 ModelAndView(适用于前后端不分离)若处理器方法处理完后需要跳转到其它资源，且又要在跳转的资源间传递数据，此时处理器方法返回ModelAndView比较好。若要返回ModelAndView，则处理器方法中需要定义ModelAndView对象若该处理器方法只是进行跳转而不传递数据，或只传递数据而并不向任何资源跳转(如对页面的Ajax异步响应)，此时若返回ModelAndView则将总有一部分多余————要么Model多余，要么View多余。此时返回ModelAndView将不合适 String(适用于前后端不分离)处理器方法返回的字符串可以指定逻辑视图名，通过视图解析器(InternalResourceViewResolver内部资源视图解析器)解析可以将其转换为物理视图地址也可以直接返回资源的物理视图名，此时就不需要在视图解析器中再配置前辍与后辍 返回void(了解)若处理器对请求处理后无需跳转到其它任何资源，此时处理器方法可定义为返回void。例如对Ajax异步请求的响应，此时需要使用HttpServletResponse将返回结果通过writer写出 返回对象(常用,适用于前后端分离)返回的对象不是作为逻辑视图出现的，而是作为直接在页面显示的数据出现的。常使用json格式返回，此时需要使用@ResponseBody注解于处理器方法上(将转换后的json数据放入到响应体中) 在spring配置文件中配置&lt;mvc:annotation-driven/&gt;：Object数据转为Json数据需要消息转换器HttpMessageConverter完成。转换器的开启需要由&lt;mvc:annotation-driven/&gt;完成 导入jackson相关的包：spring的转换器底层依赖了jackson将对象转为json数据 &lt;url-pattern&gt;解读： *.xxx：一般情况下SpringMVC的中央调度器DispatcherServlet的&lt;url-pattern&gt;常使用后辍匹配方式，如写为*.do、*.action或*.mvc /：此时中央调度器DispatcherServlet会拦截所有url，会将向静态资源(例如css、js、jpg、png等资源)的获取请求当作是一个普通的处理器请求。此时中央调度器会调用处理器映射器为其查找相应的处理器，这当然是找不到的。因此在这种情况下，所有的静态资源获取请求均会报404错误 SpringMVC静态资源处理： &lt;mvc:default-servlet-handler/&gt;：声明了&lt;mvc:default-servlet-handler/&gt;后SpringMVC框架会在容器中创建DefaultServletHttpRequestHandler处理器对象。它像一个检查员，会对进入DispatcherServlet的URL进行筛查。如果发现是静态资源的请求，就将该请求转由Web应用服务器默认的Servlet处理。一般的服务器都有默认的Servlet &lt;mvc:resources/&gt;：在Spring3.0版本后，Spring定义了专门用于处理静态资源访问请求的处理器ResourceHttpRequestHandler。并且添加了&lt;mvc:resources/&gt;标签，专门用于解决静态资源无法访问问题 123456&lt;!-- location：表示静态资源所在目录;目录不要使用/WEB-INF/及其子目录 mapping：表示对该资源的映射后的请求地址--&gt;&lt;mvc:resources mapping=\"/images/**\" location=\"/images/\"/&gt;&lt;mvc:resources mapping=\"/js/**\" location=\"/js/\"/&gt; 定义方式实现控制器： 介绍：实现接口Controller定义控制器是较老的办法。且一个控制器中只有一个方法，如果要多个方法则需要定义多个Controller；定义的方式比较麻烦 定义步骤： 自定义控制器实现Controller接口，实现handleRequest方法 123456789public class TestController implements Controller &#123; public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123; // 返回一个模型视图对象 ModelAndView mv = new ModelAndView(); mv.addObject(\"msg\",\"TestController\"); mv.setViewName(\"test\"); return mv; &#125;&#125; 在SpringMVC配置文件中注册bean 12&lt;!-- name对应请求路径,class对应处理请求的类 --&gt;&lt;bean name=\"/test\" class=\"com.xiong.controller.TestController\"/&gt; 结果跳转方式： ModelAndView：根据设置的view名称和视图解析器跳到指定的页面。页面：{视图解析器前缀} + viewName + {视图解析器后缀} ServletApi：通过设置ServletAPI，不需要视图解析器 通过HttpServletResponse进行输出：httpServletResponse.getWriter().println(&quot;Hello~~~&quot;); 通过HttpServletResponse实现重定向：httpServletResponse.sendRedirect(&quot;/index.jsp&quot;); 通过HttpServletResponse实现转发：httpServletRequest.getRequestDispatcher(&quot;/WEB-INF/jsp/test.jsp&quot;).forward(httpServletRequest, httpServletResponse); SpringMVC 不使用视图解析器： 1234567891011121314151617181920@Controllerpublic class TestController &#123; @RequestMapping(\"/test/t1\") public String test1()&#123; // 转发 return \"/index.jsp\"; &#125; @RequestMapping(\"/test/t2\") public String test2()&#123; // 转发二 return \"forward:/index.jsp\"; &#125; @RequestMapping(\"/test/t3\") public String test3()&#123; // 重定向 return \"redirect:/index.jsp\"; &#125;&#125; 使用视图解析器： 12345678910111213141516@Controllerpublic class TestController2 &#123; @RequestMapping(\"/test2/t1\") public String test1()&#123; //转发 return \"test\"; &#125; @RequestMapping(\"/test2/t2\") public String test2()&#123; // 重定向 return \"redirect:/index.jsp\"; // 重定向到另一个请求 // return \"redirect:hello.do\"; &#125;&#125; 数据接收： 提交域名称和处理方法参数不一致：使用@RequestParam 提交的是一个表单对象：要求提交的表单域和对象属性名一致 数据显示 通过ModelAndView： 12345678@RequestMapping(\"/hello\")public ModelAndView hello()&#123; // 返回一个模型视图对象 ModelAndView mv = new ModelAndView(); mv.addObject(\"msg\",\"hello\"); mv.setViewName(\"test\"); return mv;&#125; 通过ModelMap： 1234567@RequestMapping(\"/hello\")public String hello(ModelMap model)&#123; // 封装要显示到视图中的数据 // 相当于req.setAttribute(\"name\", \"sobxiong\"); model.addAttribute(\"name\", \"sobxiong\"); return \"hello\";&#125; 通过Model： 1234567@RequestMapping(\"/hello\")public String hello(Model model)&#123; // 封装要显示到视图中的数据 // 相当于req.setAttribute(\"name\", \"sobxiong\"); model.addAttribute(\"msg\", \"sobxiong\"); return \"test\";&#125; Model：只有寥寥几个方法，只适合用于储存数据，简化了对于Model对象的操作和理解ModelMap：继承了LinkedMap，除了实现了自身的一些方法，同样继承了LinkedMap的方法和特性ModelAndView：可以在储存数据的同时设置返回的逻辑视图，进行控制展示层的跳转 使用配置实现返回结果转换为json(不常见)： 1234567891011121314&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults=\"true\"&gt; &lt;bean class=\"org.springframework.http.converter.StringHttpMessageConverter\"&gt; &lt;constructor-arg value=\"UTF-8\"/&gt; &lt;/bean&gt; &lt;bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"objectMapper\"&gt; &lt;bean class=\"org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean\"&gt; &lt;property name=\"failOnEmptyBeans\" value=\"false\"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; jackson默认把时间转成timestamps形式 表单中enctype属性说明： application/x-www=form-urlencoded：默认方式，只处理表单域中的value属性值，采用这种编码方式的表单会将表单域中的值处理成URL编码方式 multipart/form-data：这种编码方式会以二进制流的方式来处理表单数据，这种编码方式会把文件域指定文件的内容也封装到请求参数中，不会对字符编码。 text/plain：除了把空格转换为’+’外，其他字符都不做编码处理，这种方式适用直接通过表单发送邮件 文件上传： 介绍：Servlet3.0规范提供方法来处理文件上传，但这种上传需要在Servlet中完成SpringMVC则提供了更简单的封装，为文件上传提供了直接的支持，这种支持是用即插即用的MultipartResolver实现的Spring MVC使用Apache Commons FileUpload技术实现了一个MultipartResolver实现类：CommonsMultipartResolver。因此，SpringMVC的文件上传还需要依赖Apache Commons FileUpload的组件SpringMVC上下文中默认没有装配MultipartResolver，因此默认情况下不能处理文件上传工作。如果想使用Spring的文件上传功能，则需要在上下文中配置MultipartResolver为了能上传文件，还必须将前端页面的表单method设置为POST，并将enctype设置为multipart/form-data。只有在这样的情况下，浏览器才会把用户选择的文件以二进制数据发送给服务器 使用步骤： 导入commons-fileupload和servlet-api依赖： 123456789101112&lt;!-- 文件上传 --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- servlet-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt;&lt;/dependency&gt; 配置bean：multipartResovler 12345678&lt;!-- 文件上传配置 --&gt;&lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt; &lt;!-- 请求的编码格式 --&gt; &lt;property name=\"defaultEncoding\" value=\"utf-8\"/&gt; &lt;!-- 上传文件大小上限,单位为字节(10485760=10M) --&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;property name=\"maxInMemorySize\" value=\"40960\"/&gt;&lt;/bean&gt; 编写处理器方法 123456789101112131415161718192021222324252627282930313233343536@RequestMapping(value = \"/upload.do\")@ResponseBodypublic String upload(@RequestParam(\"file\") CommonsMultipartFile file) &#123; // 获取文件名 String fileName = file.getOriginalFilename(); log.info(\"File name: &#123;&#125; , size: &#123;&#125;\", fileName, file.getSize()); // 如果文件大小为0或文件名为空,返回失败 if (file.getSize() == 0 || StringUtils.isEmpty(fileName)) &#123; return \"error\"; &#125; // 创建文件上传路径 File uploadDirectory = new File(\"/Users/sobxiong/Downloads\"); // 文件输入流 try (InputStream is = file.getInputStream(); OutputStream os = new FileOutputStream(new File(uploadDirectory, fileName))) &#123; int len; byte[] buffer = new byte[1024]; while ((len = is.read(buffer)) != -1) &#123; os.write(buffer, 0, len); os.flush(); &#125; &#125; catch (IOException e) &#123; log.error(\"IOException\", e); return \"error\"; &#125; // 方式2 /*try &#123; file.transferTo(Paths.get(\"/Users/sobxiong/Downloads/\" + fileName)); &#125; catch (IOException e) &#123; log.error(\"IOException\", e); return \"error\"; &#125;*/ return \"success\";&#125; CommonsMultipartFile的常用方法： String getOriginalFilename()：获取上传文件的原名 InputStream getInputStream()：获取文件流 void transferTo(File dest)：将上传文件保存到一个目录文件中 SpringMVC核心技术 请求转发和重定向： 介绍：当处理器对请求处理完毕后，向其它资源进行跳转时，有两种跳转方式：请求转发与重定向。根据所要跳转的资源类型，又可分为两类：跳转到页面与跳转到其它处理器 对于请求转发的页面，可以是WEB-INF中页面；而重定向的页面，不能为WEB-INF中页面。因为重定向相当于用户再次发出一次请求，而用户是不能直接访问WEB-INF中资源的 原理：SpringMVC框架把原来Servlet中的请求转发和重定向操作进行了封装。现在可以使用简单的方式实现转发和重定向： forward：表示转发，示例如下： request.getRequestDispatcher(&quot;xx.jsp&quot;).forward() redirect：表示重定向，示例如下： response.sendRedirect(&quot;xxx.jsp&quot;) 请求转发： 处理器方法返回ModelAndView时，可在setViewName()指定的视图前添加 “forward:”，此时视图不再与视图解析器一同工作，这样可在配置了解析器时指定不同位置的视图。视图页面必须写出相对于项目根的路径。forward操作不需要视图解析器 处理器方法返回String时，需在视图路径前面加入”forward:视图完整路径” 请求重定向(同请求转发,把forward替换为redirect) 异常处理： 介绍：SpringMVC框架常用@ExceptionHandler和@ControllerAdvice注解处理异常 @ExceptionHandler注解： 介绍：使用注解@ExceptionHandler可以将一个方法指定为异常处理方法。该注解只有一个可选属性value(Class&lt;?&gt;数组)，该属性用于指定该注解的方法所要处理的异常类(即需要匹配的异常)被注解的方法返回值可以是ModelAndView、String或void，方法名随意，方法参数可以是Exception及其子类对象、HttpServletRequest、HttpServletResponse等。系统会自动为这些参数赋值 使用步骤： 准备(自定义异常,自定义异常响应页面等) 在处理器方法上添加注解： 1234567@ExceptionHandler(value = Throwable.class)public ModelAndView doException(Throwable t) &#123; ModelAndView mv = new ModelAndView(); mv.addObject(\"exception\", t); mv.setViewName(\"error\"); return mv;&#125; 不过一般不这样使用，而是将异常处理方法专门定义在一个类中，作为全局的异常处理类 @ControllerAdvice注解： 介绍：ControllerAdvice字面意思就是”控制器增强”，用于给控制器对象增强功能。使用@ControllerAdvice注解修饰的类中可以使用@ExceptionHandler。当使用@RequestMapping注解修饰的方法抛出异常时，会执行@ControllerAdvice修饰的类中的对应异常处理方法@ControllerAdvice由@Component注解修饰，需要由包扫描组件支持 使用步骤： 添加启动包扫描和注册注解驱动的xml配置 定义全局异常处理类 123456789101112131415161718@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = Exception.class) public ModelAndView doException(Exception e) &#123; ModelAndView mv = new ModelAndView(); mv.addObject(\"exception\",e); mv.setViewName(\"error\"); return mv; &#125; @ExceptionHandler(value = ArithmeticException.class) public ModelAndView doArithmeticException(ArithmeticException e) &#123; ModelAndView mv = new ModelAndView(); mv.addObject(\"arithmeticException\",e); mv.setViewName(\"error\"); return mv; &#125;&#125; 拦截器 介绍：SpringMVC中的Interceptor拦截器非常重要，它的主要作用是拦截指定的用户请求，并进行相应的预处理与后处理。其拦截的时间节点在”处理器映射器根据用户提交的请求映射出了所要执行的处理器类,并且也找到了要执行该处理器类的处理器适配器,在处理器适配器执行处理器之前”。在处理器映射器映射出所要执行的处理器类时，已经将拦截器与处理器组合为了一个处理器执行链，并返回给了中央调度器 拦截器HandlerInterceptor： 介绍：自定义拦截器，需要实现HandlerInterceptor接口 接口方法介绍： preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)：该方法在处理器方法执行之前执行。其返回值为 boolean，若为true，则紧接着会执行处理器方法，且会将afterCompletion()方法放入到一个专门的方法栈中等待执行 postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)：该方法在处理器方法执行之后执行。处理器方法若最终未被执行，则该方法不会执行。由于该方法是在处理器方法执行完后执行，且该方法参数中包含ModelAndView，因此该方法可以修改处理器方法的处理结果数据，且可以修改跳转地址 afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)： 当preHandle()方法返回true时，会将该方法放到专门的方法栈中，等到对请求进行响应的所有工作完成之后才执行该方法。即该方法是在中央调度器渲染(数据填充)了响应页面之后执行的，此时对ModelAndView的操作也对响应没有影响。该方法是最后执行的方法，一般用于清除资源 使用步骤： 定义拦截器对象： 123456789101112131415161718@Slf4jpublic class MyInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; log.info(\"preHandle() ~~~\"); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; log.info(\"postHandle() ~~~\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; log.info(\"afterCompletion() ~~~\"); &#125;&#125; 注册拦截器 12345678910111213&lt;!-- 注册拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;!-- &lt;mvc:mapping&gt;：用于指定当前注册的拦截器可以拦截的请求路径,/**表示拦截所有请求,可以设置多个 /**包括路径及其自路径 /*只会拦截/xx而不会拦截/xx/xx --&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;bean class=\"com.xiong.springmvc.controller.MyInterceptor\"/&gt; &lt;/mvc:interceptor&gt; &lt;!-- &lt;mvc:interceptor&gt;可以设置多个 --&gt;&lt;/mvc:interceptors&gt;","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://sobxiong.github.io/tags/SpringMVC/"}]},{"title":"Data Structure","slug":"BasicSkill/DataStructure","date":"2020-12-03T14:38:55.000Z","updated":"2021-02-07T14:28:32.012Z","comments":true,"path":"2020/12/03/BasicSkill/DataStructure/","link":"","permalink":"https://sobxiong.github.io/2020/12/03/BasicSkill/DataStructure/","excerpt":"内容 并查集 Trie字典树 树状数组 平衡二叉查找树","text":"内容 并查集 Trie字典树 树状数组 平衡二叉查找树 并查集 介绍：并查集是一种树型的数据结构，用于处理一些不相交集合(Disjoint Sets)的合并及查询问题。常常在使用中以森林来表示 核心思想：用集合的一个元素代表集合 主要操作： 合并(Union)：把两个不相交的集合合并为一个集合 查询(Find)：查询两个元素是否在同一个集合 过程图示： 假设有六个元素，首先初始化(各自为战) 元素3与元素1合并 元素2与元素1合并 同理元素5、6和元素4合并 元素1与元素4合并 路径压缩：最原始的并查集效率是很低的，如果以最坏的情况合并，则会变成链表，查找最底部的元素的父元素需要花费O(n)时间既然只考虑一个元素对应的根节点而不是所有的祖先节点(每个元素到根节点的路径尽可能短)，那么最好的情况就是形成仅为两层的树 代码实现： 123456789101112131415161718192021222324252627282930#define N 20int unionSet[N];// 初始化,将元素的根元素设置为自身void init() &#123; for (int i = 0; i &lt; N; ++i) &#123; unionSet[i] = i; &#125;&#125;// 查询元素n的根元素int find_root(int n) &#123; // 下面逻辑的简化写法 return n == unionSet[n] ? n : (unionSet[n] = find_root(unionSet[n])); /** // 如果当前元素就是根元素,返回自身 if (unionSet[n] == n) return n; // 得到当前元素的根元素 int root = find_root(n); // 压缩路径(延迟压缩,只有在合并后的首次查询才进行),将当前查询链上的元素的根元素设置为root unionSet[n] = root; return root; **/&#125;// 合并元素n1、n2void union_elements(int n1, int n2) &#123; // 将n1元素的root值设置为n2元素的root值 unionSet[find_root(n1)] = find_root(n2);&#125; Trie字典树 介绍：又称单词查找树、Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计、排序和保存大量的字符串(但不仅限于字符串)，所以经常被搜索引擎系统用于文本词频统计。优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高 核心思想：空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的 三个基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串 每个节点的所有子节点包含的字符都不相同 基本操作：查找、插入和删除(删除较为少见) 举例：单词组：banana、band、bank、apple、apply、applet图示： 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 封装字典树节点数据结构class TrieNode &#123; private: // 是否为单词结尾字符的标记 bool wordTag = false; // 计数标记,用于删除 int countTag = 0; // 下层节点,26个指针的数组(a-z),并显式赋值为nullptr TrieNode *next[26] = &#123;nullptr&#125;; public: void insert(const string &amp;word) &#123; // 从头节点开始 TrieNode *cur = this; for (const char &amp;c : word) &#123; // 如果查找的字符节点为空则创建 if (!cur-&gt;next[c - 'a']) cur-&gt;next[c - 'a'] = new TrieNode; // 前往下一层节点,表示当前字符已满足 cur = cur-&gt;next[c - 'a']; // 技术标记增加 cur-&gt;countTag++; &#125; // 记录当前是单词结尾字符 cur-&gt;wordTag = true; &#125; bool search(const string &amp;word) &#123; // 从头节点开始 TrieNode *cur = this; for (const char &amp;c : word) &#123; // 如果查找的字符节点为空则返回false,查询不到 if (!cur-&gt;next[c - 'a']) return false; cur = cur-&gt;next[c - 'a']; &#125; // 返回当前节点是否为单词结尾 return cur-&gt;wordTag; &#125; bool searchPrefix(const string &amp;word) &#123; TrieNode *cur = this; for (const char &amp;c : word) &#123; if (!cur-&gt;next[c - 'a']) return false; cur = cur-&gt;next[c - 'a']; &#125; // 返回true,前缀无需关注是否为单词节点 return true; &#125;&#125;;// 具体测试TrieNode root;root.insert(\"banana\");root.insert(\"band\");root.insert(\"bank\");root.insert(\"apple\");root.insert(\"apply\");root.insert(\"applet\");cout &lt;&lt; root.search(\"banana\") &lt;&lt; endl;cout &lt;&lt; root.search(\"banan\") &lt;&lt; endl;cout &lt;&lt; root.searchPrefix(\"apply\") &lt;&lt; endl;cout &lt;&lt; root.search(\"apply\") &lt;&lt; endl;cout &lt;&lt; root.searchPrefix(\"appl\") &lt;&lt; endl;cout &lt;&lt; root.search(\"appl\") &lt;&lt; endl; 树状数组 介绍：树状数组是一个查询和修改复杂度都为logn的数据结构。主要用于数组的单点修改以及区间求和 背景问题：有一个数组a，下标从1到n。现在需要进行w次修改、q次查询，修改指修改数组中某一个元素的值；查询指查询数组中任意一个区间的和 问题分析：首先分析下朴素做法的时间复杂度，修改是O(1)的时间复杂度，而查询的话是O(n)的复杂度，总体时间复杂度为O(qn)；可能会想到使用前缀和来优化这个查询，此时查询的复杂度为O(1)，而修改时需要修改修改点之后的所有前缀和，因此修改的时间复杂度是O(n)，总体时间复杂度还是O(qn)。而树状数组的做法综合了这两种朴素方式，降低了整体时间复杂度 树状数组 lowbit函数 作用：求某个数的二进制表示中最低的一位1 代码表示：int lowbit(int x) return x &amp; -x; 原理： 核心思想：设原数组为a，节点值为A1～An，新开辟的数组为c，节点值为C1～Cn。每个节点不知管辖当前节点的值，而是管辖一个区域的数据。设节点编号为x，那么这个节点管辖的区间为2^k(其中k为x的二进制末尾0的个数)个元素。且区间最后一个元素必为Ax C1 = A1C2 = A1 + A2C3 = A3C4 = A1 + A2 +A3 + A4C5 = A5C6 = A5 + A6C7 = A7C8 = A1 + A2 + A3 + A4 + A5 + A6 + A7 + A8… \b关键操作 获取前缀和：通过二进制拆分获取所需下标。比如13的前缀和，13的二进制为1101，根据末尾的1获取数，每次抹去最后一个1。得到三个值1101(13,管辖2^0=1个数)、1100(12,管辖2^2=4个数)和1000(8,管辖2^3=8个数)，因此Sum(0~13) = C8 + C12 + C13。因此单次查询复杂度为O(logn) 单点修改：必须修改每个包含修改值的C元素，相当于查询的逆过程。以6为例，6的二进制值为0110，在末尾1处加1，得到1000(8)；再在末尾1处加1，得到10000(16)，完成，共需修改6、8、16处节点的值。因此单次修改复杂度也为O(logn) 实现代码： 1234567891011121314151617181920// 求某个数的二进制表示中最低的一位1int lowbit(int x) &#123; return x &amp; -x;&#125;// 查询1~x的前缀和int query(int x, vector&lt;int&gt; c) &#123; int ans = 0; while (x) &#123; ans += c[x]; x -= lowbit(x); &#125; return ans;&#125;// 对Ax原值基础上加上一个值vvoid add(int x, int v, vector&lt;int&gt; c) &#123; while (x &lt; c.size()) &#123; c[x] += v; x += lowbit(x); &#125;&#125; 扩展：区间修改 比如将C区间[3, 6]的每个数都加上5，只需对C3加5，C7减5，因为C[3, 6]被C3影响，而C7~Cn受到C7和C3的共同影响，结果不变 平衡二叉查找树 介绍：AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树 背景问题：二叉树最差查找节点的效率近似于单链表 核心操作： 插入 删除 删除共有4种情况 既有左孩子又有右孩子 只有左孩子 只有右孩子 叶子节点 自平衡 实现代码： \b数据结构： 1234567private class Node &#123; private final K key; private V value; private Node left, right, parent; private int nodeNum; private int depth;&#125; 插入操作： 123456789101112131415161718192021222324252627282930313233public void put(K key, V value) &#123; // 记录原始节点数 int nodeNum = root == null ? 0 : root.nodeNum; // 具体插入,统一有无根节点情况 root = put(root, key, value, root); // 如果是修改操作,无需进行自平衡 if (nodeNum == root.nodeNum) return; // 找到插入节点 Node putNode = findNode(root, key); // 平衡整棵树 balance(putNode);&#125;// 递归插入private Node put(Node node, K key, V value, Node parent) &#123; // 返回具体插入的节点 if (node == null) return new Node(key, value, parent); // 判断查找方向 int cmp = key.compareTo(node.key); // 更新节点值 if (cmp == 0) &#123; node.value = value; return node; &#125; // 向右插入 if (cmp &gt; 0) node.right = put(node.right, key, value, node); // 向左插入 else node.left = put(node.left, key, value, node); // 更新当前节点挂载的节点数 node.nodeNum = 1 + size(node.left) + size(node.right); // 返回当前节点 return node;&#125; 删除操作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public void delete(K key) &#123; assert size() &gt; 0; // 查找具体删除节点 Node delNode = findNode(root, key); if (delNode == null) return; // 删除节点并自平衡 balance(delete(delNode));&#125;/*** 删除指定节点** @param node 待删除节点* @return 替代节点*/private Node delete(Node node) &#123; Node parent = node.parent, temp; // 只有左孩子 if (node.left != null &amp;&amp; node.right == null) &#123; temp = node; // 指向左孩子 node = node.left; node.parent = temp.parent; // 更新当前节点高度信息 updateDepth(node); &#125; else if (node.left == null &amp;&amp; node.right != null) &#123; // 只有右孩子 temp = node; // 指向右孩子 node = node.right; node.parent = temp.parent; // 更新当前节点高度信息 updateDepth(node); &#125; else if (node.left == null) &#123; // 叶子结点 // 如果父节点存在 if (parent != null) &#123; // 更新父节点高度信息 updateDepth(parent); &#125; else &#123; // 删除根节点 root = null; &#125; &#125; else &#123; // 左右孩子均存在 // 找到替代元素 temp = min(node.right); // 更新值 node.value = temp.value; parent = temp.parent; updateDepth(parent); &#125; return parent;&#125; 自平衡操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/*** LR旋转：先左旋转再右旋转** @param node 离操作节点最近的失衡节点* @return 新父节点*/private Node LRRotate(Node node) &#123; RRRotate(node.left); return LLRotate(node);&#125;/*** LL旋转** @param node 离操作节点最近的失衡节点* @return 新父节点*/private Node LLRotate(Node node) &#123; // 获取失衡节点的父节点和左孩子 Node parent = node.parent, child = node.left; // 设置child右孩子的父指针 if (child.right != null) &#123; child.right.parent = node; &#125; // 失衡节点的做孩子变更为child的右孩子 node.left = child.right; // 更新失衡节点的高度信息 updateDepth(node); // 失衡节点变成child的右孩子 child.right = node; // 设置child的父节点为原失衡节点的父节点 child.parent = parent; // 如果失衡节点不是根,更新父节点 if (parent != null) &#123; // 指向更新后的新孩子child if (parent.left == node) parent.left = child; else parent.right = child; &#125; // 设置失衡节点的父亲 node.parent = child; // 更新child节点的高度信息 updateDepth(child); return child;&#125;/*** RL旋转：先右旋转再左旋转** @param node 离操作节点最近的失衡节点* @return 新父节点*/private Node RLRotate(Node node) &#123; LLRotate(node.right); return RRRotate(node);&#125;/*** RR旋转** @param node 离操作结点最近的失衡的结点* @return 新父节点*/private Node RRRotate(Node node) &#123; // 获取失衡节点的父节点和右孩子 Node parent = node.parent, child = node.right; // 设置child节点左孩子的父指针 if (child.left != null) child.left.parent = node; // 失衡节点的右孩子变更为child的左孩子 node.right = child.left; // 更新失衡节点的高度信息 updateDepth(node); // 失衡节点变成child的左孩子 child.left = node; // 设置child的父结点为原失衡节点的父结点 child.parent = parent; // 如果失衡节点不是根结点,更新父节点 if (parent != null) &#123; // 指向更新后的新孩子child if (parent.left == node) parent.left = child; else parent.right = child; &#125; // 设置失衡节点的父节点 node.parent = child; // 更新child结点的高度信息 updateDepth(child); return child;&#125;/*** AVL树调整** @param node 插入的节点*/private void balance(Node node) &#123; // 平衡因子 int balance; while (node != null) &#123; // 更新当前节点的高度信息 updateDepth(node); // 获取当前节点的平衡因子信息 balance = getBalance(node); // 不平衡 if (balance &gt; 1 || balance &lt; -1) &#123; // 左子树高 if (balance &gt; 1) &#123; // LL型 if (getBalance(node.left) &gt; 0) node = LLRotate(node); else node = LRRotate(node); // LR型 &#125; else &#123; // 右子树高 // RR型 if (getBalance(node.right) &lt; 0) node = RRRotate(node); else node = RLRotate(node); // RL型 &#125; // 判断是否到达根节点 if (node.parent == null) &#123; // 设置新的根节点 root = node; break; &#125; &#125; // 依次设置父节点 node = node.parent; &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"}]},{"title":"Spring基础","slug":"SpringSeries/Spring/Spring基础","date":"2020-12-03T10:29:41.000Z","updated":"2020-12-07T11:34:07.793Z","comments":true,"path":"2020/12/03/SpringSeries/Spring/Spring基础/","link":"","permalink":"https://sobxiong.github.io/2020/12/03/SpringSeries/Spring/Spring%E5%9F%BA%E7%A1%80/","excerpt":"内容 Spring概述 IOC控制反转 AOP面向切面编程 事务操作 Spring5新功能","text":"内容 Spring概述 IOC控制反转 AOP面向切面编程 事务操作 Spring5新功能 Spring概述 Spring是什么：Spring是于2003年兴起的一个轻量级的Java开发框架，是为了解决企业应用开发的复杂性而创建的。核心是控制反转(IoC)和面向切面编程(AOP) Spring的优点： 轻量：Spring框架使用的jar都比较小，核心功能的所需的jar总共在3M左右。框架运行占用的资源少，运行效率高。不依赖其他jar 解耦合：提供了Ioc控制反转，由容器管理对象和对象的依赖关系。原来在程序代码中的对象创建方式现在由容器完成。对象之间的依赖解耦合 AOP编程的支持 方便集成各种优秀框架 Spring体系结构：Spring由20多个模块组成，可以分为数据访问/集成(Data Access/Integration)、Web、面向切面编程(AOP, Aspects)、提供JVM的代理(Instrumentation)、消息发送(Messaging)、核心容器(Core Container)和测试(Test) IOC控制反转 Ioc介绍：控制反转(IoC, Inversion of Control)是一个概念、一种思想。指将传统上由程序代码直接操控的对象控制权交给容器，通过容器来实现对象的装配和管理。控制反转就是将对象控制权的转移，从程序代码本身反转到了外部容器。通过容器实现对象的创建、属性赋值、依赖的管理IoC的实现方式多种多样，当前比较流行的实现方式是依赖注入(DI)依赖：A类中含有B的实例，在A实例中调用B实例的方法完成功能，即类A对类B存在依赖依赖注入(DI, Dependency Injection)：指程序运行过程中若需要调用另一个对象协助时，无须在代码中创建被调用者，而是依赖于外部容器，由外部容器创建后传递给程序Spring使用依赖注入(DI)实现IoC。Spring的依赖注入对调用者与被调用者几乎没有任何要求，完全支持对象之间依赖关系的管理。Spring容器是一个超级工厂，负责创建、管理所有的Java对象，这些Java对象被称为Bean。Spring容器管理着容器中Bean之间的依赖关系 IOC实现基本介绍： IOC思想基于IOC容器实现，IOC容器底层就是对象工厂 Spring提供IOC容器实现的两种方式(两种接口)： BeanFactory：IOC容器的基本实现，是Spring内部的使用接口，不提供开发人员进行使用。加载配置文件时不会创建对象，在获取对象(使用)才去创建对象 ApplicationContext：BeanFactory接口的子接口，提供更多更强大的功能，一般由开发人员进行使用。加载配置文件时候就会把在配置文件对象进行创建 具体ApplicationContext容器创建方式： 基于xml：ApplicationContext context = new ClassPathXmlApplicationContext(&quot;chapter2/bean1.xml&quot;); 基于注解：ApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class); ApplicationContext容器对象的装配时机：在容器对象初始化时，将其中的所有对象一次性全部装配好。以后代码中使用到这些对象只需从内存中直接获取即可。执行效率较高，但内存占用较多 IOC管理Bean 什么是Bean管理： Spring创建对象 Spring注入属性 Bean管理的两种方式： 基于xml： 基础语法：&lt;bean id=&quot;user&quot; class=&quot;chapter1.User&quot;/&gt; bean标签用于实现对象的创建 常用属性有： id：唯一标识 class：类全路径(包类路径)，只能是类，不能是接口 默认通过反射调用无参构造器创建对象 指定多个配置文件： 多个配置文件中有一个总文件，总配置文件将各其它子文件通过&lt;import/&gt;引入。在Java代码中只需要使用总配置文件对容器进行初始化即可也可使用通配符，此时要求父配置文件名不能满足所能匹配的格式，否则将出现循环递归包含 属性注入方式： 通过setter注入(最常用)： 123456&lt;bean id=\"book\" class=\"chapter1.Book\"&gt; &lt;!-- bean对应类需要有对应的setter方法 --&gt; &lt;!-- 引用类型通过ref指定引用关系,ref值为某bean的id值 --&gt; &lt;property name=\"bName\" value=\"深入理解JVM\"/&gt; &lt;property name=\"bAuthor\" value=\"周志明\"/&gt;&lt;/bean&gt; 通过有参构造函数注入(一般不用)： 123456&lt;bean id=\"book\" class=\"chapter1.Book\"&gt; &lt;!-- bean对应类需要有对应的有参构造器 --&gt; &lt;!-- index指明对应构造器的第几个参数,从0开始,一般不用,顺序与构造器声明顺序一致 --&gt; &lt;constructor-arg name=\"bName\" value=\"深入理解JVM\"/&gt; &lt;constructor-arg name=\"bAuthor\" value=\"周志明\"/&gt;&lt;/bean&gt; 通过p名称空间注入(也是调用setter方法,方式不同,一般不用)： 12&lt;!-- 添加p名称空间 --&gt;&lt;bean id=\"book\" class=\"chapter1.Book\" p:bName=\"深入理解JVM\" p:bAuthor=\"周志明\"/&gt; 自动装配：根据指定装配规则(属性名称或者属性类型)，Spring自动将匹配的属性值进行注入 1234567891011121314&lt;!-- bean标签属性autowire配置自动装配,常用的两个配置： byName：根据属性名称注入,注入属性的bean的id值和属性名称一样 byType：根据属性类型注入(要么与属性类型相同,要么有继承或实现的关系,但同源的bean只能有一个,多于一个容器就不知道如何匹配)--&gt;&lt;bean id=\"employee\" class=\"chapter1.Employee\" autowire=\"byName/byType\"&gt; &lt;property name=\"name\" value=\"SOBXiong\"/&gt; &lt;property name=\"age\" value=\"23\"/&gt;&lt;/bean&gt;&lt;bean id=\"dept\" class=\"chapter1.Department\"&gt; &lt;property name=\"name\" value=\"独栋小别墅\"/&gt; &lt;property name=\"id\" value=\"90001\"/&gt;&lt;/bean&gt; 导入外部属性文件(properties文件)： 传统声明方式 123456&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/test\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"password\"/&gt;&lt;/bean&gt; 导入properties文件方式 1234prop.driverClass=com.mysql.jdbc.Driverprop.url=jdbc:mysql://localhost:3306/testprop.userName=rootprop.password=password 123456789&lt;!-- 引入外部属性文件(需要引入context名称空间) --&gt;&lt;context:property-placeholder location=\"classpath:jdbc.properties\"/&gt;&lt;!-- 数据库连接池配置(引入properties文件) --&gt;&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;prop.driverClass&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;prop.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;prop.userName&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;prop.password&#125;\"/&gt;&lt;/bean&gt; 注入属性类型： 字面量： null值 123&lt;property name=\"address1\"&gt; &lt;null/&gt;&lt;/property&gt; 属性值包含特殊字符 123456&lt;property name=\"address2\"&gt; &lt;!-- 使用&lt;![CDATA[]]转义 --&gt; &lt;value&gt;&lt;![CDATA[&lt;&lt;南京&gt;&gt;]]&gt;&lt;/value&gt; &lt;!-- 使用&amp;lt;/&amp;gt;代表'&lt;'和'&gt;' --&gt; &lt;!--&lt;value&gt;&amp;lt;&amp;lt;南京&amp;gt;&amp;gt;&lt;/value&gt;--&gt;&lt;/property&gt; 外部bean： 引用外部bean 12345678&lt;bean id=\"person\" class=\"chapter1.Person\"&gt; &lt;property name=\"name\" value=\"SOBXiong\"/&gt; &lt;property name=\"book\" ref=\"book1\"/&gt;&lt;/bean&gt;&lt;bean id=\"book1\" class=\"chapter1.Book\"&gt; &lt;property name=\"BName\" value=\"并发编程实战\"/&gt; &lt;property name=\"BAuthor\" value=\"Doug Li\"/&gt;&lt;/bean&gt; 内部bean赋值 123456789&lt;bean id=\"person\" class=\"chapter1.Person\"&gt; &lt;property name=\"name\" value=\"SOBXiong\"/&gt; &lt;property name=\"book\"&gt; &lt;bean class=\"chapter1.Book\"&gt; &lt;property name=\"BName\" value=\"并发编程实战\"/&gt; &lt;property name=\"BAuthor\" value=\"Doug Li\"/&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 级联赋值 12345678910&lt;!-- 引用设置重复属性会覆盖原来外部bean设置的属性值 --&gt;&lt;bean id=\"person\" class=\"chapter1.Person\"&gt; &lt;property name=\"name\" value=\"SOBXiong\"/&gt; &lt;property name=\"book\" ref=\"book1\"/&gt; &lt;property name=\"book.BAuthor\" value=\"Doug Li\"/&gt; &lt;property name=\"book.BName\" value=\"并发编程实战1\"/&gt;&lt;/bean&gt;&lt;bean id=\"book1\" class=\"chapter1.Book\"&gt; &lt;property name=\"BName\" value=\"并发编程实战\"/&gt;&lt;/bean&gt; 数组/集合类： 使用内置标签： 1234567891011121314151617181920212223242526272829303132333435&lt;!-- ref同理 --&gt;&lt;bean id=\"student\" class=\"chapter1.Student\"&gt; &lt;!-- 注入数组 --&gt; &lt;property name=\"arrayValue\"&gt; &lt;array&gt; &lt;value&gt;array01&lt;/value&gt; &lt;value&gt;array02&lt;/value&gt; &lt;value&gt;array03&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;!-- 注入List --&gt; &lt;property name=\"listValue\"&gt; &lt;list&gt; &lt;value&gt;list01&lt;/value&gt; &lt;value&gt;list02&lt;/value&gt; &lt;value&gt;list03&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 注入Map --&gt; &lt;property name=\"mapValue\"&gt; &lt;map&gt; &lt;entry key=\"mapKey01\" value=\"mapValue01\"/&gt; &lt;entry key=\"mapKey02\" value=\"mapValue02\"/&gt; &lt;entry key=\"mapKey03\" value=\"mapValue03\"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- 注入Set --&gt; &lt;property name=\"setValue\"&gt; &lt;set&gt; &lt;value&gt;setValue01&lt;/value&gt; &lt;value&gt;setValue02&lt;/value&gt; &lt;value&gt;setValue03&lt;/value&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt; 使用util名称空间 12345678910&lt;!-- 使用util标签注入list集合 --&gt;&lt;util:list id=\"testList\"&gt; &lt;value&gt;utilList01&lt;/value&gt; &lt;value&gt;utilList02&lt;/value&gt; &lt;value&gt;utilList03&lt;/value&gt;&lt;/util:list&gt;&lt;bean id=\"student1\" class=\"chapter1.Student\"&gt; &lt;property name=\"listValue\" ref=\"testList\"/&gt;&lt;/bean&gt; 基于注解： Spring针对Bean创建对象的注解类型(功能是一样的,名称只是规范和区别作用)： @Component @Service @Controller @Repository 基于注解方式实现对象创建(引入spring-aop依赖)： 开启组件扫描 xml方式： 123456&lt;!-- 1、可以使用多个context:component-scan标签指定不同的包路径 2、指定base-package的多个值可以使用分隔符(逗号、分号或空格均可,但不建议空格) 3、base-package代表指定到父包名,容器启动会扫描包及其子包中的注解--&gt;&lt;context:component-scan base-package=\"chapter2\"/&gt; 配置类注解(替代xml配置文件)方式： 123@Configuration // 作为配置类,替代xml@ComponentScan(basePackages = &#123;\"chapter2\"&#125;)public class SpringConfig &#123;&#125; 组件扫描规则设置： use-default-filters：是否使用默认filter(扫描@Component、@Service、@Controller、@Repository,默认true)，为true时不能和exclude-filter配合使用 include-filter：设置扫描哪些内容 exclude-filter：设置不扫描哪些内容 创建Bean类： 1234567// value属性值表示bean的id,可省略,默认是类名的首字母小写@Component(value = \"userService\")public class UserService &#123; public void method1() &#123; System.out.println(\"UserService method1() ~~~\"); &#125;&#125; 属性注入(注解在field字段上,无需setter)： @Autowired：根据属性类型进行自动装配(required属性可指定是否忽略注入失败,默认true) @Qualifier：根据名称进行注入，需要和@Autowired一起使用 @Resource：默认根据名称注入，可通过value和name属性指定注入规则(可以加到setter()上) @Value：注入普通类型属性，常量/配置文件中的值(可以加到setter()上) Bean的类型： 普通bean：在配置文件中定义的bean类型就是返回类型 工厂bean(FactoryBean)：在配置文件定义的bean类型可以和返回类型不一样 工厂bean创建的步骤： 自定义类实现接口FactoryBean，作为工厂bean 实现接口里面的方法，在实现的方法中定义返回的bean类型 在xml中定义 具体案例： 自定义工厂bean 12345678910111213public class TestBeanFactory implements FactoryBean&lt;Course&gt; &#123; // 返回Course对象 public Course getObject() throws Exception &#123; Course course = new Course(); course.setId(1L); course.setName(\"分布式系统\"); return course; &#125; public Class&lt;?&gt; getObjectType() &#123; return Course.class; &#125; public boolean isSingleton() &#123; return false; &#125;&#125; Spring的xml配置文件&lt;bean id=&quot;testBeanFactory&quot; class=&quot;chapter1.TestBeanFactory&quot;/&gt; Bean的作用域 Singleton：单实例，Spring默认的Bean作用域；加载Spring配置文件时就会创建单实例对象 Prototype：多实例，在调用getBean()方法时创建多实例对象 Bean的生命周期 生命周期介绍：从对象创建到销毁的过程 具体生命周期过程： 通过构造器创建bean实例(无参数构造) 为bean的属性设置值或对其他bean的引用(调用setter方法) 调用bean的初始化方法(需要配置初始化方法) bean使用(对象获取到并使用) 当容器关闭时候，调用bean的销毁的方法(需要配置销毁方法) 代码演示： xml配置如下 123&lt;bean id=\"order\" class=\"chapter1.Order\" init-method=\"initMethod\" destroy-method=\"destroyMethod\"&gt; &lt;property name=\"name\" value=\"testOrder\"/&gt;&lt;/bean&gt; Java代码如下 123456789101112131415161718192021222324252627282930class Order &#123; private String name; public Order() &#123; System.out.println(\"Order() ~~~\"); &#125; public void setName(String name) &#123; this.name = name; System.out.println(\"setName\"); &#125; public void initMethod() &#123; System.out.println(\"initMethod() ~~~\"); &#125; public void destroyMethod() &#123; System.out.println(\"destroyMethod() ~~~\"); &#125;&#125;@Testpublic void test4() &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"chapter1/bean3.xml\"); Order order = context.getBean(\"order\", Order.class); System.out.println(\"Get order bean ~~~\"); System.out.println(\"order = \" + order); // 显式关闭容器对象,让bean实例销毁,否则不会触发destroyMethod ((ClassPathXmlApplicationContext) context).close();&#125; 具体运行结果如下 123456Order() ~~~setNameinitMethod() ~~~Get order bean ~~~order = chapter1.Order@dd0c991destroyMethod() ~~~ Bean的后置处理器对Bean生命周期的影响： 通过构造器创建bean实例(无参数构造) 为bean的属性设置值或对其他bean的引用(调用setter方法) 将bean实例传递给bean的后置处理器，执行postProcessBeforeInitialization()方法 调用bean的初始化方法(需要配置初始化方法) 将bean实例传递给bean的后置处理器，执行postProcessAfterInitialization()方法 bean使用(对象获取到并使用) 当容器关闭时候，调用bean的销毁的方法(需要配置销毁方法) 代码演示(基于上个例子)：增加的xml配置如下&lt;bean id=&quot;testBeanPostProcessor&quot; class=&quot;chapter1.TestBeanPostProcessor&quot;/&gt;增加的java代码如下 1234567891011public class TestBeanPostProcessor implements BeanPostProcessor &#123; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(\"postProcessBeforeInitialization() ~~~ \" + beanName + \" , \" + bean); return bean; &#125; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(\"postProcessAfterInitialization() ~~~ \" + beanName + \" , \" + bean); return null; &#125;&#125; 具体运行结果如下 12345678Order() ~~~setNamepostProcessBeforeInitialization() ~~~ order , chapter1.Order@5609159binitMethod() ~~~postProcessAfterInitialization() ~~~ order , chapter1.Order@5609159bGet order bean ~~~order = chapter1.Order@5609159bdestroyMethod() ~~~ AOP面向切面编程 介绍：AOP(Aspect Oriented Programming)意为面向切面编程。利用AOP可以对业务逻辑的各个部分进行隔离，从而使业务逻辑各部分之间的耦合度降低，提高程序的可重用性，提高开发的效率。AOP可以将交叉业务逻辑封装成切面，利用将切面织入到主业务逻辑中。所谓交叉业务逻辑是指通用的、与主业务逻辑无关的代码，如安全检查、事务、日志、缓存等 底层原理：动态代理 存在接口：使用JDK动态代理(创建接口实现类代理对象,增强类的方法) 案例： 123456789101112131415161718192021/* 调用Proxy类的newProxyInstance()方法返回代理对象 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 参数解释如下： loader：类加载器 interfaces：增强方法所在的类实现的接口,支持多接口 InvocationHandler：创建代理对象,增强功能的主要逻辑*/@Testpublic void test1() &#123; UserDaoImpl impl = new UserDaoImpl(); UserDao userDao = (UserDao) Proxy.newProxyInstance(this.getClass().getClassLoader(), new Class[]&#123;UserDao.class&#125;, (proxy, method, args) -&gt; &#123; log.info(\"Before method: &#123;&#125; , args: &#123;&#125;\", method.getName(), Arrays.toString(args)); Object res = method.invoke(impl, args); log.info(\"After method return: &#123;&#125;\", res); return res; &#125;); userDao.add(5, 10); log.info(\"UserDao: &#123;&#125;\", userDao);&#125; 打印结果： 123452020-12-05 20:22:03.759 [main] INFO chapter3.ProxyTest - Before method: add , args: [5, 10]2020-12-05 20:22:03.762 [main] INFO chapter3.ProxyTest - After method return: 152020-12-05 20:22:03.763 [main] INFO chapter3.ProxyTest - Before method: toString , args: null2020-12-05 20:22:03.763 [main] INFO chapter3.ProxyTest - After method return: chapter3.UserDaoImpl@4b44655e2020-12-05 20:22:03.763 [main] INFO chapter3.ProxyTest - UserDao: chapter3.UserDaoImpl@4b44655e 不存在接口：使用Cglib动态代理(创建子类的代理对象,增强类的方法) AOP中的术语： 连接点：指可以被切面织入的具体方法。通常业务接口中的方法均为连接点 切入点：指声明的一个或多个连接点的集合。被标记为final的方法不能作为连接点与切入点 通知(增强)：表示切面的执行时间，也叫增强。通知定义了增强代码切入到目标代码的时间点。通知类型不同，切入时间不同。切入点定义切入的位置，通知定义切入的时间 切面：切面泛指交叉业务逻辑。实际就是对主业务逻辑的一种增强 目标对象：指将要被增强的对象。即包含主业务逻辑的类的对象 Spring中使用AOP 基本介绍：Spring底层使用到AspectJ实现AOP功能。Spring框架一般也是基于AspectJ提供AOP功能 相关依赖：Spring-aspects(包含aspectj) 切入点表达式： 作用：对哪个类的那个方法进行增强 语法结构： 1execution(modifiers-pattern? ret-type-pattern declaring-type-pattern?name-pattern(param-pattern) throws-pattern?) modifiers-pattern：访问权限类型ret-type-pattern：返回值类型declaring-type-pattern：包名类名name-pattern(param-pattern)：方法名(参数类型和参数个数)throws-pattern：抛出异常类型‘?’表示可选的部分总体可表示为：execution(访问权限 方法返回值 方法声明(参数) 异常类型) 涉及到的符号解释： 符号 意义 * 0至多个任意字符 .. 用在方法参数中表示任意多个参数;用在包名后表示当前包及其子包路径 + 用在类名后表示当前类及其子类;用在接口后表示当前接口及其实类 具体例子：execution(* com.xiong.dao.DocService.*(..)) 具体使用： 在业务类上声明@Component注解让其加入Spring容器 创建增强类(编写增强逻辑) 声明@Component加入Spring容器 声明@Aspect需要生成代理对象 配置不同类型的通知(使用切入点表达式) 可选项，有多个增强类对同一个方法进行增强时可以声明@Order(int priority)设置增强类优先级，数值类型越小优先级越高 注解配置切入点案例如下： 123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@Component@Aspectclass UserProxy &#123; // 前置通知,可有JoinPoint参数 @Before(value = \"execution(* chapter3.User.add(..))\") public void methodBefore() &#123; log.info(\"UserProxy methodBefore() ~~~\"); &#125; // 后置通知(返回通知),注解中有returning属性用于接受目标方法返回值 @AfterReturning(value = \"execution(* chapter3.User.add(..))\") public void methodAfterReturning() &#123; log.info(\"UserProxy methodAfterReturning() ~~~\"); &#125; // 最终通知 @After(value = \"execution(* chapter3.User.add(..))\") public void methodAfter() &#123; log.info(\"UserProxy methodAfter() ~~~\"); &#125; // 异常通知,注解中有throwing属性用于接受抛出的异常 @AfterThrowing(value = \"execution(* chapter3.User.add(..))\") public void methodAfterThrowing() &#123; log.info(\"UserProxy methodAfterThrowing() ~~~\"); &#125; // 环绕通知 @Around(value = \"execution(* chapter3.User.add(..))\") public Object methodAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; log.info(\"UserProxy methodAround() ~~~\"); log.info(\"Before jointPoint invoke ~~~\"); // 被增强的方法执行 Object ans = proceedingJoinPoint.proceed(); log.info(\"After jointPoint invoke ~~~\"); return ans; &#125;&#125; 抽取相同的切入点进行化简： 12345678// 抽取相同的切入点@Pointcut(value = \"execution(* chapter3.User.add(..))\")public void pointcutMethod() &#123;&#125;@Before(value = \"pointcutMethod()\")public void pointcutBefore() &#123; log.info(\"UserProxy pointcutBefore() ~~~\");&#125; xml配置切入点案例如下： 12345678910&lt;!-- 配置aop增强 --&gt;&lt;aop:config&gt; &lt;!-- 配置切入点 --&gt; &lt;aop:pointcut id=\"pointcut\" expression=\"execution(* chapter3.Book.buy())\"/&gt; &lt;!-- 配置切面 --&gt; &lt;aop:aspect ref=\"bookProxy\"&gt; &lt;!-- 增强作用在具体的方法上 --&gt; &lt;aop:before method=\"beforeMethod\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 配置Spring环境(xml/注解) 基于xml： 1234&lt;!-- 开启组件自动扫描 --&gt;&lt;context:component-scan base-package=\"chapter3\"/&gt;&lt;!-- 开启Aspect生成代理对象 --&gt;&lt;aop:aspectj-autoproxy/&gt; 基于注解： 1234@Configuration@ComponentScan(basePackages = &#123;\"chapter3\"&#125;)@EnableAspectJAutoProxy(proxyTargetClass = true)public class AspectConfig &#123;&#125; 事务操作 基础介绍：事务是数据库中的概念(一组操作要么全部成功,要么全部失败)，在Dao层，但一般将事务提升到Service业务层 四个特性(ACID)：原子性、一致性、隔离性、持久性 Spring中的事务管理： 编程式事务管理 123456789try &#123; transaction.begin(); doSomething();&#125;catch (Exception e)&#123; doSomethingAfterException(e); transaction.rollback();&#125;finally &#123; transaction.commit();&#125; 声明式事务管理 推荐使用，底层使用AOP Spring事务管理类： 基类为PlatformTransactionManager接口，定义了事务的提交、回滚以及获取事务的状态信息操作 两个常用的实现类： DataSourceTransactionManager：使用JDBC或MyBatis进行数据库操作时使用 HibernateTransactionManager：使用Hibernate(JPA)进行持久化数据时使用 Spring的回滚方式：默认发生运行时异常和error时回滚，发生受查(编译)异常时提交。对于受查异常也可以手工设置其回滚方式 Throwable类是Java语言中所有错误或异常的超类。只有当对象是此类(或其子类之一)的实例时，才能通过Java虚拟机或者throw语句抛出Error是程序在运行过程中出现的无法处理的错误，比如OutOfMemoryError、ThreadDeath、NoSuchMethodError等。当这些错误发生时，程序是无法处理(捕获或抛出)的，JVM一般会终止线程程序在编译和运行时出现的另一类错误称之为异常，它是JVM通知程序员的一种方式。通过这种方式，让程序员知道已经或可能出现错误，要求程序员对其进行处理。异常分为运行时异常与受查异常：运行时异常，是RuntimeException类或其子类，即只有在运行时才出现的异常。如NullPointerException、ArrayIndexOutOfBoundsException、IllegalArgumentException等均属于运行时异常。这些异常由JVM抛出，在编译时不要求必须处理(捕获或抛出)。只要代码编写足够仔细，程序足够健壮，运行时异常是可以避免的受查异常，也叫编译时异常(即在代码编写时要求必须捕获或抛出的异常)。若不处理，则无法通过编译。如SQLException、ClassNotFoundException和IOException等都属于受查异常RuntimeException及其子类以外的异常均属于受查异常。自定义的Exception的子类(即用户自定义的异常)也属受查异常。在定义异常时，只要未明确声明定义的为RuntimeException的子类，那么定义的就是受查异常 事务管理操作步骤： 声明需要事务操作的方法/类： 基于注解方式(声明@Transactional注解)： @Transactional用在方法上：只能用于public方法上。对于其他非public方法，如果声明了注解@Transactional，虽然Spring不会报错，但不会将指定事务织入到该方法中。Spring会忽略掉所有非public方法上的@Transaction注解@Transactional用在在类上：则表示该类上所有的方法均将在执行时织入事务 123456@Transactional(propagation = Propagation.REQUIRED, rollbackFor = Throwable.class)public void transferAccount(String fromUsername, String toUsername, Double money) &#123; accountDao.reduceMoney(fromUsername, money); // int i = 10 / 0; accountDao.addMoney(toUsername, money);&#125; 基于xml配置方式： 配置通知： 1234567&lt;!-- 配置通知 --&gt;&lt;tx:advice id=\"txadvice\"&gt; &lt;!-- 配置事务参数 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"transferAccount\" propagation=\"REQUIRED\"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 配置切入点和切面： 1234567&lt;!-- 配置事务切入点和切面 --&gt;&lt;aop:config&gt; &lt;!-- 配置切入点 --&gt; &lt;aop:pointcut id=\"pt\" expression=\"execution(* chapter5.AccountService.*(..))\"/&gt; &lt;!-- 配置切面 --&gt; &lt;aop:advisor advice-ref=\"txadvice\" pointcut-ref=\"pt\"/&gt;&lt;/aop:config&gt; 配置事务管理器 基于注解方式(此方式只支持注解方式声明)： 123456789101112131415161718192021222324252627282930313233@Configuration // 配置类@ComponentScan(basePackages = \"chapter5\") // 配置包扫描@EnableTransactionManagement // 开启事务public class SpringAnnoConfig &#123; // 创建数据库连接池 @Bean public DruidDataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///test\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"password\"); return dataSource; &#125; // 创建JdbcTemplate对象 @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource) &#123; // 会在ioc容器中根据类型找到dataSource JdbcTemplate jdbcTemplate = new JdbcTemplate(); // 注入dataSource jdbcTemplate.setDataSource(dataSource); return jdbcTemplate; &#125; // 创建事务管理器 @Bean public DataSourceTransactionManager transactionManager(DataSource dataSource) &#123; DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(); transactionManager.setDataSource(dataSource); return transactionManager; &#125;&#125; 基于xml方式(是否声明支持注解根据声明事务的方式) 配置基于注解的声明方式： 123456789&lt;!-- 事务管理器tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 注入dataSource --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt;&lt;!-- 开启事务注解,需要引入tx命名空间 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt;&lt;!-- 开始包扫描 --&gt;&lt;context:component-scan base-package=\"chapter5\"/&gt; 配置基于配置的声明方式： 12345&lt;!-- 事务管理器tx --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 注入dataSource --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt; 事务注解相关属性介绍： propagation：事务传播行为(处于不同事务中的方法在相互调用时,执行期间事务的维护情况)，默认REQUIRED 传播属性 描述 PROPAGATION_REQUIRED Spring默认的事务传播行为;如果存在当前事务则用当前事务;否则就新建一个事务 PROPAGATION_REQUIRES_NEW 如果当前存在事务把当前事务挂起,开启一个新事务,新事务执行完毕后唤醒之前挂起的事务继续执行。如果不存在当前事务则新建一个事务 PROPAGATION_SUPPORTS 支持当前事务,如果当前没有事务就以非事务方式执行 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作,如果当前存在事务就把当前事务挂起 PROPAGATION_MANDATORY 支持当前事务,如果当前没有事务就抛出异常 PROPAGATION_NEVER 以非事务方式执行,如果当前存在事务则抛出异常 PROPAGATION_NESTED 如果当前存在事务则在当前事务的嵌套事务内执行。否则启动一个新的事务并在自己的事务内运行 ioslation：事务隔离级别，默认DEFAULT 存在三种读问题： 读问题 描述 脏读 一个未提交事务读取到另一个未提交事务的数据 不可重复读 一个未提交事务读取到另一提交事务修改数据 幻读 一个未提交事务读取到另一提交事务添加数据 提供的四种隔离级别： 隔离级别 脏读 不可重复读 幻读 DEFAULT 采用数据库默认的事务隔离级别 \\ \\ READ_UNCOMMITTED(读未提交) 有 有 有 READ_COMMITTED(读已提交) 无 有 有 REPEATABLE_READ(可重复读) 无 无 有 SERIALIZABLE(串行化) 无 无 无 MySQL默认隔离级别为REPEATABLE_READ,Oracle默认为READ_COMMITTED timeout：用于设置本操作与数据库连接的超时时限 单位为秒，默认-1(即没有时限) readOnly：用于设置该方法对数据库的操作是否是只读的，默认false rollbackFor：指定需要回滚的异常类 类型为Class[]，默认值为空数组。若只有一个异常类时，可以不使用数组 rollbackForClassName：指定需要回滚的异常类类名 类型为String[]，默认值为空数组。若只有一个异常类时，可以不使用数组 noRollbackFor：指定不需要回滚的异常类 noRollbackForClassName：指定不需要回滚的异常类类名 Spring5新功能","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://sobxiong.github.io/tags/Spring/"}]},{"title":"SpringCloud基础","slug":"SpringSeries/SpringCloud/SpringCloud基础","date":"2020-11-18T11:03:17.000Z","updated":"2020-11-21T11:25:08.189Z","comments":true,"path":"2020/11/18/SpringSeries/SpringCloud/SpringCloud基础/","link":"","permalink":"https://sobxiong.github.io/2020/11/18/SpringSeries/SpringCloud/SpringCloud%E5%9F%BA%E7%A1%80/","excerpt":"内容 SpringCloud概述 Eureka注册中心介绍 Eureka停更后的替换组件 Ribbon负载均衡介绍","text":"内容 SpringCloud概述 Eureka注册中心介绍 Eureka停更后的替换组件 Ribbon负载均衡介绍 SpringCloud概述 微服务是什么：微服务架构下的一整套解决方案 SpringCloud是什么：分布式微服务架构的一站式解决方案，是多种微服务架构落地技术的集合体，俗称微服务全家桶 SpringCloud版本SpringCloud采用英国伦敦地铁站的名称来命名，并由地铁站名称字母A-Z依此类推的形式发布迭代版本SpringCloud是由许多子项目组成的综合项目，各子项目有不同的发布节奏，为了管理SpringCloud与各子项目的版本依赖关系，发布了一个清单，其中包括了某个SpringCloud版对应的子项目版本。为了避免SpringCloud版本号与子项目版本号混淆，SpringCloud版采用了名称而非版本号命名，例如Angel、Brixton。当SpringCloud的发布内容积累到临界点或者一个重大BUG被解决后，会发布一个Service releases版本，俗称SRX版本，比如Greenwich.SR2就是SpringCloud发布的Greenwich版本的第二个SRX版本 SpringBoot和SpringCloud的版本约束SpringBoot和SpringCloud的版本选择也不是任意的，而是应该参考官网的约束配置地址：https://spring.io/projects/spring-cloud#overview版本对应：https://start.spring.io/actuator/info SpringCloud各种组件的停更/升级/替换 停更的具体形式： 被动修复Bugs 不再接受合并请求 不再发布新版本 组件具体明细条目 服务调用 Eureka Zookeeper Consul Nacos(推荐) 服务调用 Feign OpenFeign(推荐) Ribbon LoadBalancer 服务降级 Hystrix resilience4j sentienl(推荐) 服务网关 Zuul Zuul2 Gateway(推荐) 服务配置 Config Nacos(推荐) 服务总线 Bus Nacos(推荐) SpringCloud资料官网文档：https://spring.io/projects/spring-cloud#learnSpringCloud中文文档：https://www.bookstack.cn/read/spring-cloud-docs/docs-index.md Eureka注册中心介绍 Eureka基础知识： 什么是服务注册？Eureka Server作为服务注册功能的服务器，它是服务注册中心，而系统中其他微服务，使用Eureka客户端连接到Eureka Server并维持心跳连接，这样系统维护人员就可以通过 Eureka Server来监控各个微服务是否正常运行在服务注册与发现中有一个注册中心，服务器启动时，会把当前自己的服务器信息比如服务地址、通信地址等注册到注册中心上，另一方(消费者)以别名的方式在注册中心上获取实际的服务器通讯地址，然后再实现本地RPC调用远程RPC Eureka的两个组件 Eureka Server：提供服务注册服务。各个微服务节点通过配置启动后，会在 Eureka Server中进行注册，这样Eureka Server中的服务注册表中将会存储所有可用服务节点的信息 Eureka Client：通过注册中心进行访问。是一个Java客户端，用于简化与Eureka Server的交互，客户端也同时具备一个内置的、使用轮询负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳(默认周期30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中将这个服务节点移除(默认90秒) Eureka工作原理： 服务注册：将服务信息注册进注册中心 服务发现：从注册中心上获取服务信息 实质：存key服务命名，取value调用地址 单机Eureka Server搭建(小口诀：建module,改pom,写yml,主启动)： 导入依赖： 12345&lt;!-- eureka server --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 修改yml配置文件： 1234567891011121314server: port: 7001eureka: instance: # eureka服务端实例名称 hostname: localhost client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己就是注册中心,职责是维护服务实例,并不需要去检索服务 fetch-registry: false service-url: # 设置与eureka server交互的地址;查询服务和注册服务都需要依赖这个地址 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 启动类上添加注解声明启动Eureka服务端 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServer7001Application &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer7001Application.class, args); &#125;&#125; 测试(看到eureka服务页面)：http://localhost:7001/ Eureka Client搭建： 导入依赖： 12345&lt;!-- eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 修改yml配置文件： 1234567891011server: port: 8001eureka: client: # 表示是否将自己注册进Eureka Server,默认为true register-with-eureka: true # 是否从EurekaServer抓取已有的注册信息,默认为true; # 单节点无所谓,集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: false service-url: defaultZone: http://localhost:7001/eureka 启动类上添加注解声明启动Eureka客户端 1234567@SpringBootApplication@EnableEurekaClientpublic class ProviderPayment8001Application &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer7001Application.class, args); &#125;&#125; 测试：http://localhost:7001/ 可以看到Instances中包含服务提供方 集群Eureka配置 \b背景：微服务RPC远程调用最核心就是高可用。假设注册中心只有一个，如果出现了故障，那么将会导致整个微服务不可用，所以需要搭建Eureka注册中心集群，实现负载均衡和故障容错 集群原理：相互注册、相互守望 前提：由于hostname不能重复，在本地hosts修改映射，将eureka7001.com、eureka7002.com都映射到localhost上 具体步骤： Eureka Server修改yml配置： EurekaServer7001配置 1234567891011121314server: port: 7001eureka: instance: # eureka服务端实例名称 hostname: eureka7001.com client: # 表示不向注册中心注册自己 register-with-eureka: false # false表示自己就是注册中心,职责就是维护服务实例,无需检索服务 fetch-registry: false service-url: # 向另外的eureka服务注册,如果多个用,隔开 defaultZone: http://eureka7002.com:7002/eureka/ EurekaServer7002配置 1234567891011121314server: port: 7002eureka: instance: # eureka服务端实例名称 hostname: eureka7002.com client: # 表示不向注册中心注册自己 register-with-eureka: false # false表示自己就是注册中心,职责就是维护服务实例,无需检索服务 fetch-registry: false service-url: # 向另外的eureka服务注册, defaultZone: http://eureka7001.com:7001/eureka/ 测试：http://eureka7001.com:7001、http://eureka7002.com:7002 分别发现另一方成为各自的DS Replicas Eureka Client集群(服务)注册进Eureka集群 背景：假设有两个微服务payment8001和payment8002需要注册进上面的Eureka集群 具体步骤： Eureka Client集群(服务)修改yml配置： Payment8001配置 1234567891011121314151617181920212223server: port: 8001spring: application: # 服务名称,为了保证服务对外暴露的是同一个服务提供者,服务名要保持一致 name: provider-paymenteureka: client: # 表示向注册中心注册自己,默认为true register-with-eureka: true # 是否从EurekaServer抓取已有的注册信息,默认为true # 单节点无所谓,集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 入驻地址,向eurekaServer注册,多个地址用','分割 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: # 设置实例编号,用于区分 instance-id: provider-payment-8001 # 是否显示ip prefer-ip-address: true Payment8002配置 1234567891011121314151617181920212223server: port: 8002spring: application: # 服务名称,为了保证服务对外暴露的是同一个服务提供者,服务名要保持一致 name: provider-paymenteureka: client: # 表示向注册中心注册自己,默认为true register-with-eureka: true # 是否从EurekaServer抓取已有的注册信息,默认为true # 单节点无所谓,集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 入驻地址,向eurekaServer注册,多个地址用','分割 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: # 设置实例编号,用于区分 instance-id: provider-payment-8001 # 是否显示ip prefer-ip-address: true 测试：http://eureka7001.com:7001 发现PAYMENT-SERVICE中两个服务提供者，分别为8001和8002 调用服务提供者 背景：上述工作完成了服务提供者payment-provider集群注册进eureka集群中，此时需要有一个消费者微服务调用服务 具体步骤： 导入依赖： 12345&lt;!-- eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 编写yml： 1234567891011121314151617server: port: 80spring: application: name: consumer-order-80eureka: client: # 将自己注册进EurekaServer,默认为true register-with-eureka: true # 从EurekaServer抓取已有的注册信息,默认为true # 单节点无所谓,集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # defaultZone: http://eureka7001.com:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 主启动： 1234567@SpringBootApplication@EnableEurekaClientpublic class ConsumerOrder80Application &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerOrder80Application.class, args); &#125;&#125; 设置RestTemplate的负载均衡策略： 12345678@Configurationpublic class ApplicationContextConfig &#123; @Bean // 赋予RestTemplate负载均衡能力 // 这是Ribbon的功能,Eureka默认自带Ribbon @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 具体消费端Controller： 1234567891011121314151617181920212223@RestController@Slf4j@RequestMapping(\"/order\")public class OrderController &#123; // 服务提供方的具体服务名,由eureka负责解析 public static final String PAYMENT_URL = \"http://PROVIDER-PAYMENT/payment\"; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancer loadBalancer; @GetMapping(\"/payment/add\") public Result add(Payment payment) &#123; return restTemplate.postForObject(PAYMENT_URL + \"/add\", payment, Result.class); &#125; @GetMapping(\"/payment/get/&#123;id&#125;\") public Result getById(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(PAYMENT_URL + \"/get/\" + id, Result.class); &#125;&#125; 测试：http://localhost/order/payment/get/1 actuator微服务信息完善 需要导入的依赖： 12345678910&lt;!-- web启动器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 监控 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 查看健康信息：http://hostname:port/actuator/health 设置微服务显示名称和ip显示 123456Erueka: instance: # 服务名称 instance-id: payment8001 # 访问路径显示IP地址 prefer-ip-address: true 服务发现Discovery 作用：可以通过服务发现获取注册进eureka的微服务的信息 相关类： @EnableDiscoveryClient DiscoveryClient 具体API： 获取列表：List&lt;String&gt; services = discoveryClient.getServices(); 获取实例：List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;PAYMENT-SERVICE&quot;); 获取ServiceId：serviceInstance.getServiceId(); 获取端口号：serviceInstance.getPort(); 获取URL：serviceInstance.getURL(); 具体步骤： 在payment8001的controller中添加代码： 1234567891011121314@Autowiredprivate DiscoveryClient discoveryClient;@GetMapping(\"/discovery\")public Result discovery() &#123; List&lt;String&gt; services = discoveryClient.getServices(); for (String service : services) &#123; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(service); for (ServiceInstance instance : instances) &#123; log.info(\"ServiceId: &#123;&#125; , host: &#123;&#125; , port: &#123;&#125; , uri: &#123;&#125;\", instance.getServiceId(), instance.getHost(), instance.getPort(), instance.getUri()); &#125; &#125; return new Result(200, \"查询成功~~~\", discoveryClient);&#125; 测试：http://localhost:8001/payment/discovery 控制台输出如下 122020-11-19 19:16:39.535 INFO 4394 --- [nio-8001-exec-9] c.x.cloud.controller.PaymentController : ServiceId: PROVIDER-PAYMENT , host: 10.21.176.180 , port: 8001 , uri: http://10.21.176.180:80012020-11-19 19:16:39.535 INFO 4394 --- [nio-8001-exec-9] c.x.cloud.controller.PaymentController : ServiceId: PROVIDER-PAYMENT , host: 10.21.176.180 , port: 8002 , uri: http://10.21.176.180:8002 返回json结果如下 123456789101112131415&#123; \"resultCode\": 200, \"resultMessage\": \"查询成功~~~\", \"resultData\": &#123; \"discoveryClients\": [&#123; \"order\": 0, \"services\": [\"provider-payment\"] &#125;, &#123; \"order\": 0, \"services\": [] &#125;], \"services\": [\"provider-payment\"], \"order\": 0 &#125;&#125; Eureka自我保护机制 概念：保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表的信息，不再删除服务注册表中的数据，也就是不会注销任何微服务如果在Eureka Server的首页看到以下这段提示，说明Eureka进入了保护模式通俗的话来说：某时刻某一个微服务不可用了，Eureka不会立刻清理，依旧会对该微服务的信息进行保存。这属于CAP里面的AP分支 导致原因：默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例，默认为90秒。但当网络分区故障发生(延时、卡顿、拥挤)时，微服务与Eureka Server之间无法正常通信，以上行为可能变得非常危险了————因为微服务本身其实是健康的，此时不应该注销这个微服务。Eureka通过自我保护模式来解决这个问题，当Eureka Server节点在短时间丢失过多客户端，那么这个节点就会进入自我保护模式，这是一种高可用的机制在自我保护模式下，Eureka Server会保护服务注册表中的信息，不在注销任何服务实例综上，自我保护模式是一种应对网络异常的安全保护措施，它的架构哲学是宁可保留所有微服务，也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加健壮，稳定 禁止自我保护(Eureka默认开启自我保护)： Eureka服务端设置： 123456eureka: server: # 关闭自我保护机制 enable-self-preservation: false # 心跳时间默认90s,改为2000ms,即2s eviction-interval-timer-in-ms: 2000 Eureka客户端设置 123456eureka: instance: # Eureka客户端向服务端发送心跳的时间间隔,单位为秒,默认30秒 lease-renewal-interval-in-seconds: 1 # Eureka服务端在收到最后一次心跳后等待时间上限,单位为秒,默认90秒,超时将剔除服务 lease-expiration-duration-in-seconds: 2 设置完成后，只要服务宕机，会马上从服务注册列表中清楚 Eureka停更之后的替代者： Zookeeper Consul Nacos Eureka停更后的替换组件 Zookeeper Zookeeper介绍：一个分布式协调工具，可以实现注册中心功能 注册服务进Zookeeper： 引入pom依赖： 123456789101112131415161718&lt;!-- SpringBoot整合zookeeper客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!-- 先排除自带的zookeeper3.5.3 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 添加zookeeper3.6.2版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.6.2&lt;/version&gt;&lt;/dependency&gt; 修改yml配置文件： 1234567891011server: port: 8004spring: application: # 服务别名——注册进zookeeper注册中心的服务名 # 多个服务实例要设置同一个服务别名 name: provider-payment cloud: zookeeper: connect-string: test1:2181 修改主启动类： 12345678@SpringBootApplication// 该注解用于向使用consul或者zookeeper作为注册中心时注册服务@EnableDiscoveryClientpublic class ProviderPayment8004Application &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderPayment8004Application.class, args); &#125;&#125; 思考：服务已经成功注册到Zookeeper客户端，那么注册上去的节点为临时节点还是持久节点？首先Eureka有自我保护机制，也就是某个服务下线后，不会立刻清除该服务，而是将服务保留一段时间Zookeeper一样在服务下线后也会等待一段时间，之后才会把该节点删除，这就说明Zookeeper上的节点是临时节点 Consul Consul介绍 简介：Consul是一套开源的分布式服务发现和配置管理系统，由HashiCorp公司用Go语言开发提供了微服务系统中的服务治理、配置中心、控制总线等功能，这些功能中的每一个都可以根据需要单独使用，也可以一起使用构建全方位的服务网路，总之Consul提供了一种完整的服务网络解决方案具有很多优点，包括：基于raft协议，比较简洁；支持健康检查；同时支持HTTP和DNS协议；支持跨数据中心的WAN集群；提供图形化界面；跨平台，支持Linux、MAC、Windows 官网：https://www.consul.io/ 功能： 服务发现：提供HTTP和DNS两种发现方式 健康监测：支持多种方法，HTTP，TCP，Docker，Shell脚本定制化 KV存储：Key，Value的存储方式 多数据中心：Consul支持多数据中心 可视化Web界面 安装： 官网下载(可执行文件) 查看版本：consul --version 运行：consul agent -dev 测试：访问http://test1:8500进入consul可视化界面 注册服务进Consul： 引入pom依赖： 12345&lt;!-- consul --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 修改yml配置文件： 1234567891011server: port: 8006spring: application: name: provider-payment cloud: consul: host: test1 port: 8500 discovery: service-name: $&#123;spring.application.name&#125; 测试：访问http://test1:8500进入consul可视化界面，发现微服务已注册进consul 总结三个注册中心： 组件名 语言 健康检查 对外暴露接口 CAP Spring Cloud集成 Eureka Java 可配支持 HTTP AP 已集成 Consul Go 支持 HTTP/DNS CP 已集成 Zookeeper Java 支持 客户端 CP 已集成 CAP理论：C(Consistency)表示强一致性；A(Availability)表示高可用；P(Partition Tolerance)表示分区容错性。CAP理论关注粒度是数据，而不是整体系统设计的策略CAP理论的核心：一个分布式系统不可能同时很好的满足一致性、可用性和分区容错性这个三个需求。现在的微服务架构要么是CP要么是AP(即P一定需要保证)，最多只能较好地同时满足两个根据CAP原理可将一个分布式系统分成CA、CP和AP三大类： CA：单点集群，满足一致性、可用性的系统，通常在可扩展性上不太满足 CP：满足一致性、分区容忍性，通常性能不是特别高 AP：满足可用性、分区容忍性，通常对一致性要求低一些 AP架构(Eureka)：因为同步原因出现问题，而造成数据没有一致性当出现网络分区后，为了保证高可用，系统B可以返回旧值，保证系统的可用性结论：违背了一致性C的要求，只满足可用性和分区容错性，即AP CP架构(Zookeeper、Consul)：当出现网络分区后，为了保证一致性，就必须拒绝请求，否者无法保证一致性结论：违背了可用性A的要求，只满足一致性和分区容错性，即CP Ribbon负载均衡介绍 Ribbon介绍：Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具Ribbon是NetFlix发布的开源项目。主要功能是提供客户端的软件负载均衡算法和服务调用。Ribbon客户端组件提供了一系列完善的配置项如连接超时、重试等。简单的说，就是在配置文件中列出Load Balancer(简称LB)后面所有的机器，Ribbon会自动地基于某种规则(简单轮询、随机连接等)去连接这些机器。很容易使用Ribbon实现自定义的负载均衡算法 负载均衡介绍：Load Balance，简单来说就是将用户的请求平摊地分配到多个服务上，从而达到系统的HA(高可用)。常见的负载均衡有软件Nginx、LVS等，硬件有F5等 集中式LB：在服务的消费方和提供方之间使用独立的LB设施(可以是硬件,如F5;也可以是软件,如Nginx)，由该设施负责把访问请求通过某种策略转发至服务的提供方 进程内LB：将LB逻辑集成到消费方————消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址 Ribbon和Nginx的对比： Nginx是服务器负载均衡，客户端所有的请求都会交给nginx，然后由nginx实现转发请求，即负载均衡是由服务端实现的 Ribbon是本地负载均衡，在调用微服务接口时会从注册中心上获取注册信息服务列表，再缓存到JVM本地，从而在本地实现RPC远程调用 Ribbon工作原理：Ribbon其实就是一个软负载均衡的客户端组件，它可以和其它所需请求的客户端结合使用，和Eureka结合只是其中的一个实例Ribbon在工作时分成两步： 首先选择Eureka Server，它优先选择在同一个区域内负载较少的Server 再根据用户指定的策略，从Server取到的服务注册列表中选择一个地址(Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权) 具体实践： 引入Ribbon：新版Eureka已默认引入Ribbon，无需额外引入 核心组件IRule介绍： Ribbon默认使用轮询作为负载均衡算法 IRule根据特定算法从服务列表中选取一个要访问的服务，IRule是一个接口 12345public interface IRule&#123; public Server choose(Object key); public void setLoadBalancer(ILoadBalancer lb); public ILoadBalancer getLoadBalancer();&#125; Ribbon提供了多种IRule的默认实现 共有以下七种： RoundRobinRule：轮询 RandomRule：随机 RetryRule：先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重试，获取可用服务 WeightedResponseTimeRule：对RoundRobinRule的扩展，响应速度越快的实例选择的权重越大，越容易被选择 BestAvailableRule：会先过滤掉由于多次访问故障而处于短路跳闸状态的服务，然后选择一个并发量最小的服务 AvailabilityFilteringRule：先过滤掉故障实例，在选择并发较小的实例 ZoneAvoidanceRule：默认规则，符合判断server所在区域的性能和server的可用性选择服务器 默认负载均衡算法替换 Ribbon的小bug：官网警告自定义的配置类不能放在@ComponentScanner所扫描的当前包以及子包下，否者自定义的这个配置类就会被所有的Ribbon客户端所共享，达不到特殊化定制的目的了(不能在SpringApplication主启动类的同级及子包下) 创建自定义Rule接口： 12345678@Configurationpublic class MyRibbonRule &#123; @Bean public IRule getRule()&#123; // 自定义为随机规则 return new RandomRule(); &#125;&#125; 在主启动类中设置新规则(@RibbonClient) 12345678@SpringBootApplication@EnableEurekaClient@RibbonClient(name = \"PROVIDER-PAYMENT\", configuration = MyRibbonRule.class)public class ConsumerOrder80Application &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerOrder80Application.class, args); &#125;&#125; 手写Ribbon负载均衡算法 原理：记实际调用服务器位置下标为serviceIndex，服务器集群总数量为serviceCount，rest接口请求次数为n，则有：serviceIndex = n % serviceCount(即轮询的原理) RoundRobinRule原理(发现采用思想一样,再加入了一些判断和CAS线程安全保证)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class RoundRobinRule extends AbstractLoadBalancerRule &#123; private AtomicInteger nextServerCyclicCounter; private static final boolean AVAILABLE_ONLY_SERVERS = true; private static final boolean ALL_SERVERS = false; public RoundRobinRule() &#123; nextServerCyclicCounter = new AtomicInteger(0); &#125; public RoundRobinRule(ILoadBalancer lb) &#123; this(); setLoadBalancer(lb); &#125; public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; int count = 0; while (server == null &amp;&amp; count++ &lt; 10) &#123; List&lt;Server&gt; reachableServers = lb.getReachableServers(); List&lt;Server&gt; allServers = lb.getAllServers(); int upCount = reachableServers.size(); int serverCount = allServers.size(); if ((upCount == 0) || (serverCount == 0)) &#123; return null; &#125; int nextServerIndex = incrementAndGetModulo(serverCount); server = allServers.get(nextServerIndex); if (server == null) &#123; /* Transient. */ Thread.yield(); continue; &#125; if (server.isAlive() &amp;&amp; (server.isReadyToServe())) &#123; return (server); &#125; // Next. server = null; &#125; return server; &#125; private int incrementAndGetModulo(int modulo) &#123; for (;;) &#123; int current = nextServerCyclicCounter.get(); int next = (current + 1) % modulo; if (nextServerCyclicCounter.compareAndSet(current, next)) return next; &#125; &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125;&#125; 实现自己版本的负载均衡算法： 原理：从Eureka服务器获取实例地址信息 + 机器数取余 + JUC(CAS + 原子整型) 准备工作：删除RestTemplate上的@LoadBalance注解，防止Ribbon LB的干扰 仿造创建LoadBalanced接口： 123public interface LoadBalancer &#123; ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances);&#125; 创建实现类：MyLoadBalancer 12345678910111213141516171819202122232425262728@Component@Slf4jpublic class MyLoadBalancer implements LoadBalancer &#123; // 原子整型 private final AtomicInteger atomicInteger = new AtomicInteger(0); // 获取Rest调用的次数 public final int getAndIncrement() &#123; int current, next; do &#123; // 获取当前值 current = atomicInteger.get(); // 计数达到最大值,重回0 next = current &gt;= Integer.MAX_VALUE ? 0 : current + 1; // CAS比较并交换 &#125; while (!atomicInteger.compareAndSet(current, next)); log.info(\"Next: &#123;&#125;\", next); return next; &#125; // 获取具体服务提供者实例信息 @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) &#123; // 获取当前访问机器的下标：调用次数 % 机器总数 int index = getAndIncrement() % serviceInstances.size(); return serviceInstances.get(index); &#125;&#125; 具体使用： 123456789101112// 注入自己声明为@Component的MyLoadBalancer@Autowiredprivate LoadBalancer loadBalancer;@GetMapping(\"/payment/getLb/&#123;id&#125;\")public Result getByIdInLoadBalance(@PathVariable(\"id\") Long id) &#123; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"PROVIDER-PAYMENT\"); if (instances == null || instances.isEmpty()) return null; ServiceInstance instance = loadBalancer.instances(instances); URI uri = instance.getUri(); return restTemplate.getForObject(uri + \"/payment/get/\" + id, Result.class);&#125; Ribbon停更后的替代者：Spring Cloud自己提供的LoadBalancer","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://sobxiong.github.io/tags/SpringCloud/"}]},{"title":"Effective Java","slug":"ProgrammingLanguage/Java/Effective_Java","date":"2020-11-15T08:28:20.000Z","updated":"2020-11-20T10:59:35.652Z","comments":true,"path":"2020/11/15/ProgrammingLanguage/Java/Effective_Java/","link":"","permalink":"https://sobxiong.github.io/2020/11/15/ProgrammingLanguage/Java/Effective_Java/","excerpt":"内容 引言 创建和销毁对象 对于所有对象都通用的方法","text":"内容 引言 创建和销毁对象 对于所有对象都通用的方法 引言Java语言支持四种类型：接口(包括注释)、类(包括enum)、数组和基本类型。前三种种类型通常被称为引用类型(reference type)，类实例和数组是对象(object)，而基本类型的值则不是对象。类的成员(member)由它的域(field)、方法(method)、成员类(member class)和成员接口(member interface)组成。方法的签名(signature)由它的名称和所有参数类型组成；签名不包括方法的返回类型 创建和销毁对象 第一条：用静态工厂方法代替构造器 第一大优势在于前者有名称。如果构造器的参数本身没有确切地描述正被返回的对象，那么具有适当名称的静态工厂会更容易使用，产生的客户端代码也更易于阅读 第二大优势在于不必在每次调用它们的时候都创建一个新对象。这使得不可变类可以使用预先构建好的实例，或者将构建好的实例缓存起来，进行重复利用，从而避免创建不必要的重复对象 第三大优势在于它们可以返回原返回类型的任何子类型的对象。这样在选择返回对象的类时就有了更大的灵活性。这种灵活性的一种应用是API可以返回对象，同时又不会使对对象的类变成公有的。以这种方式隐藏实现类会使API变得非常简洁 第四大优势在于所返回的对象的类可以随着每次调用而发生变化，这取决于静态工厂方法的参数值。只要是已声明的返回类型的子类型，都是允许的 第五大优势在于方法返回的对象所属的类，在编写包含该静态工厂方法的类时可以不存在(规范,可插拔,例如JDBC具体实现) 主要缺点在于类如果不含公有的或者受保护的构造器，就不能被子类化(Collections中便利的实现类子类化) 总结：静态工厂方法和公有构造器都各有用处，需要理解它们各自的长处。静态工厂经常更加合适，切忌第一反应就是提供公有的构造器，而不先考虑静态工厂 第二条：遇到多个构造器参数时要考虑使用构建器 静态工厂和构造器有个共同的局限性：它们都不能很好地扩展到大量的可选参数 方案1：重叠构造器(telescoping constructor)模式。在这种模式下，提供的第一个构造器只有必要的参数，第二个构造器有一个可选参数，第三个构造器有两个可选参数，依此类推。重叠构造器模式可行，但当有许多参数的时候，客户端代码会很难编写，并且仍然较难阅读 方案2：JavaBean模式。在这种模式下，先调用一个无参构造器来创建对象，然后再调用setter 方法来设置每个必要的参数，以及每个相关的可选参数。这种模式弥补了重叠构造器模式的不足：创建实例很容易，代码读起来也很容易 JavaBean模式的缺点：JavaBean模式自身有着很严重的缺点。因为构造过程被分到了几个调用中，在构造过程中JavaBean可能处于不一致的状态。类无法仅仅通过检验构造器参数的有效性来保证一致性。试图使用处于不一致状态的对象将会导致失败，这种失败与包含错误的代码大相径庭，因此调试起来十分困难。另一点不足在于JavaBean模式使得把类做成不可变的可能性不复存在，这就需要付出努力确保线程安全 不一致的解释：模拟多线程获取同一个JavaBean的场景，线程A获取Obj对象，对其属性进行set；同时线程B获取Obj对象对其进行get；这时可能会出现线程A中没有set完毕，线程B就开始get相应的属性 方案3：建造者(Buidler)模式。它既能保证重叠构造器模式那样的安全性，也能保证JavaBean模式那么好的可读性。它不直接生成想要的对象，而是让客户端利用所有必要的参数调用构造器(或静态工厂)，得到一个builder对象。然后客户端在builder对象上调用类似setter的方法来设置每个相关的可选参数。最后客户端调build()方法来生成通常是不可变的对象。这个builder通常是它构建的类的静态成员类 案例： 123456789101112131415161718192021222324252627282930313233343536373839public class MilkTea &#123; private final int ice; private final int sugar; private final boolean addPearl; private final int size; public static class Builder &#123; private int ice = NORMAL_ICE; private int sugar = NORMAL_SUGAR; private boolean addPearl = false; private final int size; public Builder(int size) &#123; this.size = size; &#125; public Builder ice(int ice) &#123; this.ice = ice; return this; &#125; public Builder sugar(int sugar) &#123; this.sugar = sugar; return this; &#125; public Builder addPearl(boolean addPearl) &#123; this.addPearl = addPearl; return this; &#125; public MilkTea build() &#123; return new MilkTea(this); &#125; &#125; private MilkTea(Builder builder) &#123; this.size = builder.size; this.sugar = builder.sugar; this.addPearl = builder.addPearl; this.ice = builder.ice; &#125;&#125; 优点： 客户端代码很容易编写、易于阅读。模拟了具名的可选参数 适用于类层次结构。 使用平行层次结构的builder时，各自嵌套在相应的类中。抽象类有抽象的builder，具体类有具体的builder 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class AbstractResource &#123; // 公共属性... // 泛型,递归参数类型,在子类中适当地进行方法链接,无需转换类型 abstract static class Builder&lt;T extends Builder&lt;T&gt;&gt; &#123; // 公共属性... public T setCommonFileds(...) &#123; // 公共属性赋值 return self(); &#125; abstract AbstractResource build(); // 模拟self类型 protected abstract T self(); &#125; AbstractResource(Builder&lt;?&gt; builder) &#123; // 设置公共属性... &#125;&#125;public class ConcreteResource extends AbstractResource &#123; // 公共属性... public static class Builder extends AbstractResource.Builder&lt;Builder&gt; &#123; // 公共属性... public Builder setFields(...)&#123; // 子类特有属性赋值 return this; &#125; // build返回都是子类的类型 @Override AbstractResource build() &#123; return new ConcreteResource(this); &#125; @Override protected Builder self() &#123; return this; &#125; &#125; private ConcreteResource(Builder builder) &#123; super(builder); // 设置公共属性... &#125;&#125; Builder模式十分灵活 缺点： 为了创建对象，必须先创建它的构建器 模式较冗长，但容易扩展 总结：如果类的构造器或者静态工厂中具有多个参数，Builder模式是一种不错的选择，特别是当大多数参数类型相同或是可选参数时 第三条：用私有构造器或者枚举类型强化Singleton属性 Singleton是指仅仅被实例化一次的类，通常被用来代表无状态的对象，比如那些本质上唯一的系统组件 方案1：饿汉式(静态常量),懒加载问题有时可忽略 12345678class Singleton &#123; // 1、构造器私有化(防止外部new) private Singleton() &#123;&#125; // 2、类内创建对象(静态常量) private final static Singleton instance = new Singleton(); // 3、向外暴露静态公共方法,返回单例instance public static Singleton getInstance() &#123; return instance; &#125;&#125; 缺陷：如果Singleton需要可序列化，仅仅加上implements Serializable是不够的。为了维护并保证Singleton，必须声明所有实例域都是瞬时(transient)的，并提供一个readResolve方法。否则每次反序列化一个序列化的实例时都会创建一个新的实例 方案2：声明一个包含单个元素的枚举类型 123public enum Singleton&#123; INSTANCE;&#125; 优点：该方式无偿提供了序列化机制，绝对防止多次实例化，即使是在面对复杂的序列化或者反射攻击的时候。虽然这种方法还没有广泛采用，但单枚举类型经常成为实现Singleton的最佳方法 注意：如果Singleton必须扩展一个超类，而不是扩展Enum时，则不宜使用这个方法 \b\b\b\b\b单例模式的其他介绍参见设计模式 第四条：通过私有构造器强化不可实例化的能力 有时可能需要编写只包含静态方法和静态域的类。这些工具类不希望被实例化，因为实例化对它没有任何意义。然而在缺少显式构造器的情况下，编译器会自动提供一个公有的、无参的缺省构造器。对于用户而言，这个构造器与其他的构造器没有任何区别 企图通过将类做成抽象类来强制该类不可被实例化是行不通的。该类可以被子类化并且该子类也可以被实例化。这种方式还会产生误导 有些简单方法可以确保类不可被实例化。由于只有当类不包含显式的构造器时，编译器才会生成缺省的构造器，因此只要让该类包含一个私有构造器，它就不能被实例化： 123456public class UtilClass &#123; private UtilClass() &#123; throw new AssertionError(); &#125; // ...&#125; 抛出异常能避免在类内部调用私有构造器；最好的做法是在私有构造器中标明注释以及抛出异常时显式指出异常信息。这种方法也有副作用————它使得此类不能被子类化(所有构造器都必须显式或隐式调用超类构造器) 第五条：优先考虑依赖注入来引用资源 有许多类会依赖一个或多个底层的资源，但静态工具类Singleton类不适合需要引用底层资源的类 依赖注入适用于任意数量的资源以及任意的依赖形式。依赖注入的对象资源具有不可变性，因此多个客户端可以共享依赖对象(假设客户端们想要的是同一个底层资源)。依赖注入也同样适用于构造器、静态工厂和构建器 依赖注入的最简单的模式是当创建一个新实例时就将该资源传到构造器中；另一种有用的变体是将资源工厂(factory)传给构造器，工厂是可以被重复调用来创建类型实例的一个对象，这类工厂具体表现为工厂方法模式(Java8增加的接口SupplierT&lt;&gt;最适合用于表示工厂)；另一种方式是采用依赖注入框架，如Dagger、Guice或Spring(设置成手动依赖注入的API,一般都适用) 总结：不要用Singleton和静态工具类来实现依赖一个或多个底层资源的类，且该资源的行为会影响到该类的行为；也不要直接用这个类来创建这些资源。应该将这些资源或者工厂传给构造器(静态工厂/构建器)，通过它们来创建类。该实践就被称作依赖注入，它极大地提升了类的灵活性、可重用性和可测试性 第六条：避免创建不必要的对象 一般来说最好能用单个对象，而不是在每次需要的时候就创建一个相同功能的新对象。重用方式既快速，又流行。如果对象是不可变的(immutable)，它就始终可以被重用 对于同时提供了静态工厂方法(static factory method)和构造器的不可变类，通常优先使用静态工厂方法而不是构造器，以避免创建不必要的对象 有些对象创建的成本比其他对象要高得多。如果重复地需要这类”昂贵的对象”，建议将它缓存下来重用 案例如下： 12345678910// 方式1static boolean isRomanNumeral(String s) &#123; return s.matches(\"xxxx\");&#125;// 方式2private static final Pattern pattern = Pattern.compile(\"xxxx\");static boolean isRomanNumeral(String s) &#123; return pattern.matcher(s).matches();&#125; 说明：String.matches()方法易于查看一个字符串是否与正则表达式相匹配，但并不适合在注重性能的情形中重复使用。问题在于，它在内部为正则表达式创建了一个Pattern实例，却只使用了一次，之后就可以进行垃圾回收了。创建Pattern的实例的成本很高，因为需要将正则表达式编译成一个有限状态机(finite state machine)。为了提升性能，应该显式地将正则表达式编译成一个Pattern实例(不可变)，让它成为类初始化的一部分，并将它缓存起来 如果一个对象是不变的，那么它显然能够被安全地重用，但其他有些情形则并不总是这么明显。考虑虑适配器(adapter)的情形，有时也叫作视图(view)。适配器是指这样一个对象：它把功能委托给一个后备对象(backing object)，从而为后备对象提供一个可以替代的接口。由于适配器除了后备对象之外没有其他的状态信息，所以针对某个给定对象的特定适配器而言，它不需要创建多个适配器实例 例如Map接口的keySet()方法返回该Map对象的Set视图，其中包含该Map中所有的键(key)。乍看之下，好像每次调用keySet()都应该创建一个新的Set实例，但对于一个给定的Map对象，实际上每次调用keySet()都返回同样的Set实例。虽然被返回的Set实例一般是可改变的，但所有返回的对象在功能上是等同的；当其中一个返回对象发生变化的时候，所有其他的返回对象也要发生变化，因为它们是由同一个Map实例支撑的 另一种创建多余对象的方法，称作自动装箱(autoboxing)。它允许程序员将基本类型和装箱基本类型(Boxed Primitive Type)混用，按需要自动装箱和拆箱。自动装箱使基本类型和装箱基本类型之间的差别变得模糊起来，但并没有完全消除。它们在语义上还有着微妙的差别，在性能上也有着比较明显的差别 案例如下 12345private static long sum() &#123; Long sum = 0L; for (long i = 0; i &lt;= Integer.MAX_VALUE; i++) sum += i; return sum;&#125; 说明：这段程序算出的答案是正确的，但是比实际情况要更慢一些，只因为声明为装箱类型。变量sum 被声明成Long而不是long意味着程序构造了大约2^31个多余的Long实例(大约每次往Long sum中增加long时构造一个实例)。因此，要优先使用基本类型而不是装箱基本类型，要当心无意识的自动装箱 不要错误地认为本条目所介绍的内容暗示着”创建对象的代价非常昂贵,应尽可能避免创建对象”。相反，由于小对象的构造器只做很少量的显式工作，小对象的创建和回收动作是非常廉价的，特别是在现代的JVM 实现上更是如此。通过创建附加的对象，提升程序的清晰性、简洁性和功能性，这通常是件好事 反之通过维护自己的对象池(object pool)来避免创建对象并不是一种好的做法，除非池中的对象是非常重量级的。正确使用对象池的典型对象示例就是数据库连接池。建立数据库连接的代价是非常昂贵的，因此重用这些对象非常有意义。而且，数据库的许可可能限制只能使用一定数量的连接。但一般而言，维护自己的对象池必定会把代码弄得很乱，同时增加内存占用(footprint)，并且还可能会损害性能。现代的JVM实现具有高度优化的垃圾回收器，其性能很容易就会超过轻量级对象池的性能 第七条：消除过期的对象引用 简单案例： 12345678910111213141516171819202122232425public class Stack &#123; private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() &#123; elements = new Object[DEFAULT_INITIAL_CAPACITY]; &#125; public void push(Object e) &#123; ensureCapacity(); elements[size++] = e; &#125; public Object pop() &#123; if (size == 0) throw new EmptyStackException(); return elements[--size]; &#125; private void ensureCapacity() &#123; if (elements.length == size) elements = Arrays.copyOf(elements, size + 1); &#125;&#125; 案例解读：没有很明显的错误。无论如何测试，它都会成功地通过每一项测试，但是当中隐藏着一个问题。不严格地讲，这段程序有一个”内存泄漏”，随着垃圾回收器活动的增加，或者由于内存占用的不断增加，程序性能的降低会逐渐表现出来。在极端的情况下，这种内存泄漏会导致磁盘交换(Disk Paging)，甚至导致程序失败(OutOfMemoryError错误)，但这种失败情形相对比较少见 案例中哪里发生了内存泄漏呢？如果一个栈先是增长然后再收缩，那么从栈中弹出来的对象将不会被当作垃圾回收，即使使用栈的程序不再引用这些对象，它们也不会被回收。这是因为栈内部维护着对这些对象的过期引用(obsolete reference)。所谓的过期引用，是指永远也不会再被解除的引用。在本例中，凡是在elements数组的”活动部分”(active portion)之外的任何引用都是过期的。活动部分是指elements中下标小于size的那些元素 在支持垃圾回收的语言中，内存泄漏是很隐蔽的(称这类内存泄漏为”无意识的对象保持”(unintentional object retention)更为恰当)。如果一个对象引用被无意识地保留起来了，那么垃圾回收机制不仅不会处理这个对象，而且也不会处理被这个对象所引用的所有其他对象。即使只有少量的几个对象引用被无意识地保留下来，也会有许许多多的对象被排除在垃圾回收机制之外，从而对性能造成潜在的重大影响 这类问题的修复方法很简单：一旦对象引用已经过期，只需清空这些引用即可。对于上述案例中的Stack类而言，只要一个单元被弹出栈，指向它的引用就过期了。pop()方法的修订版本如下所示： 1234567public Object pop() &#123; if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; return result;&#125; 清空过期引用的另一个好处是，如果它们以后又被错误地解除引用，程序就会立即抛出NullPointerException异常，而不是悄悄地错误运行下去。尽快地检测出程序中的错误总是有益的 当第一次被类似这样的问题困扰的时候，往往会过分小心：对于每一个对象引用，一旦程序不再用到它，就把它清空。其实这样做既没必要，也不是我们所期望的，因为这样做会把程序代码弄得很乱。清空对象引用应该是一种例外，而不是一种规范行为。消除过期引用最好的方法是让包含该引用的变量结束其生命周期。如果是在最紧凑的作用域范围内定义每一个变量，这种情形就会自然地发生 一般来说，只要类是自己管理内存，就应该警惕内存泄漏问题。一旦元素被释放掉，则该元素中包含的任何对象引用都应该被清空 内存泄漏的另一个常见来源是缓存。一旦把对象引用放到缓存中，它就很容易被遗忘掉，从而使得它不再有用之后很长一段时间内仍然留在缓存中。一种有效的方案如下：只要在缓存之外存在对某个项的键的引用，该项就有意义，那么就可以用WeakHashMap代表缓存。当缓存中的项过期之后，它们就会自动被删除。但只有当所要的缓存项的生命周期是由该键的外部引用而不是由值决定时，WeakHashMap才有用处 更为常见的情形则是，”缓存项的生命周期是否有意义”并不是很容易确定，随着时间的推移，其中的项会变得越来越没有价值。在这种情况下，缓存应该时不时地清除掉没用的项。这项清除工作可以由一个后台线程(可能是ScheduledThreadPoolExecutor)来完成，或者也可以在给缓存添加新条目的时候顺便进行清理。LinkedHashMap类利用它removeEldestEntry()方法可以很容易地实现后一种方案。对于更复杂的缓存，可以使用java.lang.ref 内存泄漏的第三个常见来源是监昕器和其他回调。如果你实现了一个API，客户端在这个API中注册了回调，却没有显式地取消注册，那么除非你采取某些动作，否则它们就会不断地堆积起来。确保回调立即被当作垃圾回收的最佳方法是只保存它们的弱引用(weak reference)，例如，只将它们保存成WeakHashMap中的键 由于内存泄漏通常不会表现成明显的失败，所以它们可以在一个系统中存在很多年。往往只有通过仔细检查代码，或者借助于Heap剖析工具(Heap Profiler)才能发现内存泄漏问题。因此如果能够在内存泄漏发生之前就知道如何预测此类问题并阻止它们发生，那是最好不过的 第8条：避免使用终结方法和清除方法 终结方法(finalizer)通常是不可预测的，也是很危险的，一般情况下是不必要的。用终结方法会导致行为不稳定、性能降低，以及可移植性问题。当然，终结方法也有其可用之处；但是根据经验，应该避免使用终结方法。在Java9中使用清除方法(cleaner)代替了终结方法。清除方法没有终结方法那么危险，但仍然不可预测、运行缓慢，一般情况下也是不必要的 在C++中，析构器是回收一个对象所占用资源的常规方法，是构造器所必需的对应物。而在Java中，当一个对象变得不可到达的时候，垃圾回收器会回收与该对象相关联的存储空间，并不需要程序员做专门的工作。C++的析构器也可以被用来回收其他的非内存资源，而在Java中一般用try-finally块来完成类似的工作 终结方法和清除方法的缺点在于不能保证会被及时执行。从一个对象变得不可到达开始，到它的终结方法被执行，所花费的这段时间是任意长的。这意味着，注重时间(time-critical)的任务不应该由终结方法或者清除方法来完成。例如用终结方法或者清除方法来关闭已经打开的文件，这就是个严重的错误，因为打开文件的描述符是一种很有限的资源。如果系统无法及时运行终结方法或者清除方法就会导致大量的文件仍然保留在打开状态，于是当一个程序再也不能打开文件的时候，它可能会运行失败 及时地执行终结方法和清除方法正是垃圾回收算法的一个主要功能，这种算法在不同的JVM实现中会大相径庭。如果程序依赖于终结方法或者清除方法被执行的时间点，那么这个程序的行为在不同的JVM中运行的表现可能就会截然不同 延迟终结过程并不只是一个理论问题。在很少见的情况下，为类提供终结方法可能会随意地延迟其实例的回收过程。Java语言规范并不保证哪个线程将会执行终结方法，所以除了不使用终结方法之外，并没有很轻便的办法能够避免这样的问题。在这方面，清除方法比终结方法稍好一些，因为类的设计者可以控制自己的清除线程，但清除方法仍然在后台运行，处于垃圾回收器的控制之下，因此不能确保及时清除 Java语言规范不仅不保证终结方法或者清除方法会被及时地执行，而且根本就不保证它们会被执行。当一个程序终止的时候，某些已经无法访问的对象上的终结方法却根本没有被执行，这是完全有可能的。结论是：永远不应该依赖终结方法或者清除方法来更新重要的持久状态。例如，依赖终结方法或者清除方法来释放共享资源(比如数据库)上的永久锁，这很容易让整个分布式系统垮掉 不要被System.gc()和System.runFinalization()这两个方法所诱惑，它们确实增加了终结方法或者清除方法被执行的机会，但是它们并不保证终结方法或者清除方法会被执行。唯一声称保证它们会被执行的两个方法是System.runFinalizersOnExit()及其臭名昭著的孪生兄弟Runtime.runFinalizersOnExit()。这两个方法都有致命的缺陷，井且已经被废弃很久了 使用终结方法和清除方法有非常严重的性能损失 终结方法有一个严重的安全问题：它们为终结方法攻击(finalizer attack)打开了类的大门。终结方法攻击背后的思想很简单：如果从构造器或者它的序列化对等体(readObject和readResolve方法)抛出异常，恶意子类的终结方法就可以在构造了部分的应该已经半途夭折的对象上运行。这个终结方法会将对该对象的引用记录在一个静态域中，阻止它被垃圾回收。一旦记录到异常的对象，就可以轻松地在这个对象上调用任何原本永远不允许在这里出现的方法。从构造器抛出的异常，应该足以防止对象继续存在；有了终结方法的存在，这一点就做不到了。这种攻击可能造成致命的后果。final类不会受到终结方法攻击，因为没有人能够编写出final类的恶意子类。为了防止非final类受到终结方法攻击，要编写一个空的final的finalize()方法 如果类的对象中封装的资源(例如文件或者线程)确实需要终止，应该怎么做才能不用编写终结方法或者清除方法呢？只需让类实现AutoCloseable，并要求其客户端在每个实例不再需要的时候调用close()方法，一般是利用try-with-resources确保终止，即使遇到异常也是如此。值得提及的一个细节是，该实例必须记录下自己是否已经被关闭了————close()方法必须在一个私有域中记录下”该对象已经不再有效”。如果这些方法是在对象已经终止之后被调用，其他的方法就必须检查这个域，并抛出IllegalStateException异常 学finalize()… 总而言之，除非是作为安全网，或者是为了终止非关键的本地资源，否则请不要使用清除方法，对于在Java9之前的发行版本，则尽量不要使用终结方法。若使用了终结方法或者清除方法，则要注意它的不确定性和性能后果 第9条：try-with-resources优先于try-finally Java类库中包括许多必须通过调用close()方法来手工关闭的资源。例如InputStream、OutputStrea以及java.sql.Connection。客户端经常会忽略资源的关闭，造成严重的性能后果也就可想而知了。虽然这其中的许多资源都是用终结方法作为安全网，但效果并不理想 根据经验，try-finally语句是确保资源会被适时关闭的最佳方法，就算发生异常或者返回也一样 一个try-finally的示例 12345678static String firstLineOfFile(String path) throws IOException &#123; BufferedReader reader = new BufferedReader(new FileReader(path)); try &#123; return reader.readLine(); &#125; finally &#123; reader.close(); &#125;&#125; 即使用try-finally语句正确地关闭了资源，也存在着些许不足。因为在try块和finally块中的代码，都可能会抛出异常。例如在firstLineOfFile()方法中，如果底层的物理设备异常，那么调用readLine()方法就会抛出异常。基于同样的原因，调用close()方法也会出现异常。在这种情况下，第二个异常完全抹除了第一个异常。在异常堆枝轨迹中，完全没有关于第一个异常的记录，这在现实的系统中会导致调试变得非常复杂，因为通常需要看到第一个异常才能诊断出问题何在。虽然可以通过编写代码来禁止第一个异常，保留第一个异常，但事实上没有人会这么做，因为实现起来太烦琐了 当Java7引人try-with-sources语句时，所有这些问题一下子就全部解决。要使用这个构造的资源，必须先实现AutoCloseable接口，其中包含了声明返回值void的close()方法。Java类库与第三方类库中的许多类和接口，现在都实现或扩展了AutoCloseable接口。如果编写了一个类且它代表的是必须被关闭的资源，那么该类也应该实现AutoCloseable firstLineOfFile的try-with-sources示例 12345static String firstLineOfFile(String path) throws IOException &#123; try (BufferedReader reader = new BufferedReader(new FileReader(path))) &#123; return reader.readLine(); &#125;&#125; 使用try-with-resources不仅使代码变得更简洁易懂，也更容易进行诊断。以firstLineOfFile()方法为例，如果调用readLine()和(不可见的)close()方法都抛出异常，后一个异常就会被禁止，以保留第一个异常。事实上，为了保留想要看到的那个异常，即便多个异常都可以被禁止。这些被禁止的异常并不是简单地被抛弃了，而是会被打印在堆栈轨迹中，并注明它们是被禁止的异常。通过编程调用getSuppressed()方法还可以访问到它们，getsuppressed()方法已经添加到Java7的Throwable类中 在try-with-resources语句中还可以使用catch子句，就像在平时的try-finally语句一样 结论：在处理必须关闭的资源时，始终要优先考虑用try-with-resources，而不是用try-finally。这样得到的代码将更加简洁、清晰，产生的异常也更有价值。有了try-with-resources语句，在使用必须关闭的资源时，就能更轻松地正确编写代码了。实践证明，这个用try-finally是不可能做到的 对于所有对象都通用的方法","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"}]},{"title":"Java日志","slug":"ProgrammingLanguage/Java/Java日志","date":"2020-10-29T14:06:04.000Z","updated":"2020-11-02T01:32:08.222Z","comments":true,"path":"2020/10/29/ProgrammingLanguage/Java/Java日志/","link":"","permalink":"https://sobxiong.github.io/2020/10/29/ProgrammingLanguage/Java/Java%E6%97%A5%E5%BF%97/","excerpt":"内容 日志介绍 日志实现 日志门面 SpringBoot中的日志","text":"内容 日志介绍 日志实现 日志门面 SpringBoot中的日志 日志介绍 日志文件是用于记录系统操作事件的文件集合，可分为事件日志和消息日志。具有处理历史数据、诊断问题的追踪以及理解系统的活动等重要作用。在计算机中，日志文件是记录在操作系统或其他软件运行中发生的事件或在通信软件的不同用户之间的消息的文件 日志的价值、好处： 记录系统中硬件、软件和系统问题的信息，监视系统中发生的事件 检查错误发生的原因 发现一些之前从未意识到的问题 现有Java日志框架介绍： 日志实现： JUL(java util logging) logback log4j log4j2 日志门面： JCL(Jakarta Commons Logging) slf4j(Simple Logging Facade for Java) log4j2 为什么需要日志框架： 集中精力完成系统的业务逻辑设计 框架一般是成熟，稳健的，可以处理系统很多细节问题 经过实践检验，结构很好，扩展性强，可以不断升级 Java日志框架主要解决的问题： 控制日志输出的内容和格式 控制日志输出的位置(file,console) 日志优化：异步日志，日志文件的归档和压缩 日志系统的维护 面向接口开发——日志的门面(适配性能更高的日志框架) 日志实现 JUL入门 JUL介绍：全称Java util Logging，是java原生的日志框架，使用时不需要另外引用第三方类库。相对其他日志框架使用方便，学习简单，能够在小型应用中灵活使用 架构介绍：Loggers：记录器，应用程序通过获取Logger对象调用其API来发布日志信息。Logger通常是应用程序访问日志系统的入口Appenders：也称为Handlers，每个Logger都会关联一组Handlers。Logger将日志交给关联Handlers处理，由Handlers负责将日志做记录。Handlers是一个抽象，其具体的实现决定了日志记录的位置，可以是控制台、文件、网络上的其他日志服务或操作系统日志等Layouts：也称为Formatters，负责对日志事件中的数据进行转换和格式化。Layouts决定了数据在一条日志记录中的最终形式Level：每条日志消息都有一个关联的日志级别。该级别粗略指导了日志消息的重要性和紧迫，可以将Level和Loggers，Appenders关联以便于过滤消息Filters：过滤器，根据需要定制哪些信息会被记录，哪些信息会被放行 入门案例： 123456789101112// 1、获取日志记录器Logger logger = Logger.getLogger(getClass().getName());// 2、日志记录输出logger.info(\"Hello JUL~~~\");// 通用方法进行日志记录logger.log(Level.INFO, \"Hello SOBXiong~~~\");// 通过占位符方式输出变量值String name = \"SOBXiong\";int age = 23;logger.log(Level.INFO, \"Hello &#123;0&#125;,&#123;1&#125;\", new Object[]&#123;name, age&#125;); 日志级别： SEVERE(最高值) WARNING INFO(默认级别) CONFIG FINE FINER FINEST(最低值) OFF(关闭日志记录) ALL(启用所有消息的日志记录) 自定义日志级别案例： 1234567891011121314151617181920212223242526272829303132333435// 1、获取日志记录器Logger logger = Logger.getLogger(getClass().getName());// 关闭系统默认配置logger.setUseParentHandlers(false);// 自定义日志级别// 创建ConsoleHandlerConsoleHandler consoleHandler = new ConsoleHandler();// 创建简单格式转换对象SimpleFormatter simpleFormatter = new SimpleFormatter();// 进行关联consoleHandler.setFormatter(simpleFormatter);logger.addHandler(consoleHandler);// 配置日志具体级别logger.setLevel(Level.ALL);consoleHandler.setLevel(Level.ALL);// FileHandler文件输出FileHandler fileHandler = new FileHandler(\"jul.log\");fileHandler.setFormatter(simpleFormatter);// 进行关联(一个logger可以设置多个handler)logger.addHandler(fileHandler);// 2、日志记录输出logger.severe(\"Hello SOBXiong\");logger.warning(\"Hello SOBXiong\");// jul默认日志级别为infologger.info(\"Hello SOBXiong\");logger.config(\"Hello SOBXiong\");logger.fine(\"Hello SOBXiong\"); Logger之间父子关系案例： 123456789101112131415161718192021222324252627/*JUL中Logger之间存在父子关系，这种父子关系通过树状结构存储。JUL在初始化时会创建一个顶层RootLogger作为所有Logger的父Logger，存储上作为树状结构的根节点。父子关系通过路径来关联*/Logger logger1 = Logger.getLogger(\"com.xiong\");Logger logger2 = Logger.getLogger(\"com\");// 测试logger1.log(Level.INFO, \"logger1 == logger2 &#123;0&#125;\", logger1.getParent() == logger2);System.out.println(logger2.getParent());// 所有日志记录器的顶级父元素: LogManager$RootLogger, name为空System.out.println(logger2.getParent().getName());// 关闭默认配置logger2.setUseParentHandlers(false);// 设置logger2日志级别ConsoleHandler consoleHandler = new ConsoleHandler();SimpleFormatter simpleFormatter = new SimpleFormatter();consoleHandler.setFormatter(simpleFormatter);logger2.addHandler(consoleHandler);logger2.setLevel(Level.ALL);consoleHandler.setLevel(Level.ALL);logger1.severe(\"Hello SOBXiong\");logger1.warning(\"Hello SOBXiong\");logger1.info(\"Hello SOBXiong\");logger1.config(\"Hello SOBXiong\");logger1.fine(\"Hello SOBXiong\"); 日志配置文件案例： 1234567891011121314151617181920212223242526272829303132333435# RootLogger顶级父元素指定的默认处理器为ConsoleHandlerhandlers=java.util.logging.ConsoleHandler,java.util.logging.FileHandler# RootLogger顶级父元素默认日志级别为ALL,名次为空.level=ALL# 自定义Loggercom.xiong.logger.handlers=java.util.logging.ConsoleHandlercom.xiong.logger.level=CONFIG# 关闭默认配置com.xiong.logger.useParentHandlers=false# 向日志文件输出的handler对象# 指定日志文件路径java.util.logging.FileHandler.pattern=java%u.log# 指定日志文件内容大小java.util.logging.FileHandler.limit=50000# 指定日志文件数量java.util.logging.FileHandler.count=1# 指定handler对象日志消息格式对象java.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter# 指定以追加方式添加日志内容java.util.logging.FileHandler.append=true# 向控制台输出的handler对象# 指定handler对象的日志级别java.util.logging.ConsoleHandler.level=ALL# 指定handler对象的日志消息格式对象java.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter# 指定handler对象的字符集java.util.logging.ConsoleHandler.encoding=UTF-8# 指定日志消息格式java.util.logging.SimpleFormatter.format=%4$s: %5$s [%1$tc]%n 123456789101112131415// 读取配置文件,通过类加载器InputStream is = getClass().getClassLoader().getResourceAsStream(\"logging.properties\");// 创建LogManagerLogManager logManager = LogManager.getLogManager();// 通过LogManager加载配置文件logManager.readConfiguration(is);// 创建日志记录器Logger logger = Logger.getLogger(getClass().getName());logger.severe(\"Hello SOBXiong1\");logger.warning(\"Hello SOBXiong2\");logger.info(\"Hello SOBXiong3\");logger.config(\"Hello SOBXiong4\");logger.fine(\"Hello SOBXiong5\"); 日志原理解析： 初始化LogManager LogManager加载logging.properties配置 添加Logger到LogManager 从单例LogManager获取Logger 设置级别Level，并指定日志记录LogRecord Filter提供了日志级别之外更细粒度的控制 Handler用来处理日志输出位置 Formatter用来格式化LogRecord log4j入门 log4j介绍：Log4j是Apache下的一款开源的日志框架，通过在项目中使用Log4J，可控制日志信息输出到控制台、文件、甚至是数据库中。可控制每一条日志的输出格式；通过定义日志的输出级别，可以更灵活地控制日志的输出过程；方便项目的调试。官网：http://logging.apache.org/log4j/1.2/ 入门案例： 123456&lt;!-- log4j依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920// 初始化配置信息,当前暂使用代码不使用配置文件BasicConfigurator.configure();// 获取日志记录器对象Logger logger = Logger.getLogger(Log4jTest.class);// 日志记录输出logger.info(\"Hello Log4j\");// 日志级别// 严重错误,一般会造成系统崩溃并终止运行logger.fatal(\"fatal\");// 错误信息,不会影响系统运行logger.error(\"error\");// 警告信息,可能会发生问题logger.warn(\"error\");// 运行信息,数据连接、网络连接、IO操作等等logger.info(\"info\");// 调试信息,一般在开发中使用,记录程序变量参数传递信息等等logger.debug(\"debug\");// 追踪信息,记录程序所有的流程信息logger.trace(\"trace\"); 日志级别： fatal：指出每个将会导致应用程序退出的严重的错误事件 error：指出虽然发生错误事件，但仍然不影响系统继续运行 warn：表明会出现潜在的错误情形 info：一般用于粗粒度级别上，强调应用程序的运行全程 debug：一般用于细粒度级别上，对调试应用程序非常有帮助 trace：程序追踪，可以用于输出程序运行中的变量，显示执行的流程 OFF：用来关闭日志记录 ALL：启用所有消息的日志记录 组件：log4j主要由Loggers(日志记录器)、Appenders(输出端)和Layout(日志格式化器)组成。其中Loggers控制日志的输出级别与日志是否输出；Appenders指定日志的输出方式(输出到控制台、文件等)；Layout控制日志信息的输出格式 Loggers：日志记录器，负责收集处理日志记录。实例的命名就是类的全限定名，Logger的名字大小写敏感，其命名有继承机制。例如：name为org.apache.commons的logger会继承name为org.apache的loggerlog4j中有一个特殊的logger叫”root”，它是所有logger的根，也意味着其他所有的logger都会直接或者间接地继承自root。root logger可以用Logger.getRootLogger()方法获取 Appenders：用来指定日志输出到哪个地方，可以同时指定日志的输出目的地。常用有以下5种： 输出端类型 作用 ConsoleAppender 将日志输出到控制台 FileAppender 将日志输出到文件中 DailyRollingFileAppender 将日志输出到一个日志文件,并且每天输出到一个新的文件 RollingFileAppender 将日志信息输出到一个日志文件,并且指定文件的最大尺寸;当文件大小达到指定尺寸时,会自动把文件改名,同时产生一个新的文件 JDBCAppender 把日志信息保存到数据库中 Layouts：布局器Layouts用于控制日志输出内容的格式，可使用各种指定的格式输出日志。常用的Layouts有以下3种： 格式化器类型 作用 HTMLLayout 格式化日志输出为HTML表格形式 SimpleLayout 简单的日志输出格式化,打印的日志格式为(info - message) PatternLayout 最强大的格式化器,可以根据自定义格式输出日志;如果没有指定转换格式,就是用默认的转换格式 Layout格式： 1234567891011121314151617# log4j采用类似C语言printf()函数的打印格式格式化日志信息,具体的占位符及其含义如下： %m 输出代码中指定的日志信息%p 输出优先级,即DEBUG、INFO等%n 换行符%r 输出自应用启动到输出该log信息耗费的毫秒数%c 输出打印语句所属的类的全名%t 输出产生该日志的线程全名%d 输出服务器当前时间,默认为ISO8601;也可以指定格式,如：%d&#123;yyyy年MM月dd日 HH:mm:ss&#125;%l 输出日志时间发生的位置,包括类名、线程、及在代码中的行数。如：Test.main(Test.java:10)%F 输出日志消息产生时所在的文件名称%L 输出代码中的行号%% 输出一个'%'字符# 可以在'%'与字符之间加上修饰符来控制最小宽度、最大宽度和文本的对其方式：%5c 输出category名称,最小宽度是5;category&lt;5,默认的情况下右对齐%-5c 输出category名称,最小宽度是5;category&lt;5,\"-\"号指定左对齐,会有空格%.5c 输出category名称,最大宽度是5;category&gt;5,就会将左边多出的字符截掉;&lt;5不会有空格%20.30c 输出category名称,&lt;20补空格,并且右对齐;&gt;30就从左边多出的字符截掉 配置文件案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 默认类路径下的log4j.properties文件# 指定RootLogger顶级父元素默认配置# 指定日志级别为trace,使用appender为console、filelog4j.rootLogger = trace,console# 自定义logger对象设置,不显式声明appender则使用rootLogger的appenderlog4j.logger.com.xiong.logger = info,file# 指定控制台日志输出的appenderlog4j.appender.console = org.apache.log4j.ConsoleAppender# 指定消息格式layoutlog4j.appender.console.layout = org.apache.log4j.PatternLayout# 指定消息格式内容(OGNL表达式)log4j.appender.console.layout.conversionPattern = [%-10p]%r %l %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %m%n# 日志文件输出的appender对象log4j.appender.file = org.apache.log4j.FileAppender# 指定消息格式layoutlog4j.appender.file.layout = org.apache.log4j.PatternLayout# 指定消息格式内容(OGNL表达式)log4j.appender.file.layout.conversionPattern = [%-10p]%r %l %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %m%n# 指定日志文件保存路径log4j.appender.file.file = log4j.log# 指定日志文件的字符集log4j.appender.file.encoding = UTF-8# 按照文件大小拆分的appender对象log4j.appender.rollingFile = org.apache.log4j.RollingFileAppender# 指定消息格式layoutlog4j.appender.rollingFile.layout = org.apache.log4j.PatternLayout# 指定消息格式内容(OGNL表达式)log4j.appender.rollingFile.layout.conversionPattern = [%-10p]%r %l %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %m%n# 指定日志文件保存路径log4j.appender.rollingFile.file = log4j.log# 指定日志文件的字符集log4j.appender.rollingFile.encoding = UTF-8# 指定日志文件内容的大小log4j.appender.rollingFile.maxFileSize = 1MB# 指定日志文件的数量log4j.appender.rollingFile.maxBackupIndex = 10# 按照时间规则拆分的appender对象log4j.appender.dailyFile = org.apache.log4j.DailyRollingFileAppender# 指定消息格式layoutlog4j.appender.dailyFile.layout = org.apache.log4j.PatternLayout# 指定消息格式内容(OGNL表达式)log4j.appender.dailyFile.layout.conversionPattern = [%-10p]%r %l %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %m%n# 指定日志文件保存路径log4j.appender.dailyFile.file = log4j.log# 指定日志文件的字符集log4j.appender.dailyFile.encoding = UTF-8# 指定日期的拆分规则log4j.appender.dailyFile.datePattern = '.'yyyy-MM-dd-HH-mm-ss logback入门： logback介绍：Logback是由log4j创始人设计的另一个开源日志组件，性能比log4j要好。官网：https://logback.qos.ch/index.htmllogback主要分为三个模块： logback-core：基础核心模块 logback-classic：log4j的一个改良版本，并完整实现了slf4j API logback-access：访问模块与Servlet容器集成提供通过Http来访问日志的功能 入门案例： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 123456789101112public static final Logger logger = LoggerFactory.getLogger(LogbackTest.class);@Testpublic void testQuick() &#123; // 由于logback和slf4j是同一作者,API设置差不多 // 日志输出 logger.error(\"error\"); logger.warn(\"warn\"); logger.info(\"info\"); logger.debug(\"debug\"); logger.trace(\"trace\");&#125; logback配置： 读取配置流程(依次去读)： logback.groovy logback-test.xml logback.xml 默认配置 logback组件间的关系： Logger：日志记录器，关联到应用的对应的context上后，主要用于存放日志对象，也可以定义日志类型、级别 Appender：用于指定日志输出的目的地，可以是控制台、文件、数据库等等 Layout：负责把事件转换成字符串(格式化的日志信息)。在logback中Layout对象被封装在encoder中 基本配置信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;configuration&gt; &lt;!-- 日志输出格式： %-5level: 级别,左对齐,5个字符 %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;: 格式化日期 %c: 类的完整名称 %M: method方法名 %L: 行号 %thread: 线程名称 %m/%msg: 信息 %n: 换行 --&gt; &lt;!-- 定义打印pattern --&gt; &lt;property name=\"pattern\" value=\"%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %c [%thread] %-5level %msg%n\"/&gt; &lt;!-- 定义日志文件保存路径属性 --&gt; &lt;property name=\"logDir\" value=\"logback\"/&gt; &lt;!-- 控制台日志输出的appender --&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 控制输出流对象,默认System.out,改为System.err --&gt; &lt;target&gt;System.err&lt;/target&gt; &lt;!-- 日志消息格式配置 --&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 日志文件输出的appender --&gt; &lt;appender name=\"file\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;!-- 日志文件保存路径 --&gt; &lt;file&gt;$&#123;logDir&#125;/tmp.log&lt;/file&gt; &lt;!-- 日志消息格式配置 --&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- HTML格式日志文件输出appender --&gt; &lt;appender name=\"htmlFile\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;!-- 日志文件保存路径 --&gt; &lt;file&gt;$&#123;logDir&#125;/tmp.html&lt;/file&gt; &lt;!-- html日志消息格式配置 --&gt; &lt;encoder class=\"ch.qos.logback.core.encoder.LayoutWrappingEncoder\"&gt; &lt;layout class=\"ch.qos.logback.classic.html.HTMLLayout\"&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/layout&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 日志拆分和归档压缩的appender对象 --&gt; &lt;appender name=\"rollFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 日志文件保存路径 --&gt; &lt;file&gt;$&#123;logDir&#125;/roll_logback.log&lt;/file&gt; &lt;!-- 日志消息格式配置 --&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 指定拆分规则 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt; &lt;!-- 按照时间和压缩格式声明拆分的文件名 --&gt; &lt;!-- %i根据文件排序 --&gt; &lt;fileNamePattern&gt;$&#123;logDir&#125;/rolling.%d&#123;yyyy-MM-dd-HH-mm-ss&#125;.%i.log.gz&lt;/fileNamePattern&gt; &lt;!-- 按照文件大小拆分 --&gt; &lt;maxFileSize&gt;1MB&lt;/maxFileSize&gt; &lt;/rollingPolicy&gt; &lt;!-- 日志级别过滤器 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 日志过滤规则 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 异步日志 --&gt; &lt;appender name=\"async\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt; &lt;!-- 指定某个具体的appender --&gt; &lt;appender-ref ref=\"rollFile\"/&gt; &lt;/appender&gt; &lt;!-- root logger配置 --&gt; &lt;root level=\"ALL\"&gt; &lt;!-- &lt;appender-ref ref=\"console\"/&gt; &lt;appender-ref ref=\"file\"/&gt; &lt;appender-ref ref=\"htmlFile\"/&gt; --&gt; &lt;appender-ref ref=\"async\"/&gt; &lt;/root&gt; &lt;!-- 自定义logger对象 additivity: 自定义logger对象是否继承rootLogger --&gt; &lt;logger name=\"com.xiong.logger\" level=\"info\" additivity=\"false\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;/logger&gt;&lt;/configuration&gt; logback-access使用：logback-access模块与Servlet容器(如Tomcat、Jetty)集成以提供HTTP访问日志功能。可使用logback-access模块来替换tomcat的访问日志 将logback-access.jar与logback-core.jar复制到$TOMCAT_HOME/lib/目录下 修改$TOMCAT_HOME/conf/server.xml中的Host元素中添加： 1&lt;Valve className=\"ch.qos.logback.access.tomcat.LogbackValve\" /&gt; logback默认会在$TOMCAT_HOME/conf下查找文件logback-access.xml 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;!-- 参考自http://logback.qos.ch/access.html#configuration --&gt; &lt;!-- always a good activate OnConsoleStatusListener --&gt; &lt;statusListener class=\"ch.qos.logback.core.status.OnConsoleStatusListener\"/&gt; &lt;property name=\"LOG_DIR\" value=\"$&#123;catalina.base&#125;/logs\"/&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;$&#123;LOG_DIR&#125;/access.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;access.%d&#123;yyyy-MM-dd&#125;.log.zip&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;!-- 访问日志的格式 --&gt; &lt;pattern&gt;combined&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender-ref ref=\"FILE\"/&gt;&lt;/configuration&gt; log4j2入门(即是日志门面也是日志实现)： log4j2介绍：Apache Log4j2是对Log4j的升级版，参考了logback的一些优秀的设计，并且修复了一些问题，带来了一些重大的提升，主要有： 异常处理：在logback中，Appender中的异常不会被应用感知到；在log4j2中提供了一些异常处理机制 性能提升：log4j2相较于log4j和logback具有明显的性能提升 自动重载配置：参考了logback的设计，提供了自动刷新参数配置，在生产上可以动态地修改日志的级别而不需要重启应用 无垃圾机制：log4j2在大部分情况下都可以使用其设计的一套无垃圾机制，避免频繁的日志收集导致的JVM GC官网：https://logging.apache.org/log4j/2.x/ 入门案例： 123456789101112&lt;!-- Log4j2门面API--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Log4j2日志实现 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt; 12345678910111213// 定义日志记录器对象public static final Logger logger = LogManager.getLogger(Log4j2Test.class);// 快速入门@Testpublic void testQuick() &#123; // 日志消息输出 logger.error(\"error\"); logger.warn(\"warn\"); logger.info(\"info\"); logger.debug(\"debug\"); logger.trace(\"trace\");&#125; log4j2配置：log4j2默认加载classpath下的log4j2.xml文件中的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--status=\"debug\": warn为日志框架本身的输出日志级别monitorInterval=\"5\": 自动加载配置文件的间隔时间,不低于5s--&gt;&lt;Configuration status=\"debug\" monitorInterval=\"5\"&gt; &lt;!-- 集中配置属性进行管理,可以使用$&#123;&#125;获取 --&gt; &lt;properties&gt; &lt;property name=\"LOG_HOME\"&gt;log4j2&lt;/property&gt; &lt;/properties&gt; &lt;!-- 日志处理器 --&gt; &lt;Appenders&gt; &lt;!-- 控制台输出appender --&gt; &lt;Console name=\"Console\" target=\"SYSTEM_OUT\"&gt; &lt;PatternLayout pattern=\"%d&#123;HH:mm:ss.SSS&#125; [%t] [%-5level] %c&#123;36&#125;:%L - -- %m%n\"/&gt; &lt;/Console&gt; &lt;!-- 日志文件输出appender --&gt; &lt;File name=\"file\" fileName=\"$&#123;LOG_HOME&#125;/file.log\"&gt; &lt;PatternLayout pattern=\"[%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%-5level] %l %c&#123;36&#125; - %m%n\"/&gt; &lt;/File&gt; &lt;!-- 随机读写流输出appender,性能提高 --&gt; &lt;RandomAccessFile name=\"accessFile\" fileName=\"$&#123;LOG_HOME&#125;/accessFile.log\"&gt; &lt;PatternLayout pattern=\"[%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%-5level] %l %c&#123;36&#125; - %m%n\"/&gt; &lt;/RandomAccessFile&gt; &lt;!-- 按照一定的规则拆分日志文件appender filePattern拆分规则 --&gt; &lt;RollingFile name=\"rollingFile\" fileName=\"$&#123;LOG_HOME&#125;/rollingFile.log\" filePattern=\"log4j2/$$&#123;date:yyyy-MM-dd&#125;/rollingFile-%d&#123;yyyy- MM-dd-HH-mm&#125;-%i.log\"&gt; &lt;!-- 日志级别过滤器 --&gt; &lt;ThresholdFilter level=\"debug\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/&gt; &lt;!-- 日志消息格式 --&gt; &lt;PatternLayout pattern=\"[%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%-5level] %l %c&#123;36&#125; - %msg%n\"/&gt; &lt;!-- 策略 --&gt; &lt;Policies&gt; &lt;!-- 在系统启动时触发拆分规则,产生一个新日志文件 --&gt; &lt;OnStartupTriggeringPolicy/&gt; &lt;!-- 按照文件大小进行拆分,产生一个新日志文件 --&gt; &lt;SizeBasedTriggeringPolicy size=\"10 MB\"/&gt; &lt;!-- 按照时间节点拆分,规则由filePattern定义 --&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;/Policies&gt; &lt;!-- 在同一个目录下,文件个数限定,超过进行覆盖 --&gt; &lt;DefaultRolloverStrategy max=\"30\"/&gt; &lt;/RollingFile&gt; &lt;/Appenders&gt; &lt;!-- logger定义 --&gt; &lt;Loggers&gt; &lt;!-- 使用rootLogger配置以及level --&gt; &lt;Root level=\"trace\"&gt; &lt;AppenderRef ref=\"Console\"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; log4j2异步日志：log4j2最大的特点就是异步日志，其性能的提升也主要在异步日志Log4j2提供了两种实现异步日志的方式： 通过AsyncAppender，对应Appender组件 通过AsyncLogger，对应Logger组件 导入依赖(异步日志需要另外依赖) 123456&lt;!--异步日志依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.3.4&lt;/version&gt;&lt;/dependency&gt; AsyncAppender方式： 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Configuration status=\"warn\"&gt; &lt;properties&gt; &lt;property name=\"LOG_HOME\"&gt;logs&lt;/property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;File name=\"file\" fileName=\"$&#123;LOG_HOME&#125;/log4j2.log\"&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/File&gt; &lt;Async name=\"Async\"&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/Async&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=\"error\"&gt; &lt;AppenderRef ref=\"Async\"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; AsyncLogger方式：AsyncLogger才是log4j2的重头戏，也是官方推荐的异步方式。它可使调用Logger.log返回地更快。有两种选择：全局异步和混合异步 全局异步：所有的日志都异步的记录，在配置文件上不用做任何改动，只需要添加一个log4j2.component.properties配置 1Log4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector 混合异步：可在应用中同时使用同步日志和异步日志，这使得日志的配置方式更加灵活 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Configuration status=\"WARN\"&gt; &lt;properties&gt; &lt;property name=\"LOG_HOME\"&gt;logs&lt;/property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;File name=\"file\" fileName=\"$&#123;LOG_HOME&#125;/log4j2.log\"&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/File&gt; &lt;Async name=\"Async\"&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/Async&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;AsyncLogger name=\"com.xiong\" level=\"trace\" includeLocation=\"false\" additivity=\"false\"&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/AsyncLogger&gt; &lt;Root level=\"info\" includeLocation=\"true\"&gt; &lt;AppenderRef ref=\"file\"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 使用异步日志需要注意的问题： 如果使用异步日志，AsyncAppender、AsyncLogger和全局日志不要同时出现。性能会和AsyncAppender一致，降至最低(木桶原理) 需设置includeLocation=false，打印位置信息会急剧降低异步日志的性能，比同步日志还要慢 log4j2无垃圾记录：垃圾收集暂停是延迟峰值的常见原因。对于许多系统而言，需要花费大量精力来控制这些暂停许多日志库(包括以前版本的Log4j)在稳态日志记录期间分配临时对象，如日志事件对象、字符串、字符数组、字节数组等。这会对垃圾收集器造成压力并增加GC暂停发生的频率从版本2.6开始，默认情况下Log4j以”无垃圾”模式运行，重用对象和缓冲区，并且尽可能不分配临时对象。还有一个”低垃圾”模式，它不是完全无垃圾，但不使用ThreadLocal字段Log4j版本2.6中的无垃圾日志记录部分通过重用ThreadLocal字段中的对象来实现，部分通过在将文本转换为字节时重用缓冲区来实现有两个单独的系统属性可用于手动控制Log4j避免创建临时对象的机制： log4j2.enableThreadlocals：true(非Web应用程序的默认值)，则对象存储在ThreadLocal字段中并重新使用，否则将为每个日志事件创建新对象 log4j2.enableDirectEncoders：tru(默认)，则将日志事件转换为文本，此文本转换为字节而不创建临时对象。注意：由于共享缓冲区上的同步，在此模式下多线程应用程序的同步日志记录性能可能更差。如果应用程序是多线程的并且日志记录性能很重要，请考虑使用异步记录器 日志门面 背景：当系统变得更加复杂时，日志就容易发生混乱。随着系统开发的进行，可能会更新不同的日志框架，这会造成当前系统中存在不同的日志依赖，难以统一地管理和控制。就算强制要求所有的模块使用相同的日志框架，系统中也难以避免使用其他类似Spring、MyBatis等其他的第三方框架，它们依赖于不同的日志框架，而且它们自身的日志系统有着不一致性，依然会导致日志体系的混乱借鉴JDBC的思想，可为日志系统也提供一套门面，那么就可以面向这些接口规范来开发，免去直接依赖具体的日志实现框架 日志框架出现顺序：log4j -&gt; JUL -&gt; JCL -&gt; slf4j -&gt; logback -&gt; log4j2 具体日志门面框架： JCL入门： 介绍：JCL(Jakarta Commons Logging)是Apache提供的一个通用日志API。它为”所有的Java日志实现”提供一个统一的接口，它自身也提供一个简单日志的实现(SimpleLog,但功能非常常弱)。它允许使用不同的具体日志实现框架：Log4j、JDK自带的日志(JUL)以及SimpleLog。JCL有两个基本的抽象类：Log(基本记录器)和LogFactory(负责创建Log实例) 入门案例： 12345&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 1234567891011public void testQuick()&#123; // 获取log日志记录器对象 Log log = LogFactory.getLog(JCLTest.class); // 日志记录输出 log.info(\"Hello JCL\"); log.fatal(\"fatal\"); log.error(\"error\"); log.warn(\"warn\"); log.info(\"info\"); log.debug(\"debug\");&#125; JCL原理： 通过LogFactory动态加载Log实现类 获取具体的日志实现： 12345678private static final String[] classesToDiscover = new String[]&#123; \"org.apache.commons.logging.impl.Log4JLogger\", \"org.apache.commons.logging.impl.Jdk14Logger\", \"org.apache.commons.logging.impl.Jdk13LumberjackLogger\", \"org.apache.commons.logging.impl.SimpleLog\"&#125;;// ...// 默认加载第一个发现的日志实现框架for(int i = 0; i &lt; classesToDiscover.length &amp;&amp; result == null; ++i) &#123; result = this.createLogFromClass(classesToDiscover[i], logCategory, true);&#125; slf4j入门： 介绍：简单日志门面slf4j((Simple Logging Facade For Java))主要是为了给Java日志访问提供一套标准、规范的API框架。主要意义在于提供接口，具体的实现交由其他日志框架，如log4j2和logback等slf4j自身也提供功能较为简单的实现，但基本不使用。slf4j是目前市面上最流行的日志门面。现在项目中基本上都使用slf4j作为日志门面，配上具体的实现框架(log4j2、logback等)，中间使用桥接器完成桥接slf4j日志门面主要提供两大功能：日志框架的绑定和桥接官方网站：https://www.slf4j.org/ 入门案例： 123456789101112&lt;!--slf4j core 使用slf4j必須添加--&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!--slf4j 自带的简单日志实现 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223public static final Logger LOGGER = LoggerFactory.getLogger(Slf4jTest.class);@Testpublic void test01() &#123; // 日志输出 LOGGER.error(\"error\"); LOGGER.warn(\"warn\"); LOGGER.info(\"info\"); LOGGER.debug(\"debug\"); LOGGER.trace(\"trace\"); // 使用占位符输出日志信息 String name = \"SOBXiong\"; Integer age = 23; LOGGER.info(\"Name: &#123;&#125; , age: &#123;&#125;\", name, age); // 异常信息输出 try &#123; int i = 1 / 0; &#125; catch (Exception e) &#123; LOGGER.error(\"Error Occurs: \", e); &#125;&#125; slf4j的好处： 使用slf4j框架，可在部署时迁移到所需的日志记录框架 slf4j提供了对所有流行的日志框架的绑定，例如log4j，JUL，Simple logging和NOP等。因此可在部署时切换到任何这些框架 无论使用哪种绑定，slf4j都支持参数化日志记录消息。由于slf4j将应用程序和日志记录框架分离，因此可以轻松编写独立于日志记录框架的应用程序，而无需担心用于编写应用程序的日志记录框架 slf4j提供了一个简单的Java工具，称为迁移器。使用此工具，可以迁移现有项目到slf4j 绑定日志实现(Bind)：slf4j支持各种日志框架。slf4j发行版附带了几个称为”slf4j绑定”的jar包，每个绑定对应一个受支持的框架 绑定流程： 添加slf4j-api的依赖 使用slf4j的API在项目中进行统一的日志记录 绑定具体的日志实现框架 绑定已经实现了slf4j的日志框架：直接添加对应依赖 绑定没有实现slf4j的日志框架：先添加日志的适配器，再添加实现类的依赖 slf4j有且仅有一个日志实现框架的绑定(如果出现多个默认使用第一个依赖日志实现) 常用的绑定日志实现pom依赖： 123456789101112131415161718192021222324252627282930313233343536&lt;!-- slf4j core,使用slf4j必须添加 --&gt;&lt;!-- logback默认支持 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!-- log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jul --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jcl --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jcl&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!-- nop --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt; 绑定原理：要切换日志框架只需替换类路径上的slf4j绑定。例如从java.util.logging切换到log4j，只需将slf4j-jdk14.jar替换为slf4j-log4j12.jar即可slf4j不依赖于任何特殊的类装载。实际上每个slf4j绑定在编译时都是硬连线以使用一个且只有一个特定的日志记录框架。以下是一般概念的图解说明： 桥接旧日志框架(Bridge)通常，依赖的某些组件依赖于slf4j以外的日志记录API。假设这些组件在不久的将来不会切换到slf4j。为解决该情况，slf4j附带了几个桥接模块，这些模块将对log4j、JCL和java.util.logging的API调用重定向，就好像它们是对slf4j API操作一样桥接解决的是项目中日志的遗留问题，当系统中存在之前的日志API，可通过桥接转换到slf4j的实现： 先去除之前老的日志框架的依赖 添加slf4j提供的桥接组件 为项目添加slf4j的具体实现常用的桥接依赖： 123456789101112131415161718&lt;!-- log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jul --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt;&lt;!-- jcl --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.27&lt;/version&gt;&lt;/dependency&gt; 注意： jcl-over-slf4j.jar和slf4j-jcl.jar不能同时部署。前一个jar文件将导致JCL将日志系统的选择委托给slf4j，后一个jar文件将导致slf4j将日志系统的选择委托给JCL，从而导致无限循环(其余同理) 所有的桥接都只对Logger日志记录器对象有效，如果程序中调用了内部的配置类或者是Appender、Filter等对象，将无法产生效果 slf4j原理： slf4j通过LoggerFactory加载日志具体的实现对象 LoggerFactory在初始化的过程中，通过performInitialization()方法绑定具体的日志实现 在绑定具体实现时通过类加载器加载org/slf4j/impl/StaticLoggerBinder.class 因此只要是一个日志实现框架，且在org.slf4j.impl包中提供一个自己的StaticLoggerBinder类，提供具体日志实现的LoggerFactory，就可以被slf4j加载 SpringBoot中的日志 基本介绍：SpringBoot框架在企业中的使用越来越普遍，SpringBoot日志也是开发中常用的日志系统。SpringBoot默认采用slf4j作为日志门面，logback作为日志实现来记录日志 SpringBoot中的日志设计 1234&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 总结： 默认使用slf4j作为日志门面，logback作为日志实现 将jul和log4j转为slf4j \bSpringBoot中日志的使用： 修改默认日志配置： 123456logging.level.com.itheima=trace# 在控制台输出的日志的格式,同logbacklogging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] [%-5level] %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.file=logs/springboot.loglogging.pattern.file=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n 指定配置：在类路径下添加每个日志框架的配置文件时，SpringBoot就不使用默认配置 日志框架 配置文件 logback logback-spring.xml,logback.xml(直接被日志框架识别) log4j2 log4j2-spring.xml,log4j2.xml JUL logging.properties 使用SpringBoot解析日志配置 123456789&lt;!-- logback-spring.xml --&gt;&lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;springProfile name=\"dev\"&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=\"prod\"&gt; &lt;pattern&gt;%d&#123;yyyyMMdd:HH:mm:ss.SSS&#125; [%thread] %-5level %msg%n&lt;/pattern&gt; &lt;/springProfile&gt;&lt;/encoder&gt; 12# application.propertiesspring.profiles.active = dev 将日志切换为log4j2(log4j2 + slf4j是趋势) 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除logback --&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 添加log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[],"tags":[{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"}]},{"title":"设计模式","slug":"BasicSkill/DesignPattern","date":"2020-10-09T14:41:27.000Z","updated":"2020-11-07T08:41:41.524Z","comments":true,"path":"2020/10/09/BasicSkill/DesignPattern/","link":"","permalink":"https://sobxiong.github.io/2020/10/09/BasicSkill/DesignPattern/","excerpt":"内容 七大原则 UML类图 设计模式概述 单例模式 工厂模式 原型模式 建造者模式 适配器模式 桥接模式 装饰者模式 组合模式 外观模式 享元模式 代理模式 模板方法模式 命令模式 访问者模式 迭代器模式 观察者模式 中介者模式 备忘录模式 解释器模式 状态模式 策略模式 职责链模式","text":"内容 七大原则 UML类图 设计模式概述 单例模式 工厂模式 原型模式 建造者模式 适配器模式 桥接模式 装饰者模式 组合模式 外观模式 享元模式 代理模式 模板方法模式 命令模式 访问者模式 迭代器模式 观察者模式 中介者模式 备忘录模式 解释器模式 状态模式 策略模式 职责链模式 七大原则 设计模式目的：编写软件过程中，程序员面临着来自耦合性、内聚性、可维护性、可扩展性、重用性和灵活性等多方面的挑战，设计模式是为了让程序(软件)具有更好的 代码重用性(相同功能的代码,不用多次编写) 可读性(编程规范性,便于其他程序员的阅读和理解) 可扩展性(当需要增加新的功能时非常的方便,也称为可维护性) 可靠性(当我们增加新的功能后对原来的功能没有影响) 使程序呈现高内聚，低耦合的特性 设计模式原则其实就是程序员在编程时应当遵守的原则，也是各种设计模式的基础 设计原则核心思想： 找出应用中可能需要变化之处，把它们独立出来，不和不需要变化的代码混在一起 面向接口编程，而不是面向实现编程 为了交互对象之间的松耦合设计而努力 七大原则： 单一职责原则：一个类和方法只做一件事，一个类应该也只有一个引起它修改的原因 接口隔离原则：客户端不应依赖它不需要的接口 依赖倒转(倒置)原则：细节依赖抽象，下层依赖上层 里氏替换原则：子类应该可以完全替换父类。在使用继承时只扩展新功能而不破坏父类原有的功能 开闭原则：一个软件实体如类、模块和函数应该对修改封闭，对扩展开放 迪米特原则：最小知道原则，一个类不应知道自己操作的类的细节 合成复用原则 单一职责原则 基本介绍：对类来说一个类应该只负责一项职责。如类A负责两个不同职责——职责1和2。当职责1需求变更而改变A时，可能造成职责2执行错误，所以需要将类A的粒度分解为A1和A2 案例分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243// 原始方案// 交通工具类class Vehicle &#123; public void run(String vehicle) &#123; System.out.println(vehicle + \" 在公路上运行....\");&#125;&#125;Vehicle vehicle = new Vehicle();vehicle.run(\"摩托车\");vehicle.run(\"汽车\");vehicle.run(\"飞机\");// 改进方案1// 1、遵守单一职责原则// 2、但是这样做的改动很大,将类分解同时修改客户端class RoadVehicle &#123; public void run(String vehicle) &#123; System.out.println(vehicle + \"公路运行\");&#125;&#125;class AirVehicle &#123; public void run(String vehicle) &#123; System.out.println(vehicle + \"天空运行\");&#125;&#125;class WaterVehicle &#123; public void run(String vehicle) &#123; System.out.println(vehicle + \"水中运行\");&#125;&#125;RoadVehicle roadVehicle = new RoadVehicle();roadVehicle.run(\"摩托车\");roadVehicle.run(\"汽车\");AirVehicle airVehicle = new AirVehicle();airVehicle.run(\"飞机\");// 改进方案2// 1、没有对原来的类做大的修改,只是增加方法// 2、虽然没有在类这个级别上遵守单一职责原则,但在方法级别上仍然是遵守单一职责class Vehicle &#123; public void run(String vehicle) &#123; System.out.println(vehicle + \" 在公路上运行....\");&#125; public void runAir(String vehicle) &#123; System.out.println(vehicle + \" 在天空上运行....\");&#125; public void runWater(String vehicle) &#123; System.out.println(vehicle + \" 在水中行....\");&#125;&#125;Vehicle vehicle = new Vehicle();vehicle.run(\"摩托车\");vehicle.run(\"汽车\");vehicle.runAir(\"飞机\"); 注意事项和细节 降低类的复杂度，一个类只负责一项职责(尽量) 提高类的可读性、可维护性 降低变更引起的风险 通常情况下，我们应当遵守单一职责原则。只有逻辑足够简单时才可以在代码级违反单一职责原则；只有类中方法数量足够少时才可以在方法级别保持单一职责原则 接口隔离原则 基本介绍：客户端不应该依赖它不需要的接口(一个类对另一个类的依赖应该建立在最小的接口上) 案例分析： 改进措施：将接口Interface1拆分为独立的几个接口，类A和C分别与它们需要的接口建立依赖关系(也就是采用接口隔离原则) 改进结果： 123456789101112131415161718interface interface1 &#123; void operation1();&#125;interface interface2 &#123; void operation2(); void operation3();&#125;interface interface3 &#123; void operation4(); void operation5();&#125;class A implements interface1, interface2 &#123; // ...&#125;class B implements interface1, interface3 &#123; // ...&#125; 依赖倒转原则 基本介绍： 高层模块不应该依赖低层模块，二者都应该依赖其抽象 抽象不应该依赖细节，细节应该依赖抽象 依赖倒转(倒置)的中心思想是面向接口编程 设计理念：相对于细节的多变，抽象的东西要稳定的多。以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。在java中抽象指的是接口或抽象类，细节是具体的实现类 使用接口或抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成 案例分析： 12345678910111213141516171819202122232425262728293031323334// 原始版本// 如果我们getInfo需要微信、短信等消息// 则新增类同时Person类也要增加相应的接收方法class Email &#123; public String getInfo() &#123; return \"电子邮件信息: hello,world\";&#125;&#125;class Person &#123; public void receive(Email email) &#123; System.out.println(email.getInfo());&#125;&#125;Person person = new Person();person.receive(new Email());// 改进方案：引入一个抽象的接口IReceiver表示接收者// 这样Person类与接口IReceiver发生依赖// Email、WeiXin等属于接收者的范围,各自实现IReceiver接口,遵循了依赖倒转原则interface IReceiver &#123; public String getInfo();&#125;class Email implements IReceiver &#123; public String getInfo() &#123; return \"电子邮件信息: hello,world\";&#125;&#125;class WeiXin implements IReceiver &#123; public String getInfo() &#123; return \"微信信息: hello,ok\";&#125;&#125;// 新增接收者不需要对Person类进行改动class Person &#123; // 改为对接口IReceiver的依赖 public void receive(IReceiver receiver ) &#123; System.out.println(receiver.getInfo());&#125;&#125;Person person = new Person();person.receive(new Email());person.receive(new WeiXin()); 依赖关系传递的三种方式： 接口依赖 12345678910111213interface IRemote &#123; void closeTv(ITv tv);&#125;interface ITv &#123; void close(); &#125;class HuaweiTv implements ITv &#123; @Override public void close() &#123; System.out.println(\"Close Huawei TV~~~\");&#125;&#125;class Mate30Pro implements IRemote &#123; @Override public void closeTv(ITv tv) &#123; System.out.println(\"Mate30Pro close tv~~~\"); tv.close(); &#125;&#125; 构造方法传递 12345678910interface ITv &#123; void close();&#125;class HuaweiTv implements ITv &#123; @Override public void close() &#123; System.out.println(\"Close Huawei TV~~~\");&#125;&#125;class Mate30Pro &#123; private ITv tv; public Mate30Pro(ITv tv) &#123; this.tv = tv;&#125; public void close() &#123; this.tv.close();&#125;&#125; setter方式传递 12345678910interface ITv &#123; void close();&#125;class HuaweiTv implements ITv &#123; @Override public void close() &#123; System.out.println(\"Close Huawei TV~~~\");&#125;&#125;class Mate30Pro &#123; private ITv tv; public setTv(ITv tv) &#123; this.tv = tv;&#125; public void close() &#123; this.tv.close();&#125;&#125; 注意事项和细节： 低层模块尽量都要有抽象类或接口，或者两者都有，程序稳定性更好 变量的声明类型尽量是抽象类或接口，这样变量引用和实际对象间存在一个缓冲层，利于程序扩展和优化 继承时遵循里氏替换原则 里氏替换原则 OO(Object Oriented,面向对象)继承性的思考和说明： 继承包含这一层含义：父类中凡是已经实现好的方法，实际上是在设定规范和契约。虽然它不强制要求所有的子类必须遵循这些契约，但是如果子类对这些已经实现的方法任意修改，就会对整个继承体系造成破坏 继承在给程序设计带来便利的同时，也带来了弊端。如使用继承会给程序带来侵入性、程序的可移植性降低、增加对象间的耦合性；如果一个类被其他的类所继承，则当这个类需要修改时，必须考虑到所有的子类，并且父类修改后，所有涉及子类的功能都有可能产生错误 问题提出：在编程中，如何正确的使用继承?——遵循里氏替换原则 基本介绍： 里氏替换原则(Liskov Substitution Principle)在1988年由麻省理工学院的以为姓里的女士提出 如果每个类型为T1的对象o1都有类型为T2的对象o2，使得以T1定义的所有程序P在所有的对象o1都代换成o2时程序P的行为没有发生变化，那么类型T2是类型T1的子类型。换句话说，所有引用基类的地方必须都能透明地使用其子类的对象 在使用继承时，遵循里氏替换原则，在子类中尽量不重写父类的方法 里氏替换原则告诉我们继承实际上让两个类耦合性增强了，在适当的情况下，可通过聚合、组合和依赖来解决问题 开闭原则 基本介绍： 开闭原则(Open Closed Principle)是编程中最基础、最重要的设计原则 一个软件实体如类、模块和函数应该对扩展开放(对提供方)，对修改关闭(对使用方)。用抽象构建框架，用实现扩展细节 当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化 编程中设计模式和其他原则的基础就是开闭原则 案例分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 原始版本class GraphicEditor &#123; public void drawShape(Shape s) &#123; if (s.type == 1) drawRectangle(s); else if (s.type == 2) drawCircle(s); // 新增三角形 else if (s.type == 3) drawTriangle(s); &#125; public void drawRectangle(Shape r) &#123; System.out.println(\"Draw Rectangle\");&#125; public void drawCircle(Shape r) &#123; System.out.println(\"Draw Circle\");&#125; // 新增三角形 public void drawTriangle(Shape r) &#123; System.out.println(\"Draw Triangle\");&#125;&#125;class Shape &#123; int type;&#125;class Rectangle extends Shape &#123; Rectangle() &#123; super.type = 1;&#125;&#125;class Circle extends Shape &#123; Circle() &#123; super.type = 2;&#125;&#125;// 新增三角形class Triangle extends Shape &#123; Triangle() &#123; super.type = 3;&#125;&#125;GraphicEditor graphicEditor = new GraphicEditor();graphicEditor.drawShape(new Rectangle());graphicEditor.drawShape(new Circle());graphicEditor.drawShape(new Triangle());// 改进版本class GraphicEditor &#123; public void drawShape(Shape s) &#123; s.draw();&#125;&#125;interface Shape&#123; void draw();&#125;class Rectangle implements Shape &#123; @Override public void draw()&#123; System.out.println(\"Draw Rectangle\");&#125;&#125;class Circle implements Shape &#123; @Override public void draw()&#123; System.out.println(\"Draw Circle\");&#125;&#125;// 新增三角形class Triangle implements Shape &#123; @Override public void draw()&#123; System.out.println(\"Draw Triangle\");&#125;&#125;// 一样的调用方式GraphicEditor graphicEditor = new GraphicEditor();graphicEditor.drawShape(new Rectangle());graphicEditor.drawShape(new Circle());graphicEditor.drawShape(new Triangle()); 迪米特法则 基本介绍： 一个对象应该对其他对象保持最少的了解 类与类关系越密切，耦合度越大 迪米特法则(Demeter Principle)又叫最少知识原则，即一个类对自己依赖的类知道的越少越好。也就是说，对于被依赖的类不管多么复杂，都尽量将逻辑封装在类的内部。对外除了提供public方法，不对外泄露任何信息 迪米特法则还有个更简单的定义：只与直接的朋友通信 直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多：依赖、关联、组合和聚合等。其中称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类不是直接的朋友。也就是说，陌生的类最好不要以局部变量的形式出现在类的内部 注意事项和细节： 迪米特法则的核心是降低类之间的耦合 注意：迪米特法则只是要求降低类间(对象间)耦合关系，并不是要求完全没有依赖关系 合成复用原则(Composite Reuse Principle)：尽量使用合成/聚合的方式，而不是使用继承 UML类图 UML基本介绍： UML——Unified modeling language(统一建模语言)是一种用于软件系统分析和设计的语言工具，用于帮助软件开发人员进行思考和记录思路的结果 UML本身是一套符号的规定，就像数学符号和化学符号一样。这些符号用于描述软件模型中的各个元素和它们之间的关系，比如类、接口、实现、泛化、依赖、组合、聚合等 UML图分类： 用例图(use case) 静态结构图：类图(描述类与类之间的关系,是UML图中最核心的)、对象图、包图、组件图、部署图 动态行为图：交互图(时序图与协作图)、状态图、活动图 UML类图基本介绍： 用于描述系统中的类(对象)本身的组成和类(对象)之间的各种静态关系 类之间的关系：依赖、泛化(继承)、实现、关联、聚合与组合 类之间的关系： 依赖关系(Dependence)： 基本介绍：只要是在类中用到了对方，那么他们之间就存在依赖关系。如果没有对方，连编绎都通过不了 具体体现： 类的成员属性 类的成员方法的返回类型 类的成员方法接收的参数类型 类的成员方法中使用到 存在继承、实现等多态关系 泛化关系(Generalization)：泛化关系实际上就是继承关系，是依赖关系的特例 实现关系(Implementation)：实现关系实际上就是实现(接口)关系，是依赖关系的特例 关联关系(Association)： 基本介绍：关联关系实际上就是类与类之间的联系，是依赖关系的特例(引用数) 性质： 具有导航性：即双向或单向关系 具有多重性：如”1”(表示有且仅有一个)、”0…”(表示0个或者多个)、”0,1”(表示0个或1个),”n…m”(表示n到m个),”m…”(表示至少m个) 聚合关系(Aggregation)：表示的是整体和部分的关系，整体与部分可以分开。聚合关系是关联关系的特例，所以具有关联的导航性与多重性 组合关系(Composition)：也是整体与部分的关系，但是整体与部分不可以分开(逻辑或者代码层面上) 设计模式概述 基本介绍： 设计模式是程序员在面对同类软件工程设计问题所总结出来的有用的经验。设计模式不是代码，而是某类问题的通用解决方案，设计模式(Design pattern)代表了最佳的实践。这些解决方案是众多软件开发人员经过相当长的一段时间的试验总结出来的 设计模式的本质：提高软件的维护性、通用性和扩展性，降低软件的复杂度 设计模式并不局限于某种语言，Java，PHP，C++都有设计模式 类型： 创建型模式：单例模式、抽象工厂模式、原型模式、建造者模式、工厂模式 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式 行为型模式：模版方法模式、命令模式、访问者模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式(Interpreter模式)、状态模式、策略模式、职责链模式(责任链模式) 单例模式 介绍：保证一个类只有一个实例，哪怕多线程同时访问，并提供一个全局访问此实例的方法 典型场景： 数据库连接池 Spring中的单例Bean 单例设计模式的八种实现方式 饿汉式(静态常量) 案例代码： 12345678class Singleton &#123; // 1、构造器私有化(防止外部new) private Singleton() &#123;&#125; // 2、类内创建对象(静态常量) private final static Singleton instance = new Singleton(); // 3、向外暴露静态公共方法,返回单例instance public static Singleton getInstance() &#123; return instance;&#125;&#125; 优缺点总结： 优点：写法较简单，在类装载的时候就完成了实例化。避免了线程同步问题 缺点：在类装载时就完成了实例化，没有达到Lazy Loading(懒加载)的效果。如果从始至终未使用过这个实例，则会造成内存的浪费 该方式基于类加载机制避免了多线程的同步问题，instance在类装载时就实例化。虽然导致类装载的原因有很多种，在单例模式中大多数时候都是调用getInstance()方法。但不能确定有其他的方式(或者其他的静态方法)导致类装载，这时候初始化instance就没有达到Lazy Loading的效果 结论：该单例模式可用，但可能造成内存浪费(一般可忽略) 饿汉式(静态代码块) 案例代码： 123456789101112class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态变量实例 private static Singleton instance; // 3、在静态代码块中,创建单例对象 static &#123; instance = new Singleton(); &#125; // 4、提供一个公有静态方法,返回实例对象 public static Singleton getInstance() &#123; return instance;&#125;&#125; 优缺点总结： 该方式和方式一类似，过将类实例化的过程放在静态代码块中。在类装载时执行静态代码块中的代码，初始化类的实例。优缺点同方式一 结论：该单例模式可用，但可能造成内存浪费(一般可忽略) 懒汉式(线程不安全) 案例代码： 1234567891011class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态变量实例 private static Singleton instance; // 3、提供一个公有静态方法,当调用该方法时才去创建instance实例 public static Singleton getInstance() &#123; if(instance == null) instance = new Singleton(); return instance; &#125;&#125; 优缺点总结： 起到了Lazy Loading的效果，但只能在单线程下使用 在多线程下，当一个线程进入了if判断语句块，还未来得及往下执行；同时另一个线程也通过了这个判断语句，这时便会产生多个实例。所以在多线程环境下不可使用这种方式 结论：在实际开发中，不使用这种方式 懒汉式(线程安全,同步方法) 案例代码： 1234567891011class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态变量实例 private static Singleton instance; // 3、提供一个公有静态方法,当调用该方法时才去创建instance实例(声明为同步方法,解决线程安全问题) public static synchronized Singleton getInstance() &#123; if(instance == null) &#123; instance = new Singleton();&#125; return instance; &#125;&#125; 优缺点总结： 解决了线程安全问题 效率太低了，每个线程在想获得该类的实例时执行getInstance()方法都要进行同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例，直接return即可。方法进行同步效率太低 结论：在实际开发中，不推荐使用这种方式 懒汉式(线程不安全,同步代码块) 案例代码： 123456789101112131415class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态变量实例 private static Singleton instance; // 3、提供一个公有静态方法,当调用该方法时才去创建instance实例(加入synchronized同步代码块,还存在线程安全问题) public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 优缺点总结： 还存在线程安全问题(都进入到判断后,未开始同步,会实例化两次) 结论：在实际开发中，不使用这种方式 双重检查(Double-Check) 案例代码： 12345678910111213141516class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态变量实例(volatile声明,内存可见) private static volatile Singleton instance; // 3、提供一个公有静态方法,设置双重检查,解决线程安全问题,同时解决懒加载问题,保证了效率,推荐使用 // 几乎解决了线程安全问题 public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton();&#125; &#125; &#125; return instance; &#125;&#125; 优缺点总结： Double-Check概念是多线程开发中常使用到的。进行了两次if检查，这几乎可以保证线程安全 实例化代码只执行一次，再次访问时直接返回实例化对象。也避免反复进行方法同步 线程安全、延迟加载、效率较高 结论：在实际开发中推荐使用该方式 静态内部类 案例代码： 123456789101112class Singleton &#123; // 1、私有化构造器 private Singleton() &#123;&#125; // 2、声明静态内部类,该类中有一个静态常量Singleton private static class SingletonInstance &#123; private static final Singleton INSTANCE = new Singleton(); &#125; // 3、提供一个公有静态方法,直接返回静态内部类中的静态常量INSTANCE public static synchronized Singleton getInstance() &#123; return SingletonInstance.INSTANCE; &#125;&#125; 优缺点总结： 该方式在Singleton类被装载时并不会立即实例化，而是在首次调用getInstance()方法时装载SingletonInstance类，从而完成Singleton的实例化 类的静态属性只会在第一次加载类的时候初始化，在这里JVM帮助我们保证了线程的安全性。在类进行初始化时其他线程是无法进入的 优点：避免了线程不安全，利用静态内部类特点实现延迟加载，效率高 结论：推荐使用 枚举 案例代码： 1234567// 1、声明枚举类enum Singletion&#123; // 2、声明一个实例 INSTANCE; // 测试方法 public void sayOK() &#123; System.out.println(\"ok~\");&#125;&#125; 优缺点总结： 借助JDK1.5中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象 在有继承的场景下不适用 结论：推荐使用(Effective Java作者推荐) 源码中的应用： 1234567// Runtime.class// 采用饿汉式创建,因为其他地方需要用到,不会产生内存浪费public class Runtime &#123; private Runtime() &#123;&#125; private static Runtime currentRuntime = new Runtime(); public static Runtime getRuntime() &#123; return currentRuntime;&#125;&#125; 单例模式注意事项和细节说明： 单例模式保证了系统内存中该类只存在一个对象，节省了系统资源。对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能 当想实例化一个单例类的时候，要使用相应的获取对象的方法(通常是getInstance())，而不是使用new创建 单例模式使用的场景：需要频繁地进行创建和销毁的对象、创建对象耗时过多或耗费资源过多(即重量级对象)但又经常用到的对象、工具类对象、频繁访问数据库或文件的对象(比如数据源、session工厂等) 工厂模式 问题背景：在平时编程中，构建对象最常用的方式是new一个对象。乍一看这种做法没什么不好，而实际上这也属于一种硬编码。每new一个对象，相当于调用者多知道了一个类，增加了类与类之间的联系，不利于程序的松耦合。其实构建过程可以被封装起来，工厂模式便是用于封装对象的设计模式 简单工厂模式 基本介绍：让一个工厂类继承构建所有对象的职责(将构建工作封装到一个工厂类中) 案例代码： 123456789101112131415161718192021222324// 只是对传统方式做了一层简单的封装class PhoneFactory &#123; // 调用处代码修改较小,大多只需在工厂类中修改 public Phone create(String brand) &#123; // 如果某个构造方式相当复杂,可以大大减少代码重复 switch (brand) &#123; case \"apple\": return new IPhone(); case \"huawei\": &#123; Phone phone = new Mate() // 具体设置工作... return phone; &#125; default: throw new IllegalArgumentException(\"No other brands now~~~\"); &#125; &#125;&#125;// 调用PhoneFactory factory = new PhoneFactory();// 直接new需要知道mate和iphone的具体构造细节Phone mate = factory.create(\"huawei\");Phone iphone = factory.create(\"apple\");mate.takePhoto();iphone.takePhoto(); 弊端： 如果需生产的产品过多会导致工厂类过于庞大，承担过多的职责，变成超级类。每个产品生产过程的修改都需要修改工厂类(不止一个引起修改的原因)。违背了单一职责原则 当要生产新的产品时，必须在工厂类中添加新的判断分支。而开闭原则告诉我们：类应该对修改封闭。即添加新功能时最好只需增加新的类，而不是修改既有的类 工厂方式模式： 由来：为了解决简单工厂的两处弊端 基本介绍：定义一个创建对象的抽象方法，由子类决定要实例化的类。工厂方法模式将对象的实例化推迟到子类 案例代码： 123456789101112131415161718192021222324252627/*1、产品种类增加时不会变成超级工厂,工厂类会变多,保持灵活2、改变只需改变对应工厂的方法3、新增产品,无需修改已有的工厂,只需添加新工厂*/// 注意：factory接口必须声明慎重,更改接口需要更改所有的工厂类interface PhoneFactory &#123; Phone create();&#125;public class AppleFactory implements PhoneFactory &#123; public Phone create() &#123; return new IPhone(); &#125;&#125;public class HuaweiFactory implements PhoneFactory&#123; public Phone create() &#123; return new Mate(); &#125;&#125;// 调用PhoneFactory appleFactory = new AppleFactory();Phone iphone = appleFactory.create();PhoneFactory huaweiFactory = new HuaweiFactory();Phone mate = huaweiFactory.create();iphone.takePhoto();mate.takePhoto(); 抽象工厂模式： 基本介绍：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。简单来说工厂方法是创建出一种产品，抽象工厂则是创建一类产品 案例代码： 1234567891011121314151617interface TerminalFactory &#123; Phone create(); Pad create(); Watch ceate();&#125;public class AppleFactory implements TerminalFactory &#123; public Phone create() &#123; return new IPhone(); &#125; public Pad create() &#123; return new IPad(); &#125; public Watch create() &#123; return new Watch(); &#125;&#125;// ... 源码中的应用(简单工厂)： 123456789101112131415161718192021222324252627Calendar.getInstance();// Calendar.classpublic static Calendar getInstance() &#123; return createCalendar(TimeZone.getDefault(), Locale.getDefault(Locale.Category.FORMAT));&#125;private static Calendar createCalendar(TimeZone zone, Locale aLocale) &#123; // ... Calendar cal = null; if (aLocale.hasExtensions()) &#123; String caltype = aLocale.getUnicodeLocaleType(\"ca\"); if (caltype != null) &#123; switch (caltype) &#123; case \"buddhist\": cal = new BuddhistCalendar(zone, aLocale); break; case \"japanese\": cal = new JapaneseImperialCalendar(zone, aLocale); break; case \"gregory\": cal = new GregorianCalendar(zone, aLocale); break; &#125; &#125; &#125; // ...&#125; 总结： 工厂模式的意义：将实例化对象的代码提取出来放到一个类中统一管理和维护，达到解耦的目的，从而提高项目的扩展和维护性 设计模式的依赖抽象原则： 创建对象实例时尽量不要直接new，而是封装到工厂的方法中 尽量不要让类继承具体类，而是继承抽象类或者是实现接口 尽量不要覆盖基类中已经实现的方法 原型模式 传统方式 案例代码： 12345678910111213141516// 以买周董同款奶茶为例public class MilkTea &#123; private String type; private boolean isCold;&#125;MilkTea jZhouMilkTea = new MilkTea();jZhouMilkTea.type = \"珍珠奶茶\";jZhouMilkTea.isCold = true;// 假复制(和周董喝的是同一杯奶茶)MilkTea xiongMilkTea = jZhouMilkTea;// 真复制MilkTea xiongMilkTea = new MilkTea();xiongMilkTea.type = jZhouMilkTea.type;xiongMilkTea.isCold = jZhouMilkTea.isCold; 优缺点： 优点：比较好理解，简单易操作 如果对象的属性较多或需要复制的数量较多，那么会造成大量的重复 如果对象改变，使用复制的代码也需进行较大的改动 原型模式 基本介绍： 原型模式(Prototype)指用原型实例指定创建对象的细节，通过拷贝原型创建新的对象 原型模式是一种创建型设计模式，允许通过一个对象再创建另外一个可定制的对象而无需知道如何创建的细节 Java中原生支持——Object的clone()方法 案例代码： 123456789101112131415// Java自带的clone()方法是浅拷贝,只有基本类型的属性会被拷贝,类类型几乎都是传递引用(String等除外)public class MilkTea implements Cloneable&#123; private String type; private boolean isCold; @Override public MilkTea clone() throws CloneNotSupportedException &#123; return (MilkTea) super.clone(); &#125;&#125;MilkTea jZhouMilkTea = new MilkTea();jZhouMilkTea.type = \"珍珠奶茶\";jZhouMilkTea.isCold = true;MilkTea xiongMilkTea = jZhouMilkTea.clone(); 注意事项和细节： 创建新的对象比较复杂时可以利用原型模式简化对象的创建过程，同时也能够提高效率 不用重新初始化对象，而是动态地获得对象运行时的状态 如果原始对象发生变化(增加或者减少属性)，其它克隆对象的也会发生相应的变化，无需修改代码 在实现深克隆的时候可能需要比较复杂的代码 源码中的应用：Java中的Object的clone()方法，采用C++ Cloneable接口，否则运行时出错 浅拷贝和深拷贝： 浅拷贝介绍： 对于数据类型是基本数据类型的成员变量，浅拷贝会直接进行值传递(将该属性值复制一份给新的对象) 对于数据类型是引用数据类型的成员变量(某个数组、某个类的对象等)，那么浅拷贝会进行引用传递(实际也是值拷贝,引用值拷贝)，即只是将该成员变量的引用值(内存地址)复制一份给新的对象。因此实际上两个对象的该成员变量都指向同一个实例。在该情况下，在一个对象中修改该成员变量会影响到另一个对象的该成员变量值 Java Object的clone()方法默认就是浅拷贝 深拷贝介绍： 复制对象的所有基本数据类型的成员变量值 为所有引用数据类型的成员变量申请存储空间，复制每个引用数据类型成员变量所引用的对象(该对象可达的所有对象)。即对象进行深拷贝要对整个对象(包括对象的引用类型)进行拷贝 在Java中可通过以下两种方式实现深拷贝： 自定义类中实现cloneable接口重写clone()方法 通过对象序列化 案例代码： 123456789101112131415161718192021222324252627282930313233public class Test implements Serializable, Cloneable &#123; private static final long serialVersionUID = 1L; private String value;&#125;public class DeepCloneObject implements Serializable, Cloneable &#123; public String name; public Test test; @Override protected Object clone() throws CloneNotSupportedException &#123; Object obj = null; obj = super.clone(); DeepCloneObject deepObj = (DeepCloneObject) obj; deepObj.test = (Test) test.clone(); return deepObj; &#125; public Object deepClone() &#123; // 序列化 try (ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.write(this); ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis)) &#123; // 反序列化 DeepCloneObject deepObj = (DeepCloneObject) ois.readObject(); return deepObj; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 建造者模式 基本介绍： 建造者模式(Builder Pattern)是一种对象构建模式。将一个复杂的构建与其表示想分离，使同样的构建过程可以创建不同的表示 传统的建造者模式采用”建造者-指挥者”方式 现在的建造者模式主要用来链式调用生成不同的配置 案例代码： 123456789101112131415161718192021222324252627282930313233343536373839public class MilkTea &#123; private String name; private double price; private boolean addIce; private MilkTea() &#123;&#125; // ...getter/setter public static class Builder &#123; private MilkTea milkTea = new MilkTea(); public Builder() &#123; milkTea.setName(\"珍珠奶茶\"); milkTea.setPrice(12.5d); milkTea.setAddIce(true); &#125; public Builder setName(String name) &#123; milkTea.setName(name); return this; &#125; public Builder setPrice(double price) &#123; milkTea.setPrice(price); return this; &#125; public Builder addIce(boolean addIce) &#123; milkTea.setAddIce(addIce); return this; &#125; public MilkTea build() &#123; return milkTea; &#125; &#125;&#125;MilkTea milkTea = new MilkTea.Builder().setName(\"波霸奶茶\").addIce(true).build(); 源码中的应用：OkHttp、Retrofit等 适配器模式(待完善) 基本介绍：适配器模式(Adapter Pattern)是结构型模式，将某个类的接口转换成客户端期望的另一个接口表示，目的是兼容性，让原本因接口不匹配不能一起工作的两个类可以协同工作。其别名为包装器(Wrapper) 具体介绍： 类适配器模式： 基本介绍：Adapter类，通过继承src类，实现dst类接口，完成src到dst的适配 注意事项和细节： Java是单继承机制，类适配器需要继承src类。这就要求dst必须是接口，有一定局限性 src类的方法在Adapter中都会暴露出来，增加了使用的成本 由于继承了src类，可根据需求重写src类的方法，使得Adapter的灵活性增强 对象适配器模式： 基本介绍： 基本思路和类适配器模式相同，Adapter类不继承src类，而持有src类的实例以解决兼容性的问题——即持有src类对象，实现dst类接口，完成src到dst的适配 根据”合成复用原则”，在系统中尽量使用关联关系(聚合)来替代继承关系 对象适配器模式是适配器模式常用的一种 注意事项和细节： 对象适配器和类适配器算是同一种思想，只不过实现方式不同 根据合成复用原则，使用组合替代继承。解决了类适配器必须继承src的局限性问题，也不再要求dst必须是接口 使用成本更低，更灵活 接口适配器模式： 一些书籍称为缺省适配器模式 核心思想：当无需实现接口提供的全部方法时，可先设计一个抽象类实现接口，并为该接口中每个方法提供一个默认实现(空实现)。则该抽象类的子类可有选择地覆盖父类的某些方法来实现需求 适用于一个接口不使用其所有的方法的情况 源码中的应用：通过jdbc访问SQLServer(jdbc-odbc) 桥接模式 基本介绍： 桥接模式(Bridge Pattern)是一种结构型设计模式，指将实现与抽象放在两个不同的类层次中，使两个层次可以独立改变 桥接模式基于类的最小设计原则，通过使用封装、聚合及继承等行为让不同的类承担不同的职责。主要特点是把抽象(Abstraction)与行为实现(Implementation)分离开来，从而保持各部分的独立性以及应对他们的功能扩展 传统模式： 需求1：绘三种图案：矩形、圆形和三角形 解决方案： 12345678910111213141516// 依据OOP思想,三个具体实现类一个抽象接口public interface Shape&#123; void draw();&#125;class Rectangle implements Shape&#123; @Override public void draw()&#123; System.out.println(\"Draw Rectangle~~~\"); &#125;&#125;class Circle implements Shape&#123; @Override public void draw()&#123; System.out.println(\"Draw Circle~~~\"); &#125;&#125;class Triangle implements Shape&#123; @Override public void draw()&#123; System.out.println(\"Draw Triangle~~~\"); &#125;&#125; 需求2：在1的基础上添加颜色选择，每种颜色都需有四种不同颜色 解决方案： 复用形状，将具体形状定义为父类，每种不同颜色的图形继承其形状父类，共12个类 复用颜色，将每种颜色定义为父类，每种不同颜色的图形继承其颜色父类，共12个类 采用桥接模式，将形状与颜色分离，根据需要对颜色和形状组合，不会产生类爆炸问题 1234567891011121314public interface Color&#123; String getColor();&#125;public class Red implements Color&#123; @Override public String getColor()&#123; return \"red\"; &#125;&#125;// Yellow Blue Green...class Rectange implements Shape()&#123; private Color color; void setColor(Color color)&#123; this.color = color; &#125; @Override public void draw()&#123; System.out.println(\"Draw \" + color.getColor() + \"Triangle~~~\"); &#125;&#125; 注意事项和细节： 实现了抽象和实现部分的分离，从而极大地提高了系统的灵活性。让抽象部分和实现部分独立开来，这有助于系统进行分层设计，从而产生更好的结构化系统 桥接模式替代多层继承方案，可以减少子类的个数，降低系统的管理和维护成本 桥接模式要求正确识别出系统中两个独立变化的维度(抽象、和实现)，其使用范围有一定的局限 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用 装饰者模式 基本介绍： 装饰者模式动态地将新功能附加到对象上。在对象功能扩展方面比继承更有弹性，体现了开闭原则(OCP) 主要作用： 增强一个类原有的功能 为一个类添加新的功能 案例代码： 12345678910111213141516171819public interface Condiment&#123; void getCondiment();&#125;public class Milk implements Condiment&#123; @Override public void getCondiment()&#123; System.out.println(\"Milk~~~\"); &#125;&#125;public class IceDecorator implements Condiment&#123; private final Condiment origin; public IceDecorator(Condiment condiment)&#123; origin = condiment; &#125; @Override public void getCondiment()&#123; System.out.println(\"Add Ice~~~\"); origin.getCondiment(); &#125;&#125;Condiment condiment = new IceDecorator(new Milk());Condiment.getCondiment(); 源码中的应用： 1234567// FilterInputStream.classpublic class FilterInputStream extends InputStream &#123; protected volatile InputStream in; protected FilterInputStream(InputStream in) &#123; this.in = in; &#125;&#125; 组合模式 基本介绍：组合模式(Composite Pattern)又叫部分整体模式，属于结构型模式。用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象来表示部分以及整体层次 案例代码： 123456789101112131415161718192021public abstract class File &#123; private String name; private Date createTime; abstract public void printInfo();&#125;public class ConcreteFile extends File &#123; @Override public void printInfo() &#123; System.out.println(\"ConcreteFile name: \" + name + \" , createTime: \" + createTime); &#125;&#125;public class Folder extends File&#123; private List&lt;File&gt; childFiles = new ArrayList&lt;&gt;(); public void addFile(File file)&#123; childFiles.add(file);&#125; @Override public void printInfo() &#123; System.out.println(\"Folder name: \" + name + \" , createTime: \" + createTime); for (File file : childFiles) &#123; file.printInfo(); &#125; &#125;&#125; 注意事项和细节： 能简化客户端操作，客户端只需要面对一致的对象而不用考虑整体部分或者节点叶子的问题 具有较强的扩展性，当要更改组合对象时只需要调整内部的层次关系，客户端不用做出任何改动 方便创建出复杂的层次结构。客户端不用理会组合里的组成细节，易添加节点从而创建出复杂的树形结构 需要遍历组织机构或处理的对象具有树形结构时，非常适合使用组合模式 要求较高的抽象性，如果非叶节点和叶节点有很多差异性的话，比如很多方法和属性都不一样，不适合使用组合模式 外观模式 基本介绍：外观模式(Facade Pattern)又名门面模式。外部与一个子系统的通信必须通过一个统一的外观对象进行，为子系统的一组接口提供一个一致的界面，外观模式定义了一个高层接口，使得子系统更易使用 注意事项和细节： 外观模式对外屏蔽了子系统的细节，降低了客户端使用子系统的复杂性；使客户端与子系统解耦，子系统内部的模块更易维护和扩展 当系统需进行分层设计时可考虑使用Facade模式 维护一个遗留的大型系统时，可能该系统已变得非常难以维护和扩展。此时可考虑为新系统开发一个Facade类来提供遗留系统较清晰简单的接口，让新系统与Facade类交互，提高复用性 合理地使用外观模式可以更好地划分访问层次，不能过多或不合理地使用外观模式。使用外观模式好还是直接调用模块好取决于问题复杂度和实际情况。要以让系统有层次和利于维护为目的 享元模式 基本介绍： 通过运用共享技术有效地支持大量细粒度的对象 常用于系统底层开发，解决系统的性能问题。像数据库连接池，里面都是创建好的连接对象，需要时可以直接使用，避免重新创建；如果没有线程再创建 能够解决对象重复创建销毁的资源耗费。当系统中有大量相似对象需要缓冲池时，不需总是创建新对象，而是从缓冲池里拿 经典的应用场景就是池技术——String常量池、数据库连接池、缓冲池等；享元模式是池技术的重要实现方式 内部状态和外部状态 享元模式提出了两个要求：细粒度和共享对象。这就涉及到内部状态和外部状态了，即将对象的信息分为两个部分——内部状态和外部状态 内部状态指对象共享出来的信息，存储在享元对象内部且不会随环境的改变而改变 外部状态指对象得以依赖的一个标记，是随环境改变而改变、不可共享的状态 源码中的应用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 测试案例// 第二次把127全替换为200Integer[] integers = new Integer[]&#123; Integer.valueOf(127), new Integer(127), Integer.valueOf(127), new Integer(127)&#125;;for (int i = 0; i &lt; integers.length; i++) &#123; for (int j = i + 1; j &lt; integers.length; j++) &#123; System.out.println(String.format(\"i%d.equals(i%d)[%s], i%d == i%d[%s]\", i, j, integers[i].equals(integers[j]), i, j, integers[i] == integers[j])); &#125;&#125;/* 第一次结果： i0.equals(i1)[true], i0 == i1[false] i0.equals(i2)[true], i0 == i2[true] i0.equals(i3)[true], i0 == i3[false] i1.equals(i2)[true], i1 == i2[false] i1.equals(i3)[true], i1 == i3[false] i2.equals(i3)[true], i2 == i3[false]*/// Integer.classpublic final class Integer extends Number implements Comparable&lt;Integer&gt; &#123; // 如果i在[low, high]区间,在cache中获取,否则返回新创建的对象 public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; // 内部缓存,使用享元模式 private static class IntegerCache &#123; // 最低-128 static final int low = -128; static final int high; static final Integer cache[]; static &#123; // 最高127,但可以通过VM设置 // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; // 在静态初始化时把[-128, 127]全加入缓存 for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125;&#125; 注意事项和细节 “享”表示共享，”元”表示对象 系统中有大量对象且这些对象消耗大量内存并且对象的状态大部分可以外部化时，可考虑选用享元模式 用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。大多用HashMap/HashTable存储 大大减少了对象的创建开销，降低了程序内存的占用，提高效率 提高了系统的复杂度，需剥离出内部状态和外部状态。外部状态具有固化特性，不随内部状态的改变而改变。此为使用享元模式需要注意的地方 要注意划分内部状态和外部状态，并且通常需要一个工厂类加以控制 代理模式 基本介绍： 代理模式：为一个对象提供一个替身以控制对该对象的访问。通过代理对象访问目标对象的好处是——可在目标对象实现的基础上，增强额外的功能操作——即扩展目标对象的功能 被代理的对象可以是远程对象、创建开销大的对象或需要安全控制的对象 代理模式有不同的形式，主要有三种：静态代理、JDK代理(又名接口代理,底层采用asm)和Cglib代理(可在内存动态地创建对象,无需实现接口,属于动态代理的范畴,底层采用asm) 静态代理 基本介绍：静态代理在使用时需要定义接口或父类，被代理对象(即目标对象)与代理对象一起实现相同的接口或是继承相同父类(形如装饰模式,但重在控制) 案例代码： 1234567891011121314151617181920212223public interface ITestDao &#123; void test();&#125;public class TestDao implements ITestDao &#123; @Override public void test() &#123; System.out.println(\"TestDao test()~~~\"); &#125;&#125;public class TestDaoProxy implements ITestDao&#123; private ITestDao target; public TestDaoProxy(ITestDao target) &#123; this.target = target; &#125; @Override public void test() &#123; System.out.println(\"Enter TestDaoProxy test()~~~\"); target.test(); System.out.println(\"Leave TestDaoProxy test()~~~\"); &#125;&#125;ITestDao testDao = new TestDao();TestDaoProxy testDaoProxy = new TestDaoProxy(testDao);testDaoProxy.test(); 优缺点总结： 优点：在不修改目标对象功能前提下能通过代理对象对目标功能进行扩展 缺点：因代理对象需要与目标对象实现一样的接口，因此会有很多代理类，一旦接口增加方法，目标对象与代理对象都要维护 JDK代理： 基本介绍： 代理对象不需要实现接口，但目标对象要实现接口，否则不能用动态代理 代理对象的生成是利用JDK的API，动态地在内存中构建代理对象 案例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243public interface ITestDao &#123; void test(); void testWithParam(String value);&#125;public class TestDao implements ITestDao &#123; @Override public void test() &#123; System.out.println(\"TestDao test()~~~\"); &#125; @Override public void testWithParam(String value) &#123; System.out.println(\"TestDao testWithParam(\" + value + \")~~~\"); &#125;&#125;public class ProxyFactory &#123; // 维护一个目标对象 private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; // 生成代理对象 public Object getProxyInstance() &#123; // ClassLoader loader：指定当前目标对象使用的类加载,获取加载器的方法是固定的 // Class&lt;?&gt;[] interfaces：目标对象实现的接口类型,使用泛型方式确定类型 // InvocationHandler h：事件处理,执行目标对象方法时会触发事件处理器方法,会把当前目标对象方法作为参数传入 return Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), (Object proxy, Method method, Object[] args) -&gt; &#123; System.out.println(\"Jdk Proxy start~~~\"); // 反射机制调用目标对象方法 Object result = method.invoke(target, args); System.out.println(\"Jdk Proxy end~~~\"); return result; &#125;); &#125;&#125;// 给目标对象创建代理对象ITestDao proxyInstance = (ITestDao)new ProxyFactory(new TestDao()).getProxyInstance();proxyInstance.test();System.out.println(proxyInstance.testWithParam(\"Hello Proxy\"));System.out.println(proxyInstance);System.out.println(proxyInstance.getClass()); Cglib代理 基本介绍： 静态代理和JDK代理模式都要求目标对象实现一个接口，但有时候目标对象只是一个单独的对象且并没有实现任何的接口，这时候可使用目标对象子类来实现代理——Cglib代理 Cglib代理也叫作子类代理，它在内存中构建一个子类对象从而实现对目标对象功能的扩展，一些资料也将Cglib代理归属到动态代理 Cglib是一个强大的高性能的代码生成包，它可在运行期扩展java类与实现java接口。它广泛地被许多AOP框架使用，如Spring AOP，用于实现方法拦截 在AOP编程中如何选择代理模式： 目标对象需要实现接口，用JDK代理 目标对象不需要实现接口，用Cglib代理 Cglib包的底层是通过使用字节码处理框架ASM来转换字节码并生成新的类 注意事项： 需要引入cglib的jar文件(Spring中集成了Cglib的使用) 注意代理的类不能为final，否则报错——java.lang.IllegalArgumentException 目标对象的方法如果为final/static方法，那么就不会被拦截——即不会执行目标对象额外的业务方法 案例代码： 123456789101112131415161718192021222324252627282930313233public class TestDao &#123; public void test() &#123; System.out.println(\"TestDao test()~~~\"); &#125;&#125;public class ProxyFactory implements MethodInterceptor &#123; // 维护一个目标对象 private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; // 生成代理对象 public Object getProxyInstance() &#123; // 1、创建一个工具类 Enhancer enhancer = new Enhancer(); // 2、设置父类 enhancer.setSuperclass(target.getClass()); // 3、设置回调函数 enhancer.setCallback(this); // 4、创建子类对象即代理对象 return enhancer.create(); &#125; // 重写intercept方法,会调用目标对象的方法 @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Cglib Proxy start~~~\"); Object result = method.invoke(target, args); System.out.println(\"Cglib Proxy end~~~\"); return result; &#125;&#125;TestDao proxyInstance = (TestDao) new ProxyFactory(new TestDao()).getProxyInstance();proxyInstance.test();System.out.println(proxyInstance);System.out.println(proxyInstance.getClass()); 几种常见的代理模式(常见变体) 缓存代理：如当请求图片文件等资源时，先到缓存代理取，如果取不到资源再到公网或者数据库取，然后缓存 远程代理：通过远程对象的本地代表可以把远程对象当本地对象来调用。远程代理通过网络和真正的远程对象沟通信息 同步代理：主要使用在多线程编程中完成多线程间同步工作 模板方法模式 基本介绍： 模板方法模式(Template Method Pattern)又叫模板模式，属于行为型模式。在一个抽象类公开定义执行方法的模板。子类可按需重写方法实现，但调用将以抽象类中定义的方式进行 模板方法模式定义一个操作中算法的骨架，而将一些步骤延迟到子类，这使得子类可以不改变一个算法的结构就可以重定义算法的某些特定步骤 注意事项和细节： 基本思想：算法只存在于一个地方也就是在父类中，容易修改。需要修改算法时只需修改父类的模板方法或已经实现的某些步骤，子类就会继承这些修改 实现了代码复用的最大化。父类的模板方法和已实现的某些步骤会被子类继承直接使用 既统一了算法也提供了很大的灵活性。父类的模板方法确保算法结构保持不变，同时由子类提供部分步骤的实现 模式的不足之处：每一个不同的实现都需要一个子类实现，这会导致类的个数增加，使得系统更加庞大 不希望子类覆写的方法(模版方法)用final修饰；要求子类必须覆写的方法用abstract修饰 模板方法模式使用场景：当要完成在某个过程，该过程要执行一系列步骤且这一系列的步骤基本相同，但其个别步骤在实现时可能不同。这种情况下通常考虑用模板方法模式来处理 命令模式 基本介绍：命令模式(Command Pattern)将一个请求封装为一个对象，可参数化请求对象，支持对请求排队、记录和撤销的操作 案例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public interface ICommand &#123; void execute(); void undo();&#125;public class LightOpenCommand implements ICommand &#123; Light light; public LightOpenCommand(Light light) &#123; this.light = light;&#125; @Override public void execute() &#123; System.out.println(\"Monitor light turn on~~~\"); light.open(); &#125; @Override public void undo() &#123; System.out.println(\"Monitor light turn off~~~\"); light.close(); &#125;&#125;public class LightCloseCommand implements ICommand &#123; Light light; public LightCloseCommand(Light light) &#123; this.light = light; &#125; @Override public void execute() &#123; System.out.println(\"Monitor light turn off~~~\"); light.close(); &#125; @Override public void undo() &#123; System.out.println(\"Monitor light turn on~~~\"); light.open(); &#125;&#125;public class TelevisionOpenCommand implements ICommand &#123; Television television; public TelevisionOpenCommand(Television television) &#123; this.television = television; &#125; @Override public void execute() &#123; System.out.println(\"Monitor television turn on~~~\"); television.open(); &#125; @Override public void undo() &#123; System.out.println(\"Monitor television turn off~~~\"); television.close(); &#125;&#125;public class TelevisionCloseCommand implements ICommand &#123; Television television; public TelevisionCloseCommand(Television television) &#123; this.television = television; &#125; @Override public void execute() &#123; System.out.println(\"Monitor television turn off~~~\"); television.close(); &#125; @Override public void undo() &#123; System.out.println(\"Monitor television turn on~~~\"); television.open(); &#125;&#125;public class MicroCommand implements ICommand &#123; List&lt;ICommand&gt; iCommands; public MicroCommand(List&lt;ICommand&gt; iCommands) &#123; this.iCommands = iCommands;&#125; @Override public void execute() &#123; System.out.println(\"MicroCommand execute~~~\"); for (ICommand iCommand : iCommands) &#123; iCommand.execute(); &#125; &#125; @Override public void undo() &#123; System.out.println(\"MicroCommand undo~~~\"); for (ICommand iCommand : iCommands) &#123; iCommand.undo(); &#125; &#125;&#125;Light light = new Light();ICommand lightOpenCommand = new LightOpenCommand(light);ICommand lightCloseCommand = new LightCloseCommand(light);Television television = new Television();ICommand televisionOpenCommand = new TelevisionOpenCommand(television);ICommand televisionCloseCommand = new TelevisionCloseCommand(television);ICommand microCommand = new MicroCommand(Arrays.asList(lightCloseCommand, lightOpenCommand, televisionOpenCommand, televisionCloseCommand));lightOpenCommand.execute();lightOpenCommand.undo();lightCloseCommand.execute();lightCloseCommand.undo();televisionOpenCommand.execute();televisionOpenCommand.undo();televisionCloseCommand.execute();televisionCloseCommand.undo();microCommand.execute();microCommand.undo(); 注意事项和细节： 容易设计一个命令队列。只要把命令对象放到列队就可以多线程地执行命令 容易实现请求的撤销和重做 可能导致某些系统有过多的具体命令类，增加了系统的复杂度 空命令也是一种设计模式，它省去了判空的操作 经典应用场景：界面的一个按钮都是一条命令、模拟CMD(DOS命令)、订单的撤销/恢复、触发-反馈机制 访问者模式 基本介绍： 访问者模式(Visitor Pattern)封装一些作用于某种数据结构各元素的操作，使得可在不改变数据结构的前提下定义作用于这些元素的新操作 核心思想：将数据结构与数据操作分离，解决数据结构和操作耦合性问题 基本工作原理：在被访问的类中加一个对外提供访问的接口(accept) 主要应用场景：需要对一个对象结构中的对象进行很多不同操作(这些操作彼此没有关联)，同时需避免这些操作”污染”这些对象的类 案例代码： 12345678910111213141516171819202122232425262728293031323334353637public class Chip &#123; private String name; private double value; public void visit(Visitor visitor)&#123; visitor.accept(this); &#125;&#125;public interface Visitor &#123; void accept(Chip chip);&#125;public class AMD implements Visitor &#123; @Override public void accept(Chip chip) &#123; chip.setName(\"Ryzen 9 5950X Design\"); chip.setValue(4000); &#125;&#125;public class TSMC implements Visitor &#123; @Override public void accept(Chip chip) &#123; chip.setName(\"Ryzen 9 5950X Original Entrusted Manufacture\"); chip.setValue(4500); &#125;&#125;public class TMALL implements Visitor &#123; @Override public void accept(Chip chip) &#123; chip.setName(\"Ryzen 9 5950X Sell\"); chip.setValue(5500); &#125;&#125;Chip chip = new Chip();List&lt;Visitor&gt; capitalists = Arrays.asList(new AMD(), new TSMC(), new TMALL());for (Visitor capitalist : capitalists) &#123; chip.visit(capitalist); logger.info(\"Visit By &#123;&#125; , Chip -&gt; &#123;&#125; , &#123;&#125;\", capitalist.getClass().getSimpleName(), chip.getName(), chip.getValue());&#125; 注意事项和细节： 优点： 符合单一职责原则、使程序具有优秀的扩展性、灵活性非常高 可对功能进行统一，可应用于报表、UI、拦截器与过滤器等场景，适用于数据结构相对稳定的系统 缺点 具体元素对访问者公布细节，即访问者关注了其他类的内部细节，违背了迪米特法则且具体元素变更比较困难 违背了依赖倒转原则。访问者依赖的是具体元素，而不是抽象元素 总结：如果一个系统有比较稳定的数据结构，又有经常变化的功能需求，那么访问者模式就比较合适 迭代器模式 基本介绍：迭代器模式(Iterator Pattern)属于行为型模式，它提供一种方法访问一个容器对象中各个元素，而又无需暴露该对象的内部细节 源码中的应用：JDK(Collection.class, Iterator.class) 注意事项和细节： 优点 提供一个统一的方法遍历对象 隐藏了对象内部细节 隐藏了一种设计思想：一个类应只有一个引起变化的原因(单一责任原则)。剥离迭代器，把管理对象集合和遍历对象集合的责任分开 当要展示一组相似对象或遍历一组相同对象时，适合使用迭代器模式 缺点：当遍历细节不同时，会生成多个具体迭代器类 观察者模式 基本介绍：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新 源码中的应用：JDK中的Observable和Observer类 中介者模式 基本介绍：中介者模式(Mediator Pattern)属于行为型模式，定义一个中介对象来封装一系列对象之间的交互。使原来有对象的耦合松散，且可以独立地改变它们之间的交互 注意事项和细节： 多个类相互耦合会形成网状结构，使用中介者模式将网状结构分离为星型结构，进行解耦 减少类间依赖，降低了耦合，符合迪米特原则 中介者承担了较多的责任，需要处理所有类之间的协调工作，一旦中介者出现了问题，整个系统就会受到影响 如果设计不当，中介者对象本身会变得过于复杂 备忘录模式 基本介绍：备忘录模式(Memento Pattern)属于行为型模式，在不破坏封装性的条件下，通过备忘录对象存储另一个对象内部状态的快照，在将来合适时把这个对象还原到存储时的状态 注意事项和细节： 为用户提供了一种可以恢复状态的机制，可使用户能比较方便地回到某个历史的状态 实现了信息的封装，使得用户无需关心状态的保存细节 消耗资源：如果类的成员变量过多，势必会占用比较大的资源，且每一次保存都会消耗一定的内存 适用的应用场景： 打游戏时的存档 Windows里的Ctrl + z 浏览器中的后退 数据库的事务管理 解释器模式 基本介绍： 在编译原理中，一个表达式通过词法分析器形成词法单元，而后这些词法单元再通过语法分析器构建语法分析树，最终形成一颗抽象的语法分析树。这里词法分析器和语法分析器都可以看做是解释器 解释器模式(Interpreter Pattern)：给定一门语言(表达式)，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子(表达式) 将不可拆分的最小单元称之为终结表达式，可被拆分的表达式称之为非终结表达式 注意事项和细节： 应用场景：编译器、运算表达式计算、正则表达式、机器人等 可能带来的问题：解释器模式会引起类膨胀；解释器模式通常采用递归，这将会导致调试复杂、运行效率降低 状态模式 基本介绍： 状态模式(State Pattern)主要用来解决对象在多种状态转换时需要对外输出不同的行为的问题。状态和行为是一一对应的，状态之间可以相互转换 当一个对象的内在状态改变时允许改变其行为，这个对象看起来像是改变了其类 注意事项和细节： 代码有很强的可读性。状态模式将每个状态的行为封装到对应的一个类中 方便维护。将容易产生问题的if-else语句删除了，如果把每个状态的行为都放到一个类中，每次调用方法时都要判断当前是什么状态，不但会产出很多if-else语句，而且容易出错 符合”开闭原则”，容易增删状态 会产生很多类。每个状态都需要一个对应的类，当状态过多时会产生很多类，加大维护难度 应用场景：当一个事件或者对象有多种状态，状态之间会相互转换，对不同的状态要求有不同的行为时可考虑状态模式 策略模式 基本介绍：定义了一系列算法，并将每一个算法封装起来，且使它们可以相互替换。策略模式让算法独立于使用它的客户而独立变化。简单来说，即殊途同归——当我们做同一件事有多种方式时可将每种方法封装起来，在不同的场景选择不同的策略，调用不同的方法 源码中的应用：图片加载框架(Glide,picaso等)缓存策略 注意事项和细节： 关键是分析项目中变化部分与不变部分 注意多用组合/聚合、少用继承 体现了OCP原则，客户端增加行为不用修改原有代码，只要添加一种策略(或者行为)即可，避免使用多重if-else 每添加一个策略就要增加一个类，当策略过多时会导致类数目庞大 更好的实践：与工厂模式结合，将不同的策略对象封装到工厂类中，只需传递不同的策略类型从工厂中获取对应的策略对象 职责链模式 基本介绍： 职责链模式(Chain of Responsibility Pattern)又叫责任链模式，属于行为型模式。它为请求创建了一个处理者对象的链，对请求的发送者和接收者进行解耦 通常每个处理者都包含对另一个处理者的引用。如果一个处理者不能处理该请求，那么它会把该请求传给下一个处理者，依此类推 源码中的应用：javax包下的FilterChain、SpringMVC包装的FilterChain 注意事项和细节： 将请求和处理分开，实现解耦，提高系统的灵活性 责任分担，每个处理者只处理自身该处理的任务，其余交由下一个处理者完成或提前返回 性能会受到影响，特别是在链比较长的时候。因此需控制链中最大节点数量 采用了类似递归的方式，调试不方便","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"}]},{"title":"Docker","slug":"BasicSkill/Docker","date":"2020-10-09T07:22:59.000Z","updated":"2020-12-16T01:55:39.332Z","comments":true,"path":"2020/10/09/BasicSkill/Docker/","link":"","permalink":"https://sobxiong.github.io/2020/10/09/BasicSkill/Docker/","excerpt":"内容 Docker简介 Docker安装 Docker常用命令 Docker镜像 Docker容器数据卷 Dockerfile Docker安装步骤 Docker镜像发布","text":"内容 Docker简介 Docker安装 Docker常用命令 Docker镜像 Docker容器数据卷 Dockerfile Docker安装步骤 Docker镜像发布 Docker简介 Docker是什么： Docker出现背景： 一款产品从开发到上线，从操作系统，到运行环境，再到应用配置。开发/运维之间的协作需要我们关心很多东西，特别是各种版本的迭代之后，不同版本环境的兼容，对运维人员都是考验 Docker之所以发展如此迅速，就是因为它对此给出了一个标准化的解决方案 环境配置如此麻烦，换一台机器，就要重来一次，费力费时。能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。利用Docker可以消除协作编码时”在我的机器上可正常工作”的问题 之前在服务器配置一个应用的运行环境，要安装各种软件，有时还不能跨平台，移植应用也非常麻烦 传统上认为，软件编码开发和测试环节结束后，所产出的成果即是程序或是能够编译执行的二进制字节码等。为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件。开发需要清楚地告诉运维部署团队用的全部配置文件和所有软件环境，即便如此仍然会发生部署失败的状况。Docker镜像的设计打破过去”程序即应用”的观念。透过镜像(images)将作业系统核心除外地运行应用程序所需要的系统环境，由下而上打包，达到应用程序跨平台间的无缝接轨运行 Docker理念： Docker是基于Go语言实现的云开源项目 Docker的主要目标是”Build, Ship and Run Any App, Anywhere”。即通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP(可以是一个WEB应用或数据库应用等)及其运行环境能够做到”一次封装，到处运行“ Linux容器技术的出现就解决了这样一个问题，而Docker就是在它的基础上发展过来的。将应用运行在Docker容器上面，Docker容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作 总结：解决了运行环境和配置问题软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术 Docker与传统虚拟机技术 虚拟机技术： 虚拟机(virtual machine)是带环境安装的一种解决方案。 可以在一种操作系统里面运行另一种操作系统(Windows系统里面运行Linux系统)，应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样。而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美地运行了另一套系统，能够使应用程序、操作系统和硬件三者之间的逻辑不变 虚拟机的缺点： 资源占用多 冗余步骤多 启动慢 容器虚拟化技术： 由于前面虚拟机存在这些缺点，Linux发展出了另一种虚拟化技术——Linux容器(Linux Containers,缩写为LXC) Linux容器并不模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行 Docker和传统虚拟化方式的不同之处： 传统虚拟机技术是虚拟出一套硬件后在其上运行一个完整操作系统，再在该系统上再运行所需的应用进程 容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便 每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源 Docker能干嘛： 开发/运维(DevOps,一次构建、随处运行)： 一次构建、随处运行：传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间 更便捷的升级和扩缩容：随着微服务架构和Docker的发展，大量的应用会通过微服务方式构建。应用的开发构建将变成搭乐高积木一样，每个Docker容器将变成一块”积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级 更简单的系统运维：应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复 更高效的计算资源利用：Docker是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的Hypervisor支持，所以在一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率 Docker去哪下： 官网：https://www.docker.com/ 镜像仓库：https://hub.docker.com/ Docker安装 前提：Docker只能运行在CentOS-6.5或更高的版本的CentOS上，要求系统为64位、系统内核版本为2.6.32-431或者更高版本(以CentOS为例) Docker的基本组成： 镜像(image)：Docker镜像就是一个只读的模板。镜像可以用来创建容器，一个镜像可以创建多个容器 容器(container)： Docker利用容器独立运行的一个或一组应用。容器是用镜像创建的运行实例 它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的Linux环境(包括root用户权限、进程空间、用户空间和网络空间等)和运行在其中的应用程序 容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的 仓库(repository)： 仓库是集中存放镜像文件的场所 仓库(Repository)和仓库注册服务器(Registry)是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签(tag) 仓库分为公开仓库(Public)和私有仓库(Private)两种形式 最大的公开仓库是Docker Hub，里面存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云等 总结： 区分并理解仓储/镜像/容器这些概念 Docker本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是image镜像文件。只有通过这个镜像文件才能生成Docker容器。image文件可以看作是容器的模板。Docker根据image文件生成容器的实例。同一个image文件可以生成多个同时运行的容器实例 image文件生成的容器实例本身也是一个文件，称为镜像文件 一个容器运行一种服务，当我们需要的时候就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 仓储是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以 安装步骤(CentOS7) 参考网址：https://docs.docker.com/engine/install/centos/ 具体步骤： 卸载老版本依赖 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 设置yum仓库(repository) 1234sudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 下载最新版本Docker(ce版本——免费,ee版本——商业收费) 1sudo yum install docker-ce docker-ce-cli containerd.io 启动Docker服务 123sudo systemctl start docker# 设置docker服务开机自启动sudo systemctl enable docker 卸载Docker： 123456# 关闭docker服务sudo systemctl stop docker# 删除docker包和依赖sudo yum remove docker-ce docker-ce-cli containerd.io# 删除docker libsudo rm -rf /var/lib/docker 测试docker：docker version 配置docker阿里云镜像加速：控制台 -&gt; 容器镜像服务 -&gt; 镜像加速器 -&gt; 查看操作文档 永远的hello world： 运行：docker run hello-world run hello-world的流程： 底层原理 Docker是怎么工作的：Docker是一个CS结构的系统，Docker守护进程运行在主机上，通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。容器是一个运行时环境，就是”🐳背上的集装箱” 为什么Docker比虚拟机(VM)快： docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化，运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker会在效率上有明显优势 docker利用的是宿主机的内核，而不需要Guest OS。因此当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核。从而避免引寻、加载操作系统内核等比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载Guest OS，整个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统、省略了新建过程，新建一个docker容器只需要几秒钟 Docker常用命令 帮助命令： docker version docker info docker –help 镜像命令： docker images [Options] 介绍：列出本地主机上的镜像 显示参数介绍： REPOSITORY：表示镜像的仓库源 TAG：镜像的标签 IMAGE ID：镜像ID CREATED：镜像创建时间 SIZE：镜像大小同一仓库源可以有多个TAG，代表这个仓库源的不同个版本，我们使用REPOSITORY:TAG来定义不同的镜像如果不指定一个镜像的版本标签，docker将默认使用centos:latest镜像(系统为CentOS) 常用Options说明： -a：列出本地所有的镜像(含中间映像层) -q：只显示镜像id –digests：显示镜像的摘要信息 –no-trunc：显示完整的镜像信息 docker search [Options] 镜像名 默认搜索源：https://hub.docker.com 常用Options说明： –no-trunc：显示完整的镜像描述 -s：列出收藏数不小于指定值的镜像 –automated：只列出automated build类型的镜像 docker pull 镜像名[:标签]：下载指定镜像 docker rmi：删除镜像 删除单个：docker rmi -f 镜像id/镜像名[:标签] 删除多个：docker rmi -f 镜像名1[:标签] 镜像名2[:标签] 删除全部：docker rmi -f $(docker images -qa) 容器命令： 新建并启动容器(有镜像才能创建容器)：docker run [Options] image [Command] [args…] 常用Options说明： --name dockerName：为容器指定一个名称 -d：后台运行容器，并返回容器ID(也即启动守护式容器) -i：以交互模式运行容器，通常与-t同时使用 -t：为容器重新分配一个伪输入终端，通常与-i同时使用 -P: 随机端口映射 -p: 指定端口映射，有以下四种格式: ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 举例： 12# 使用镜像centos:latest以交互模式启动一个容器,在容器内执行/bin/bash命令docker run -it centos /bin/bash 说明： 操作：docker run -d centos 现象：然后使用docker ps -a进行查看运行的容器，会发现容器已经退出 原因：Docker容器后台运行，就必须有一个前台进程。容器运行的命令如果不是那些一直挂起的命令(比如运行top、tail)，就会自动退出。这是docker的机制问题，比如web容器。以nginx为例，正常情况下，我们配置启动服务只需要启动响应service即可，例如service nginx start。但是这样做，nginx以后台进程模式运行，就导致docker前台没有运行的应用。这样的容器后台启动后，会立即自杀。因为它觉得无事可做。因此最佳的解决方案是将你要运行的程序以前台进程的形式运行 列出当前所有正在运行的容器：docker ps [OPTIONS] 常用Options说明： -a：列出当前所有正在运行、历史上运行过的容器 -l：显示最近创建的容器 -n：显示最近n个创建的容器 -q：静默模式，只显示容器编号 –no-trunc：不截断输出 退出容器(两种方式) 容器停止退出：exit 容器不停止退出：ctrl+P+Q 启动容器：docker start 容器id/容器名 停止容器：docker stop 容器id/容器名 强制停止容器：docker kill 容器id/容器名 删除已停止的容器： 删除单个容器：docker rm 容器id 一次性删除多个容器(-f——force强制,关闭已启动的)： docker rm -f 容器id1 容器id2 … docker rm -f $(docker ps -a -q) docker ps -a -q | xargs docker rm 查看容器日志：docker logs -f -t –tail 条数 容器id 参数说明： -t：加入时间戳 -f：跟随最新的日志打印 –tail num：显示最后多少条 查看容器内运行的进程：docker top 容器id 查看容器内部细节(资源、配置)：docker inspect 容器id 进入正在运行的容器并以命令行交互： 两种方式： docker exec -it 容器id /bin/bash docker attach 容器id 两种方式区别： attach：直接进入容器启动命令的终端，不会启动新的进程 exec：是在容器中打开新的终端，并且可以启动新的进程 从容器内拷贝文件到主机上：docker cp 容器id:容器文件路径 主机文件路径 命令一览： 命令 介绍 attach Attach to a running container(当前shell下attach连接指定运行镜像) build Build an image from a Dockerfile(通过Dockerfile定制镜像) commit Create a new image from a container changes(提交当前容器为新的镜像) cp Copy files/folders from the containers filesystem to the host path(从容器中拷贝指定文件或者目录到宿主机中) create Create a new container(创建一个新的容器,同run,但不启动容器) diff Inspect changes on a container’s filesystem(查看docker容器变化) events Get real time events from the server(从docker服务获取容器实时事件) exec Run a command in an existing container(在已存在的容器上运行命令) export Stream the contents of a container as a tar archive(导出容器的内容流作为一个tar归档文件,对应import) history Show the history of an image(展示一个镜像形成历史) images List images(列出系统当前镜像) import Create a new filesystem image from the contents of a tarball(从tar包中的内容创建一个新的文件系统映像,对应export) info Display system-wide information(显示系统相关信息) inspect Return low-level information on a container(查看容器详细信息) kill Kill a running container(kill指定docker容器) load Load an image from a tar archive(从一个tar包中加载一个镜像,对应save) login Register or Login to the docker registry server(注册或者登陆一个 docker源服务器) logout Log out from a Docker registry server(从当前Docker registry退出) logs Fetch the logs of a container(输出当前容器日志信息) port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT(查看映射端口对应的容器内部源端口) pause Pause all processes within a container(暂停容器) ps List containers(列出容器列表) pull Pull an image or a repository from the docker registry server(从docker镜像源服务器拉取指定镜像或者库镜像) push Push an image or a repository to the docker registry server(推送指定镜像或者库镜像至docker源服务器) restart Restart a running container(重启运行的容器) rm Remove one or more containers(移除一个或者多个容器) rmi Remove one or more images(移除一个或多个镜像——无容器使用该镜像才可删除,否则需删除相关容器才可继续或-f强制删除) run Run a command in a new container(创建一个新的容器并运行一个命令) save Save an image to a tar archive(保存一个镜像为一个tar包,对应load) search Search for an image on the Docker Hub(在docker hub中搜索镜像) start Start a stopped containers(启动容器) stop Stop a running containers(停止容器) tag Tag an image into a repository(给源中镜像打标签) top Lookup the running processes of a container(查看容器中运行的进程信息) unpause Unpause a paused container(取消暂停容器) version Show the docker version information(查看docker版本号) wait Block until a container stops, then print its exit code(截取容器停止时的退出状态值) Docker镜像 是什么：镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件。它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件 UnionFS(联合文件系统,类比花卷)： 介绍：Union文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统。它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像(没有父镜像)，可以制作各种具体的应用镜像 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统。联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 Docker镜像加载原理： docker的镜像实际上由一层一层的文件系统(UnionFS)组成 bootfs(boot file system)主要包含bootloader和kernel，bootloader主要是引导加载kernel。Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs rootfs(root file system)在bootfs之上。包含典型Linux系统中的/dev、/proc、/bin和/etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等 为什么Docker中CentOS镜像出奇的小？(平时安装进虚拟机的CentOS都是好几个G,docker里才200M)对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了。因为底层直接用Host的kernel，自己只需要提供rootfs就行。由此可见对于不同的linux发行版，bootfs基本是一致的，rootfs会有差别，因此不同的发行版可以公用bootfs Docker镜像采用分层结构的理由：最大好处就是共享资源。比如有多个镜像都从相同的base镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像，同时内存中也只需加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享 特点：Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作”容器层”，”容器层”之下的都叫”镜像层” commit命令补充 命令介绍：提交容器副本使之成为一个新的镜像 命令格式：docker commit -m=”提交的描述信息” -a=”作者” 容器id 要创建的目标镜像名:[标签] Docker容器数据卷 是什么：Docker的理念是将软件与运行的环境打包形成容器运行，运行可以伴随着容器。但对数据的要求希望是持久化的、容器之间希望有可能共享数据。Docker容器产生的数据如果不通过docker commit生成新的镜像使得数据作为镜像的一部分保存下来，那么当容器删除后，数据自然也就没有了。为了能保存数据在docker中我们使用卷。卷类似Redis里面的rdb和aof文件 能干嘛： 容器的持久化 容器间继承+共享数据 卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过Union File System提供一些用于持续存储或共享数据的特性。卷的设计目的就是数据的持久化，它完全独立于容器的生存周期，Docker不会在容器删除时删除其挂载的数据卷 特点： 数据卷可在容器之间共享或重用数据 卷中的更改可以直接生效 数据卷中的更改不会包含在镜像的更新中 数据卷的生命周期一直持续到没有容器使用它为止 数据卷添加 直接命令添加：docker run -it -v /主机目录路径:/容器目录路径 镜像名 查看是否成功：docker inspect 容器id 容器停止退出后，主机修改后数据依然同步 设置只读(read only,容器)：docker run -it -v /主机目录路径:/容器目录路径:ro 镜像名 Dockerfile添加： 在新建Dockerfile添加volume指令： 1234# 说明: 处于可移植和分享的考虑# 使用-v 主机目录:容器目录这种方式不能直接在Dockerfile中实现# 宿主机目录是依赖于特定宿主机的,并不能够保证在所有的宿主机上都存设定的特定目录VOLUME [\"/dataVolumeContainer\"] 完整Dockerfile： 12345# volume testFROM centosVOLUME [\"/dataVolumeContainer1\", \"/dataVolumeContainer2\"]CMD echo \"Build Docker with Volume succeed~~~\"CMD /bin/bash 完整流程： 编写上述Dockerfile build生成镜像：docker build -f Dockerfile -t sobxiong/centos . run运行容器：docker run -it sobxiong/centos /bin/bash 查看目录是否存在，测试创建文件并写入内容 查看宿主机对应目录：docker inspect 容器id 前往对应目录查看内容 数据卷容器 是什么：命名的容器挂载数据卷，其它容器通过挂载这个(父容器)实现数据共享。挂载数据卷的容器称为数据卷容器 前提：以sobxiong/centos为模板运行容器test1，它具有/dataVolumeContainer1和/dataVolumeContainer2容器卷 容器间传递共享： 先启动父容器test1，并在dataVolumeContainer2中新增内容 以继承方式启动test2和test3：docker run -it –name test2 –volumes-from test1 sobxiong/centos test2和test3分别在dataVolumeContainer2中新增内容 test1中可以看到新增的内容 删除test1后，test2修改的内容test3依旧可读 删除test2后，test3依旧可读之前内容 新建test4继承test3再删除test3，之前内容依旧可见 结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止 Dockerfile 是什么：用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本 构建三步骤： 编写Dockerfile文件 docker build docker run Dockerfile具体实例 123456# 以CentOS镜像为例# https://github.com/CentOS/sig-cloud-instance-images/blob/12a4f1c0d78e257ce3d33fe89092eee07e6574da/docker/DockerfileFROM scratchADD centos-8-x86_64.tar.xz /LABEL org.label-schema.schema-version=\"1.0\" org.label-schema.name=\"CentOS Base Image\" org.label-schema.vendor=\"CentOS\" org.label-schema.license=\"GPLv2\" org.label-schema.build-date=\"20200809\"CMD [\"/bin/bash\"] Dockerfile基础知识： 每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令按照从上到下，顺序执行 ‘#’表示注释 每条指令都会创建一个新的镜像层，并对镜像进行提交 执行Dockerfile的大致流程 docker从基础镜像(scratch)运行一个容器 执行一条指令并对容器作出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行Dockerfile中的下一条指令直到所有指令都执行完成 小总结： 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段： Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件的运行态 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石： Dockerfile：定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务、内核进程打交道时,需要考虑如何设计namespace的权限控制)等等 Docker镜像：在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行Docker镜像时真正开始提供服务 Docker容器：直接提供服务 Dockerfile体系结构(保留字指令) FROM：基础镜像，当前新镜像是基于哪个镜像的 MAINTAINER：镜像维护者的姓名和邮箱地址 RUN：容器构建时需要运行的命令 EXPOSE：当前容器对外暴露出的端口 WORKDIR：指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 ENV：用来在构建镜像过程中设置环境变量 123# 环境变量可以在后续的任何RUN指令中使用,就如同在命令前面指定了环境变量前缀一样# 也可以在其它指令中直接使用这些环境变量,如：WORKDIR $MY_PATHENV MY_PATH /usr/mytest ADD：将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包 COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中源路径的文件/目录复制到新的一层的镜像内的目标路径位置 COPY src dest COPY [“src”, “dest”] VOLUME：容器数据卷，用于数据保存和持久化工作 CMD：指定一个容器启动时要运行的命令；Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT：指定一个容器启动时要运行的命令；ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及参数(不像CMD,不会被替换,都生效) ONBUILD：当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发 小总结： 案例： Base镜像(scratch)：Docker Hub中99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的 自定义镜像mycentos： 编写： 目标： 基于centos镜像 登陆后默认路径为/ 安装vim编辑器 安装net-tools(支持ifconfig) 内容： 12345678910FROM centosMAINTAINER sobxiongENV MYPATH /usr/localWORKDIR $MYPATHRUN yum -y install vimRUN yum -y install net-toolsEXPOSE 80CMD echo $MYPATHCMD echo \"success--------------ok\"CMD /bin/bash 构建：docker build -f Dockerfile -t 新镜像名:Tag . 运行：docker run -it 新镜像名:Tag 列出镜像变更历史：docker history 镜像名 CMD/ENTRYPOINT：均指定一个容器启动时要运行的命令 CMD：Dockerfile中可以有多个CMD 指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT：docker run之后的参数会被当做参数传递给ENTRYPOINT，之后形成新的命令组合 总结： Docker安装步骤 搜索镜像 拉取镜像 查看镜像 启动镜像 停止容器 移除容器 Docker镜像发布 发布流程(阿里云) 生成镜像： 从Dockerfile构建 从容器创建一个新镜像：docker commit [Options] 容器id [Repository[:Tag]] 将本地镜像推送到阿里云 登陆阿里云 创建仓库镜像：命名空间、仓库名称 根据提示推送镜像到registery(此后可查看可下载)","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"}]},{"title":"Linux常用命令","slug":"BasicSkill/Linux/Linux常用命令","date":"2020-10-09T02:59:50.000Z","updated":"2020-10-09T07:23:31.356Z","comments":true,"path":"2020/10/09/BasicSkill/Linux/Linux常用命令/","link":"","permalink":"https://sobxiong.github.io/2020/10/09/BasicSkill/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"内容 top命令 free命令 df命令 vmstat命令 iostat命令","text":"内容 top命令 free命令 df命令 vmstat命令 iostat命令 top命令 查看整机性能：top(主要cpu) 按数字1查看cpu各核心情况： us user sy system id idle(空闲率,越高越好) load average：a b c(系统1、5、15分钟的系统平均负载量,如果abc平均大于0.6说明系统负担重,大于0.8说明系统快宕机) q退出 低配版：uptime free命令 查看内存：free(默认kb) free -m(MB)、free -g(GB) df命令 查看磁盘：df(disk free,默认kb) df -h(以MB为单位) vmstat命令 查看简单的系统性能：vmstat -n 2 3(2代表每两秒采集一次,3代表共采集三次) 重要参数： r：runtime process(运行进程数) b：blocking process(阻塞进程数,越少越好) iostat命令 查看磁盘IO情况：iostat -xdk 2 3(2,3同上) 重要参数： r/s：每秒读 w/s：每秒写 %util：一秒中有百分之多少的时间用于I/O操作，或者说一秒中有多少时间I/O队列是非空的","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"},{"name":"Linux","slug":"Linux","permalink":"https://sobxiong.github.io/tags/Linux/"}]},{"title":"Java基础知识","slug":"ProgrammingLanguage/Java/Java基础知识","date":"2020-10-08T15:17:04.000Z","updated":"2021-03-04T12:10:45.750Z","comments":true,"path":"2020/10/08/ProgrammingLanguage/Java/Java基础知识/","link":"","permalink":"https://sobxiong.github.io/2020/10/08/ProgrammingLanguage/Java/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"内容 基础知识 进阶知识","text":"内容 基础知识 进阶知识 基础知识 访问修饰符：Java有三个显式关键字来设置类中的访问权限：public(公开)、private(私有)和protected(受保护)。访问修饰符决定了谁能使用它们修饰的方法、变量或类 四种访问修饰符： public(公开)：表示任何人都可以访问和使用该元素 private(私有)：除了类本身和类内部的方法，外界无法直接访问该元素。private是类和调用者之间的屏障。任何试图访问私有成员的行为都会报编译时错误 protected(受保护)：类似于private，区别是子类可以访问protected的成员，但不能访问 private成员 default(默认)：如果不使用前面的三者，默认就是default访问权限。default被称为包访问，因为该权限下的资源可以被同一包(库组件)中其他类的成员访问 每个编译单元(文件)中只能有一个public修饰的类，或者没有 类不能用private和protected修饰，只能用public或者空(default,包访问权限符)修饰 零碎知识点： Java是单继承结构 区别组合和聚合的一种方式是整体和部分的生命周期联系(生命周期同步为组合,否则为聚合) 尽量使用组合而不是继承，继承要慎重 final： 修饰变量：修饰对象引用时，final使引用恒定不变，但对象本身属性是可以修改的(static只会附加静态的属性)；未定义的final属性必须在构造函数或者初始化块(静态/非静态)中赋值 修饰方法：明确禁止子类覆写方法(private方法隐式指定为final,因为除类本身外不能访问) 修饰类：禁止类被继承，类中方法隐式地被指定为final 类的代码在首次使用时加载(Class被加载) 包含抽象方法的类叫抽象类，如果一个类包含一个或多个抽象方法，那么类本身也必须限定为抽象的；可将一个不包含任何抽象方法的类指明为abstract 常用数据类型： 基本数据类型： 基本类型 大小 最小值 最大值 默认值 包装类型 boolean / / / false Boolean char 16bits Unicode0 Unicode2^16-1 \\u0000(null) Character byte 8bits -128 127 (byte)0 Byte short 16bits -2^15 2^15-1 (short)0 Short int 32bits -2^31 2^31-1 0 Integer long 64bits -2^63 2^63-1 0L Long float 32bits IEEE754 IEEE754 0.0f Float double 64bits IEEE754 IEEE754 0.0d Double void / / / / Void 基本数据类型只有是字段(类的成员变量/数组成员)/静态变量时才会设置为默认值，局部变量定义的基本数据类型没有默认值 高精度数值：BigInteger、BigDecimal 数组：对象数组默认元素初始化为null，基本类型数组默认元素初始化为0 运算符： 相等： ==和!=：比较对象引用 equals()：可覆写，默认也是比较对象引用 移位运算符： &lt;&lt;：向左移动指定位数，低位补0 &gt;&gt;：向右移动指定位数，如果值为正，高位补0；否则高位补1 &gt;&gt;&gt;：零扩展向右移动指定位数，无论值的正负，高位都补0 移位匹配位数(short、char、byte虽然位数少会提升为int,但可移动的位数只有本身长度) 截断和舍入：float和double转为整数值时，小数位将被截断(不存在四舍五入)；四舍五入只能通过Math.round()方法 label(标签)：唯一用到标签的地方在循环语句之前；当在循环中嵌套循环或者开关时，break、continue关键字可以和标签搭配使用 方法： 如果两个方法命名相同，Java通过参数列表进行区分(无返回值信息,顺序可以不同)————方法签名包括方法名和参数 如果类未显式声明构造器，编译器自动创建一个无参构造器 finalize()方法：当垃圾回收器准备回收对象的内存时，首先会调用其finalize()方法(不保证一定会发生)，并在下一轮的垃圾回收动作发生时，才会真正回收对象占用的内存。注意该方法不等同于C++中的析构函数。该函数在本地方法情况下存在较大的作用 创建对象的过程(以类Test为例) 即使没有显式地使用static关键字，构造器实际上也近似静态方法。所以当首次创建Test类型的对象或是首次访问Test类的静态方法或属性时，Java解释器必须在类路径中查找以定位Test.class 当加载完Test.class后(将创建一个Class对象)，有关静态初始化的所有动作都会执行。因此静态初始化只会在首次加载Class对象时初始化一次 当调用new Test()创建对象时，首先会在堆上为Test对象分配足够的存储空间 分配的存储空间首先会被清零，接着会将Test对象中的所有基本类型数据设置为默认值，引用被置为null 执行所有出现在字段定义处的初始化动作 执行构造器 显式的非静态与静态实例初始化： 123456789// 静态初始化static &#123; // ...&#125;// 非静态初始化,构造器之前执行&#123; // ...&#125; Java5中重写方法添加了对协变返回类型的支持，重写方法的返回值类型可以是被重写方法返回值类型的子类 不能重写基类的private方法，这样只会屏蔽，而在派生类中生成一个新的方法 初始化的过程： 分配给对象的存储空间初始化为二进制0 调用基类构造器；如果此时在基类构造器中调用多态方法将会调用到派生类的方法，但派生类的属性目前全为二进制0(可能导致隐蔽的错误) 按声明顺序初始化成员 调用派生类的构造器 多态 绑定：将一个方法调用和一个方法主体关联起来 前期绑定：若绑定发生在程序运行前(如果有的话,由编译器和链接器实现)；它是面向过程语言默认绑定方式，C语言只有这一种前期绑定这种方法调用 后期绑定(动态绑定/运行时绑定)：后期绑定意味着在运行时根据对象的类型进行绑定。当一种语言实现了后期绑定，就必须具有某种机制在运行时能判断对象的类型，从而调用恰当的方法。即编译器仍然不知道对象的类型，但方法调用机制能找到正确的方法体并调用。每种语言的后期绑定机制都不同，但是可以想到对象中一定存在某种类型信息 Java中除了static和final方法(private方法也是隐式的final)外，其他所有方法都是后期绑定。这意味着通常情况下不需要判断后期绑定是否会发生————它自动发生 基类和派生类声明同名的变量会被分配到不同的存储空间，任何属性访问都被编译器解析，因此不存在多态 静态方法没有多态特性，只与类关联 抽象类和接口的区别： 特性 接口 抽象类 组合 新类可以组合多个接口 只能继承单一抽象类 状态 不能包含属性(除了静态属性,不支持对象状态) 可以包含属性,非抽象方法可能引用这些属性 默认方法和抽象方法 不需要在子类中实现默认方法。默认方法可以引用其他接口的方法 必须在子类中实现抽象方法 构造器 没有构造器 可以有构造器 可见性 隐式public 可以是protected或public 内部类：定义在另一个类中的类 内部类自动拥有对其外部类所有成员的访问权(当某个外部类的对象创建了一个内部类对象时,此内部类对象必定会秘密地捕获一个指向那个外部类对象的引用。然后在访问此外部类的成员时用那个引用来选择外部类的成员) 在拥有外部类对象之前是不可能创建内部类对象的。这是因为内部类对象会暗自地连接到建它的外部类对象上。但是如果创建的是嵌套类(静态内部类)，那么它就不需要对外部类对象的引用 private内部类可以完全隐藏实现的细节，但通过对外暴露接口的方式提供服务(只能得到接口的引用,内部类的引用得不到,因为不可见) 可以在一个方法或者任意的作用域内定义内部类 定义一个匿名内部类时，如果内部要使用一个外部环境对象，那么需要参数引用是final的(传给基类构造器无需final) 匿名类中不能有命名构造器，但通过实例初始化能达到构造器的效果 匿名内部类与正规的继承相比有些受限————因为匿名内部类要么继承类，要么实现接口(也只能实现一个接口)，但不能两者兼备 嵌套类是声明为static的内部类，它无需内部类对象与其外部类对象之间有联系 创建嵌套类的对象时不需要其外部类的对象；不能从嵌套类的对象中访问非静态的外部类对象 普通内部类的字段与方法，只能放在类的外部层次上，所以普通的内部类不能有static数据和static字段，也不能包含嵌套类。但是嵌套类可以包含所有这些东西 嵌套类可作为接口的一部分，接口中的任何类都自动是public和static的；甚至可以在接口的内部类中实现外部接口 一个内部类被嵌套多少层并不重要————它能透明地访问所有它所嵌入的外部类的所有成员 内部类可以近似提供继承多个具体或抽象的类的能力 闭包(closure)是一个可调用的对象，它记录了一些信息，这些信息来自于创建它的作用域。内部类是面向对象的闭包，因为它不仅包含外部类对象(创建内部类的作用域)的信息，还自动拥有一个指向此外部类对象的引用。在此作用域内，内部类有权操作所有的成员，包括private成员(Java8及以后还可以使用lambda表达式实现闭包) 因为内部类的构造器必须连接到指向其外部类对象的引用，所以在继承内部类的时候————那个指向外部类对象的”秘密的”引用必须被初始化，因此继承内部类的构造器必须显式定义含有外部类引用的参数并调用outerClass.super() 集合 Java5引入Iterable接口，任何实现了该接口的类都可以使用增强for循环遍历(Collection接口满足,例外的是数组) 进阶知识 自动资源管理：Java7增加了一个新特性：该特性提供了另外一种管理资源的方式，这种方式能自动关闭文件(或资源)。这个特性有时被称为自动资源管理(Automatic Resource Management, ARM)，该特性以try语句的扩展版为基础。当不再需要文件(或其他资源)时，可以防止无意中忘记释放它们 123456789101112131415/*自动资源管理基于try语句的扩展形式：当try代码块结束,自动释放资源。不需要显式调用close()方法。该形式也称为\"带资源的try语句\"注意:1、try语句中声明的资源被隐式声明为final,资源的作用局限于带资源的try语句2、可以在一条try语句中管理多个资源,每个资源以';'隔开即可3、需要关闭的资源必须实现AutoCloseable接口或其子接口Closeable*/try(需要关闭的资源声明)&#123; // 可能发生异常的语句&#125; catch(异常类型变量名) &#123; // 异常的处理语句&#125; finally&#123; // 一定执行的语句&#125; switch字符串：Java7增加了在字符串上switch的用法，这其实时一个逻辑扩展的语法糖(通过字符串的hashCode()等条件转换成整数的switch-case语句) 封装：将数据和方法包装进类中并把具体实现隐藏，结果是一个同时带有特征和行为的数据类型 接口： Java8允许接口包含默认方法和静态方法 接口中的属性被隐式指明为static和final 函数式编程： Lambda表达式与单独定义类和采用匿名内部类是等价的 Lambda表达式是最小可能语法编写的函数定义，它产生函数，但表现为类 Lambda基本语法： 参数，接着箭头”-&gt;”，接着方法体 如果只有一个参数时不需要括号”()”，如果没有参数必须使用”()”表示空参数列表，如果又多个参数将参数列表放在”()”中 如果方法体是单行，无需花括号”{}”，结果自动成为返回值，使用return非法；如果多行，需要”{}”和显式的return 可以编写递归Lambda表达式，但递归方法必须是实例变量或静态变量 方法引用以”::”为特征，左侧是类或对象的名称，右侧是方法名，但没有参数列表(隐式输入传入对象,普通方法隐含需要this,静态方法无需this)；构造器的方法引用是new 可以将方法引用传递给函数式接口(名称无关紧要,只要参数类型和返回类型相同) 高阶函数：消费或者生产函数的函数 被Lambda表达式引用的局部变量必须是final或者等同final效果的(对象引用可以改变改变属性)；但Lambda可以没限制地引用实例变量和静态变量 函数组合：多个函数组合成新函数，java.util.function接口中包含支持函数组合的方法 组合方法 具体操作 andThen(argument) 执行原操作,再执行参数操作 compose(argument) 执行参数操作,再执行原操作 and(argument) 原谓词(Predicate)和参数谓词的短路逻辑与 or(argument) 原谓词和参数谓词的短路逻辑或 negate() 该谓词的逻辑非 柯里化：将一个多参数的函数转换为一系列单参数函数 流式编程： 流(Streams)是与任何特定存储机制无关的元素序列————流是”没有存储”的 流的核心好处：程序短小且更易理解 流式编程的核心特征：内部迭代(看不到迭代的过程,使代码可读性更强,能更简单使用多核处理器) 流是懒加载的，它只在绝对必要时才计算 流操作的类型有三种：创建流、修改流元素(中间操作)以及消费流元素(终端操作,通常意味着收集流元素) 命令式编程指明了每一步如何做，而声明式编程声明了要做什么而不指明每一步如何做；声明式编程是函数式编程的风格 流创建： Stream.of()方法 集合.stream()方法 随机数流：random对象.ints(from, to)方法(long、double同,可使用boxed()方法装箱) Stream.generate()方法：把任意Supplier&lt;T&gt;用于生成T的流 IntStream.range()方法(long、double类似) Stream.iterate(x, y)：x是第一个元素(种子)；y是一个函数用于迭代生成元素，会存储每次生成的元素，第一次传入种子 Stream.Builder：用于接收信息并创建流 Arrays.stream()方法 中间操作： peek()：帮助调试，无修改查看流中元素 sorted()：排序，传入一个Comparator参数 distinct()：消除流中重复元素(相比创建set集合消除重复工作量来的少) filter()：过滤操作，若为true则保留 map()：改变流元素(mapToInt、mapToLong和mapToDouble同理) flatMap()：扁平化元素————将产生流的函数应用于每个元素上，然后每个流扁平化为元素(floatMapToInt、floatMapToLong和floatMapToDouble同理) 终端操作： 转为数组 toArray()：将流转换成适当类型的数组 toArray(generator)：在特殊情况下，生成自定义类型的数组 循环(遍历) forEach(Consumer)：普通循环(并行下不保证顺序) forEachOrdered(Consumer)：保证forEach按照原始流顺序操作(并行下也保证顺序) 转为集合 collect(Collector)：使用Collector收集流元素到结果集合中(Collectors.toCollection(xxx::new)可用于构建任何类型集合,toMap同理) collect(Supplier, BiConsumer, BiConsumer)：同上；参数1用于创建新的结果集合，参数2用于添加一个元素(逻辑)，参数3用于添加一个集合(逻辑) 组合 reduce(BinaryOperator)：使用BinaryOperator来组合所有流中的元素。因为流可能为空，其返回值为Optional reduce(identity, BinaryOperator)：功能同上，但使用identity作为其组合的初始值。因此如果流为空，identity就是结果 reduce(identity, BiFunction, BinaryOperator)：更复杂的使用形式，它可以提高效率。通常可以显式地组合map和reduce来更简单地表达它 匹配 allMatch(Predicate)：所有都满足Predicate则返回为true；在第一个不满足处停止执行 anyMatch(Predicate)：任一满足Predicate则返回true；在第一个满足时停止执行 noneMatch(Predicate)：所有都不满足Predicate则返回true；在第一个满足时停止执行 查找 findFirst()：返回第一个流元素的Optional，如果流为空则返回Optional.empty findAny()：返回含有任意流元素的Optional，如果流为空则返回Optional.empty(非并行流会选择第一个元素) 信息 count()：返回流中的元素个数 max(Comparator)：返回根据传入的Comparator所决定的最大元素(数值流无需Comparator) min(Comparator)：返回根据传入的Comparator所决定的最小元素(数值流无需Comparator) average()：求取流元素平均值(数值流专有) sum()：对所有流元素进行求和(数值流专有) Optional：防止从空流中获取元素的中断(用于包装成统一的对象,包括null) 便利的解包函数(简化包含对象的检查和执行操作)： ifPresent(Consumer)：当值存在时调用Consumer，否则什么也不做 orElse(otherObject)：如果值存在则直接返回，否则生成otherObject orElseGet(Supplier)：如果值存在则直接返回，否则使用Supplier函数生成一个可替代对象 orElseThrow(Supplier)：如果值存在直接返回，否则使用Supplier函数生成一个异常 创建(通过Optional静态方法) Optional.empty()：生成一个空Optional Optional.of(value)：将一个非空值包装到Optional里 Optional.ofNullable(value)：针对一个可能为空的值————为空时自动生成Optional.empty，否则将值包装在Optional中 Optional对象操作(流中) filter(Predicate)：对Optional中的内容应用Predicate并将结果返回(如果不满足或者本身已为空则返回Optional.empty) map(Function)：应用Function于Optional中的内容并返回结果(Optional为空返回Optional.empty) flatMap(Function)：同map；应用于已生成Optional的映射函数，所以不会将结果封装在Optional中(除非显式封装)","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://sobxiong.github.io/tags/Java/"}]},{"title":"NIO","slug":"ProgrammingLanguage/Java/NIO","date":"2020-10-05T15:01:22.000Z","updated":"2020-11-14T04:01:45.549Z","comments":true,"path":"2020/10/05/ProgrammingLanguage/Java/NIO/","link":"","permalink":"https://sobxiong.github.io/2020/10/05/ProgrammingLanguage/Java/NIO/","excerpt":"内容 NIO简介 缓冲区(Buffer) 通道(Channel) 选择器(Selector) 其他","text":"内容 NIO简介 缓冲区(Buffer) 通道(Channel) 选择器(Selector) 其他 NIO简介 NIO简介：Java NIO(New I0)是从Java 1.4版本开始引入的一个新的I0 API，可以替代标准的Java I0 API。NIO与原来的I0有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的I0操作。NIO将以更加高效的方式进行文件的读写操作 NIO系统的核心：通道(Channel)和缓冲区(Buffer)。通道表示打开到I0设备(例如：文件、套接字)的连接。若需要使用NIO系统，需要获取用于连接I0设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。简言之，Channel负责传输，Buffer负责存储 NIO与IO的主要区别： IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 阻塞和非阻塞介绍： 阻塞：传统的I0流都是阻塞式的。也就是说，当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行I0操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降 非阻塞：NIO是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞I0的空闲时间用于在其他通道上执行I0操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端 NIO主要有三大核心组件：通道(Channel)、缓冲区(Buffer)以及选择器(Selector) 缓冲区(Buffer) 介绍： 一个用于特定基本数据类型的容器的，在java.nio包中定义，所有缓冲区都是Buffer抽象类的子类。NIO中的Buffer主要用于与NIO通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的 Buffer就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean除外)，有以下Buffer常用子类：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer以及DoubleBuffer。上述Buffer类它们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个Bufferd对象： 12// 创建一个容量为capacity的XxxBuffer对象static XxxBuffer allocate(int capacity); 基本属性(标记、位置、限制、容量遵守以下不变式：0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity)： 容量(capacity)：表示Buffer最大数据容量，capacity不能为负，并且创建后不能更改 限制(limit)：第一个不应该读取或写入的数据的索引，即位于limit后的数据不可读写。limit不能为负，并且不能大于其容量capacity 位置(position)：下一个要读取或写入的数据的索引。position不能为负，并且不能大于其限制limit 标记(mark)与重置(reset)：标记是一个索引，通过Buffer中的mark()方法指定Buffer中一个特定的position，之后可以通过调用reset()方法恢复到这个position 常用方法 方法 描述 Buffer clear() 清空缓冲区并返回对缓冲区的引用 Buffer flip() 将缓冲区的界限设置为当前位置,并将当前位置重置为0 int capacity() 返回Buffer的capacity大小 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回Buffer的界限(limit)的位置 Buffer limit(int n) 将设置缓冲区界限为n,并返回一个具有新limit的缓冲区对象 Buffer mark() 对缓冲区设置标记 int position() 返回缓冲区的当前位置position Buffer position(int n) 将设置缓冲区的当前位置为n,并返回修改后的Buffer对象 int remaining() 返回position和limit之间的元素个数 Buffer reset() 将位置position转到以前设置的mark所在的位置 Buffer rewind() 将位置设为为0,取消设置的mark 数据操作：Buffer所有子类提供了两个用于数据操作的方法——get()与put()方法 获取Buffer中的数据 get()：读取单个字节 get(byte[] dst)：批量读取多个字节到dst中 get(int index)：读取指定索引位置的字节(不会移动position) 放入数据到Buffer中 put(byte b)：将给定单个字节写入缓冲区的当前位置 put(byte[]src)：将src中的字节写入缓冲区的当前位置 put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动position) 直接与非直接缓冲区 字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则Java虚拟机会尽最大努力直接在此缓冲区上执行本机I/0操作。也就是说，在每次调用基础操作系统的一个本机I/0操作之前(或之后)，虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中(或从中间缓冲区中复制内容) 直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机I/0操作影响的大型、持久的缓冲区。-般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们 直接字节缓冲区还可以通过FileChannel的map()方法将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer。Java平台的实现有助于通过JNI从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常 字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其isDirect()方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理 通道(Channel) 介绍：由java.nio.channels包定义。Channel表示I0源与目标打开的连接。Channel类似于传统的”流”。只不过Channel本身不能直接访问数据，Channel只能与Buffer进行交互 主要实现类 FileChannel：用于读取、写入、映射和操作文件的通道 DatagramChannel：通过UDP读写网络中的数据通道 SocketChannel：通过TCP读写网络中的数据 ServerSocketChannel：可以监听新进来的TCP连接，对每一个新进来的连接都会创建一个Socke tChannel 获取通道： 对支持通道的对象调用getChannel()方法。支持通道的类包括FileInputStream、FileOutputStream、RandomAccessFile、DatagramSocket、Socket、ServerSocket 使用Files类的静态方法newByteChannel()获取字节通道、或者通过通道的静态方法open()打开并返回指定通道 数据传输： 将Buffer数据写入Channel： 1int writeLen = channel.write(buffer); 从Channel读取数据到Buffer 1int readLen = channel.read(buffer); 分散与聚集 分散读取(Scattering Reads)：从Channel中读取的数据”分散”到多个Buffer中注意：按照缓冲区的顺序,从Channel中读取的数据依次将Buffer填满 聚集写入(Gathering Writes)：将多个Buffer中的数据”聚集”到Channel注意：按照缓冲区的顺序,写入position和limit之间的数据到Channel 数据通道相互传输：将数据从源通道传输到其他Channel中 12toChannel.transferFrom(fromChannel, count, position);fromChannel.transforTo(position, count, toChannel); FileChannel的常用方法： 方法 描述 int read(ByteBuffer dst) 从Channel中读取数据到ByteBuffer long read(ByteBuffer[] dsts) 将Channel中的数据”分散”到ByteBuffer[] int write(ByteBuffer src) 将ByteBuffer中的数据写入到Channel long write(ByteBuffer[] srcs) 将ByteBuffer[]中的数据”聚集”到Channel long position() 返回此通道的文件位置 FileChannel position(long p) 设置此通道的文件位置 long size() 返回此通道的文件的当前大小 FileChannel truncate(long s) 将此通道的文件截取为给定大小 void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中 选择器(Selector) 介绍：选择器(Selector)是SelectableChannle对象的多路复用器，Selector可以同时监控多个SelectableChannel的I0状况，也就是说，利用Selector可使一个单独的线程管理多个Channel。Selector是非阻塞I0的核心 常见方法： 方法 描述 Set&lt;SelectionKey&gt; keys() 所有的SelectionKey集合。代表注册在该Selector上的Channel selectedKeys() 被选择的SelectionKey集合。返回此Selector的已选择键集 int select() 监控所有注册的Channel,当它们中间有需要处理的I0操作时,该方法返回,并将对应得的SelectionKey加入被选择的SelectionKey集合中,该方法返回这些Channel的数量 int select(long timeout) 可以设置超时时长的select()操作 int selectNow() 执行一个立即返回的select()操作,该方法不会阻塞线程 Selector wakeup() 使一个还未返回的select()方法立即返回 void close() 关闭该选择器 SelectableChannle继承结构 选择器使用： 创建Selector：通过调用Selector.open()方法创建一个Selector 向选择器注册通道：SelectableChannel.register(Selector sel,int ops) 当调用register()向选择器注册通道时，选择器对通道的监听事件通过第二个参数ops指定 可以监听的事件类型(可使用SelectionKey的四个常量表示)： 读：SelectionKey.OP_READ(1) 写：SelectionKey.OP_WRITE(4) 连接：SelectionKey.OP_CONNECT(8) 接收：SelectionKey.OP_ ACCEPT(16) 若注册时不止监听一个事件，则可以使用”位或”操作符连接 SelectionKey： 介绍：表示SelectableChannel和Selector之间的注册关系。每次向选择器注册通道时就会选择一个事件(选择键)。选择键包含两个表示为整数值的操作集。操作集的每一位都表示该键的通道所支持的一类可选择操作 常用方法： 方法 描述 int interestOps() 获取感兴趣事件集合 int readyOps() 获取通道已经准备就绪的操作的集合 SelectableChannel channel() 获取注册通道 Selector selector() 返回选择器 boolean isReadable() 检测Channal中读事件是否就绪 boolean isWritable() 检测Channal中写事件是否就绪 boolean isConnectable() 检测Channel中连接是否就绪 boolean isAcceptable() 检测Channel中接收是否就绪 其他 管道(pipe)：NIO管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取 Path与Paths： java.nio.file.Path接口代表-一个平台无关的平台路径，描述了目录结构中文件的位置 Paths提供get()方法用来获取Path对象：Path get(String first, String … more)：用于将多个字符串串连成路径 Path常用方法: 方法 描述 boolean endsWith(String path) 判断是否以path路径结束 boolean startsWith(String path) 判断是否以path路径开始 boolean isAbsolute() 判断是否是绝对路径 Path getFileName() 返回与调用Path对象关联的文件名 Path getName(int idx) 返回的指定索引位置idx的路径名称 int getNameCount() 返回Path根目录后面元素的数量 Path getParent() 返回Path对象包含整个路径,不包含Path对象指定的文件路径 Path getRoot() 返回调用Path对象的根路径 Path resolve(Path p) 将相对路径解析为绝对路径 Path toAbsolutePath() 作为绝对路径返回调用Path对象 String toString() 返回调用Path对象的字符串表示形式 Files： java.nio.file.Files用于操作文件或目录的工具类 Files常用方法： 方法 描述 Path copy(Path src, Path dest, CopyOption … how) 文件的复制 Path createDirectory(Path path, FileAttribute&lt;?&gt; … attr) 创建一个目录 Path createFile(Path path, FileAttribute&lt;?&gt; … arr) 创建一个文件 void delete(Path path) 删除一个文件 Path move(Path src, Path dest, CopyOption … how) 将src移动到dest位置 long size(Path path) 返回path指定文件的大小 Files常用方法(判断)： 方法 描述 boolean exists(Path path, LinkOption … opts) 判断文件是否存在 boolean isDirectory(Path path, LinkOption … opts) 判断是否是目录 boolean isExecutable(Path path) 判断是否是可执行文件 boolean isHidden(Path path) 判断是否是隐藏文件 boolean isReadable(Path path) 判断文件是否可读 boolean isWritable(Path path) 判断文件是否可写 boolean notExists(Path path, LinkOption … opts) 判断文件是否不存在 public static &lt;A extends BasicFileAttributes&gt; A readAttributes(Path path, Class&lt;A&gt; type, LinkOption … options) 获取与path指定的文件相关联的属性 Files常用方法(操作内容)： 方法 描述 SeekableByteChannel newByteChannel(Path path, OpenOptin … how) 获取与指定文件的连接,how指定打开方式 DirectoryStream newDirectoryStream(Path path) 打开path指定的目录 InputStream newInputStream(Path path, OpenOptin … how) 获取InputStream对象 OutputStream newOutputStream(Path path, OpenOptin … how) 获取OutputStream对象","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"}]},{"title":"JVM","slug":"ProgrammingLanguage/Java/JVM","date":"2020-09-26T12:10:10.000Z","updated":"2020-11-15T07:44:12.180Z","comments":true,"path":"2020/09/26/ProgrammingLanguage/Java/JVM/","link":"","permalink":"https://sobxiong.github.io/2020/09/26/ProgrammingLanguage/Java/JVM/","excerpt":"内容 JVM体系结构概述 堆体系结构概述 堆参数调优","text":"内容 JVM体系结构概述 堆体系结构概述 堆参数调优 JVM体系结构概述 JVM位置：运行与操作系统之上(可以认为是一种中间件)，与硬件没有直接的交互 \bJVM结构 类装载器ClassLoader 作用：负责加载class文件，class文件在文件开头有特定的文件标示，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构。ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定 种类： 虚拟机自带的加载器 启动类加载器(Bootstrap) C++($JAVA_HOME/jre/lib/rt.jar) 扩展类加载器(Extension) Java($JAVA_HOME/jre/lib/ext/*.jar) 应用程序类加载器(AppClassLoader)，Java中也叫系统类加载器(System Class Loader)，加载当前应用的classpath的所有类 用户自定义加载器：java.lang.ClassLoader的子类，用户可以定制类的加载方式 种类案例： 123456789101112131415Object obj = new Object();// null// Object定义在rt.jar中,采用C++的Bootstrap加载器System.out.println(obj.getClass().getClassLoader());MyObject mObj = new MyObject();// sun.misc.Launcher$AppClassLoader@18b4aac2// MyObject是用户自定义类,采用系统类加载器AppClassLoaderSystem.out.println(mObj.getClass().getClassLoader());// sun.misc.Launcher$ExtClassLoader@61bbe9ba// 系统类加载器的父类即为扩展类加载器ExtClassLoaderSystem.out.println(mObj.getClass().getClassLoader().getParent());// null// 扩展类加载器ExtClassLoader的父类即为C++的Bootstrap加载器System.out.println(mObj.getClass().getClassLoader().getParent().getParent()); 类加载机制(双亲委派)：一个类收到了类加载请求，它首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载器中，只有当父类加载器反馈自己无法完成这个请求的时候(在它的加载路径下没有找到所需加载的Class)，子类加载器才会尝试自己去加载。采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象(也防止用户自定义了系统预先定义的类[包名和类名完全相同]造成的类加载冲突——编译器不报错,运行时报错) Execution Engine：执行引擎负责解释命令，提交操作系统执行 Native Interface(本地接口)： 本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C/C++程序(Java诞生的时候是C/C++横行的时候,要想立足,必须能够调用C/C++程序)，于是就在内存中专门开辟了一块区域处理标记为native的代码，它的具体做法是Native Method Stack中登记native方法，在Execution Engine执行时加载native libraies 目前该方法使用得越来越少了，除非是与硬件有关的应用，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用Socket通信、Web Service等 12345678910111213141516171819202122232425// Test.javapublic static void main(String[] args) &#123; Thread t1 = new Thread(); t1.start();&#125;// Thread.javapublic synchronized void start() &#123; // 同一个thread不能start()两次 if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125;&#125;private native void start0(); Native Method Stack：登记native方法，在Execution Engine执行时加载本地方法库 PC寄存器(类似汇编)： 每个线程都有一个程序计数器，是线程私有的，就是一个指针，指向方法区中的方法字节码(用来存储指向下一条指令的地址,也即将要执行的指令代码)，由执行引擎读取下一条指令 这块内存区域(空间)很小，几乎可以忽略不记，它是当前线程所执行的字节码的行号指示器，字节码解释器通过改变这个计数器的值来选取下一条需要执行的字节码指令 如果执行的是一个Native方法，那这个计数器是空的 用以完成分支、循环、跳转、异常处理、线程恢复等基础功能。不会发生内存溢出(OOM：Out Of Memory)错误 Method Area(方法区)： 是供各线程共享的运行时内存区域。它存储了每一个类的结构信息，例如运行时常量池(Runtime Constant Pool)、字段和方法数据、构造函数和普通方法的字节码内容 上面讲的是规范，在不同虚拟机中实现是不一样的，最典型的就是Java7的永久代(PermGen space)和Java8的元空间(Metaspace) 实例变量存在堆内存中，和方法区无关 Stack(栈)： 介绍：栈也叫栈内存，主管Java程序的运行。在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就Over，生命周期和线程一致，是线程私有的。8种基本类型的变量、对象的引用变量、实例方法都是在函数的栈内存中分配 栈存储什么(主要保存3类数据)： 本地变量(Local Variables)：输入参数、输出参数以及方法内的变量 栈操作(Operand Stack)：记录出栈、入栈的操作 栈帧数据(Frame Data)：包括类文件、方法等 栈运行原理：栈中的数据都是以栈帧(Stack Frame)格式存在，栈帧是一个内存区块、一个数据集、一个有关方法(Method)和运行期数据的数据集当一个方法A被调用时就产生了一个栈帧F1，并被压入到栈中；A方法又调用了B方法，于是产生的栈帧F2也被压入栈；B方法又调用了C方法，于是产生的栈帧F3也被压入栈…..方法相继执行完毕后，先弹出F3栈帧，再弹出F2栈帧，再弹出F1栈帧……遵循“先进后出”/“后进先出”原则每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。栈的大小和具体JVM的实现有关，通常在256K~756K之间，约等于1Mb左右 栈/堆/方法区的交互关系HotSpot(Java8)是使用指针的方式来访问对；Java堆中会存在访问类元数据的地址；reference存储的就是对象的地址 堆体系结构概述 Heap堆 介绍：一个JVM实例只存在一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件后，需要把类、方法、常变量放到堆内存中，保存所有引用类型的真实信息，以方便执行器执行 组成部分(逻辑上划分)： Young Generation Space(新生区 Young/New) Tenure Generation Space(老年区 Old/Tenure) Permanent Space(永久区 Perm) GC过程： 新生区是类的诞生、成长和消亡的区域，一个类在这里产生、应用、最后被垃圾回收器收集结束生命。新生区又分为两部分：伊甸区(Eden Space)和幸存者区(Survivor pace)，所有的类都是在伊甸区被new创建出来的。幸存区有两个：0区(Survivor 0 Space)和1区(Survivor 1 Space) 当伊甸区的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸区进行垃圾回收(Minor GC)，将伊甸区中的不再被其他对象所引用的对象进行销毁。然后将伊甸区中的剩余对象移动到幸存0区。若幸存0区也满了，再对该区进行垃圾回收，然后移动到1区，如果1区也满了再移动到老年区 若老年区也满了，那么这时候将发生Major GC(Full GC)进行老年区的内存清理。若老年区执行了Full GC之后发现依然无法进行对象的保存，就会产生OOM异常(OutOfMemoryError) Minor GC过程(复制 -&gt; 清空 -&gt; 互换)： Eden、Survivor From区复制到Survivor To区，年龄+1：首先，当Eden区满的时候会触发首次GC——把还活着的对象拷贝到Survivor From区。当Eden区再次触发GC时会扫描Eden区和From区，对这两个区域进行垃圾回收，经过这次回收后还存活的对象，则直接复制到To区域(如果有对象的年龄已经达到了老年的标准则赋复制老年区)，同时把这些对象的年龄+1 清空Eden、Survivor From区：然后，清空Eden和Survivor From区中的对象 Survivor To区和Survivor From区互换：最后，Survivor To和Survivor From互换，原Survivor To区成为下一次GC时的Survivor From区。部分对象会在From和To区域中复制来复制去，如此交换15次(由JVM参数MaxTenuringThreshold决定,默认为15)最终如果还是存活，就存入到老年区 方法区(Method Area) 介绍：实际而言，方法区(Method Area)和堆一样是各个线程共享的内存区域，它用于存储虚拟机加载的类信息、普通常量、静态常量和编译器编译后的代码等。虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap(非堆)，目的就是要和堆分开 方法区的实现：对于HotSpot虚拟机，很多开发者习惯将方法区称之为永久代(Parmanent Gen)，但严格本质上说两者不同，永久代是方法区的一个实现。jdk1.7的版本中，已经将原本放在永久代的字符串常量池移走(永久带是1.7版本的叫法,1.8则为元空间Metaspace) Java7永久区(7及之前)：永久存储区是一个常驻内存区域，用于存放JDK自身所携带的Class、Interface的元数据，也就是说它存储的是运行环境必须的类信息。被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭JVM才会释放此区域所占用的内存 堆参数调优 Java堆： 在Java8中永久代已经被移除，被一个称为元空间的区域所取代。元空间的本质和永久代类似 元空间与永久代之间最大的区别：永久带使用的JVM的堆内存；Java8以后的元空间并不在虚拟机中，而是使用本机物理内存 默认情况下，元空间的大小仅受本地内存限制。类的元数据放入Native Memory，字符串池和类的静态变量放入Java堆中，这样可以加载多少类的元数据就不再由MaxPermSize控制而由系统的实际可用空间来控制 堆参数(在VM options中指定) 参数 解释 -Xms 设置JVM初始内存大小,默认为物理内存的1/64 -Xmx 设置JVM最大分配内存,默认为物理内存的1/4 -XX:+PrintGCDetails 输出详细的GC处理日志 123456// 返回Java虚拟机试图使用的最大内存量long maxMemory = Runtime.getRuntime().maxMemory();// 返回Java虚拟机中的内存总量long totalMemory = Runtime.getRuntime().totalMemory();System.out.println(\"-Xmx:maxMemory = \" + maxMemory + \"Byte , \" + (maxMemory / (double) 1024 / 1024) + \"MB\");System.out.println(\"-Xms:totalMemory = \" + totalMemory + \"Byte , \" + (totalMemory / (double) 1024 / 1024) + \"MB\"); 12345678910111213141516171819202122232425262728293031323334353637// java.lang.OutOfMemoryError: Java heap space// byte[] bytes = new byte[40 * 1024 * 1024];// VM Options: -Xms8m -Xmx8m -XX:+PrintGCDetailsString str = \"www.sobxiong.com\";while (true) &#123; str += str + new Random().nextInt(88888888) + new Random().nextInt(99999999);&#125;/*[GC (Allocation Failure) [PSYoungGen: 1508K-&gt;496K(2048K)] 1508K-&gt;535K(7680K), 0.0017728 secs] [Times: user=0.01 sys=0.00, real=0.01 secs][GC (Allocation Failure) [PSYoungGen: 1882K-&gt;505K(2048K)] 1921K-&gt;797K(7680K), 0.0053175 secs] [Times: user=0.01 sys=0.00, real=0.00 secs][GC (Allocation Failure) [PSYoungGen: 2041K-&gt;352K(2048K)] 3331K-&gt;1891K(7680K), 0.0014598 secs] [Times: user=0.00 sys=0.00, real=0.01 secs][Full GC (Ergonomics) [PSYoungGen: 1488K-&gt;0K(2048K)] [ParOldGen: 5531K-&gt;1366K(5632K)] 7019K-&gt;1366K(7680K), [Metaspace: 3036K-&gt;3036K(1056768K)], 0.0054889 secs] [Times: user=0.01 sys=0.00, real=0.00 secs][GC (Allocation Failure) [PSYoungGen: 1074K-&gt;96K(2048K)] 4436K-&gt;3458K(7680K), 0.0015233 secs] [Times: user=0.01 sys=0.00, real=0.01 secs][GC (Allocation Failure) [PSYoungGen: 96K-&gt;96K(2048K)] 3458K-&gt;3458K(7680K), 0.0017007 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (Allocation Failure) [PSYoungGen: 96K-&gt;0K(2048K)] [ParOldGen: 3362K-&gt;3363K(5632K)] 3458K-&gt;3363K(7680K), [Metaspace: 3055K-&gt;3055K(1056768K)], 0.0047922 secs] [Times: user=0.02 sys=0.00, real=0.00 secs][GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2048K)] 3363K-&gt;3363K(7680K), 0.0009790 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2048K)] [ParOldGen: 3363K-&gt;3344K(5632K)] 3363K-&gt;3344K(7680K), [Metaspace: 3055K-&gt;3055K(1056768K)], 0.0045256 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]HeapPSYoungGen total 2048K, used 66K [0x00000007bfd80000, 0x00000007c0000000, 0x00000007c0000000) eden space 1536K, 4% used [0x00000007bfd80000,0x00000007bfd90978,0x00000007bff00000) from space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000) to space 512K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007bff80000)ParOldGen total 5632K, used 3344K [0x00000007bf800000, 0x00000007bfd80000, 0x00000007bfd80000) object space 5632K, 59% used [0x00000007bf800000,0x00000007bfb44040,0x00000007bfd80000)Metaspace used 3109K, capacity 4496K, committed 4864K, reserved 1056768K class space used 338K, capacity 388K, committed 512K, reserved 1048576KException in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:674) at java.lang.StringBuilder.append(StringBuilder.java:208) at com.xiong.jvm.Test2.main(Test2.java:12)*/// 不是立刻执行,禁止使用// System.gc();","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"}]},{"title":"JUC","slug":"ProgrammingLanguage/Java/JUC","date":"2020-09-18T11:28:07.000Z","updated":"2020-11-15T08:36:30.162Z","comments":true,"path":"2020/09/18/ProgrammingLanguage/Java/JUC/","link":"","permalink":"https://sobxiong.github.io/2020/09/18/ProgrammingLanguage/Java/JUC/","excerpt":"内容 JUC是什么 Lock接口 线程间通信 线程间定制化调用通信 线程八锁 线程不安全集合 Callable接口 JUC辅助类 BlockingQueue阻塞队列 ThreadPool线程池 Java8流式计算 Java8分支合并 异步回调 volatile CAS 值传递和引用传递 Java锁的类型 死锁及定位分析","text":"内容 JUC是什么 Lock接口 线程间通信 线程间定制化调用通信 线程八锁 线程不安全集合 Callable接口 JUC辅助类 BlockingQueue阻塞队列 ThreadPool线程池 Java8流式计算 Java8分支合并 异步回调 volatile CAS 值传递和引用传递 Java锁的类型 死锁及定位分析 JUC是什么 JUC介绍：JDK1.5时Java引入的并发编程工具包——java.util.concurrent 基础知识回顾： 进程/线程是什么： 进程：进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。它是操作系统动态执行的基本单元，在传统的操作系统中，进程既是基本的分配单元，也是基本的执行单元 线程：通常在一个进程中可以包含若干个线程，当然一个进程中至少有一个线程，不然没有存在的意义。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度 进程/线程例子： 进程：QQ.ext、word.exe 线程：word检查拼写、word容灾备份 线程的状态 123456789// Thread.javapublic enum State &#123; NEW, // 创建 RUNNABLE, // 准备就绪(还需等待OS),Thread实例start()后并不是马上运行,只是进入就绪状态,等待OS BLOCKED, // 阻塞 WAITING, // 等待(一直等下去——不见不散) TIMED_WAITING, // 等待(有时限的等待——过时不候) TERMINATED; // 终止&#125; wait/sleep的区别： wait/sleep都可以使当前线程暂停 wait放开手睡眠，放开手里的锁 sleep握紧手睡眠，唤醒后手里还有锁 并发/并行各自都是什么： 并发：同一时刻多个线程在访问同一个资源(例子：抢车票) 并行：多项工作同时执行，之后在汇合(例子：泡脚玩手机) Lock接口 复习Synchronized： 多线程口诀1、2： 高内聚低耦合 线程、操作、资源类 实现步骤： 创建资源类 资源类里创建同步方法(代码块) 创建线程，访问资源 卖票实例： 1234567891011121314151617181920212223242526272829303132333435/*** 题目：三个售票员,卖100张票* 多线程编程的企业级套路 + 模版* 1、高内聚低耦合* 2、线程 操作(对外暴露的调用方法) 资源类*/public class SaleTicket &#123; public static void main(String[] args) &#123; final Ticket ticket = new Ticket(); // 创建线程不能直接继承Thread类,因为Java是单继承,资源宝贵,要使用接口方式 // 如果方法体简单,可以不用继承Runnable接口,而直接采用匿名内部类/lambda表达式 // 创建线程要使用两个参数Thread(runnable, name)的方式 new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"A\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"B\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"C\").start(); &#125;&#125;// 资源类class Ticket &#123; private int number = 100; public synchronized void saleTicket() &#123; if (number &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + \"\\t卖出第\" + (number--) + \"张票\\t,还剩下\" + number + \"张票\"); &#125; &#125;&#125; Lock接口： Lock介绍(摘录自JDK1.8)：Lock implementations provide more extensive locking operations than can be obtained using synchronized methods and statements. They allow more flexible structuring, may have quite different properties, and may support multiple associated Condition objects —— 锁实现提供了比使用同步方法和语句可以获得的更广泛的锁操作。它们允许更灵活的结构，可能具有非常不同的属性，并且可能支持多个关联的条件对象 Lock的常用实现类ReentrantLock(可重入锁) 1234567891011121314151617181920212223// Lock使用模版class SharedResource &#123; private final ReentrantLock lock = new ReentrantLock(); /** * synchronized与Lock的区别 * 1、首先synchronized是java内置关键字,在jvm层面;Lock是个java类 * 2、synchronized无法判断是否获取锁的状态,Lock可以判断是否获取到锁 * 3、synchronized会自动释放锁(a:线程执行完同步代码会释放锁;b:线程执行过程中发生异常会释放锁);Lock需在finally中手动释放锁(unlock()方法释放锁),否则容易造成线程死锁 * 4、用synchronized关键字的两个线程1和线程2,如果当前线程1获得锁,线程2线程等待。如果线程1阻塞,线程2则会一直等待下去;而Lock锁就不一定会等待下去,如果尝试获取不到锁,线程可以不用一直等待就结束了 * 5.synchronized的锁可重入、不可中断、非公平,而Lock锁可重入、可判断、可公平(默认非公平,二者皆可) * 6.Lock锁适合大量同步的代码的同步问题,synchronized锁适合代码少量的同步问题 */ public void competitionMethod() &#123; // block until condition holds lock.lock(); try &#123; // ... method body &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; Lock方式卖票实例： 123456789101112131415161718192021222324252627282930313233public class SaleTicket &#123; public static void main(String[] args) &#123; final Ticket ticket = new Ticket(); new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"A\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"B\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt;= 120; i++) ticket.saleTicket(); &#125;, \"C\").start(); &#125;&#125;// 资源类class Ticket &#123; private int number = 100; private final Lock lock = new ReentrantLock(); public void saleTicket() &#123; lock.lock(); try &#123; if (number &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + \"\\t卖出第\" + (number--) + \"张票\\t,还剩下\" + number + \"张票\"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 线程间通信 题目：两个线程来操作初始值为零的一个变量，实现一个线程对该变量加1,另一个线程对该变量减1。实现交替10个轮次,变量初始值为0 线程间通信： 生产者/消费者模型 通知等待唤醒机制 多线程口诀3： 判断 干活 通知 老版本synchronized实现： 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class Cake &#123; private int number = 0; public synchronized void increment() throws InterruptedException &#123; // 1、判断 if (number != 0) &#123; this.wait(); &#125; // 2、干活 number++; System.out.println(Thread.currentThread().getName() + \"\\t生产,剩余\" + number); // 3、通知 this.notifyAll(); &#125; public synchronized void decrement() throws InterruptedException &#123; // 1、判断 if (number == 0) &#123; this.wait(); &#125; // 2、干活 number--; System.out.println(Thread.currentThread().getName() + \"\\t消费,剩余\" + number); // 3、通知 this.notifyAll(); &#125;&#125;/*** 题目：两个线程来操作初始值为零的一个变量,实现一个线程对该变量加1,另一个线程对该变量减1;实现交替10个轮次,变量初始值为0* 1、高聚合低耦合前提下,线程操作资源类* 2、判断/干活/通知*/public class ThreadWaitNotify &#123; public static void main(String[] args) &#123; Cake cake = new Cake(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ProducerA\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ConsumerA\").start(); &#125;&#125; 结果：符合要求 如果换成4个线程(2消费者,2生产者) 12345678910111213141516171819202122232425262728293031323334353637383940414243// 只改变mainpublic static void main(String[] args) &#123; Cake cake = new Cake(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ProducerA\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ConsumerA\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ProducerB\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; cake.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"ConsumerB\").start();&#125; 结果：出现错误，有可能生产出大于1的cake来 原因：换成4个线程会导致错误——虚假唤醒，因为在Java多线程判断时，不能用if。错误出在了判断上面：如果突然有一个增加cake的线程进入到if里面了，但突然中断了并交出控制权。等到唤醒后由于是if，不需要再次进行验证，而是直接走下去了，所以进行了错误的增加 解决方法：把所有的资源类的increment()和decrement()方法中的if判断变为while判断 多线程口诀4：注意多线程之间的虚假唤醒 新版本Lock实现： 新老版本对标： synchronized - Lock wait - await notify - signal Lock示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class Cake1 &#123; private int number = 0; private final Lock lock = new ReentrantLock(); private final Condition condition = lock.newCondition(); public void increment() &#123; lock.lock(); try &#123; // 1、判断 while (number != 0) &#123; condition.await(); System.out.println(Thread.currentThread().getName() + \"\\t生产,剩余\" + number); &#125; // 2、干活 number++; // 3、通知 condition.signalAll(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void decrement() &#123; lock.lock(); try &#123; // 1、判断 while (number == 0) &#123; condition.await(); System.out.println(Thread.currentThread().getName() + \"\\t消费,剩余\" + number); &#125; // 2、干活 number--; // 3、通知 condition.signalAll(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;/*** 题目：两个线程来操作初始值为零的一个变量,实现一个线程对该变量加1,另一个线程对该变量减1;实现交替10个轮次,变量初始值为0* 1、高聚合低耦合前提下,线程操作资源类* 2、判断/干活/通知* 3、多线程交互中,必须要防止多线程的虚假唤醒,也即(判断只能用while,不能用if)*/public class ThreadAwaitSignal &#123; public static void main(String[] args) &#123; Cake1 cake = new Cake1(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; cake.increment(); &#125; &#125;, \"ProducerA\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; cake.decrement(); &#125; &#125;, \"ConsumerA\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; cake.increment(); &#125; &#125;, \"ProducerB\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; cake.decrement(); &#125; &#125;, \"ConsumerB\").start(); &#125;&#125; 线程间定制化调用通信 题目：多线程之间按顺序调用，实现A -&gt; B -&gt; C，三个线程启动,要求如下：AAAAA打印5次，BBBBB打印10次，CCCCC打印15次，以上操作进行10轮 多线程口诀5：标志位 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394class ShareResource &#123; private int number = 1; // 1 -&gt; A, 2 -&gt; B, 3 -&gt; C // 一把锁lock private final Lock lock = new ReentrantLock(); // 三把钥匙condition private final Condition conditionA = lock.newCondition(); private final Condition conditionB = lock.newCondition(); private final Condition conditionC = lock.newCondition(); public void printFromA() &#123; lock.lock(); try &#123; // 1、判断 while (number != 1) &#123; conditionA.await(); &#125; // 2、干活 for (int i = 0; i &lt; 5; i++) &#123; System.out.println(\"AAAAA ~~~\"); &#125; // 3、通知(修改标志位,通知下一个) number = 2; conditionB.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printFromB() &#123; lock.lock(); try &#123; // 1、判断 while (number != 2) &#123; conditionB.await(); &#125; // 2、干活 for (int i = 0; i &lt; 10; i++) &#123; System.out.println(\"BBBBB ~~~\"); &#125; // 3、通知(修改标志位,通知下一个) number = 3; conditionC.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void printFromC() &#123; lock.lock(); try &#123; // 1、判断 while (number != 3) &#123; conditionC.await(); &#125; // 2、干活 for (int i = 0; i &lt; 15; i++) &#123; System.out.println(\"CCCCC ~~~\"); &#125; // 3、通知(修改标志位,通知下一个) number = 1; conditionA.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;/*** 题目：多线程之间按顺序调用,实现A -&gt; B -&gt; C,三个线程启动,要求如下：AAAAA打印5次,BBBBB打印10次,CCCCC打印15次,以上操作进行10轮* 1、高聚合低耦合前提下,线程操作资源类* 2、判断/干活/通知* 3、多线程交互中,必须要防止多线程的虚假唤醒,也即(判断只能用while,不能用if)* 4、标志位*/public class ThreadOrderAccess &#123; public static void main(String[] args) &#123; ShareResource shareResource = new ShareResource(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) shareResource.printFromA(); &#125;, \"A\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) shareResource.printFromB(); &#125;, \"B\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) shareResource.printFromC(); &#125;, \"C\").start(); &#125;&#125; 线程八锁 八锁示例： 情况1(标准访问) 12345678910111213141516171819202122232425262728293031class Phone &#123; public synchronized void sendEmail() throws Exception &#123; System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 1、标准访问,请问先打印邮件还是短信? 邮件public class Lock8 &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况2(其一线程sleep) 1234567891011121314151617181920212223242526272829303132class Phone &#123; public synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 2、邮件方法暂停4秒,请问先打印邮件还是短信? 邮件public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况3(新增一个普通方法) 123456789101112131415161718192021222324252627282930313233343536class Phone &#123; public synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125; public void hello() &#123; System.out.println(\"Hello ~~~\"); &#125;&#125;// 3、在2的基础上,新增并使用一个普通方法hello(),请问先打印邮件还是hello? hellopublic class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone.hello(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况4(两个对象) 123456789101112131415161718192021222324252627282930313233class Phone &#123; public synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 4、两部手机,请问先打印邮件还是短信? 短信public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); Phone phone1 = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone1.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况5(改为静态同步方法) 1234567891011121314151617181920212223242526272829303132class Phone &#123; public static synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public static synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 5、两个静态同步方法,同一部手机,请问先打印邮件还是短信? 邮件public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况6(两个对象调用静态同步方法) 123456789101112131415161718192021222324252627282930313233class Phone &#123; public static synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public static synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 6、两个静态同步方法,两部手机,请问先打印邮件还是短信? 邮件public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); Phone phone1 = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone1.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况7(一个静态同步方法,一个普通同步方法) 1234567891011121314151617181920212223242526272829303132class Phone &#123; public static synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 7、一个普通同步方法,一个静态同步方法,一部手机,请问先打印邮件还是短信? 短信public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 情况8(一个静态同步方法,一个普通同步方法,两个对) 123456789101112131415161718192021222324252627282930313233class Phone &#123; public static synchronized void sendEmail() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"Send Email ~~~\"); &#125; public synchronized void sendMessage() throws Exception &#123; System.out.println(\"Send Message ~~~\"); &#125;&#125;// 8、一个普通同步方法,一个静态同步方法,两部手机,请问先打印邮件还是短信? 短信public class Test &#123; public static void main(String[] args) throws Exception &#123; Phone phone = new Phone(); Phone phone1 = new Phone(); new Thread(() -&gt; &#123; try &#123; phone.sendEmail(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; try &#123; phone1.sendMessage(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"B\").start(); &#125;&#125; 八锁分析： 情况1、2：如果一个对象有多个synchronized方法，某个时刻内只要有一个线程去调用当前对象的一个synchronized方法，那么其它线程只能等待。换句话说，某个时刻内只能有唯一一个线程去访问这些synchronized方法。锁作用的是当前对象this，this被锁定后其它的线程都不能进入到当前对象的其它的synchronized方法(情况1、2都进入了sendEmail()方法,因此不响应sendMessage()方法) 情况3、4：普通方法和同步锁无关，一个线程调用了synchronized方法，另一个线程可以同时调用普通方法；当换成两个对象后，synchronized锁的是对象实例，而当前有两个实例，锁的就不是同一把锁了，因此sendMessage先打印 情况5、6：对于静态同步方法，锁是当前类的Class对象，对于同一个Phone类锁是相同的(Phone.class)，因此进入sendEmail()方法后不会响应sendMessage()方法，而是等待sendEmail()方法执行完毕 情况7、8：对于普通同步方法和静态同步方法，他们锁的对象不同，普通同步方法锁的是当前对象实例(Phone的一个实例对象)，而静态同步方法锁的是当前类的Class对象(Phone.class)。他们锁的对象不同，不会相互影响，因此先打印sendMessage 线程八锁总结： synchronized实现同步的基础：Java中的每一个对象都可以作为锁。具体表现为以下3种形式： 对于普通同步方法，锁是当前实例对象 对于静态同步方法，锁是当前类的Class对象 对于同步方法块，锁是Synchonized括号里配置的对象 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。也就是说如果一个实例对象的普通同步方法获取锁后，该实例对象的其他普通同步方法必须等待已获取锁的方法释放锁后才能获取锁 其他实例对象的普通同步方法跟当前实例对象的普通同步方法用的是不同的锁(不同的实例对象)，所以无须等待当前实例对象已获取锁的普通同步方法释放锁就可以获取他们自己的锁 所有静态同步方法用的是同一把锁——类对象本身，普通同步方法的锁和静态同步方法的锁是两个不同的对象，所以静态同步方法与普通同步方法之间是不会有竞态条件的。但一旦一个静态同步方法获取锁后，其他静态同步方法都必须等待该方法释放锁后才能获取锁(而不管是同一个实例对象的静态同步方法之间，还是不同实例对象的静态同步方法之间，只要它们是同一个类的实例对象) 线程不安全集合 线程不安全的集合 ArrayList 情况1：3个线程同时读写ArrayList(结果：运行基本不报错,但是会出现List中有时内容为null或者集合元素个数不等于3的情况) 情况2：30个线程同时读写ArrayList(结果：运行报错——java.util.ConcurrentModificationException并发修改异常) 123456789public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3 or 30; i++) &#123; new Thread(() -&gt; &#123; list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); &#125;, \"list\" + i).start(); &#125;&#125; 出错原因：ArrayList本身就是线程不安全的(为了性能考虑,不加锁性能提升但会出错误) 123456// ArrayList.javapublic boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 解决方案： 改用Vector(线程安全,加了synchronized,加锁数据一致但性能下降;性能较差,不要使用) 1234567// Vector.javapublic synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125; Collections工具类 少量数据可以使用，通过在ArrayList外包装一层同步机制 Collections.synchronizedList(new ArrayList&lt;&gt;()) CopyOnWriteArrayList(推荐使用) CopyOnWrite容器即写时复制的容器。往一个容器添加元素的时候，不直接往当前容器Object[]添加，而是先将当前容器Object[]进行copy，复制出一个新的容器Object[] newElements，然后向新的容器Object[] newElements里添加元素。添加元素后，再将原容器的引用指向新的容器setArray(newElements) 这样做的好处是可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器是一种读写分离的思想，读和写不同的容器 1234567891011121314151617181920// CopyOnWriteArrayList.javapublic boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 加锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; // copy原始数据 Object[] newElements = Arrays.copyOf(elements, len + 1); // 新增数据 newElements[len] = e; // 引用更新 setArray(newElements); return true; &#125; finally &#123; // 解锁 lock.unlock(); &#125;&#125; HashSet(HashSet底层就是HashMap) 示例： 123456789101112public static void main(String[] args) &#123; // new HashSet&lt;&gt;() // Collections.synchronizedSet(new HashSet&lt;&gt;()) // new CopyOnWriteArraySet&lt;&gt;() Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;(); for (int i = 0; i &lt; 30; i++) &#123; new Thread(() -&gt; &#123; set.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(set); &#125;, \"set\" + i).start(); &#125;&#125; 解决方案： Collections工具类 Collections.synchronizedSet(new HashSet&lt;&gt;()) CopyOnWriteArraySet 底层还是CopyOnWriteArrayList 123456789101112public class CopyOnWriteArraySet&lt;E&gt; extends AbstractSet&lt;E&gt; implements java.io.Serializable &#123; private static final long serialVersionUID = 5457747651344034263L; private final CopyOnWriteArrayList&lt;E&gt; al; /** * Creates an empty set. */ public CopyOnWriteArraySet() &#123; al = new CopyOnWriteArrayList&lt;E&gt;(); &#125; // ...&#125; HashMap 示例： 123456789101112public static void main(String[] args) &#123; // new HashMap&lt;&gt;() // Collections.synchronizedMap(new HashMap&lt;&gt;()) // new ConcurrentHashMap&lt;&gt;() Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;(); for (int i = 0; i &lt; 300; i++) &#123; new Thread(() -&gt; &#123; map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0, 8)); System.out.println(map); &#125;, \"map\" + i).start(); &#125;&#125; 解决方案： Collections工具类 Collections.synchronizedMap(new HashMap&lt;&gt;()) ConcurrentHashMap Callable接口 获得多线程的方法有几种? 继承Thread类(不建议使用) 实现Runnale接口 实现Callable接口 从线程池获取 Callable是什么：一个JDK1.5推出的线程接口，比Runnable更强大。是一个函数式接口，可用作lambda表达式。能在线程执行完成后返回结果(应用场景一般在于批处理业务,如转账时需要返回结果的状态码,代表本次操作的成功与否) 与Runnable的区别： 是否有返回值 是否会抛出异常 落地方法不同(run()/call()) 123456789class MyThread implements Runnable &#123; @Override public void run() &#123;&#125;&#125;class MyThread2 implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; return null; &#125;&#125; 怎么使用： 直接替换runnable：不可行，Thread的构造方法传参都是Runnable接口，没有Callable接口 找中间人FutureTask：FutureTask类实现了Runnable接口，并且接收一个Callable接口作为构造函数 12345678910111213141516171819202122232425262728293031323334353637383940// FutureTask.classpublic class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; // ... public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable &#125; // ...&#125;class MyThread2 implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; TimeUnit.SECONDS.sleep(4); System.out.println(\"~~~\" + Thread.currentThread().getName() + \" Come in call() ~~~\"); return \"1024\"; &#125;&#125;/*** 多线程第3种创建多线程的方式* get()方法一般请放在最后一行,它会阻塞线程*/public class CallableDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(new MyThread2()); new Thread(futureTask, \"A\").start(); new Thread(futureTask, \"B\").start(); // System.out.println(Thread.currentThread().getName() + \"计算中~~~\"); // 使用类似自旋锁的方式判断是否运行完毕 while (!futureTask.isDone())&#123; TimeUnit.MILLISECONDS.sleep(500); System.out.println(Thread.currentThread().getName() + \"计算中~~~\"); &#125; System.out.println(futureTask.get()); System.out.println(futureTask.get()); System.out.println(Thread.currentThread().getName() + \"计算完成~~~\"); &#125;&#125; 运行结果如下 123456789101112main计算中~~~main计算中~~~main计算中~~~main计算中~~~main计算中~~~main计算中~~~main计算中~~~~~~A Come in call() ~~~main计算中~~~10241024main计算完成~~~ 说明：多个线程执行一个FutureTask时只会计算一次，结果缓存，因此Come in call()方法只打印一次。如果需要两个线程同时计算任务时，需要定义两个futureTask FutureTask/Callable应用场景：在主线程中需要执行比较耗时的操作但又不想阻塞主线程时，可把这些操作交给FutureTask对象在后台完成。当主线程将来需要操作结果时可以通过FutureTask对象获得后台作业的计算结果或者执行状态。一般FutureTask多用于耗时的计算任务，主线程可在完成自己的任务后再去获取结果。仅在计算完成时才能检索结果；如果计算尚未完成，则会阻塞get()方法。get()方法获取结果只有在计算完成时获取，否则会阻塞直到任务转入完成状态，最后返回结果或者抛出异常。一旦计算完成，就不会再重新开始或取消计算，如果再次调用结果方法，会将缓存的结果直接返回 JUC辅助类 CountDownLatch(减少计数) 概念：让一些线程阻塞直到另一些线程完成一系列操作才被唤醒 原理：CountDownLatch主要有两个方————countDown()以及await()。当一个或多个线程调用await()方法时，这些线程会阻塞。其它线程调用countDown()方法会将计数器减1(调用countDown()方法的线程不会阻塞)，当计数器的值变为0时，因await()方法阻塞的线程会被唤醒，继续执行 例子： 场景：假设一个自习室里有7个人，其中有一个是班长，班长的主要职责就是在其它6个同学走了后关灯、锁教室门然后走人，因此班长是需要最后一个走的。需要一种方法能够控制班长这个线程最后一个执行，而其它线程是随机执行的 代码： 12345678910111213141516171819202122232425262728// 要求：所有子线程完成后(所有同学离开教室),主线程退出(班长离开教室)public class CountDownLatchDemo &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(finalI); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" 离开教室~~~\"); countDownLatch.countDown(); &#125;, UUID.randomUUID().toString().substring(0, 8)).start(); &#125; countDownLatch.await(); System.out.println(Thread.currentThread().getName() + \" 班长关门走人~~~\"); &#125; // 常规方法无法完成,会有乱序 private static void closeDoor() &#123; for (int i = 0; i &lt; 6; i++) &#123; new Thread(() -&gt; System.out.println(Thread.currentThread().getName() + \" 离开教室~~~\"), i + \"\").start(); &#125; System.out.println(Thread.currentThread().getName() + \" 班长关门走人~~~\"); &#125;&#125; 运行结果如下 1234567891011121314151617# 普通版本0 离开教室~~~2 离开教室~~~3 离开教室~~~1 离开教室~~~main 班长关门走人~~~4 离开教室~~~5 离开教室~~~# CountDownLatch版本a4055b7f 离开教室~~~816b8658 离开教室~~~1876e706 离开教室~~~9657fae5 离开教室~~~4833f0f9 离开教室~~~6d229a84 离开教室~~~main 班长关门走人~~~ CyclicBarrier(循环栅栏) 概念：让一些线程阻塞直到另一些线程完成一系列操作才被唤醒。方式与CountDownLatch相反，做加法，开始为0，加到某个值时才开始执行 原理：CyclicBarrier的字面意思是可循环(Cyclic)使用的屏障(Barrier)。它做的事情是让一组线程到达一个屏障(也可以叫同步点)时被阻塞，直到最后一个线程到达屏障时，屏障才会开门；此时所有被屏障拦截的线程才会继续干活。线程进入屏障通过CyclicBarrier的await()方法 例子： 场景：集齐7颗龙珠召唤神龙 代码： 123456789101112131415161718192021222324// 要求：子线程全部完成后再运行指定方法(集齐七棵龙珠召唤神龙)public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -&gt; System.out.println(Thread.currentThread().getName() + \" 召唤神龙~~~\")); for (int i = 1; i &lt;= 7; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(finalI); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"收集到第\" + finalI + \"颗龙珠~~~\"); try &#123; cyclicBarrier.await(); // 在7个线程中最后一个线程到达await()屏障,之后下面的语句和cyclicBarrier中设定的动作才会被调度执行 System.out.println(Thread.currentThread().getName() + \"收集第\" + finalI + \"颗龙珠完毕~~~\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;, i + \"\").start(); &#125; &#125;&#125; 运行结果如下 1234567891011121314151 收集到第1颗龙珠~~~2 收集到第2颗龙珠~~~3 收集到第3颗龙珠~~~4 收集到第4颗龙珠~~~5 收集到第5颗龙珠~~~6 收集到第6颗龙珠~~~7 收集到第7颗龙珠~~~7 召唤神龙~~~7 收集第7颗龙珠完毕~~~1 收集第1颗龙珠完毕~~~3 收集第3颗龙珠完毕~~~2 收集第2颗龙珠完毕~~~6 收集第6颗龙珠完毕~~~5 收集第5颗龙珠完毕~~~4 收集第4颗龙珠完毕~~~ Semaphore(信号量) 概念：信号量，用于两个目的： 用于共享资源的互斥使用 用于并发线程数的控制 原理：在信号量上了定义两种操作：acquire()————获取，当一个线程调用acquire()操作时，它要么成功并获取信号量(信号量减1)，要么一直等下去直到有线程释放信号量或超时；release()————释放，会将信号量的值加1，然后唤醒等待的线程 例子： 场景：抢车位，假设有6辆车，3个停车位 代码： 12345678910111213141516171819202122232425// 要求：只有三个线程，但是希望六个线程都能够运行(有3个空闲车位,共有6辆车,一开始3辆车抢到,之后开走1辆另外的车占1个车位)public class SemaphoreDemo &#123; public static void main(String[] args) &#123; // 模拟资源类,有3个空车位 // false表示非公平锁,默认也是非公平锁 Semaphore semaphore = new Semaphore(3, false); for (int i = 0; i &lt; 6; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; try &#123; // 获取信号量(车位) semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \" 抢到了车位 ~~~\"); TimeUnit.SECONDS.sleep(finalI); System.out.println(Thread.currentThread().getName() + \" 离开了车位 ~~~\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放信号量(车位) semaphore.release(); &#125; &#125;, i + \"号车\").start(); &#125; &#125;&#125; 运行结果如下 1234567891011120号车 抢到了车位 ~~~2号车 抢到了车位 ~~~1号车 抢到了车位 ~~~0号车 离开了车位 ~~~3号车 抢到了车位 ~~~1号车 离开了车位 ~~~4号车 抢到了车位 ~~~2号车 离开了车位 ~~~5号车 抢到了车位 ~~~3号车 离开了车位 ~~~4号车 离开了车位 ~~~5号车 离开了车位 ~~~ BlockingQueue阻塞队列 阻塞队列介绍：首先是一个队列，大致的数据结构如下图所示： 线程1往阻塞队列里添加元素，线程2从阻塞队列里移除元素 当队列是空的，从队列中获取元素的操作将会被阻塞 当队列是满的，从队列中添加元素的操作将会被阻塞 试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素 试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多个元素，或者完全清空使队列变得空闲起来，再进行后续新增 阻塞的解释：在多线程领域，所谓的阻塞就是指在某些情况下线程会被挂起，但一旦条件满足，被挂起的线程又会自动被唤起 阻塞队列的好处： 不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，为这一切BlockingQueue都一手包办了 在concurrent包发布以前，多线程环境下每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给程序开发带来不小的复杂度 阻塞队列种类： 继承图： 各实现类介绍： ArrayBlockingQueue：由数组结构组成的有界阻塞队列 LinkedBlockingQueue：由链表结构组成的有界(但大小默认值为integer.MAX_VALUE)的阻塞队列 PriorityBlockingQueue：支持优先级排序的无界阻塞队列 DelayQueue：使用优先级队列实现的延迟无界阻塞队列 SynchronousQueue：不存储元素的阻塞队列，也即单个元素的队列(生产一个,消费一个,不存储元素,不消费不生产) LinkedTransferQueue：由链表组成的无界阻塞队列 LinkedBlockingDeque：由链表组成的双向阻塞队列 阻塞队列核心方法： 方法类型 解释 抛出异常 当阻塞队列满时，再往队列里add插入元素会抛出异常IllegalStateException:Queue full；当阻塞队列空时，再往队列里remove移除元素会抛出异常NoSuchElementException 特殊值 插入方法————成功ture，失败false；移除方法————成功返回出队列的元素，队列里没有就返回null 一直阻塞 当阻塞队列满时，生产者线程继续往队列里put元素，队列会一直阻塞生产者线程直到put数据成功(元素被消费)或响应中断退出；当阻塞队列空时，消费者线程试图从队列里take元素，队列会一直阻塞消费者线程直到队列可用(元素被生产) 超时退出 当阻塞队列满时，队列会阻塞生产者线程一定时间，超过限时后生产者线程会退出 用处 线程池 消息中间件 生产者消费者模式 \b需求：一个初始值为0的变量，两个线程对其交替操作，一个加1，一个减1，来五轮 多线程口诀： 线程、操作、资源类 判断、干活、通知 防止虚假唤醒机制 传统版： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class ShareData &#123; private int num = 0; private final Lock lock = new ReentrantLock(); private final Condition condition = lock.newCondition(); public void increment() throws Exception &#123; // 加锁 lock.lock(); try &#123; // 循环判断 while (num != 0) &#123; // 等待,不生产 condition.await(); &#125; // 干活 num++; System.out.println(Thread.currentThread().getName() + \"\\t\" + num); // 通知唤醒 condition.signalAll(); &#125; finally &#123; // 解锁 lock.unlock(); &#125; &#125; public void deIncrement() throws Exception &#123; // 加锁 lock.lock(); try &#123; // 判断 while (num == 0) &#123; // 等待,不生产 condition.await(); &#125; // 干活 num--; System.out.println(Thread.currentThread().getName() + \"\\t\" + num); // 通知唤醒 condition.signalAll(); &#125; finally &#123; // 解锁 lock.unlock(); &#125; &#125;&#125;public class ProdConsumerTraditionDemo &#123; public static void main(String[] args) &#123; ShareData shareData = new ShareData(); new Thread(() -&gt; &#123; for (int i = 1; i &lt; 5; i++) &#123; try &#123; shareData.increment(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"t1\").start(); new Thread(() -&gt; &#123; for (int i = 1; i &lt; 5; i++) &#123; try &#123; shareData.deIncrement(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;, \"t2\").start(); &#125;&#125; 运行结果如下 12345678t1 1t2 0t1 1t2 0t1 1t2 0t1 1t2 0 阻塞队列版： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class MyResource &#123; // 默认开启,进行生产/消费 // volatile修饰,保证多线程内存可见性 private volatile boolean flag = true; private final AtomicInteger atomicInteger = new AtomicInteger(); // 依赖注入,定义接口,而非实现 private final BlockingQueue&lt;String&gt; blockingQueue; public MyResource(BlockingQueue&lt;String&gt; blockingQueue) &#123; this.blockingQueue = blockingQueue; System.out.println(blockingQueue.getClass().getName()); &#125; public void myProduce() throws Exception &#123; String data; boolean returnValue; // 多线程环境的判断一定要使用while进行,防止出现虚假唤醒 while (flag) &#123; data = atomicInteger.incrementAndGet() + \"\"; returnValue = blockingQueue.offer(data, 2L, TimeUnit.SECONDS); if (returnValue) &#123; System.out.println(Thread.currentThread().getName() + \" insert \" + data + \" succeed~~~\"); &#125; else &#123; System.out.println(Thread.currentThread().getName() + \" insert \" + data + \" fail~~~\"); &#125; TimeUnit.SECONDS.sleep(1); &#125; System.out.println(Thread.currentThread().getName() + \" myProduce() finish~~~\"); &#125; public void myConsume() throws Exception &#123; String result; // 多线程环境的判断一定要使用while进行,防止出现虚假唤醒 while (flag) &#123; result = blockingQueue.poll(2L, TimeUnit.SECONDS); if (null == result || result.isEmpty()) &#123; flag = false; System.out.println(Thread.currentThread().getName() + \" over 2 seconds\"); return; &#125; System.out.println(Thread.currentThread().getName() + \" get \" + result + \" succeed~~~\"); &#125; System.out.println(Thread.currentThread().getName() + \" myConsume() finish~~~\"); &#125; public void stop() &#123; this.flag = false; &#125;&#125;public class ProduceConsumeBlockQueueDemo &#123; public static void main(String[] args) &#123; MyResource myResource = new MyResource(new ArrayBlockingQueue&lt;&gt;(10)); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \" produce thread start~~~\"); try &#123; myResource.myProduce(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"Produce Thread\").start(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \" Consume thread start~~~\"); try &#123; myResource.myConsume(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, \"Consume Thread\").start(); try &#123; TimeUnit.SECONDS.sleep(5); myResource.stop(); System.out.println(\"Main Stop()~~~\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果如下 12345678910111213141516java.util.concurrent.ArrayBlockingQueueProduce Thread produce thread start~~~Consume Thread Consume thread start~~~Produce Thread insert 1 succeed~~~Consume Thread get 1 succeed~~~Produce Thread insert 2 succeed~~~Consume Thread get 2 succeed~~~Produce Thread insert 3 succeed~~~Consume Thread get 3 succeed~~~Produce Thread insert 4 succeed~~~Consume Thread get 4 succeed~~~Produce Thread insert 5 succeed~~~Consume Thread get 5 succeed~~~Main Stop()~~~Produce Thread myProduce() finish~~~Consume Thread over 2 seconds ThreadPool线程池 为什么使用线程池：主要特点有线程复用、控制最大并发数、管理线程线程池做的主要工作就是控制运行的线程的数量，处理过程中将任务放入到队列中，然后线程创建后，启动这些任务，如果线程数量超过了最大数量则排队等候，等其它线程执行完毕，再从队列中取出任务来执行 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的销耗 提高响应速度。当任务到达时，任务可以不需要等待线程创建就能立即执行 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控 线程池如何使用： 线程池类继承图： 获取线程池的几种方式： Executors.newFixedThreadPool(int)：创建一个具有n个固定线程的线程池 执行长期的任务，性能较好 创建一个定长线程池，可控制线程数最大并发数，超出的线程会在队列中等待 corePoolSize和MaxmumPoolSize是相等的，为输入的n；使用的底层阻塞队列是LinkedBlockingQueue Executors.newSingleThreadExecutor()：创建一个只有1个线程的单线程池 一个任务一个任务执行的场景 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行 corePoolSize和MaxmumPoolSize都设置为1；使用的底层阻塞队列是LinkedBlockingQueue Executors.newCachedThreadPool()：创建一个可扩容的线程池 使用执行很多短期异步的小程序或负载较轻的服务器 创建一个可缓存线程池，如果线程长度超过处理需要，可灵活回收空闲线程。如无线程可回收，则新建新线程 corePoolSize设置为0，maxmumPoolSize设置为Integer.MAX_VALUE；使用的底层阻塞队列是SynchronousQueue；来了任务就创建线程运行，如果线程空闲超过传入指定的keepAliveTime时间，就销毁线程 Executors.newScheduledThreadPool(int)：创建周期性执行任务的线程池 线程池支持定时以及周期性执行任务，创建一个corePoolSize为传入参数，最大线程数为整形的最大数的线程池 使用的底层阻塞队列为DelayedWorkQueue Executors创建线程原理： 线程池参数解释： 12345678910111213141516171819202122public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize：核心线程数，线程池中的常驻核心线程数 在创建线程池后，当有请求任务就会安排池中的线程去执行请求任务 当线程池中的线程数目达到corePoolSize后，就会把到达的请求任务放到缓存队列中 maximumPoolSize：线程池中能够容纳同时执行的最大线程数，此值必须大于等于1 keepAliveTime：多余的空闲线程的存活时间， 若当前池中线程数量超过corePoolSize，且当空闲时间达到keepAliveTime时，多余线程会被销毁，直到只剩下corePoolSize个线程为止 默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用 unit：keepAliveTime的时间单位 workQueue：任务队列，用于存储被提交但尚未被执行的任务(也即上面介绍的阻塞队列) LinkedBlockingQueue：链表阻塞队列 SynchronousBlockingQueue：同步阻塞队列 threadFactory：表示生成线程池中工作线程的线程工厂，用于创建线程，一般默认即可 handler：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数(maximumPoolSize)时，如何来拒绝请求执行的Runnable的策略 线程池底层工作原理： 在创建了线程池后，开始等待提交过来的任务请求 当调用execute()方法添加一个请求任务时，线程池会做出如下判断： 如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务 如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列 如果这个时候队列满了，且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行 当一个线程完成任务时，它会从队列中取下一个任务来执行 当一个线程无事可做超过一定的时间(keepAliveTime)时，线程会判断： 如果当前运行的线程数大于corePoolSize，那么该线程就被停掉 当线程池的所有任务完成后，线程池线程数目最终会收缩到corePoolSize 线程池拒绝策略 拒绝策略是什么：等待队列已经排满了，再也塞不下新任务了。同时，线程池中也达到了最大线程数，无法继续为新任务服务。这时就需要一种拒绝策略机制合理地处理这个问题 JDK内置的拒绝策略(内置拒绝策略均实现了RejectedExecutionHandle接口) AbortPolicy(默认)：直接抛出RejectedExecutionException异常阻止系统正常运行 CallerRunsPolicy：”调用者运行”调节机制，该策略既不会抛弃任务也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量 DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务 DiscardPolicy：该策略默默地丢弃无法处理的任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的一种策略 线程池的选用 在工作中单一的/固定数的/可变的三种创建线程池的方法哪个用的多：一个都不用如Alibaba Java开发手册规定所示 自定义线程池示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class MyThreadPoolDemo &#123; public static void main(String[] args) &#123; System.out.println(Runtime.getRuntime().availableProcessors()); // RejectedExecutionException AbortPolicy // CallerRunsPolicy() // DiscardPolicy() // DiscardOldestPolicy() ExecutorService threadPool = new ThreadPoolExecutor( 2, 5, 2L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardOldestPolicy()); try &#123; // 模拟有10个顾客来银行办理业务 for (int i = 1; i &lt;= 10; i++) &#123; threadPool.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"办理业务~~~\"); &#125;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 线程池必须要关闭,重量资源 threadPool.shutdown(); &#125; &#125; private static void useSystemPool() &#123; // 1池5个工作线程 // ExecutorService threadPool = Executors.newFixedThreadPool(5); // 1池1个工作线程 // ExecutorService threadPool = Executors.newSingleThreadExecutor(); // 1池N个工作线程 ExecutorService threadPool = Executors.newCachedThreadPool(); try &#123; // 模拟有10个顾客来银行办理业务 for (int i = 1; i &lt;= 10; i++) &#123; threadPool.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"办理业务~~~\"); &#125;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 线程池必须要关闭,重量资源 threadPool.shutdown(); &#125; &#125;&#125; 线程池的合理参数配置生产环境中如何配置corePoolSize和maximumPoolSize大小：根据具体业务来配置，分为CPU密集型和IO密集型 CPU密集型CPU密集的意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行CPU密集任务只有在真正的多核CPU上才可能得到加速(通过多线程)；而在单核CPU上，无论开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就那些CPU密集型任务配置尽可能少的线程数量：一般为————CPU核数 + 1 IO密集型由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如CPU核数 * 2IO密集型即该任务需要大量的IO操作，即大量的阻塞在单线程上运行IO密集型的任务会导致浪费大量的CPU运算能力花费在等待上；IO密集型任务中使用多线程可以大大地加速程序的运行，即使在单核CPU上。这种加速主要就是利用了被浪费掉的阻塞时间IO密集时，大部分线程都被阻塞，故需要多配置线程数：参考————CPU核数 / (1 - 阻塞系数)通常阻塞系数在0.8 ~ 0.9左右例如：8核CPU：8 / (1 - 0.9) = 80个线程数 Java8流式计算 函数式接口(只有一个方法(除default和static方法)的接口)： Lambda表达式口诀：拷贝小括号，写死右括号，落地大括号 Lambda案例： 123456789101112131415161718192021222324252627282930interface Foo &#123; void sayHello();&#125;interface Foo1 &#123; int add(int x, int y); default double div(double x, double y) &#123; return x / y; &#125; static int multiply(int x, int y) &#123; return x * y; &#125;&#125;/*** Lambda表达式* 口诀：拷贝小括号(参数),写死右括号,落地大括号* 注释@FunctionalInterface(只有一个方法的接口,函数式接口)* default方法允许接口有默认实现(jdk1.8),可以有多个* 静态方法实现*/public class LambdaExpress &#123; public static void main(String[] args) &#123; Foo foo = () -&gt; System.out.println(\"Hello LambdaExpress\"); foo.sayHello(); Foo1 foo1 = (x, y) -&gt; 2 * x + y; System.out.println(foo1.add(1, 2)); System.out.println(foo1.div(1.0, 0.3333)); System.out.println(Foo1.multiply(2, 5)); &#125;&#125; Java内置核心四大函数式接口 Stream流 是什么：流(Stream)是数据渠道，用于操作数据源(集合、数组等)所生成的元素序列。集合讲的是数据，流讲的是计算 特点： Stream自己不会存储元素 Stream不会改变源对象。相反，他们会返回一个持有结果的新Stream Stream操作是延迟执行的。这意味着他们会等到需要结果的时候才执行(懒加载) 怎么用： 创建一个Stream：一个数据源(数组、集合) 中间操作：一个中间操作，处理数据源数据 终止操作：一个终止操作，执行中间操作链，产生结果 案例： 12345678910111213141516171819202122232425262728293031@Data@NoArgsConstructor@AllArgsConstructorclass User &#123; private Integer id; private String userName; private int age;&#125;/*** 题目：请按照给出数据，找出同时满足* 偶数ID且年龄大于24且用户名转为大写且用户名字母倒排序* 最后只输出一个用户名字*/public class StreamDemo &#123; public static void main(String[] args) &#123; User u1 = new User(11,\"a\",23); User u2 = new User(12,\"b\",24); User u3 = new User(13,\"c\",22); User u4 = new User(14,\"d\",28); User u5 = new User(16,\"e\",26); List list = Arrays.asList(u1,u2,u3,u4,u5); list.stream().filter(p -&gt; p.getId() % 2 == 0) .filter(p -&gt; p.getAge() &gt; 24) .map(f -&gt; f.getUserName().toUpperCase()) .sorted((o1, o2) -&gt; o2.compareTo(o1)) .limit(1) .forEach(System.out::println); &#125;&#125; Java8分支合并 原理(类同MapReduce)：Fork：把一个复杂任务进行分拆，大事化小Join：把分拆任务的结果进行合并 相关类： ForkJoinPool(分支合并线程池) ForkJoinTask(类似FutureTask) RecursiveTask(递归任务,继承自ForkJoinTask,递归自己) 案例： 123456789101112131415161718192021222324252627282930313233343536373839class MyTask extends RecursiveTask&lt;Long&gt; &#123; private static final Integer ADJUST_VALUE = 20; private final long begin; private final long end; private long result = 0; public MyTask(long begin, long end) &#123; this.begin = begin; this.end = end; &#125; @Override protected Long compute() &#123; if ((end - begin) &lt;= ADJUST_VALUE) &#123; for (long i = begin; i &lt;= end; i++) &#123; result += i; &#125; &#125; else &#123; long middle = (end + begin) / 2; MyTask leftTask = new MyTask(begin, middle); MyTask rightTask = new MyTask(middle + 1, end); leftTask.fork(); rightTask.fork(); result = leftTask.join() + rightTask.join(); &#125; return result; &#125;&#125;public class ForkJoinDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyTask myTask = new MyTask(0, 1023423423L); ForkJoinPool threadPool = new ForkJoinPool(); ForkJoinTask&lt;Long&gt; forkJoinTask = threadPool.submit(myTask); System.out.println(forkJoinTask.get()); threadPool.shutdown(); &#125;&#125; 异步回调 案例： 123456789101112131415161718192021public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 同步 CompletableFuture&lt;Void&gt; completableFuture = CompletableFuture.runAsync(() -&gt; System.out.println(Thread.currentThread().getName() + \"无返回!\")); completableFuture.get(); // 异步 CompletableFuture&lt;Integer&gt; completableFuture2 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"有返回!\"); int result = 1 / 0; return 1024; &#125;); // 异步回调 System.out.println(completableFuture2.whenComplete((t, u) -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"：t = \" + t); System.out.println(Thread.currentThread().getName() + \"：u = \" + u); &#125;).exceptionally(f -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"：f = \" + f.getMessage()); return 4444; &#125;).get());&#125; volatile 介绍：volatile是Java虚拟机提供的轻量级的同步机制 保证可见性 不保证原子性 禁止指令重排 JMM介绍：JMM(Java内存模型Java Memory Model,简称JMM)本身是一种抽象的概念，并不真实存在。它描述的是一组规则或规范，通过这组规范定义了程序中各个变量(包括实例字段、静态字段和构成数组对象的元素)的访问方式JMM关于同步规定： 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方成为栈空间)。工作内存是每个线程的私有数据区域，而Java内存模型中规定所有变量都存储在主内存。主内存是共享内存区域，所有线程都可访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行。首先要将变量从主内存拷贝到自己的工作空间，然后对变量进行操作，操作完成再将变量写回主内存。不能直接操作主内存中的变量，各个线程中的工作内存储存着主内存中的变量副本拷贝，因此不同的线程无法访问对方的工作内存，线程间的通讯(传值)必须通过主内存来完成，其简要访问过程如下图所示： 可见性：通过JMM的介绍，可知各个线程对主内存中共享变量的操作都是各个线程各自拷贝到自己的工作内存操作后再写回主内存中的。这将导致可能存在一个线程A修改了共享变量X的值，该值还未写回主内存中；此时另外一个线程B又对内存中的共享变量X进行操作，但此时线程A工作内存中的共享变量X对线程B来说并不不可见。这种工作内存与主内存同步延迟现象就造成了可见性问题 12345678910111213141516171819202122232425262728293031323334353637383940414243// 资源类class MyData &#123; // volatile int number = 0; int number = 0; public void add() &#123; number++; &#125;&#125;// 验证volatile可见性// 假如int number = 0;number变量之前没有volatile关键字修饰,没有可见性// 添加了volatile,可解决可见性问题public class VolatileDemo &#123; public static void main(String[] args) &#123; MyData myData = new MyData(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"\\t come in\"); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; myData.add(); System.out.println(Thread.currentThread().getName() + \"\\t update number\"); &#125;, \"Test\").start(); // 循环等待,直到number被更新 while (myData.number == 0) ; System.out.println(Thread.currentThread().getName() + \"\\t mission is over , number = \" + myData.number); &#125;&#125;/*当number不加volatile关键字时,主内存不更新,一直在循环中打印:Test come inTest update number当number加volatile关键字时,主内存可见,循环能正常退出打印:Test come inTest update numbermain mission is over , number = 1*/ 原子性：操作不可分割，完整性。即某个线程正在做某个具体业务时，中间不可以被加塞或被分割。需整体完整，要么同时成功要么同时失败 12345678910111213141516171819202122232425262728293031323334353637383940// 资源类class MyData &#123; // AtomicInteger number = new AtomicInteger(); volatile int number = 0; // public void add() &#123; number.getAndIncrement(); &#125; // public synchronized void add() &#123; number++; &#125; public void add() &#123; number++; &#125;&#125;// 验证volatile不保证原子性// 如何保证原子性：// 1、加synchronized关键字()// 2、使用AtomicInteger原子整型类替换intpublic class VolatileDemo &#123; public static void main(String[] args) &#123; MyData myData = new MyData(); for (int i = 0; i &lt; 20; i++) &#123; new Thread(() -&gt; &#123; for (int j = 1; j &lt;= 1000; j++) &#123; myData.add(); &#125; &#125;, \"Thread \" + i).start(); &#125; // 等待20个线程全部即算完成后,主线程继续执行(当还有子线程时,主线程算一个) while (Thread.activeCount() &gt; 2) &#123; // 线程让步,让出CPU执行时间给其他线程 Thread.yield(); &#125; // 打印最终的结果值 System.out.println(myData.number); &#125;&#125;/*当add()不加synchronized关键字时打印小于20000的数当add()加synchronized关键字时打印20000*/ 12345678910111213141516171819202122// add()方法对应的字节码反编译public class MyData &#123; volatile int number = 0; public void add() &#123; number++; &#125;&#125;public void add();Code: 0: aload_0 1: dup 2: getfield #2 // Field number:I 5: iconst_1 6: iadd 7: putfield #2 // Field number:I 10: return/*n++被拆分成三个指令：1、执行getfield从主内存拿到原始number2、执行iadd进行加1操作3、执行putfield把累加后的值写回主内存可能会出现写覆盖,因此小于20000*/ 数值丢失的原因：假设线程1和2同时修改各自工作空间的内容，因此可见性，因此需要重新写入主内存。但在线程1写入时，线程2也同时写入，这导致线程1的写入操作被挂起；线程2写完后线程1继续写入，这样线程1写入的值覆盖了线程2写入的值，造成数据丢失 有序性：计算机在执行程序时为了提高性能，编译器和处理器常常会做指令重排，一般分为以下3种：源代码 -&gt; 编译器优化的重排 -&gt; 指令并行的重排 -&gt; 内存系统的重排 -&gt; 最终执行指令单线程环境里确保程序最终执行结果和代码顺序执行的结果一致处理器在进行重新排序是必须要考虑指令之间的数据依赖性多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程使用的变量能否保持一致性是无法确定的，结果无法预测 指令重排案例： 案例一： 123456public void testSort()&#123; int x = 11; // 语句1 int y = 12; // 语句2 x = x + 5; // 语句3 y = x * x; // 语句4&#125; 正常单线程情况：1234 多线程环境可能的情况：2134、1324 上述的过程就可以当做是指令的重排，即内部执行顺序和我们的代码顺序不一样。但是指令重排也是有限制的，即不会此情况：4321 因为处理器在进行重排时候，必须考虑到指令之间的数据依赖性。语句4依赖于y以及x的申明，因为存在数据依赖，无法首先执行 案例二： int a = 0, b = 0, x = 0, y = 0; 线程1 线程2 x = a; y = b; b = 1; a = 2; x = 0; y = 0; 如果编译器对这段代码进行执行重排优化后，可能出现下列情况： 线程1 线程2 b = 1; a = 2; x = a; y = b; x = 2; y = 1; 这也就说明在多线程环境下，由于编译器优化重排的存在，两个线程使用的变量能否保持一致是无法确定的 案例三： 12345678910111213141516public class ResortSeqDemo &#123; int a = 0; boolean flag = false; public void method01() &#123; a = 1; flag = true; &#125; public void method02() &#123; if(flag) &#123; a = a + 5; System.out.println(\"Value: \" + a); &#125; &#125;&#125; 按照正常的顺序分别调用method01()和method02()，那么最终输出就是a = 6 但如果在多线程环境下，因为method01()和method02()之间不能存在数据依赖的问题，因此原先的顺序可能是 1234a = 1;flag = true;a = a + 5;System.out.println(\"Value:\" + a); 但是在经过编译器，指令，或者内存的重排后，可能会出现这样的情况： 1234flag = true;a = a + 5;System.out.println(\"Value:\" + a);a = 1; 先执行flag = true后，另外一个线程马上调用方法2，满足flag的判断，最终a = a + 5，结果为5，这样出现了数据不一致的问题 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测 这就需要通过volatile来修饰变量，来保证线程安全性 volatile对指令重排作用总结：volatile实现禁止指令重排优化，从而避免了多线程环境下程序出现乱序执行的现象内存屏障(Memory Barrier)又称内存栅栏，是一个CPU指令，作用有两个： 保证特定操作的顺序 保证某些变量的内存可见性(利用该特性实现volatile的内存可见性)由于编译器和处理器都能执行指令重排的优化，如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，即通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。内存屏障另外一个作用是刷新出各种CPU的缓存数，因此任何CPU上的线程都能读取到这些数据的最新版本 线程安全保证： 工作内存与主内存同步延迟现象导致的可见性问题： 可通过synchronized或volatile关键字解决，它们都可使一个线程修改后的变量立即对其它线程可见 对于指令重排导致的可见性问题和有序性问题： 可以使用volatile关键字解决，volatile关键字的另一个作用就是禁止重排序优化 volatile的应用：单例模式DCL 12345678910111213141516171819202122232425262728293031323334353637383940// version1：普通方式/加synchronized关键字public class SingletonDemo &#123; private static SingletonDemo instance = null; private SingletonDemo () &#123; System.out.println(Thread.currentThread().getName() + \"\\t Constructor\"); &#125; public static SingletonDemo getInstance() &#123; if(instance == null) &#123; instance = new SingletonDemo(); &#125; return instance; &#125; public static void main(String[] args) &#123; // 比较内存地址(单线程) 正确 System.out.println(SingletonDemo.getInstance() == SingletonDemo.getInstance()); // 查看打印信息(多线程) -&gt; 打印多次构造器,错误 // 改进：getInstance()方法添加关键字synchronized for (int i = 0; i &lt; 10; i++) &#123; new Thread( () -&gt; SingletonDemo.getInstance(), \"Thread\" + i).start(); &#125; &#125;&#125;/*通过引入synchronized关键字,能够解决高并发环境下的单例模式问题但synchronized属于重量级的同步机制,它只允许一个线程同时访问获取实例的方法;为了保证数据一致性而减低了并发性,因此采用的比较少*/// version2：DCL(Double Check Lock:双端检锁机制)public static SingletonDemo getInstance() &#123; if(instance == null) &#123; // 同步代码段的时候，进行检测 synchronized (SingletonDemo.class) &#123; if(instance == null) &#123; instance = new SingletonDemo(); &#125; &#125; &#125; return instance;&#125; 上面的DCL(双端检锁)机制不一定线程安全，原因是由于指令重排的存在；加入volatile可以禁止指令重排原因在于某一个线程在执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化：instance = new SingletonDemo();可以分为以下步骤(伪代码)memory = allocate(); // 1、分配对象内存空间instance(memory); // 2、初始化对象instance = memory; // 3、设置instance指向刚分配的内存地址,此时instance != null步骤2和步骤3不存在数据依赖关系。而且无论重排前还是重排后程序执行的结果在单线程中并没有改变，因此这种重排优化是允许的memory = allocate(); // 1、分配对象内存空间instance = memory; // 3、设置instance指向刚分配的内存地址,此时instance != null;但对象还没有初始化完instance(memory); // 2、初始化对象当我们执行到重排后的步骤2试图获取instance的时候会得到null，因为对象的初始化还没有完成，而在重排后的步骤3才完成。因此执行单例模式的代码时候，就会重新再创建一个instance实例指令重排只会保证串行语义的执行一致性(单线程),并不会关心多线程间的语义一致性所以当一条线程访问instance不为null时，由于instance实例未必完成初始化,也就造成了线程安全问题。因此需要引入volatile来保证出现指令重排的问题，从而保证单例模式的线程安全性 CAS 概念：CAS的全称是Compare-And-Swap(比较并交换)，它是一条CPU并发原语它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子性的CAS并发原语体现在Java语言中就是sun.misc.Unsafe类的各个方法。调用UnSafe类中的CAS方法，JVM会帮我们实现CAS汇编指令，这是一种完全依赖于硬件的功能，通过它实现了原子操作。CAS是一种系统原语(属于操作系统原语范畴)，由若干条指令组成，用于完成某个功能的一个过程。原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致的问题，也就是说CAS是线程安全的 案例： 1234567// 创建了一个AtomicInteger实例,并初始化为5AtomicInteger atomicInteger = new AtomicInteger(5);// 调用CAS方法,企图更新成2019// 两个参数：前者为5，表示期望值;后者为2019,是要求更新的值System.out.println(atomicInteger.compareAndSet(5, 2019) + \"\\t current data = \" + atomicInteger.get());// 再次调用CAS方法,企图更新成1024System.out.println(atomicInteger.compareAndSet(5, 1024) + \"\\t current data = \" + atomicInteger.get()); 第一次执行CAS方法时，期望值和原本值满足，因此修改成功，返回true和2019；但第二次执行主内存值已修改为2019，不满足期望值，本次写入失败，因此返回了false和2019类似于SVN或者Git的版本号，如果没有人更改过，就能够正常提交，否者需要先将代码pull下来，合并代码后，然后提交 CAS底层原理： 1234567891011/*** Atomically increments by one the current value.** @return the previous value*/// atomicInteger.getAndIncrement()方法源码// this：当前atomicInteger对象// valueOffset：内存偏移量,即内存地址public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 大致意思是通过valueOffset直接利用内存地址获取到值然后进行加1的操作底层又调用了一个unsafe类的getAndAddInt()方法AtomicInteger底层部分代码： 123456789public class AtomicInteger extends Number implements java.io.Serializable &#123; // ... // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; // ... private volatile int value; // ...&#125; Unsafe类： Unsafe是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地(Native)方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定的内存数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C指针一样直接操作内存。Java中的CAS操作的执行依赖于Unsafe类的方法 注意Unsafe类的所有方法都是native修饰的，也就是说unsafe类中的方法都直接调用操作系统底层资源执行相应的任务 为什么Atomic修饰的包装类，能够保证原子性，依靠的就是底层的unsafe类 变量valueOffset：表示该变量值(Atomic修饰的值)在内存中的偏移地址，Unsafe就是根据内存偏移地址获取数据的 变量value用volatile修饰：保证多线程之间内存的可见性 具体的unsafe.getAndAddInt()方法： 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; // getIntVolatile()和compareAndSwapInt()都是native方法 var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 解释： 参数解释： val1：AtomicInteger对象本身 var2：值的引用内存地址 var4：需要增加的int值 var5：用var1和var2找到的主内存中的真实值——即从主内存中拷贝到工作内存中的值(每次都要从主内存拿到最新的值并拷贝到当前线程的本地内存，然后执行compareAndSwapInt()方法再和主内存的值进行比较——在高并发环境下可能主内存值又被更新。线程不可以直接越过高速缓存直接操作主内存，所以需要执行比较方法，值统一后再执行加1操作——底层原子绑定) 实现思路：操作时需要比较当前线程工作内存中的值和主内存中的值，假设执行compareAndSwapInt()方法返回false，那么就一直执行while循环体的内容，一直刷新主内存中的值到当前线程的工作内存，直到期望的值和真实值一样 用该对象当前的值与var5比较 如果相同，更新为var5 + var4并返回true 如果不同，继续从主内存中取最新的值然后再比较，重复流程1，直到值相同，更新完成该处没有使用synchronized加锁机制，而使用CAS，这能提高并发性，同样也能实现一致性。这是因为每个线程进来后，进入do while循环体，不断地获取内存中的值，判断是否为最新的值，为最新值后再进行更新操作 具体案例：假设线程A和线程B同时执行getAndInt()方法(分别跑在不同的CPU上) AtomicInteger里面的value原始值为3(即主内存中AtomicInteger的value为3)，根据JMM模型，线程A和线程B各自持有一份值为3的AtomicInteger副本，并分别存储在各自的工作内存中 线程A通过getIntVolatile()方法拿到最新value值3，此时线程A被挂起(该线程失去CPU执行权) 线程B此时通过getIntVolatile()方法获取到最新value值，也是3。此时线程B没有被挂起，并执行了compareAndSwapInt()方法，主内存的值也是3，成功修改主内存值为4，线程B退出循环 此时线程A恢复，执行compareAndSwapInt()方法，比较发现工作内存的值3和主内存中的值4不一致，说明该值已被其它线程抢先一步修改过。因此A线程本次修改失败，再次进入循环体 线程A重新获取主内存最新的value值，因为变量value被volatile修饰，所以其它线程对它的修改线程A总能够看到，线程A继续执行compareAndSwapInt()方法进行比较并交换直到成功 Unsafe类的CAS思想：自旋(自我旋转,直到成功) 底层实现：Unsafe类中的compareAndSwapInt是一个本地方法，该方法的实现位于unsafe.cpp中 12345678UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) // 先想办法拿到变量value在内存中的地址 // 通过Atomic::cmpxchg实现比较替换,其中参数X是即将更新的值,参数e是原内存的值 UnsafeWrapper(\"Unsafe_CompareAndSwapInt\"); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END CAS缺点： 循环时间长，CPU开销大(因为执行的是do-while语句,如果比较不一致会一直循环;最差的情况就是某个线程一直取到的值和预期值都不一样,导致无限循环) 只能保证一个共享变量的原子操作 当对一个共享变量执行操作时，可以通过CAS方式来保证原子操作 当对多个共享变量执行操作时，CAS方式就无法保证操作的原子性，此时只能用锁来保证原子性 引出ABA问题 ABA问题： 介绍：CAS算法实现的一个重要前提：需要取出内存中某时刻的数据，并在当下时刻比较并交换，在这个时间差上可能会发生数据的变化比如线程1从内存位置V中取出值为A，此时另一线程2也从内存V中取出A，并且线程2进行了一些操作将值更新为B之后又将值更新为A；这时线程1进行CAS操作发现内存中仍然是A，然后线程1操作成功尽管线程1的CAS操作成功，但不代表该过程就是没有问题的 原子引用AtomicReference(能操作对象)： 1234567891011121314class User &#123; String userName; int age;&#125;User user1 = new User(\"zhangsan\", 22);User user2 = new User(\"lisi\", 23);AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;();atomicReference.set(user1);System.out.println(atomicReference.compareAndSet(user1, user2) + \"\\t\" + atomicReference.get().toString());System.out.println(atomicReference.compareAndSet(user1, user2) + \"\\t\" + atomicReference.get().toString());// 结果：// true User&#123;userName='lisi', age=23&#125;// false User&#123;userName='lisi', age=23&#125; ABA问题的解决(AtomicStampedReference,新增版本号(类似时间戳)标记)： 123456789101112131415161718// ABA问题的模拟static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100);new Thread(() -&gt; &#123; System.out.println(atomicReference.compareAndSet(100, 101) + \"\\t\" + atomicReference.get()); System.out.println(atomicReference.compareAndSet(101, 100) + \"\\t\" + atomicReference.get());&#125;, \"ABA A\").start();new Thread(() -&gt; &#123; // 暂停1秒,保证t1线程完成ABA操作 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(atomicReference.compareAndSet(100, 2019) + \"\\t\" + atomicReference.get());&#125;, \"ABA B\").start();// 结果：// true 101// true 100// true 2019 1234567891011121314151617181920212223242526272829// ABA问题的解决AtomicStampedReference// 新增版本号标记数据版本static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1);new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"\\t Version 1st: \" + atomicStampedReference.getStamp()); // 等待线程B获取版本号 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"\\t Version 2nd: \" + atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"\\t Version 3rd: \" + atomicStampedReference.getStamp());&#125;, \"ABA Solution A\").start();new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \"\\t Version 1st: \" + stamp); // 等待线程A完成一次ABA操作 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"\\t Result = \" + atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1) + \"\\t Current Version = \" + atomicStampedReference.getStamp() + \"\\t Value = \" + atomicStampedReference.getReference());&#125;, \"ABA Solution B\").start();// 结果：// ABA Solution A Version 1st: 1// ABA Solution B Version 1st: 1// ABA Solution A Version 2nd: 2// ABA Solution A Version 3rd: 3// ABA Solution B Result = false Current Version = 3 Value = 100 CAS总结： CAS是compare and swap的缩写，表示比较当前工作内存中的值和主物理内存中的值；如果相同则执行规定操作，否则继续比较直到主内存和工作内存的值一致为止 CAS有3个操作数，内存值V，旧的预期值A，要修改的更新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否者什么都不做 值传递和引用传递 举例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Person &#123; private Integer id; private String personName; public Person(String personName) &#123; this.personName = personName; &#125;&#125;public class TransferValueDemo &#123; public void changeValue1(int age) &#123; age = 30; &#125; public void changeValue2(Person person) &#123; person.setPersonName(\"XXXX\"); &#125; public void changeValue3(String str) &#123; str = \"XXX\"; &#125; public static void main(String[] args) &#123; TransferValueDemo test = new TransferValueDemo(); // 定义基本数据类型 int age = 20; test.changeValue1(age); System.out.println(\"age: \" + age); // 实例化person类 Person person = new Person(\"SOBXiong\"); test.changeValue2(person); System.out.println(\"personName: \" + person.getPersonName()); // String String str = \"SOBXiong\"; test.changeValue3(str); System.out.println(\"string: \" + str); &#125;&#125;/*输出结果：age: 20personName: XXXXstring: SOBXiong*/ ChangeValue1()执行过程八种基本数据类型，在栈里面分配内存，属于值传递栈管运行，堆管存储执行changeValue1()时，int是基本数据类型，所以传递的是int = 20这个值，传递的是一个副本，main方法里面的age并没有改变，因此输出的结果age还是20，属于值传递 ChangeValue2()执行过程Person是属于对象，作为方法参数时也是值传递，只不过传递的是引用——在堆空间的内存地址。执行changeValue2()时复制了内存地址，两个值都是指向同一个地址 ChangeValue3()执行过程String不属于基本数据类型，但是为什么执行完成后值未改变？这时因为String的特殊性，当执行String str = “SOBXiong”的时候，JVM会检查常量池中是否已存在”SOBXiong”，如果存在则不会创建，会生成一个引用指向常量池中的”SOBXiong”并把str赋值为引用的值；如果不存在，则会新建”SOBXiong”并把引用指向它并将str赋值为引用的值 Java锁的类型 公平锁/非公平锁 概念： 公平锁：多个线程按照申请锁的顺序来获取锁，先来先服务，就是公平的，也即队列 非公平锁：多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发环境下有可能造成优先级翻转，或者饥饿线程(某个线程一直得不到锁) 如何创建： 并发包中ReentrantLock的创建可以指定构造函数的boolean值来得到公平锁/非公平锁，默认是非公平锁，因为非公平锁有吞吐量比公平锁高的优点 Lock lock = new ReentrantLock(true); synchronized也是一种非公平锁 两者区别： 公平锁：很公平。在并发环境中每个线程在获取锁时会先查看此锁维护的等待队列，如果为空或当前线程是等待队列中的第一个，就占用锁，否则就会加入到等待队列中，此后按照FIFO的规则 非公平锁：较粗鲁，一上来就直接尝试占有锁，如果尝试失败，再采用类似公平锁的方式 可重入锁(递归锁) 概念：可重入锁就是递归锁指同一线程外层函数获得锁之后，内层递归函数仍然能获取到该锁的代码，同一线程在外层方法获取锁时，进入内层方法会自动获取锁也即————线程可以进入任何一个它已拥有的锁所同步的代码块ReentrantLock/Synchronized是典型的可重入锁 作用：可避免死锁 可重入锁验证： 案例一：验证Synchronized 1234567891011121314151617class Phone &#123; public synchronized void sendSMS() &#123; System.out.println(Thread.currentThread().getName() + \" invoked sendSMS()\"); // 在同步方法中调用另外一个同步方法 sendEmail(); &#125; public synchronized void sendEmail() &#123; System.out.println(Thread.currentThread().getName() + \" invoked sendEmail()\"); &#125;&#125;public class ReenterLockDemo &#123; public static void main(String[] args) &#123; Phone phone = new Phone(); new Thread(phone::sendSMS, \"t1\").start(); new Thread(phone::sendSMS, \"t2\").start(); &#125;&#125; 运行结果如下 1234t1 invoked sendSMS()t1 invoked sendEmail()t2 invoked sendSMS()t2 invoked sendEmail() 说明：sendSMS()同步方法调用sendEmail()同步方法，synchronized锁的是对象，假如不是重入锁，那么sendSMS()方法要获取一次锁，sendEmail()又要获取一次锁，就会造成死锁；由于是同一线程，再次获取锁时就是sendSMS()获取的那个锁，没有新锁产生。同时由于synchronized锁的是对象，线程t1得到锁后，线程t2只能等t1运行完sendSMS()同步方法释放完锁 案例二：验证ReentrantLock 123456789101112131415161718192021222324252627282930313233343536class Phone implements Runnable&#123; Lock lock = new ReentrantLock(); public void getLock() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \" get Lock\"); setLock(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void setLock() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \" set Lock\"); &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public void run() &#123; getLock(); &#125;&#125;public class ReenterLockDemo &#123; public static void main(String[] args) &#123; Phone phone = new Phone(); Thread t3 = new Thread(phone, \"t3\"); Thread t4 = new Thread(phone, \"t4\"); t3.start(); t4.start(); &#125;&#125; 运行结果如下 1234t3 get Lockt3 set Lockt4 get Lockt4 set Lock 说明：与加synchronized锁一样，多次获取锁后，锁是重入的，并不会锁死自己 案例三：案例二变形 1234567891011public void getLock() &#123; lock.lock(); lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \" get Lock\"); setLock(); &#125; finally &#123; lock.unlock(); lock.unlock(); &#125;&#125; 运行结果如下 1234t3 get Lockt3 set Lockt4 get Lockt4 set Lock 说明：结果与案例二一样，因此不管有几把锁，实际都是同一把锁，用同一把钥匙都能打开 案例四：案例三变形 12345678910public void getLock() &#123; lock.lock(); lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \" get Lock\"); setLock(); &#125; finally &#123; lock.unlock(); &#125;&#125; 运行结果如下 12t3 get Lockt3 set Lock 说明：加锁两次，解锁一次。程序在输出上述两句后阻塞(线程阻塞)，也就是说ReentrantLock申请加锁几次就要解锁几次 案例五：案例三变形 12345678910public void getLock() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \" get Lock\"); setLock(); &#125; finally &#123; lock.unlock(); lock.unlock(); &#125;&#125; 运行结果如下 123456789101112131415161718t3 get Lockt3 set Lockt4 get Lockt4 set LockException in thread \"t3\" Exception in thread \"t4\" java.lang.IllegalMonitorStateException at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151) at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261) at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457) at com.xiong.interview.Phone.getLock(ReenterLockDemo.java:16) at com.xiong.interview.Phone.run(ReenterLockDemo.java:31) at java.lang.Thread.run(Thread.java:748)java.lang.IllegalMonitorStateException at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151) at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261) at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457) at com.xiong.interview.Phone.getLock(ReenterLockDemo.java:16) at com.xiong.interview.Phone.run(ReenterLockDemo.java:31) at java.lang.Thread.run(Thread.java:748) 说明：加锁次数小于解锁次数，直接抛异常 自旋锁： 概念：SpinLock，指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁。好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU资源上文提及的比较并交换(CAS)底层使用的就是自旋 手写自旋锁 123456789101112131415161718192021222324252627282930313233343536373839404142public class SpinLockDemo &#123; // 原子引用线程 AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); public void myLock() &#123; Thread thread = Thread.currentThread(); while (!atomicReference.compareAndSet(null, thread)) &#123; &#125; System.out.println(thread.getName() + \" Come in ~~~\"); &#125; public void myUnlock() &#123; Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(thread.getName() + \" Come out ~~~\"); &#125; public static void main(String[] args) &#123; SpinLockDemo spinLockDemo = new SpinLockDemo(); new Thread(() -&gt; &#123; spinLockDemo.myLock(); // 暂停一会 try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; spinLockDemo.myUnlock(); &#125;,\"Thread A\").start(); // 暂停一会 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(() -&gt; &#123; spinLockDemo.myLock(); spinLockDemo.myUnlock(); &#125;,\"Thread B\").start(); &#125;&#125; 运行结果如下 1234Thread A Come in ~~~Thread A Come out ~~~Thread B Come in ~~~Thread B Come out ~~~ 说明：打印第1句5s后打印后三句话，而且out紧接第一句话。A线程调用myLock()方法自己持有锁5s，线程B进入方法后发现有线程持有锁，因此只能通过自旋等待，A线程调用myUnlock()方法释放锁后，线程B才能继续执行 独占锁(写锁)/共享锁(读锁)/互斥锁 概念：独占锁：指该锁一次只能被一个线程所持有。ReentrantLock和Synchronized都是独占锁共享锁：指该锁可以被多个线程锁持有ReentrantReadWriteLock其读锁是共享，写锁是独占。写的时候只能一个人写，但是读的时候可以多个人同时读。读锁的共享锁可保证并发读是非常高效的。读写/写写的过程是互斥的 为什么会有写锁和读锁：独占锁一次只能一个线程访问，但有一个读写分离的场景，读时想同时进行，原来独占锁的并发性就没这么好了。读锁并不会造成数据不一致的问题，因此可以多个人共享读多个线程同时读一个资源类没有任何问题，为了满足并发，读取共享资源应该可以同时进行。但若有一个线程去写共享资源，就不应该再有其他线程对该资源进行读或写操作 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class MyCache &#123; private volatile Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); public void put(String key, Object value) &#123; System.out.println(Thread.currentThread().getName() + \"\\t 正在写入：\" + key); try &#123; // 模拟网络拥堵 TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; map.put(key, value); System.out.println(Thread.currentThread().getName() + \"\\t 写入完成\"); &#125; public void get(String key) &#123; System.out.println(Thread.currentThread().getName() + \"\\t 正在读取:\"); try &#123; // 模拟网络拥堵 TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Object value = map.get(key); System.out.println(Thread.currentThread().getName() + \"\\t 读取完成：\" + value); &#125; public static void main(String[] args) &#123; MyCache myCache = new MyCache(); // 线程操作资源类，5个线程写 for (int i = 0; i &lt; 5; i++) &#123; final int tempInt = i; new Thread(() -&gt; myCache.put(tempInt + \"\", tempInt + \"\"), String.valueOf(i)).start(); &#125; // 线程操作资源类， 5个线程读 for (int i = 0; i &lt; 5; i++) &#123; final int tempInt = i; new Thread(() -&gt; myCache.get(tempInt + \"\"), String.valueOf(i)).start(); &#125; &#125;&#125; 运行结果如下 12345678910111213141516171819200 正在写入：03 正在写入：32 正在写入：21 正在写入：14 正在写入：40 正在读取:1 正在读取:2 正在读取:3 正在读取:4 正在读取:0 写入完成4 读取完成：43 读取完成：33 写入完成2 写入完成2 读取完成：24 写入完成0 读取完成：null1 写入完成1 读取完成：null 案例说明：在写入时，写线程被其他线程打断，这就造成还没写完就被挂起，其他线程开始写，这可能会造成数据的不一致。写操作需要原子 + 独占，整个过程必须是一个完整的统一体，中间不许被分割、打断。结果的打印顺序与真实顺序有出入，因为也是多线程的，实际读取到null的应该在写入完成之前执行 \b解决方案：加读写锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 增量部分// 创建一个读写锁,是一个读写一体的锁private ReentrantReadWriteLock lock = new ReentrantReadWriteLock();public void put(String key, Object value) &#123; // 写锁加锁 lock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"\\t 正在写入：\" + key); try &#123; // 模拟网络拥堵 TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; map.put(key, value); System.out.println(Thread.currentThread().getName() + \"\\t 写入完成\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 写锁释放 lock.writeLock().unlock(); &#125;&#125;public void get(String key) &#123; // 读锁加锁 lock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"\\t 正在读取:\"); try &#123; // 模拟网络拥堵 TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"\\t 读取完成：\" + map.get(key)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 读锁释放 lock.readLock().unlock(); &#125;&#125; 运行结果如下 12345678910111213141516171819200 正在写入：00 写入完成1 正在写入：11 写入完成2 正在写入：22 写入完成3 正在写入：33 写入完成4 正在写入：44 写入完成0 正在读取:1 正在读取:2 正在读取:3 正在读取:4 正在读取:1 读取完成：13 读取完成：32 读取完成：24 读取完成：40 读取完成：0 解决方案说明：写锁一次只允许一个线程进入执行写操作，而读锁允许多个线程同时进入执行读取的操作。结果证明写入操作中间不会被打断，而读操作可以同时进入 死锁及定位分析 死锁概念：死锁是指两个或多个以上的进程在执行过程中，因争夺资源而造成一种互相等待的现象。若无外力干涉，那它们都将无法继续推进下去。如果资源充足，进程的资源请求都能得到满足，死锁出现的可能性很低，否则就会因争夺有限的资源而陷入死锁 产生原因： 系统资源不足 进程运行推进的顺序不对 资源分配不当 死锁产生的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系 死锁案例： 1234567891011121314151617181920212223242526272829303132class HoldLockThread implements Runnable &#123; private final Object lockA; private final Object lockB; public HoldLockThread(Object lockA, Object lockB) &#123; this.lockA = lockA; this.lockB = lockB; &#125; @Override public void run() &#123; synchronized (lockA) &#123; System.out.println(Thread.currentThread().getName() + \" 自己持有&#123;\" + lockA + \"&#125; , 尝试获得&#123;\" + lockB + '&#125;'); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lockB) &#123; System.out.println(Thread.currentThread().getName() + \" 自己持有&#123;\" + lockB + \"&#125; , 尝试获得&#123;\" + lockA + '&#125;'); &#125; &#125; &#125;&#125;public class DeadLockDemo &#123; public static void main(String[] args) &#123; Object lockA = new Object(), lockB = new Object(); new Thread(() -&gt; new HoldLockThread(lockA, lockB).run(), \"Thread A\").start(); new Thread(() -&gt; new HoldLockThread(lockB, lockA).run(), \"Thread B\").start(); &#125;&#125; 运行结果如下 12Thread B 自己持有&#123;java.lang.Object@1b77d269&#125; , 尝试获得&#123;java.lang.Object@42f5503f&#125;Thread A 自己持有&#123;java.lang.Object@42f5503f&#125; , 尝试获得&#123;java.lang.Object@1b77d269&#125; 说明：打印上述信息后，主线程阻塞，无法结束 排查死锁： 使用jps命令定位进程编号：jps -l 使用jstack命令查看堆栈信息：jstack pid 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.251-b08 mixed mode):\"Attach Listener\" #14 daemon prio=9 os_prio=31 tid=0x00007fcd65818000 nid=0x5903 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"DestroyJavaVM\" #13 prio=5 os_prio=31 tid=0x00007fcd6607d000 nid=0xe03 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"Thread B\" #12 prio=5 os_prio=31 tid=0x00007fcd67815000 nid=0x5803 waiting for monitor entry [0x0000700006488000] java.lang.Thread.State: BLOCKED (on object monitor) at com.xiong.interview.HoldLockThread.run(DeadLockDemo.java:24) - waiting to lock &lt;0x000000076ac374a8&gt; (a java.lang.Object) - locked &lt;0x000000076ac374b8&gt; (a java.lang.Object) at com.xiong.interview.DeadLockDemo.lambda$main$1(DeadLockDemo.java:34) at com.xiong.interview.DeadLockDemo$$Lambda$2/1595428806.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)\"Thread A\" #11 prio=5 os_prio=31 tid=0x00007fcd638b8000 nid=0x5703 waiting for monitor entry [0x0000700006385000] java.lang.Thread.State: BLOCKED (on object monitor) at com.xiong.interview.HoldLockThread.run(DeadLockDemo.java:24) - waiting to lock &lt;0x000000076ac374b8&gt; (a java.lang.Object) - locked &lt;0x000000076ac374a8&gt; (a java.lang.Object) at com.xiong.interview.DeadLockDemo.lambda$main$0(DeadLockDemo.java:33) at com.xiong.interview.DeadLockDemo$$Lambda$1/2065951873.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)\"Service Thread\" #10 daemon prio=9 os_prio=31 tid=0x00007fcd64056800 nid=0xa903 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C1 CompilerThread3\" #9 daemon prio=9 os_prio=31 tid=0x00007fcd66057800 nid=0x4203 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread2\" #8 daemon prio=9 os_prio=31 tid=0x00007fcd65052800 nid=0x4303 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread1\" #7 daemon prio=9 os_prio=31 tid=0x00007fcd63843000 nid=0x4403 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread0\" #6 daemon prio=9 os_prio=31 tid=0x00007fcd6604e800 nid=0x4603 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"Monitor Ctrl-Break\" #5 daemon prio=5 os_prio=31 tid=0x00007fcd6780e800 nid=0x3f03 runnable [0x0000700005c70000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284) at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326) at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) - locked &lt;0x000000076ac839b8&gt; (a java.io.InputStreamReader) at java.io.InputStreamReader.read(InputStreamReader.java:184) at java.io.BufferedReader.fill(BufferedReader.java:161) at java.io.BufferedReader.readLine(BufferedReader.java:324) - locked &lt;0x000000076ac839b8&gt; (a java.io.InputStreamReader) at java.io.BufferedReader.readLine(BufferedReader.java:389) at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:61)\"Signal Dispatcher\" #4 daemon prio=9 os_prio=31 tid=0x00007fcd6701b000 nid=0x4803 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"Finalizer\" #3 daemon prio=8 os_prio=31 tid=0x00007fcd65813800 nid=0x3103 in Object.wait() [0x0000700005964000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000076ab08ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144) - locked &lt;0x000000076ab08ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)\"Reference Handler\" #2 daemon prio=10 os_prio=31 tid=0x00007fcd66813000 nid=0x2f03 in Object.wait() [0x0000700005861000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000076ab06c00&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x000000076ab06c00&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)\"VM Thread\" os_prio=31 tid=0x00007fcd6580f000 nid=0x4f03 runnable\"GC task thread#0 (ParallelGC)\" os_prio=31 tid=0x00007fcd6500c800 nid=0x2007 runnable\"GC task thread#1 (ParallelGC)\" os_prio=31 tid=0x00007fcd6500d000 nid=0x1b03 runnable\"GC task thread#2 (ParallelGC)\" os_prio=31 tid=0x00007fcd6500e000 nid=0x1d03 runnable\"GC task thread#3 (ParallelGC)\" os_prio=31 tid=0x00007fcd65012800 nid=0x2a03 runnable\"GC task thread#4 (ParallelGC)\" os_prio=31 tid=0x00007fcd65013800 nid=0x2c03 runnable\"GC task thread#5 (ParallelGC)\" os_prio=31 tid=0x00007fcd65014000 nid=0x5303 runnable\"GC task thread#6 (ParallelGC)\" os_prio=31 tid=0x00007fcd65014800 nid=0x2e03 runnable\"GC task thread#7 (ParallelGC)\" os_prio=31 tid=0x00007fcd65015000 nid=0x5103 runnable\"VM Periodic Task Thread\" os_prio=31 tid=0x00007fcd65053000 nid=0xa803 waiting on conditionJNI global references: 319Found one Java-level deadlock:=============================\"Thread B\": waiting to lock monitor 0x00007fcd6504d758 (object 0x000000076ac374a8, a java.lang.Object), which is held by \"Thread A\"\"Thread A\": waiting to lock monitor 0x00007fcd6504d6a8 (object 0x000000076ac374b8, a java.lang.Object), which is held by \"Thread B\"Java stack information for the threads listed above:===================================================\"Thread B\": at com.xiong.interview.HoldLockThread.run(DeadLockDemo.java:24) - waiting to lock &lt;0x000000076ac374a8&gt; (a java.lang.Object) - locked &lt;0x000000076ac374b8&gt; (a java.lang.Object) at com.xiong.interview.DeadLockDemo.lambda$main$1(DeadLockDemo.java:34) at com.xiong.interview.DeadLockDemo$$Lambda$2/1595428806.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)\"Thread A\": at com.xiong.interview.HoldLockThread.run(DeadLockDemo.java:24) - waiting to lock &lt;0x000000076ac374b8&gt; (a java.lang.Object) - locked &lt;0x000000076ac374a8&gt; (a java.lang.Object) at com.xiong.interview.DeadLockDemo.lambda$main$0(DeadLockDemo.java:33) at com.xiong.interview.DeadLockDemo$$Lambda$1/2065951873.run(Unknown Source) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 说明：查看最后一行，看到Found 1 deadlock，即存在一个死锁，上面的部分信息指示了出现问题的文件和行数","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"}]},{"title":"Nginx","slug":"Middleware/Nginx","date":"2020-09-06T03:39:08.000Z","updated":"2020-10-18T12:43:35.696Z","comments":true,"path":"2020/09/06/Middleware/Nginx/","link":"","permalink":"https://sobxiong.github.io/2020/09/06/Middleware/Nginx/","excerpt":"内容 Nginx简介 Nginx安装 Nginx常用的命令和配置文件 Nginx配置实例-反向代理 Nginx配置实例-负载均衡 Nginx配置实例-动静分离 Nginx搭建高可用集群 Nginx原理简述","text":"内容 Nginx简介 Nginx安装 Nginx常用的命令和配置文件 Nginx配置实例-反向代理 Nginx配置实例-负载均衡 Nginx配置实例-动静分离 Nginx搭建高可用集群 Nginx原理简述 Nginx简介 Nginx概述：是一个高性能的HTTP和反向代理服务器,特点是占有内存少，并发能力强，事实上Nginx的并发能力确实在同类型的网页服务器中表现较好 Nginx的作用： 作为Web服务器：Nginx可以作为静态页面的web服务器，同时还支持CGI协议的动态语言，比如perl、php等。但是不支持java。Java程序只能通过与tomcat配合完成 正向代理：如果把局域网外的Internet想象成一个巨大的资源库，则局域网中的客户端要访问Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理(需要设置代理地址) 反向代理：客户端对代理是无感知的，因为客户端不需要任何配置就可以访问。我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后再返回给客户端。此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址 负载均衡：单个服务器解决不了并发需求，可以增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况变为将请求分发到多个服务器上，将负载分发到不同的服务器。这就是所说的负载均衡 动静分离：为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力 Nginx安装 进入Nginx官网http://nginx.org/的download板块下载 具体安装Nginx 安装所需的第三方库：pcre、openssl、zlib 1yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 安装nginx 1234567# 解压缩nginx的tar.gz包tar -zxvf nginx-1.18.0.tar.gz -C /opt/module# 进入目录,执行./configurecd /opt/module/nginx-1.18.0sudo ./configure# make安装sudo make &amp;&amp; make install 测试(注意Linux的防火墙设置) 123456# 进入/usr/local/nginx/sbin目录cd /usr/local/nginx/sbin# 启动nginxsudo ./nginx# 输入当前虚拟机的地址的80端口,查看是否能看到Welcome to nginx# http://sobxiong.com Nginx常用的命令和配置文件 Nginx常用的命令(当前路径:/usr/local/nginx/sbin) 查看nginx版本号：./nginx -v 启动命令：./nginx 关闭命令：./nginx -s stop 重新加载命令(重新加载配置文件)：./nginx - s reload nginx.conf配置文件 介绍：Nginx默认的配置文件都放在主目录下的conf目录，主配置文件nginx.conf也在其中，后续对nginx的使用基本上都是对此配置文件进行相应的修改 配置文件示例： 1234567891011121314151617181920212223242526272829worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; location &#x2F; &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 &#x2F;50x.html; location &#x3D; &#x2F;50x.html &#123; root html; &#125; &#125;&#125; 配置文件解释：根据上述文件，可以明显地将nginx.conf配置文件分为三部分 全局块： 123# Nginx服务器并发处理服务的关键配置,worker_processes值越大,可以支持的并发处理量也越多# 但是会受到硬件、软件等设备的制约,一般设置为当前计算机的CPU核心数worker_processes 1; 从配置文件开始到events块之间的内容，主要会设置一些影响nginx服务器整体运行的配置指令，主要包括配置运行Nginx服务器的用户(组)、允许生成的worker process数、进程pid存放路径、日志存放路径和类型以及配置文件的引入等 events块： 1234events &#123; # 每个work process支持的最大连接数为1024 worker_connections 1024;&#125; events块涉及的指令主要影响Nginx服务器与用户的网络连接。常用的设置包括是否开启对多work process下的网络连接进行序列化、是否允许同时接收多个网络连接、选取哪种事件驱动模型来处理连接请求、每个work process可以同时支持的最大连接数等。这部分的配置对Nginx的性能影响较大，在实际中应该灵活配置 http块： 1234567891011121314151617181920212223http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; location &#x2F; &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 &#x2F;50x.html; location &#x3D; &#x2F;50x.html &#123; root html; &#125; &#125;&#125; 这算是Nginx服务器配置中修改最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里http块还可以包括http全局块、server块 http全局块：配置的指令包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链接请求数上限等 server块：server块和虚拟主机有密切关系。虚拟主机从用户角度看和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本每个http块可以包括多个server块，而每个server块就相当于一个虚拟主机而每个server块也分为全局server块以及可以同时包含多个locaton块 全局server块：最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或IP配置 location块：一个server块可以配置多个location块该块的主要作用是基于Nginx服务器接收到的请求字符串(例如server_name/uri-string)，对虚拟主机名称(也可以是IP别名)之外的字符串(例如前面的/uri-string)进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行 Nginx配置实例-反向代理 反向代理实例1 最终需求：使用nginx反向代理，访问 www.123.com 跳转到虚拟机的8080端口 实现步骤： 测试端口8080准备： 虚拟机安装Tomcat并启动(启动命令bin/startup.sh) 在mac中通过浏览器访问虚拟机Tomcat主页：http://172.16.85.201:8080 修改host文件：在mac中修改hosts文件，将 www.123.com 映射到虚拟机地址172.16.85.201。此时可以通过 www.123.com:8080 访问到测试端口 修改Nginx配置： 12345678server &#123; listen 80; server_name 172.16.85.201; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:8080; &#125;&#125; 最终测试 反向代理实例2 最终需求：使用Nginx反向代理，根据访问的路径跳转到不同端口的服务中。其中Nginx监听端口为 9001，要求访问http://172.16.85.201:9001/edu/直接跳转到172.16.85.201:8080，访问http://172.16.85.201:9001/vod/直接跳转到172.16.85.201:8081 实现步骤： 准备两个Tomcat服务器，一个8080端口，一个8081端口；创建文件夹和测试页面(在8080的Tomcat目录下创建edu目录，其内创建一个a.html测试页面;同理在8081的Tomcat目录下创建vod目录，其内创建一个b.html测试页面) 修改Nginx配置： 123456789101112server &#123; listen 9001; server_name 172.16.85.201; location ~ &#x2F;edu&#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:8080; &#125; location ~ &#x2F;vod&#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:8081; &#125;&#125; 分别测试网址&lt;172.16.85.201:9001/edu/a.html&gt;和&lt;172.16.85.201:9001/vod/b.html&gt;，验证结果 Location指令说明 用途：用于匹配URL 语法： 123location [ &#x3D; | ~ | ~* | ^~] uri &#123;&#125; 参数说明： = ：用于不含正则表达式的uri前，要求请求字符串与uri严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求 ~：用于表示uri包含正则表达式，并且区分大小写 ~*：用于表示uri包含正则表达式，并且不区分大小写 ^~：用于不含正则表达式的uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的 location后，立即使用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配 如果uri包含正则表达式，则必须要有或者*标识 Nginx配置实例-负载均衡 负载均衡示例 最终效果：浏览器访问http://172.16.85.201/edu.a.html，能够将请求负载均衡到8080端口和8081端口 准备工作： 准备一台虚拟机，装上两个Tomcat服务器，端口为8080和8081 在两个Tomcat服务器的webapps目录中，创建edu文件夹和其中的a.html用于测试 在Nginx的配置文件中进行负载均衡的配置 1234567891011121314upstream myserver&#123; server 172.16.85.201:8080; server 172.16.85.201:8081;&#125;server &#123; listen 80; server_name 172.16.85.201; location / &#123; proxy_pass http://myserver; root html; index index.html index.htm;&#125; Nginx分配服务器策略 轮询(默认)：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除 weight(权重)：weight代表权重，默认为1，权重越高被分配的客户端越多 1234upstream myserver&#123; server 172.16.85.201:8080 weight=10; server 172.16.85.201:8081 weight=20;&#125; ip_hash(适用于session)：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器 12345upstream myserver&#123; ip_hash; server 172.16.85.201:8080; server 172.16.85.201:8081;&#125; fair(第三方,公平)：按后端服务器的响应时间来分配请求，响应时间短的优先分配 12345upstream myserver&#123; server 172.16.85.201:8080; server 172.16.85.201:8081; fair;&#125; Nginx配置实例-动静分离 基本介绍：Nginx动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用Nginx处理静态页面，Tomcat处理动态页面。动静分离从目前实现角度来讲大致分为两种：一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；另外一种方法就是动态跟静态文件混合在一起发布，通过nginx来分开 动静分离示例 准备工作：在虚拟机linux系统的本地文件系统中准备静态资源，用于进行访问 Nginx进行动静分离的配置 123456789101112131415server &#123; listen 80; server_name 172.16.85.201; location /text/ &#123; root /opt/data/; index index.html index.htm; &#125; location /image/ &#123; root /opt/data/; # 开启该配置后,访问/image/页面会展示当前目录下的文件基本信息列表 autoindex on; &#125;&#125; Nginx搭建高可用集群 准备工作： 准备两台Linux虚拟机，各自都装上Nginx 在两台服务器安装keepalived：yum install keepalived -y 修改/etc/keepalived下的keepalived.conf配置： 1234567891011121314151617181920212223242526272829303132333435363738global_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 172.16.85.201 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_script chk_http_port &#123; script \"/opt/data/nginx_check.sh\" #(检测脚本执行的间隔) interval 2 weight 2&#125;vrrp_instance VI_1 &#123; # 备份服务器上将MASTER改为BACKUP state MASTER # 网卡 interface ens33 # 主、备机的virtual_router_id必须相同 virtual_router_id 51 # 主、备机取不同的优先级,主机值较大,备份机值较小 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; # VRRP H 虚拟地址 172.16.85.250 &#125;&#125; 在/opt/data下添加检测脚本文件nginx_check.sh： 123456789#!/bin/bashA=`ps -C nginx –no-header |wc -l`if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then killall keepalived fifi 启动两台Linux虚拟机上的nginx和keepalived 1234# 启动nginx(/usr/local/nginx/sbin)./nginx# 启动keepalived服务systemctl start keepalived.service 输入ifconfig可以查看到虚拟ip——172.16.85.250 测试 在主机上访问172.16.85.250，nginx主页显示正常 把主服务器(172.16.85.250)的nginx和keepalived停止 再次访问172.16.85.250，主页依旧正常 Nginx原理简述 Nginx主要采用master-worker模式 一个master和多个worker的好处： 可以使用nginx –s reload热部署 每个worker是独立的进程，如果有其中的一个worker出现问题，其他worker可继续进行争抢，实现请求过程，不会造成服务中断 worker个数：和服务器cpu数相等 发送请求，占用了多少worker的连接数：2/4 Nginx有一个master，有四个worker，每个worker支持最大的连接数1024，那么支持的最大并发数是多少?普通的静态访问最大并发数是worker_connections * worker_processes / 2；如果作为反向代理，最大并发数量应该是worker_connections * worker_processes / 4","categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Middleware","slug":"Middleware","permalink":"https://sobxiong.github.io/tags/Middleware/"}]}],"categories":[{"name":"编程","slug":"编程","permalink":"https://sobxiong.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"https://sobxiong.github.io/tags/FrontEnd/"},{"name":"Spring","slug":"Spring","permalink":"https://sobxiong.github.io/tags/Spring/"},{"name":"Middleware","slug":"Middleware","permalink":"https://sobxiong.github.io/tags/Middleware/"},{"name":"MySQL","slug":"MySQL","permalink":"https://sobxiong.github.io/tags/MySQL/"},{"name":"BasicSkill","slug":"BasicSkill","permalink":"https://sobxiong.github.io/tags/BasicSkill/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://sobxiong.github.io/tags/SpringMVC/"},{"name":"Redis","slug":"Redis","permalink":"https://sobxiong.github.io/tags/Redis/"},{"name":"LeetCode题解","slug":"LeetCode题解","permalink":"https://sobxiong.github.io/tags/LeetCode%E9%A2%98%E8%A7%A3/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://sobxiong.github.io/tags/SpringCloud/"},{"name":"Java高级","slug":"Java高级","permalink":"https://sobxiong.github.io/tags/Java%E9%AB%98%E7%BA%A7/"},{"name":"Linux","slug":"Linux","permalink":"https://sobxiong.github.io/tags/Linux/"},{"name":"Java","slug":"Java","permalink":"https://sobxiong.github.io/tags/Java/"}]}