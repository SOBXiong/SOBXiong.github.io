<!DOCTYPE html>
<html>
<head hexo-theme='https://volantis.js.org/#2.6.6'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
    <title>Flume - SOBXiong的博客</title>
  
    <meta name="keywords" content="BigData">
  
  
    <meta name="description" content="内容
Flume概述
Flume入门
Flume进阶
Flume知识点
">
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">

  

  
  <link rel="shortcut icon" type='image/x-icon' href="https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/favicon.png">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  

  <!-- import link -->
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header shadow blur">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
            <i class='https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/favicon.png'></i>
          
          
            SOBXiong
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      

<div class='l_main'>
  

  
    <article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h1 class="title">
    <a href="/2020/10/09/BigData/Flume/">
      Flume
    </a>
  </h1>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="http://xiongjc.top" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/hdImg_f757fa7e0fd65077ce52d251fc7a01d815860762755.jpg">
    <p>SOBXiong</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E7%BC%96%E7%A8%8B/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>编程</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2020年10月9日</p>
  </a>
</div>

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><ul>
<li><a href="#Flume概述">Flume概述</a></li>
<li><a href="#Flume入门">Flume入门</a></li>
<li><a href="#Flume进阶">Flume进阶</a></li>
<li><a href="#Flume知识点">Flume知识点</a></li>
</ul>
<a id="more"></a>

<h2 id="Flume概述"><a href="#Flume概述" class="headerlink" title="Flume概述"></a>Flume概述</h2><ul>
<li>Flume基本介绍：Flume是Cloudera提供的一个高可用的、高可靠的、分布式的<strong>海量日志采集、聚合和传输的系统</strong>。Flume基于流式架构，灵活简单<br><img src="Flume%E7%9A%84%E4%BD%9C%E7%94%A8.png" alt="Flume的作用"></li>
<li>Flume基础架构：<br><img src="Flume%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Flume基础架构示意图"><ol>
<li>Agent：<br>Agent是一个JVM进程，以事件的形式将数据从源头送至目的<br>Agent主要有3个部分组成：<strong>Source、Channel、Sink</strong></li>
<li>Source：<br>Source是负责接收数据到Flume Agent的组件。Source组件可以处理各种类型和格式的日志数据，包括<strong>avro</strong>、thrift、<strong>exec</strong>、jms、<strong>spooling directory</strong>、<strong>netcat</strong>、sequence generator、syslog、http、legacy</li>
<li>Sink：<br>Sink不断轮询Channel中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者发送到另一个Flume Agent<br>Sink组件目的地包括<strong>hdfs</strong>、<strong>logger</strong>、<strong>avro</strong>、thrift、ipc、<strong>file</strong>、<strong>HBase</strong>、solr、自定义</li>
<li>Channel：<br>Channel是位于Source和Sink之间的缓冲区。Channel允许Source和Sink运作在不同的速率上。Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作<br>Flume自带两种Channel：<strong>Memory Channel</strong>和<strong>File Channel</strong><ol>
<li>Memory Channel是内存中的队列。Memory Channel适用于无需关心数据丢失的情景。如果关心数据丢失，那么Memory Channel就不应该使用。程序死亡、机器宕机或者重启都会导致数据丢失</li>
<li>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据</li>
</ol>
</li>
<li>Event：<br>Event是Flume数据传输的基本单元，Flume以Event的形式将数据从源头送至目的地。<strong>Event由Header和Body两部分组成</strong>，Header用来存放该event的一些属性，为K-V结构；Body用来存放该条数据，为字节数组</li>
</ol>
</li>
</ul>
<h2 id="Flume入门"><a href="#Flume入门" class="headerlink" title="Flume入门"></a>Flume入门</h2><ul>
<li><p>Flume安装部署：</p>
<ul>
<li><p>主要资料来源：</p>
<ol>
<li>Flume官网地址：<a href="http://flume.apache.org/" target="_blank" rel="noopener">http://flume.apache.org/</a></li>
<li>文档地址：<a href="http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html" target="_blank" rel="noopener">http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html</a></li>
<li>下载地址：<a href="http://flume.apache.org/download.html" target="_blank" rel="noopener">http://flume.apache.org/download.html</a></li>
</ol>
</li>
<li><p>安装部署：</p>
<ol>
<li><p>上传并解压：tar zxvf apache-flume-1.9.0-bin.tar.gz -C /opt/module/</p>
</li>
<li><p>删除lib文件夹下的guava-11.0.2.jar以兼容Hadoop3.1.3：rm -rf guava-11.0.2.jar</p>
</li>
<li><p>设置环境变量(方便使用)：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># FLUME_HOME</span></span></span><br><span class="line">export FLUME_HOME=/opt/module/flume-1.9.0</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 记得source /etc/profile</span></span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
</li>
<li><p>Flume入门案例：</p>
<ol>
<li><p>监控端口数据：</p>
<ul>
<li><p>案例需求：使用Flume监听一个端口，收集该端口数据，并打印到控制台</p>
</li>
<li><p>案例分析：<br><img src="%E7%9B%91%E5%90%AC%E6%95%B0%E6%8D%AE%E7%AB%AF%E5%8F%A3%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%BE.png" alt="监听数据端口案例分析图"></p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>安装netcat工具：sudo yum install -y nc</p>
</li>
<li><p>查看44444端口是否被占用：sudo netstat -tunlp | grep 44444</p>
</li>
<li><p>创建并编写Agent配置文件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># netcat_memory_logger.conf</span><br><span class="line"># 设置当前agent、sources、channels、sinks的名字a1、s1、c1、s1</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line"># source配置</span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line"># channel配置</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line"># sink配置</span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line"># 声明source,sink和channel关系</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line"># 注意:一个sink只能对应一个channel</span><br><span class="line"># 一个channel可以对应多个sink</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启flume agent监听端口：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 写法1</span></span><br><span class="line">flume-ng agent --conf conf/ --name a1 --conf-file agent_conf/netcat_memory_logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="meta">#</span><span class="bash"> 写法2</span></span><br><span class="line">flume-ng agent -c conf/ -n a1 -f agent_conf/netcat_memory_logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p> 参数说明：</p>
<ol>
<li>–conf/-c：表示配置文件存储在conf/目录</li>
<li>–name/-n：表示给agent起名为a1</li>
<li>–conf-file/-f：flume本次启动读取的配置文件是在agent_conf文件夹下的netcat_memory_logger.conf文件</li>
<li>-Dflume.root.logger=INFO,console：-D表示flume运行时动态修改flume.root.logger参数属性值，并将控制台日志打印级别设置为INFO级别。日志级别包括:log、info、warn、error</li>
</ol>
</li>
<li><p>使用netcat工具向本机44444端口发送内容：nc localhost 44444(之后键入内容)</p>
</li>
<li><p>在flume监听终端观察接受数据情况</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>实时监控单个追加文件</p>
<ul>
<li><p>案例需求：实时监控文件，并上传到HDFS中</p>
</li>
<li><p>案例分析：<br><img src="%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E5%8D%95%E4%B8%AA%E8%BF%BD%E5%8A%A0%E6%96%87%E4%BB%B6%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%BE.png" alt="实时监控单个追加文件案例分析图"></p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>Flume要想将数据输出到HDFS需要依赖Hadoop相关jar包，检查/etc/profile，确认Hadoop和Java环境变量配置正确</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># JAVA_HOME</span></span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_251</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># HADOOP_HOME</span></span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建并编写Agent配置文件：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"># exec_hdfs.conf</span><br><span class="line"># 设置当前agent名,sources、channels、sinks的名字</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line"># source配置</span><br><span class="line"># 要想读取Linux系统中的文件就得按照Linux命令的规则执行命令。</span><br><span class="line"># exec即execute——执行。表示执行Linux命令来读取文件</span><br><span class="line">a1.sources.r1.type &#x3D; exec</span><br><span class="line">a1.sources.r1.command &#x3D; tail -F &#x2F;opt&#x2F;data&#x2F;test.log</span><br><span class="line"></span><br><span class="line"># channel配置</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line"># sink配置</span><br><span class="line">a1.sinks.k1.type &#x3D; hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;hadoop101:9000&#x2F;flume&#x2F;%Y%m%d&#x2F;%H</span><br><span class="line"># 是否使用本地时间戳</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp &#x3D; true</span><br><span class="line"></span><br><span class="line"># 上传文件的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix &#x3D; logs-</span><br><span class="line"># 是否按照时间滚动文件夹</span><br><span class="line">a1.sinks.k1.hdfs.round &#x3D; true</span><br><span class="line"># 多少单位时间创建一个新文件夹</span><br><span class="line">a1.sinks.k1.hdfs.roundValue &#x3D; 1</span><br><span class="line"># 定义时间单位</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit &#x3D; hour</span><br><span class="line"></span><br><span class="line"># 积攒多少哥Event才flush到HDFS</span><br><span class="line">a1.sinks.k1.hdfs.batchSize &#x3D; 100</span><br><span class="line"># 设置文件类型,可支持压缩</span><br><span class="line">a1.sinks.k1.hdfs.fileType &#x3D; DataStream</span><br><span class="line"></span><br><span class="line"># 多久生成一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval &#x3D; 600</span><br><span class="line"># 设置每个文件的滚动大小</span><br><span class="line">a1.sinks.k1.hdfs.rollSize &#x3D; 134217700</span><br><span class="line"># 文件滚动与Event数量无关</span><br><span class="line">a1.sinks.k1.hdfs.rollCount &#x3D; 0</span><br><span class="line"></span><br><span class="line"># 声明source,sink和channel关系</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line"># 注意:一个sink只能对应一个channel</span><br><span class="line"># 一个channel可以对应多个sink</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启HDFS准备接受文件：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop101</span></span><br><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启flume agent监听文件：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -c conf/ -n a1 -f agent_conf/exec_hdfs.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>在HDFS的web监控界面查看文件</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>实时监控目录下多个新文件</p>
<ul>
<li><p>案例需求：使用Flume监听整个目录的文件，并上传至HDFS</p>
</li>
<li><p>案例分析：<br><img src="%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%A4%9A%E4%B8%AA%E6%96%B0%E6%96%87%E4%BB%B6%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%BE.png" alt="实时监控目录下多个新文件案例分析图"></p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>创建并编写Agent配置文件：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># spooldir_hdfs.conf</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line"># Spooling Directory Source:用来监听一个目录进行自动收集目录中内容</span><br><span class="line"># 1.当目录中某个log文件内容被读取完毕后,该文件有两种处理方案(取决于deletePolicy配置):</span><br><span class="line">#   1、删除 2、更改扩展名.COMPLETED</span><br><span class="line"># 2.更改扩展名目的就是为了标示该文件已被读取完毕</span><br><span class="line"># 注意:该目录中的文件名不能相同,如果相同会抛异常</span><br><span class="line">a1.sources.r1.type &#x3D; spooldir</span><br><span class="line">a1.sources.r1.spoolDir &#x3D; &#x2F;opt&#x2F;data</span><br><span class="line">a1.sources.r1.fileHeader &#x3D; true</span><br><span class="line"># 忽略所有以.tmp结尾的文件,不上传</span><br><span class="line">a1.sources.r1.ignorePattern &#x3D; ([^ ]*\.tmp)</span><br><span class="line"></span><br><span class="line"># channel配置</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line"># sink配置</span><br><span class="line">a1.sinks.k1.type &#x3D; hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;hadoop101:9000&#x2F;flume2&#x2F;%Y%m%d&#x2F;%H</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp &#x3D; true</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.filePrefix &#x3D; logs-</span><br><span class="line">a1.sinks.k1.hdfs.round &#x3D; true</span><br><span class="line">a1.sinks.k1.hdfs.roundValue &#x3D; 1</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit &#x3D; hour</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.batchSize &#x3D; 100</span><br><span class="line">a1.sinks.k1.hdfs.fileType &#x3D; DataStream</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval &#x3D; 600</span><br><span class="line">a1.sinks.k1.hdfs.rollSize &#x3D; 134217700</span><br><span class="line">a1.sinks.k1.hdfs.rollCount &#x3D; 0</span><br><span class="line"></span><br><span class="line"># 声明source,sink和channel关系</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line"># 注意:一个sink只能对应一个channel</span><br><span class="line"># 一个channel可以对应多个sink</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启flume agent监听文件夹：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 说明：在使用Spooling Directory Source时,不要在监控目录中创建并持续修改文件;上传完成的文件会以.COMPLETED结尾;被监控文件夹每500毫秒扫描一次文件变动</span></span><br><span class="line">flume-ng agent -c conf/ -n a1 -f agent_conf/spooldir_hdfs.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>向data文件夹添加文件：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo sobxiong &gt;&gt; data/test1.txt</span><br><span class="line">echo testxixi &gt;&gt; data/test2.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>在HDFS的web监控界面查看文件</p>
</li>
<li><p>等待1s，查看data目录中文件后缀名变化</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>实时监控目录下的多个追加文件</p>
<ul>
<li><p>监控文件比对：Exec source适用于监控一个实时追加的文件，不能实现断点续传；Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而Taildir Source适合用于监听多个实时追加的文件，并且能够实现断点续传</p>
</li>
<li><p>案例需求：使用Flume监听整个目录的实时追加文件，并上传至HDFS</p>
</li>
<li><p>案例分析：<br><img src="%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E5%A4%9A%E4%B8%AA%E8%BF%BD%E5%8A%A0%E6%96%87%E4%BB%B6%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E5%9B%BE.png" alt="实时监控目录下的多个追加文件案例分析图"></p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>创建并编写Agent配置文件：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; TAILDIR</span><br><span class="line"></span><br><span class="line"># Taildir说明：</span><br><span class="line"># Taildir Source维护了一个json格式的position File,其会定期地往positionFile中更新每个文件读取到的最新的位置因此能够实现断点续传</span><br><span class="line"># Position File的格式如下：</span><br><span class="line"># &#123;&quot;inode&quot;:2496272,&quot;pos&quot;:12,&quot;file&quot;:&quot;&#x2F;opt&#x2F;data&#x2F;demo&#x2F;test.txt&quot;&#125;</span><br><span class="line"># 注：Linux中储存文件元数据的区域就叫做inode,每个inode都有一个号码</span><br><span class="line"># 操作系统用inode号码来识别不同的文件,Unix&#x2F;Linux系统内部不使用文件名,而使用inode号码来识别文件</span><br><span class="line"></span><br><span class="line"># 该文件中记录了source读取到的内容的位置</span><br><span class="line">a1.sources.r1.positionFile &#x3D; &#x2F;opt&#x2F;module&#x2F;flume-1.9.0&#x2F;taildir_position.json</span><br><span class="line">a1.sources.r1.filegroups &#x3D; f1</span><br><span class="line">a1.sources.r1.filegroups.f1 &#x3D; &#x2F;opt&#x2F;data&#x2F;demo&#x2F;*.txt</span><br><span class="line"></span><br><span class="line"># channel配置</span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line"># sink配置</span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line"># 声明source,sink和channel关系</span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启flume agent监听文件夹：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -c conf/ -n a1 -f agent_conf/taildir_logger.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>向demo文件夹添加文件：</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo sobxiong &gt;&gt; test1.txt</span><br><span class="line">echo testxixi &gt;&gt; test2.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>在HDFS的web监控界面查看文件</p>
</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="Flume进阶"><a href="#Flume进阶" class="headerlink" title="Flume进阶"></a>Flume进阶</h2><ul>
<li><p>Flume事务<br><img src="Flume%E4%BA%8B%E5%8A%A1%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Flume事务示意图"></p>
</li>
<li><p>Flume Agent内部原理<br><img src="Flume_Agent%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Flume Agent内部原理示意图"><br>重要组件：</p>
<ol>
<li><strong>ChannelSelector</strong><br>ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是<strong>Replicating(复制)</strong>和<strong>Multiplexing(多路复用)</strong><br>ReplicatingSelector会将同一个Event发往所有的Channel；Multiplexing会根据相应的原则，将不同的Event发往不同的Channel</li>
<li><strong>SinkProcessor</strong><br>SinkProcessor共有三种类型，分别是<strong>DefaultSinkProcessor</strong>、<strong>LoadBalancingSinkProcessor</strong>和<strong>FailoverSinkProcessor</strong><br>DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group。LoadBalancingSinkProcessor可以实现负载均衡的功能；FailoverSinkProcessor可以错误恢复的功能</li>
</ol>
</li>
<li><p>Flume拓扑结构</p>
<ol>
<li>简单串联<br><img src="%E7%AE%80%E5%8D%95%E4%B8%B2%E8%81%94%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="简单串联示意图"><br>介绍：该模式将多个flume顺序连接起来，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume，flume数量过多不仅会影响传输速率，且一旦传输过程中某个节点flume宕机，会影响整个传输系统</li>
<li>复制和多路复用<br><img src="%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="复制和多路复用示意图"><br>Flume支持将事件流向一个或者多个目的地。该模式可将相同数据复制到多个channel中，或将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地</li>
<li>负载均衡和故障转移<br><img src="%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="负载均衡和故障转移示意图"><br>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能</li>
<li>聚合<br><img src="%E8%81%9A%E5%90%88%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="聚合示意图"><br>最常见的也非常实用的模式，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等再进行日志分析等后续操作</li>
</ol>
</li>
<li><p>Flume开发案例</p>
<ol>
<li><p>使用Flume提供的时间戳拦截器：</p>
<ul>
<li><p>案例需求：使用netcat向监听的Flume的发送信息并设置Flume提供的时间戳拦截器</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) netcat -&gt; memory -&gt; logger</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line"># 设置一个拦截器(用来在headers中添加时间戳)</span><br><span class="line">a1.sources.r1.interceptors &#x3D; i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type &#x3D; timestamp</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>串联：</p>
<ul>
<li><p>案例需求：通过netcat向hadoop101的flume发送信息，hadoop101的flume将收到的消息通过arvo sink向hadoop102的flume发送，最终由hadoop102打印日志</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) netcat -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line"># hostname是写出到哪台机器</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line"></span><br><span class="line"># ------------------------------------------</span><br><span class="line"></span><br><span class="line"># agent1(hadoop102) avro -&gt; memory -&gt; logger</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; avro</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop102</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>复制：</p>
<ul>
<li><p>案例需求：通过hadoop101监听本地文件的变化，将新增的内容打包成消息通过arvo sink发送给hadoop102和hadoop103，通过复制的方式，如此hadoop102和hadoop103各自都有一份消息副本；hadoop102和hadoop103打印日志显示结果</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) exec -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks &#x3D; k1 k2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; exec</span><br><span class="line">a1.sources.r1.command &#x3D; tail -F &#x2F;opt&#x2F;data&#x2F;test.log</span><br><span class="line"># 配置channel selector(replicating默认,不配置也成)</span><br><span class="line">a1.sources.r1.selector.type &#x3D; replicating</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c2.type &#x3D; memory</span><br><span class="line">a1.channels.c2.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line">a1.sinks.k2.type &#x3D; avro</span><br><span class="line">a1.sinks.k2.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k2.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k2.channel &#x3D; c2</span><br><span class="line"></span><br><span class="line"># ------------------------------------------</span><br><span class="line"></span><br><span class="line"># agent1(hadoop102) avro -&gt; memory -&gt; logger</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; avro</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop102</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line"></span><br><span class="line"># ------------------------------------------</span><br><span class="line"></span><br><span class="line"># agent1(hadoop103) avro -&gt; memory -&gt; logger</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; avro</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop103</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>多路复用：</p>
<ul>
<li><p>案例需求：通过hadoop101监听本地文件的变化，将新增的内容打包成消息通过arvo sink发送给hadoop102和hadoop103。由于采用多路复用的方式，sink会依据消息event头部header中的key和value对数据进行分类，将各类分到各自对应的channel；如此hadoop102和hadoop103得到消息的不同部分，hadoop102和hadoop103打印日志显示结果</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) exec -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks &#x3D; k1 k2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; exec</span><br><span class="line">a1.sources.r1.command &#x3D; tail -F &#x2F;opt&#x2F;data&#x2F;test.log</span><br><span class="line"># 设置为复用</span><br><span class="line">a1.sources.r1.selector.type &#x3D; multiplexing</span><br><span class="line"># event(headers, body),根据headers中的key和value进行数据的发送</span><br><span class="line"># header指的是headers中的key值</span><br><span class="line">a1.sources.r1.selector.header &#x3D; state</span><br><span class="line"># mapping.x指的是value对应的值,&#x3D;y指的是分发到y channel</span><br><span class="line">a1.sources.r1.selector.mapping.CZ &#x3D; c1</span><br><span class="line">a1.sources.r1.selector.mapping.US &#x3D; c2</span><br><span class="line"></span><br><span class="line"># 设置拦截器,给event添加headers内容</span><br><span class="line">a1.sources.r1.interceptors &#x3D; i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type &#x3D; static</span><br><span class="line">a1.sources.r1.interceptors.i1.key &#x3D; state</span><br><span class="line">a1.sources.r1.interceptors.i1.value &#x3D; CZ</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c2.type &#x3D; memory</span><br><span class="line">a1.channels.c2.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line">a1.sinks.k2.type &#x3D; avro</span><br><span class="line">a1.sinks.k2.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k2.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k2.channel &#x3D; c2</span><br><span class="line"></span><br><span class="line"># hadoop102和hadoop103同复制案例</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>故障转移：</p>
<ul>
<li><p>案例需求：通过hadoop101监听本地文件的变化，将新增的内容打包成消息通过arvo sink发送给hadoop102。hadoop103是hadoop102的备份机，设置hadoop102的优先级大于hadoop103，如此在hadoop102正常时消息event都会发送给hadoop102；当hadoop102错误或宕机时，消息event会发送给hadoop103</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) exec -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1 k2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line">a1.sinks.k2.type &#x3D; avro</span><br><span class="line">a1.sinks.k2.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k2.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line"># 一个channel对应多个sink时要设置一个sinkgroups</span><br><span class="line">a1.sinkgroups &#x3D; g1</span><br><span class="line"># 该sink组有哪些sink实例</span><br><span class="line">a1.sinkgroups.g1.sinks &#x3D; k1 k2</span><br><span class="line"># 配置sinkProcessor类型：failover&#x2F;load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.type &#x3D; failover</span><br><span class="line"># 配置sink优先级(数值越大优先级越高)</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 &#x3D; 5</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 &#x3D; 10</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k2.channel &#x3D; c1</span><br><span class="line"></span><br><span class="line"># hadoop102和hadoop103同复制案例</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>负载均衡：</p>
<ul>
<li><p>案例需求：通过hadoop101监听44444端口，并把监听到的字符串打包成消息通过arvo sink发送给hadoop102和hadoop103。由于设置为负载均衡，故hadoop102和hadoop103都会得到消息event的一部分</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) netcat -&gt; memory -&gt; avro</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1 k2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line">a1.sinks.k2.type &#x3D; avro</span><br><span class="line">a1.sinks.k2.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k2.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sinkgroups &#x3D; g1</span><br><span class="line">a1.sinkgroups.g1.sinks &#x3D; k1 k2</span><br><span class="line">a1.sinkgroups.g1.processor.type &#x3D; load_balance</span><br><span class="line">a1.sinkgroups.g1.processor.selector &#x3D; round_robin</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k2.channel &#x3D; c1</span><br><span class="line"># hadoop102和hadoop103同复制案例</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>聚合：</p>
<ul>
<li><p>案例需求：hadoop101和hadoop102通过netcat各自监听本机的44444端口，并把监听到的字符串打包成event消息都发送给hadoop103；hadoop103显示到日志中</p>
</li>
<li><p>案例配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"># agent1(hadoop101) netcat -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line"># hostname是写出到哪台机器</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line"></span><br><span class="line"># agent1(hadoop102) netcat -&gt; memory -&gt; arvo</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop102</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line"># hostname是写出到哪台机器</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line"></span><br><span class="line"># agent1(hadoop103) avro -&gt; memory -&gt; logger</span><br><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; avro</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop103</span><br><span class="line">a1.sources.r1.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</li>
<li><p>自定义Interceptor：</p>
<ul>
<li><p>案例需求：使用hadoop101主机监听本地netcat，根据消息内容的不同(数字和字母开头)发往不同的主机(数字和字母分别发往hadoop102和hadoop103)</p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>Maven项目导入依赖：</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>编写自定义拦截器MyInterceptor——继承Flume的Interceptor，重写方法</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 自定义拦截器</span></span><br><span class="line"><span class="comment">* 作用：根据body中的内容在headers中添加指定的kv</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 初始化</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拦截单个消息</span></span><br><span class="line">  <span class="comment">// channelProcessor调用拦截器时会调用该方法并将event传过来为每个event中的header添加kv</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1、获取body中内容</span></span><br><span class="line">    <span class="keyword">byte</span>[] body = event.getBody();</span><br><span class="line">    <span class="comment">// 2、判断数据中内容</span></span><br><span class="line">    <span class="comment">// 判断内容是否为数字</span></span><br><span class="line">    <span class="keyword">if</span> (body[<span class="number">0</span>] &gt;= <span class="string">'0'</span> &amp;&amp; body[<span class="number">0</span>] &lt;= <span class="string">'9'</span>) &#123;</span><br><span class="line">      event.getHeaders().put(<span class="string">"type"</span>, <span class="string">"number"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((body[<span class="number">0</span>] &gt;= <span class="string">'A'</span> &amp;&amp; body[<span class="number">0</span>] &lt;= <span class="string">'Z'</span>) || (body[<span class="number">0</span>] &gt;= <span class="string">'a'</span> &amp;&amp; body[<span class="number">0</span>] &lt;= <span class="string">'z'</span>)) &#123;</span><br><span class="line">      event.getHeaders().put(<span class="string">"type"</span>, <span class="string">"letter"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> event;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拦截多个消息(batch)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从集合中遍历每个event</span></span><br><span class="line">    <span class="keyword">for</span> (Event event : list) &#123;</span><br><span class="line">      intercept(event);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 内部类(静态内部类)</span></span><br><span class="line"><span class="comment">  * 作用：返回MyInterceptor的实例</span></span><br><span class="line"><span class="comment">  * 注意：1、静态内部类 2、权限是public</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBuilder</span> <span class="keyword">implements</span> <span class="title">Interceptor</span>.<span class="title">Builder</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 返回一个interceptor接口实例</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> MyInterceptor(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Maven工程打包分发到服务器集群中flume的lib目录下</p>
</li>
<li><p>编写配置文件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks &#x3D; k1 k2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line">a1.sources.r1.selector.type &#x3D; multiplexing</span><br><span class="line">a1.sources.r1.selector.header &#x3D; type</span><br><span class="line">a1.sources.r1.selector.mapping.letter &#x3D; c1</span><br><span class="line">a1.sources.r1.selector.mapping.number &#x3D; c2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.interceptors &#x3D; i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type &#x3D; com.xiong.flume.MyInterceptor$MyBuilder</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line">a1.channels.c2.type &#x3D; memory</span><br><span class="line">a1.channels.c2.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; avro</span><br><span class="line">a1.sinks.k1.hostname &#x3D; hadoop102</span><br><span class="line">a1.sinks.k1.port &#x3D; 33333</span><br><span class="line">a1.sinks.k2.type &#x3D; avro</span><br><span class="line">a1.sinks.k2.hostname &#x3D; hadoop103</span><br><span class="line">a1.sinks.k2.port &#x3D; 33333</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1 c2</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br><span class="line">a1.sinks.k2.channel &#x3D; c2</span><br><span class="line"></span><br><span class="line"># hadoop102和hadoop103同复制案例</span><br></pre></td></tr></table></figure>
</li>
<li><p>前后在hadoop102、103和101上启动Flume进程，进行测试</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>自定义Source：</p>
<ul>
<li><p>案例需求：Source是负责接受数据到Flume Agent的组件。通过自定义Source发送随机数据(实际使用场景：读取MySQL数据或其他文件系统)</p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>Maven项目导入依赖：</p>
</li>
<li><p>编写自定义数据源MySource——继承Flume的AbstractSource类，实现Configurable和PollableSource接口</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 自定义source</span></span><br><span class="line"><span class="comment">* 需求：使用flume接受数据,并给每条数据添加前缀,输出到控制台。前缀可从flume配置文件中配置</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySource</span> <span class="keyword">extends</span> <span class="title">AbstractSource</span> <span class="keyword">implements</span> <span class="title">Configurable</span>, <span class="title">PollableSource</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String prefix;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 核心方法 - 获取数据并封装成event,将创建的event放入到channel中</span></span><br><span class="line"><span class="comment">  * 该方法会被循环调用</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> Status —— 一个枚举类,表示向ChannelProcessor中添加数据是否成功</span></span><br><span class="line"><span class="comment">  * READY：成功; BACKOFF：失败</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@throws</span> EventDeliveryException</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">      List&lt;Event&gt; events = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="comment">// 设置数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">      <span class="comment">// 创建event</span></span><br><span class="line">      SimpleEvent event = <span class="keyword">new</span> SimpleEvent();</span><br><span class="line">      event.setBody((prefix + UUID.randomUUID().toString().substring(<span class="number">0</span>, <span class="number">8</span>)).getBytes());</span><br><span class="line">      events.add(event);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 获取channelProcessor</span></span><br><span class="line">      ChannelProcessor channelProcessor = getChannelProcessor();</span><br><span class="line">      <span class="comment">// 将数据放入到channel中(ChannelProcessor)</span></span><br><span class="line">      <span class="comment">// channelProcessor.processEvent(event);</span></span><br><span class="line">      channelProcessor.processEventBatch(events);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">      <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status.READY;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 当source没数据可封装时,让source所在线程休息</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getBackOffSleepIncrement</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="number">2000L</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 当source没数据可封装时,让source所在线程休息的最大时间</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxBackOffSleepInterval</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="number">5000L</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取上下文,可以读取配置文件中内容</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">    prefix = context.getString(<span class="string">"prefix"</span>, <span class="string">"sobxiong"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Maven工程打包分发到服务器集群中flume的lib目录下</p>
</li>
<li><p>编写配置文件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line"># 自定义source</span><br><span class="line">a1.sources.r1.type &#x3D; com.xiong.flume.MySource</span><br><span class="line">a1.sources.r1.prefix &#x3D; sobxiong</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; logger</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动Flume进程，进行测试</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>自定义Sink</p>
<ul>
<li><p>案例需求：<br>Sink不断地轮询Channel中的事件且批量地移除它们，并将这些事件批量写入到存储、索引系统或者发送到另一个Flume Agent<br>Sink是完全事务性的。在Channel批量删除数据之前，每个Sink用Channel启动一个事务。批量事件一旦成功写出到存储系统或下一个Flume Agent，Sink就利用Channel提交事务。事务一旦被提交，该Channel从自己的内部缓冲区删除事件<br>本案例中只简单地将channel传来的数据进行打印(实际使用场景：读取Channel数据写入MySQL或其他文件系统)</p>
</li>
<li><p>实现步骤：</p>
<ol>
<li><p>Maven项目导入依赖：</p>
</li>
<li><p>编写自定义MySink——继承Flume的AbstractSink类，实现Configurable接口</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySink</span> <span class="keyword">extends</span> <span class="title">AbstractSink</span> <span class="keyword">implements</span> <span class="title">Configurable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String suffix;</span><br><span class="line">  <span class="comment">// 以日志方式输出</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(MySink<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 核心方法,用来处理sink逻辑(将channel中内容写出)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">    Status status = Status.BACKOFF;</span><br><span class="line">    <span class="comment">// 1、获取Channel</span></span><br><span class="line">    Channel channel = getChannel();</span><br><span class="line">    <span class="comment">// 2、从Channel中获取事务</span></span><br><span class="line">    Transaction transaction = channel.getTransaction();</span><br><span class="line">    <span class="comment">// 开启事务</span></span><br><span class="line">    transaction.begin();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 3、获取数据</span></span><br><span class="line">      Event event = channel.take();</span><br><span class="line">      <span class="comment">// 没有消息就阻塞等待</span></span><br><span class="line">      <span class="keyword">while</span> (event == <span class="keyword">null</span>) &#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">2</span>);</span><br><span class="line">        event = channel.take();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 4、将数据写出</span></span><br><span class="line">      logger.info(<span class="string">"headers: &#123;&#125; , body: &#123;&#125;"</span>, event.getHeaders(), <span class="keyword">new</span> String(event.getBody()) + suffix);</span><br><span class="line">      <span class="comment">// 5、提交事务</span></span><br><span class="line">      transaction.commit();</span><br><span class="line">      status = Status.READY;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">      <span class="comment">// 事务回滚</span></span><br><span class="line">      transaction.rollback();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      transaction.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 读取配置文件中内容</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">    suffix = context.getString(<span class="string">"suffix"</span>, <span class="string">" &gt; &gt; &gt; hello"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Maven工程打包分发到服务器集群中flume的lib目录下</p>
</li>
<li><p>编写配置文件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a1.sources &#x3D; r1</span><br><span class="line">a1.channels &#x3D; c1</span><br><span class="line">a1.sinks &#x3D; k1</span><br><span class="line"></span><br><span class="line"># 自定义source</span><br><span class="line">a1.sources.r1.type &#x3D; netcat</span><br><span class="line">a1.sources.r1.bind &#x3D; hadoop101</span><br><span class="line">a1.sources.r1.port &#x3D; 44444</span><br><span class="line"></span><br><span class="line">a1.channels.c1.type &#x3D; memory</span><br><span class="line">a1.channels.c1.capacity &#x3D; 1000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type &#x3D; com.xiong.flume.MySink</span><br><span class="line">a1.sinks.k1.subffix &#x3D; &gt; &gt; &gt; test</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels &#x3D; c1</span><br><span class="line">a1.sinks.k1.channel &#x3D; c1</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动Flume进程，进行测试</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="Flume知识点"><a href="#Flume知识点" class="headerlink" title="Flume知识点"></a>Flume知识点</h2><ol>
<li>如何实现Flume数据传输的监控：使用第三方框架Ganglia</li>
<li>Flume的Source，Sink，Channel的作用？<br>Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy<br>Channel组件对采集到的数据进行缓存，可以存放在Memory或File中<br>Sink组件是用于把数据发送到目的地的组件，目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义</li>
<li>Flume参数调优<ol>
<li>Source<br>增加Source个数(使用Tair Dir Source时可增加FileGroups个数)可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source以保证Source有足够的能力获取到新产生的数据<br>batchSize参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能</li>
<li>Channel<br>type选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差<br>使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能<br>Capacity参数决定Channel可容纳最大的event条数。transactionCapacity参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数<strong>transactionCapacity需要大于Source和Sink的batchSize参数</strong></li>
<li>Sink<br>增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好，够用就行，过多的Sink会占用系统资源，造成系统资源的浪费<br>batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能</li>
</ol>
</li>
<li>Flume的事务机制<br>Flume的事务机制(类似数据库的事务机制)：Flume使用两个独立的事务分别负责从Source到Channel以及从Channel到Sink的事件传递。比如spooling directory source为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Source就将该文件标记为完成。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递</li>
<li>Flume采集数据会丢失吗?<br>根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制。Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失。唯一可能丢失数据的情况是Channel采用memory channel，agent宕机导致数据丢失；或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失<br><strong>Flume不会丢失数据，但是有可能造成数据的重复。例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复</strong></li>
</ol>

          
            <div class='article_footer'>
              
                
  
    
    



  

  
    
    



  

  
    
    

<section class="widget copyright  desktop mobile">
  <div class='content'>
    
      <blockquote>
        
          
            <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

          
        
          
            <p>本文永久链接是：<a href=https://sobxiong.github.io/2020/10/09/BigData/Flume/>https://sobxiong.github.io/2020/10/09/BigData/Flume/</a></p>
          
        
      </blockquote>
    
  </div>
</section>

  

  
    
    

<section class="widget qrcode  desktop mobile">
  

  <div class='content article-entry'>
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
  </div>
</section>

  


              
            </div>
          
        </div>
        
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-10-22T23:05:23+08:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2020年10月22日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/BigData/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>BigData</p></a></div>


        
      
        
          

        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://sobxiong.github.io/2020/10/09/BigData/Flume/&title=Flume - SOBXiong的博客&summary=内容
Flume概述
Flume入门
Flume进阶
Flume知识点
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://sobxiong.github.io/2020/10/09/BigData/Flume/&title=Flume - SOBXiong的博客&summary=内容
Flume概述
Flume入门
Flume进阶
Flume知识点
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://sobxiong.github.io/2020/10/09/BigData/Flume/&title=Flume - SOBXiong的博客&summary=内容
Flume概述
Flume入门
Flume进阶
Flume知识点
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


        
        
          <div class="prev-next">
            
              <a class='prev' href='/2020/10/09/BasicSkill/Docker/'>
                <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>Docker</p>
                <p class='content'>内容
Docker简介
Docker安装
Docker常用命令
Docker镜像
Docker容器数据卷
Dockerfile
Docker安装步骤
Docker镜像发布



Docker简介...</p>
              </a>
            
            
              <a class='next' href='/2020/10/09/BasicSkill/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/'>
                <p class='title'>Linux常用命令<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
                <p class='content'>内容
top命令
free命令
df命令
vmstat命令
iostat命令



top命令
查看整机性能：top(主要cpu)
按数字1查看cpu各核心情况：
us user
sy syst...</p>
              </a>
            
          </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  <article class="post white-box reveal comments shadow">
    <section class="article typo">
      <p ct><i class='fas fa-comments'></i> 评论</p>
      
      
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
          </div>
        </section>
      
      
    </section>
  </article>


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: 'Flume',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
  

  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#内容"><span class="toc-text">内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume概述"><span class="toc-text">Flume概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume入门"><span class="toc-text">Flume入门</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume进阶"><span class="toc-text">Flume进阶</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume知识点"><span class="toc-text">Flume知识点</span></a></li></ol>
    </div>
  </section>


  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="mailto:1942991710@qq.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://github.com/SOBXiong"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        <div class='copyright'>
        <p><a href="http://xiongjc.top" target="_blank" rel="noopener">Copyright © 2017-2020 SOBXiong</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>





  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://cdn.jsdelivr.net/gh/xaoxuu/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  



  
    
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>

  
    
<script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>

  









  
    
<script src="https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js"></script>

  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var meta = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var REQUIRED_FIELDS = ['nick','mail','link'];
  var requiredFields = 'nick,mail'.split(',').filter(function(item){
    return REQUIRED_FIELDS.indexOf(item) > -1
  });
  var valine = new Valine();
  function emoji(path, idx, ext) {
      return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  valine.init({
    el: '#valine_container',
    meta: meta,
    
    appId: "dogUA2FSKGTo029M1SEwGROT-MdYXbMMI",
    appKey: "u0NdtQ8nvHoMdJPSYqm1LRxE",
    placeholder: "快来评论吧~",
    pageSize:'10',
    avatar:'robohash',
    lang:'zh-cn',
    visitor: 'true',
    highlight: 'true',
    mathJax: 'false',
    enableQQ: 'true',
    requiredFields: requiredFields,
    emojiCDN: 'https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/emoji/valine/',
    emojiMaps: emojiMaps
  })
  </script>





  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>






<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
