<!DOCTYPE html>
<html>
<head hexo-theme='https://volantis.js.org/#2.6.6'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
    <title>Kafka - SOBXiong的博客</title>
  
    <meta name="keywords" content="BigData">
  
  
    <meta name="description" content="内容
Kafka概述
Kafka快速入门
Kafka架构深入
Kafka_API
">
  

  <!-- feed -->
  

  <!-- import meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">

  

  
  <link rel="shortcut icon" type='image/x-icon' href="https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/favicon.png">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
  

  

  <!-- import link -->
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header shadow blur">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
            <i class='https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/favicon.png'></i>
          
          
            SOBXiong
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>



  <div class="l_body nocover">
    <div class='body-wrapper'>
      

<div class='l_main'>
  

  
    <article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h1 class="title">
    <a href="/2020/09/27/BigData/Kafka/">
      Kafka
    </a>
  </h1>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="http://xiongjc.top" target="_blank" rel="nofollow noopener">
    <img src="https://cdn.jsdelivr.net/gh/SOBXiong/imageBed/hdImg_f757fa7e0fd65077ce52d251fc7a01d815860762755.jpg">
    <p>SOBXiong</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/%E7%BC%96%E7%A8%8B/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>编程</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：2020年9月27日</p>
  </a>
</div>

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><ul>
<li><a href="#Kafka概述">Kafka概述</a></li>
<li><a href="#Kafka快速入门">Kafka快速入门</a></li>
<li><a href="#Kafka架构深入">Kafka架构深入</a></li>
<li><a href="#Kafka_API">Kafka_API</a></li>
</ul>
<a id="more"></a>

<h2 id="Kafka概述"><a href="#Kafka概述" class="headerlink" title="Kafka概述"></a>Kafka概述</h2><ul>
<li>消息队列(Message Queue)<ul>
<li>传统消息队列的应用场景<br><img src="%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BC%A0%E7%BB%9F%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.png" alt="消息队列传统异步处理应用场景"></li>
<li>消息队列的两种模式<ol>
<li>点对点模式(1对1,消费者主动拉取数据,消息收到后消息清除)<br>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费<br><img src="%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="点对点模式示意图"></li>
<li>发布/订阅模式(一对多,消费者消费数据之后不会清除消息)<br>消息生产者(发布)将消息发布到topic中，同时有多个消息消费者(订阅)消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费<br><img src="%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="发布订阅模式示意图"></li>
</ol>
</li>
</ul>
</li>
<li>Kafka定义：Kafka是一个分布式的基于发布/订阅模式的<strong>消息队列</strong>，主要应用于大数据实时处理领域</li>
<li>Kafka基础架构：<br><img src="Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="Kafka基础架构示意图"><ol>
<li><strong>Producer</strong>：消息生产者，就是向kafka broker发消息的客户端</li>
<li><strong>Consumer</strong>：消息消费者，向kafka broker取消息的客户端</li>
<li><strong>Consumer Group(CG)</strong>：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者</li>
<li><strong>Broker</strong>：一台kafka服务器就是一个broker，一个集群由多个broker组成，一个broker可以容纳多个topic</li>
<li><strong>Topic</strong>：可以理解为一个队列，<strong>生产者和消费者面向的都是一个topic</strong></li>
<li><strong>Partition</strong>：为了实现扩展性，一个非常大的topic可以分布到多个broker(即服务器)上，<strong>一个topic可以分为多个partition</strong>，每个partition是一个有序的队列</li>
<li><strong>Replica</strong>：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失且kafka仍然能够继续工作，<strong>kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower</strong></li>
<li><strong>leader</strong>：每个分区多个副本的”主”，生产者发送数据的对象以及消费者消费数据的对象都是leader</li>
<li><strong>follower</strong>：每个分区多个副本中的”从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader</li>
</ol>
</li>
</ul>
<h2 id="Kafka快速入门"><a href="#Kafka快速入门" class="headerlink" title="Kafka快速入门"></a>Kafka快速入门</h2><ul>
<li><p>安装部署</p>
<ul>
<li><p>集群规划：Hadoop101、hadoop102、hadoop103各自都运行zookeeper和kafka</p>
</li>
<li><p>安装包下载：<a href="http://kafka.apache.org/downloads" target="_blank" rel="noopener">http://kafka.apache.org/downloads</a></p>
</li>
<li><p>集群部署</p>
<ul>
<li><p>解压安装包：tar -zxvf kafka_2.12-2.6.0.tgz -C /opt/module</p>
</li>
<li><p>修改配置文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 需要修改的地方</span><br><span class="line"># broker(主机)的全局唯一编号,不能重复</span><br><span class="line">broker.id=x</span><br><span class="line"># 设置允许删除topic功能</span><br><span class="line">delete.topic.enable=true</span><br><span class="line"># 设置kafka运行日志存放地址</span><br><span class="line">log.dirs=/opt/module/kafka_2.12-2.6.0/logs</span><br><span class="line"># 配置链接zookeeper集群地址</span><br><span class="line">zookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量(vim + source)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># KAFKA_HOME</span><br><span class="line">export KAFKA_HOME=/opt/module/kafka_2.12-2.6.0</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发安装包(修改环境变量和配置文件的broker.id)：xsync kafka_2.12-2.6.0</p>
</li>
<li><p>启动集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 依次启动hadoop101、hadoop102、hadoop103的zookeeper</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 该命令hadoop101、hadoop102、hadoop103均需使用</span></span><br><span class="line">kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties</span><br></pre></td></tr></table></figure>
</li>
<li><p>kafka群起脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for i in `cat $HADOOP_HOME/etc/hadoop/workers`</span><br><span class="line">do</span><br><span class="line">echo "========== $i =========="</span><br><span class="line">ssh $i 'kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties'</span><br><span class="line">echo $?</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Kafka命令行操作(直接使用,不加参数可以查看用法)</p>
<ul>
<li><p>查看当前服务器中的所有topic：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper hadoop101:2181 --list</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建topic：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper hadoop101:2181 --create --replication-factor 3 --partitions 1 --topic first</span><br></pre></td></tr></table></figure>

<p>选项说明：</p>
<ol>
<li>–topic：定义topic名</li>
<li>–replication-factor：定义副本数</li>
<li>–partitions：定义分区数</li>
</ol>
</li>
<li><p>删除topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 需要server.properties中设置delete.topic.enable=<span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 否则只是标记删除</span></span><br><span class="line">kafka-topics.sh --zookeeper hadoop101:2181 --delete --topic first</span><br></pre></td></tr></table></figure>
</li>
<li><p>发送消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 出现 &gt; ,可输入消息字符</span></span><br><span class="line">kafka-console-producer.sh --broker-list hadoop101:9092 --topic first</span><br></pre></td></tr></table></figure>
</li>
<li><p>消费消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> --from-beginning会把topic以往所有的消息数据都取出来</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server hadoop101:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改分区数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper hadoop101:2181 --alter --topic first --partitions 6</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h2 id="Kafka架构深入"><a href="#Kafka架构深入" class="headerlink" title="Kafka架构深入"></a>Kafka架构深入</h2><ul>
<li><p>Kafka工作流程及文件存储机制<br><img src="Kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="Kafka工作流程示意图"></p>
<ol>
<li><p>topic<br>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的<br>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时从上次的位置继续消费</p>
</li>
<li><p>Kafka文件存储机制<br><img src="Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.png" alt="Kafka文件存储机制示意图"><br>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件——<strong>.index文件和.log文件</strong>。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称 + 分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。index和log文件以当前segment的第一条消息的offset命名</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>
</li>
<li><p>.index和.log文件详解<br><img src="index%E5%92%8Clog%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3.png" alt="index和log文件详解示意图"><br>.index文件存储大量的索引信息，.log文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址</p>
</li>
</ol>
</li>
<li><p>Kafka生产者</p>
<ul>
<li><p>分区策略</p>
<ul>
<li>分区原因<ol>
<li><strong>方便在集群中扩展</strong>，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以由多个Partition组成，因此整个集群就可以适应任意大小的数据了</li>
<li><strong>可以提高并发能力</strong>，因为可以以Partition为单位读写了</li>
</ol>
</li>
<li>分区原则：我们需要将producer发送的数据封装成一个ProducerRecord对象<br><img src="ProducerRecord%E5%AF%B9%E8%B1%A1%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0.png" alt="ProducerRecord对象构造函数"><ol>
<li>指明partition的情况下，直接将指明的值直接作为partiton值</li>
<li>没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值</li>
<li>既没有partition值又没有key值的情况下，第一次调用时随机生成一个整数(后面每次调用在这个整数上自增)，将这个值与topic可用的partition总数取余得到partition值，也就是常说的 round-robin(轮询)算法</li>
</ol>
</li>
</ul>
</li>
<li><p>数据可靠性保证<br>为保证producer发送的数据能可靠地发送到指定的topic，topic的每个partition收到producer发送的数据后都需要向producer发送ack(acknowledgement确认收到)，如果producer收到ack，就会进行下一轮的发送，否则重新发送数据<br><img src="ack%E7%A1%AE%E8%AE%A4%E4%BB%A5%E5%8F%8A%E9%87%8D%E5%8F%91.png" alt="ack确认以及重发"><br><img src="%E4%BD%95%E6%97%B6%E5%8F%91%E9%80%81ack.png" alt="何时发送ack"></p>
<ol>
<li><p>副本数据同步策略</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>半数以上完成同步,就发送ack</td>
<td>延迟低</td>
<td>选举新的leader时,容忍n台节点的故障,需要2n+1个副本</td>
</tr>
<tr>
<td>全部完成同步,才发送ack</td>
<td>选举新的leader时,容忍n台节点的故障,需要n+1个副本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p>Kafka选择了第二种方案，原因如下：</p>
<ol>
<li>同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小</li>
</ol>
</li>
<li><p>ISR<br>采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据。但有一个follower因为某种故障迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步才能发送ack。这个问题怎么解决呢？<br>Leader维护了一个动态的in-sync replica set(ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给producer发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，<strong>该时间阈值由replica.lag.time.max.ms参数设定</strong>。Leader发生故障之后，就会从ISR中选举新的leader</p>
</li>
<li><p>ack应答机制<br>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的acks参数配置：</p>
<ol>
<li>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能<strong>丢失数据</strong></li>
<li>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会<strong>丢失数据</strong><br><img src="ack=1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B%E7%A4%BA%E6%84%8F%E5%9B%BE1.png" alt="ack=1数据丢失案例示意图1"><br><img src="ack=1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B%E7%A4%BA%E6%84%8F%E5%9B%BE2.png" alt="ack=1数据丢失案例示意图2"></li>
<li>-1(all)：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成<strong>数据重复</strong><br><img src="ack=-1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B%E7%A4%BA%E6%84%8F%E5%9B%BE1.png" alt="ack=-1数据丢失案例示意图1"><br><img src="ack=-1%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%A1%88%E4%BE%8B%E7%A4%BA%E6%84%8F%E5%9B%BE2.png" alt="ack=-1数据丢失案例示意图2"></li>
</ol>
</li>
<li><p>故障处理细节<br> <img src="log%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84hw%E5%92%8Cleo.png" alt="log文件中的hw和leo"></p>
<ol>
<li>follower故障<br>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。<strong>等该follower的LEO大于等于该Partition的HW</strong>，即follower追上leader之后，就可以重新加入ISR了</li>
<li>leader故障<br>leader发生故障之后，会从ISR中选出一个新的leader。之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据<br>注意：<strong>这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复</strong></li>
</ol>
</li>
</ol>
</li>
<li><p>Exactly Once语义<br>将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义<br>At Least Once可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响<br>0.11版本的Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：At Least Once + 幂等性 = Exactly Once<br>要启用幂等性，只需要将Producer的参数中enable.idompotence设置为true即可。Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。<br>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once</p>
</li>
</ul>
</li>
<li><p>Kafka消费者</p>
<ul>
<li>消费方式<br>consumer采用pull(拉)模式从broker中读取数据<br><strong>push(推)模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的</strong>。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息<br><strong>pull模式的不足之处：如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据</strong>。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout</li>
<li>分区分配策略<br>一个consumer group中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题——即确定哪个partition由哪个consumer来消费<br>Kafka有两种分配策略：<ol>
<li>roundrobin：轮询<br><img src="roundrobin%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5.png" alt="roundrobin分配策略"></li>
<li>range：按顺序均分<br><img src="range%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5.png" alt="range分配策略"></li>
</ol>
</li>
<li>offset维护<br>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费<br>在0.9版本之前，consumer默认将offset保存在Zookeeper中；从0.9版本开始，<strong>consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets</strong></li>
</ul>
</li>
<li><p>Kafka高效读写数据</p>
<ol>
<li>顺序写磁盘<br>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到到600M/s，而随机写只有100k/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间</li>
<li><strong>应用Pagecache</strong><br>Kafka数据持久化是直接持久化到Pagecache中，这样会产生以下几个好处：<ol>
<li>I/O Scheduler会将连续的小块写组装成大块物理写从而提高性能</li>
<li>I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li>
<li>充分利用所有空闲内存(非JVM内存)。如果使用应用层Cache(即JVM堆内存)，会增加GC负担</li>
<li>读操作可直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘(直接通过Page Cache)交换数据</li>
<li>如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用<br>尽管持久化到Pagecache上可能会造成宕机丢失数据的情况，但这可以被Kafka的Replication机制解决。如果为了保证这种情况下数据不丢失而强制将Page Cache中的数据Flush到磁盘，反而会降低性能</li>
</ol>
</li>
<li>零复制(拷贝)技术<br><img src="%E5%B8%B8%E8%A7%84%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="常规数据持久化示意图"><br><img src="%E4%BC%98%E5%8C%96%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="优化的数据持久化示意图"></li>
</ol>
</li>
<li><p>Zookeeper在Kafka中的作用<br>Kafka集群中有一个broker会被选举为Controller，<strong>负责管理集群broker的上下线、所有topic的分区副本分配和leader选举等工作</strong><br>Controller的管理工作依赖于Zookeeper<br>以下为partition的leader选举过程：<br><img src="controller%E6%AD%A3%E5%B8%B8%E6%83%85%E5%86%B5%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="controller正常情况示意图"><br><img src="leader%E5%AE%95%E6%9C%BA%E6%83%85%E5%86%B5%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="leader宕机情况示意图"></p>
</li>
<li><p>Kafka事务<br>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败</p>
<ul>
<li>Producer事务<br>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID<br>为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行</li>
<li>Consumer事务(精准一次性消费)<br>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其是无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况<br>如果想完成Consumer端的精准一次性消费，那么需要kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将kafka的offset保存到支持事务的自定义介质中(比如mysql)</li>
</ul>
</li>
</ul>
<h2 id="Kafka-API"><a href="#Kafka-API" class="headerlink" title="Kafka_API"></a>Kafka_API</h2><ul>
<li><p>Producer API</p>
<ul>
<li><p>消息发送流程<br>Kafka的Producer发送消息采用的是<strong>异步发送</strong>的方式。在消息发送的过程中，涉及到了两个线程——<strong>main线程和Sender线程</strong>，以及<strong>一个线程共享变量RecordAccumulator</strong>。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker<br><img src="Kafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="Kafka消息发送流程示意图"><br>相关参数：<br><strong>batch.size</strong>：只有数据积累到batch.size之后，sender才会发送数据<br><strong>linger.ms</strong>：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据</p>
</li>
<li><p>发送API</p>
<ol>
<li><p>导入依赖：</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>编写测试代码</p>
<ul>
<li><p>异步发送</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ProducerConfig封装了一系列配置参数名的常量</span></span><br><span class="line"><span class="comment">// 1、实例化kafka集群</span></span><br><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">properties.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">properties.put(<span class="string">"acks"</span>, <span class="string">"all"</span>);</span><br><span class="line">properties.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop101:9092"</span>);</span><br><span class="line"><span class="comment">// 重试次数</span></span><br><span class="line">properties.put(<span class="string">"retries"</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// 批次大小</span></span><br><span class="line">properties.put(<span class="string">"batch.size"</span>, <span class="number">16384</span>);</span><br><span class="line"><span class="comment">// 等待时间</span></span><br><span class="line">properties.put(<span class="string">"linger.ms"</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// RecordAccumulator缓冲区大小</span></span><br><span class="line">properties.put(<span class="string">"buffer.memory"</span>, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// KafkaProducer,生产者对象,用来发送数据</span></span><br><span class="line">KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、用集群对象发送数据</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">  <span class="comment">// 封装ProducerRecord(发送的消息封装类)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 同步</span></span><br><span class="line">  <span class="comment">// producer.send(new ProducerRecord&lt;&gt;("test",Integer.toString(i),"value" + i);</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 异步</span></span><br><span class="line">  <span class="comment">// 回调函数会在producer收到ack时调用,为异步调用</span></span><br><span class="line">  <span class="comment">// 该方法有两个参数,分别是RecordMetadata和Exception;如果Exception为null,说明消息发送成功。如果Exception不为null,说明消息发送失败</span></span><br><span class="line">  <span class="comment">// 注意：消息发送失败会自动重试,不需要我们在回调函数中手动重试</span></span><br><span class="line">  producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(</span><br><span class="line">    <span class="string">"test"</span>,</span><br><span class="line">    Integer.toString(i),</span><br><span class="line">    <span class="string">"value"</span> + i</span><br><span class="line">  ), (metadata, exception) -&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == exception) System.out.println(<span class="string">"metadata = "</span> + metadata);</span><br><span class="line">    <span class="keyword">else</span> exception.printStackTrace();</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  System.out.println(<span class="string">"发送了第"</span> + i + <span class="string">"条"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3、关闭资源</span></span><br><span class="line">producer.close();</span><br></pre></td></tr></table></figure>
</li>
<li><p>同步发送</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 同步发送：一条消息发送之后,会阻塞当前线程直至返回ack</span></span><br><span class="line"><span class="comment">// 由于send()方法返回的是一个Future对象,根据Futrue对象的特点,也可实现同步发送效果,只需调用Future对象的get()方法即可</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">  producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"test"</span>, Integer.toString(i), Integer.toString(i))).get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li><p>Consumer API<br>Consumer消费数据时的可靠性是容易保证的，因为数据在Kafka中是持久化的，不用担心数据丢失问题。但由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需从故障前的位置继续消费，因此consumer需要实时记录消费到了哪个offset以便故障恢复后继续消费。offset的维护是Consumer消费数据必须考虑的问题</p>
<ul>
<li><p>提交offset</p>
<ol>
<li><p>导入依赖，同producer</p>
</li>
<li><p>编写测试代码</p>
<ul>
<li><p>自动提交offset</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ConsumerConfig封装了一系列配置参数名的常量</span></span><br><span class="line"><span class="comment">// 1、新建一个Consumer对象</span></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop101:9092"</span>);</span><br><span class="line">props.put(<span class="string">"group.id"</span>, <span class="string">"test"</span>);</span><br><span class="line"><span class="comment">// 是否开启自动提交offset</span></span><br><span class="line">props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line"><span class="comment">// 自动提交offset时间间隔</span></span><br><span class="line">props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line">props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"><span class="comment">// KafkaConsumer,消费者对象,用于消费数据</span></span><br><span class="line">KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、用这个对象接受消息</span></span><br><span class="line">consumer.subscribe(Collections.singleton(<span class="string">"first"</span>));</span><br><span class="line"><span class="comment">// 从订阅的话题中拉取数据</span></span><br><span class="line">ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">2</span>));</span><br><span class="line"><span class="comment">// 消费拉取的数据</span></span><br><span class="line"><span class="comment">// ConsumerRecord(接受的消息封装)</span></span><br><span class="line"><span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : consumerRecords) &#123;</span><br><span class="line">  System.out.println(<span class="string">"record = "</span> + record);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3、关闭Consumer</span></span><br><span class="line">consumer.close();</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动提交offset<br>虽然自动提交offset十分简洁便利，但由于是基于时间提交的，难以把握offset提交的时机。Kafka还提供了手动提交offset的API<br>手动提交offset的方法有两种：commitSync(同步提交)和commitAsync(异步提交)<br>两者相同点：<strong>将本次poll的一批数据最高的偏移量提交</strong><br>两者不同点：commitSync阻塞当前线程一直到提交成功，并且会自动失败重试(由不可控因素导致,也会出现提交失败)；commitAsync则没有失败重试机制，故有可能提交失败</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 同步提交offset</span></span><br><span class="line"><span class="comment">// 有失败重试机制,更加可靠</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">  <span class="comment">// 消费者拉取数据</span></span><br><span class="line">  ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">    System.out.printf(record);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 同步提交,当前线程会阻塞直到offset提交成功</span></span><br><span class="line">  consumer.commitSync();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 异步提交offset</span></span><br><span class="line"><span class="comment">// 比同步吞吐量高</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">  <span class="comment">// 消费者拉取数据</span></span><br><span class="line">  ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">    System.out.printf(record);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 异步提交</span></span><br><span class="line">  consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (exception != <span class="keyword">null</span>) &#123;</span><br><span class="line">        System.err.println(<span class="string">"Commit failed -&gt; "</span> + offsets);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</li>
<li><p>数据漏消费和重复消费分析<br>无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或重复消费。先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费<br><img src="%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E7%A4%BA%E6%84%8F%E5%9B%BE1.png" alt="数据重复消费示意图1"><br><img src="%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E7%A4%BA%E6%84%8F%E5%9B%BE2.png" alt="数据重复消费示意图2"></p>
</li>
</ul>
</li>
</ul>

          
            <div class='article_footer'>
              
                
  
    
    



  

  
    
    



  

  
    
    

<section class="widget copyright  desktop mobile">
  <div class='content'>
    
      <blockquote>
        
          
            <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

          
        
          
            <p>本文永久链接是：<a href=https://sobxiong.github.io/2020/09/27/BigData/Kafka/>https://sobxiong.github.io/2020/09/27/BigData/Kafka/</a></p>
          
        
      </blockquote>
    
  </div>
</section>

  

  
    
    

<section class="widget qrcode  desktop mobile">
  

  <div class='content article-entry'>
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
      
        <div class='fancybox'><img src='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/qrcode/wiki_volantis.png'
        
          height='64px'
        ></div>
      
    
  </div>
</section>

  


              
            </div>
          
        </div>
        
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-10-24T19:56:14+08:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：2020年10月24日</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/BigData/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>BigData</p></a></div>


        
      
        
          

        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer"
          
          href="http://connect.qq.com/widget/shareqq/index.html?url=https://sobxiong.github.io/2020/09/27/BigData/Kafka/&title=Kafka - SOBXiong的博客&summary=内容
Kafka概述
Kafka快速入门
Kafka架构深入
Kafka_API
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qq.png">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer"
          
          href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://sobxiong.github.io/2020/09/27/BigData/Kafka/&title=Kafka - SOBXiong的博客&summary=内容
Kafka概述
Kafka快速入门
Kafka架构深入
Kafka_API
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/qzone.png">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer"
          
          href="http://service.weibo.com/share/share.php?url=https://sobxiong.github.io/2020/09/27/BigData/Kafka/&title=Kafka - SOBXiong的博客&summary=内容
Kafka概述
Kafka快速入门
Kafka架构深入
Kafka_API
"
          
          >
          
            <img src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/logo/128/weibo.png">
          
        </a>
      
    
  </div>
</div>



        
      
    </div>
  </section>


        
        
          <div class="prev-next">
            
              <a class='prev' href='/2020/10/05/ProgrammingLanguage/Java/NIO/'>
                <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>NIO</p>
                <p class='content'>内容
NIO简介
缓冲区(Buffer)
通道(Channel)
选择器(Selector)
其他



NIO简介
NIO简介：Java NIO(New I0)是从Java 1.4版本开始引入...</p>
              </a>
            
            
              <a class='next' href='/2020/09/26/ProgrammingLanguage/Java/JVM/'>
                <p class='title'>JVM<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
                <p class='content'>内容
JVM体系结构概述
堆体系结构概述
堆参数调优



JVM体系结构概述
JVM位置：运行与操作系统之上(可以认为是一种中间件)，与硬件没有直接的交互

JVM结构

类装载器Class...</p>
              </a>
            
          </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  <article class="post white-box reveal comments shadow">
    <section class="article typo">
      <p ct><i class='fas fa-comments'></i> 评论</p>
      
      
      
      
      
      
        <section id="comments">
          <div id="valine_container" class="valine_thread">
            <i class="fas fa-cog fa-spin fa-fw fa-2x"></i>
          </div>
        </section>
      
      
    </section>
  </article>


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->



  <script>
    window.subData = {
      title: 'Kafka',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
  

  
    
    



  <section class="widget toc-wrapper shadow desktop mobile" id="toc-div" >
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#内容"><span class="toc-text">内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka概述"><span class="toc-text">Kafka概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka快速入门"><span class="toc-text">Kafka快速入门</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka架构深入"><span class="toc-text">Kafka架构深入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-API"><span class="toc-text">Kafka_API</span></a></li></ol>
    </div>
  </section>


  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="mailto:1942991710@qq.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
              <a href="https://github.com/SOBXiong"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
        </div>
      
    
      
        <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
      
    
      
        <div class='copyright'>
        <p><a href="http://xiongjc.top" target="_blank" rel="noopener">Copyright © 2017-2020 SOBXiong</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>





  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://cdn.jsdelivr.net/gh/xaoxuu/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  



  
    
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>

  
    
<script src="https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js"></script>

  









  
    
<script src="https://cdn.jsdelivr.net/npm/valine@1.4/dist/Valine.min.js"></script>

  
  <script>
  var GUEST_INFO = ['nick','mail','link'];
  var meta = 'nick,mail,link'.split(',').filter(function(item){
    return GUEST_INFO.indexOf(item) > -1
  });
  var REQUIRED_FIELDS = ['nick','mail','link'];
  var requiredFields = 'nick,mail'.split(',').filter(function(item){
    return REQUIRED_FIELDS.indexOf(item) > -1
  });
  var valine = new Valine();
  function emoji(path, idx, ext) {
      return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  valine.init({
    el: '#valine_container',
    meta: meta,
    
    appId: "dogUA2FSKGTo029M1SEwGROT-MdYXbMMI",
    appKey: "u0NdtQ8nvHoMdJPSYqm1LRxE",
    placeholder: "快来评论吧~",
    pageSize:'10',
    avatar:'robohash',
    lang:'zh-cn',
    visitor: 'true',
    highlight: 'true',
    mathJax: 'false',
    enableQQ: 'true',
    requiredFields: requiredFields,
    emojiCDN: 'https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/emoji/valine/',
    emojiMaps: emojiMaps
  })
  </script>





  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>






<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>





  <script>setLoadingBarProgress(100);</script>
</body>
</html>
